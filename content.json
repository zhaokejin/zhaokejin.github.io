{"meta":{"title":"小小冒险家的博客","subtitle":null,"description":"Spring Cloud、Docker、微服务架构、Cloud Native相关知识分享、小小冒险家的博客,毕业设计代做","author":"zhaokejin","url":"https://www.cicoding.cn"},"pages":[{"title":"文章分类","date":"2018-06-11T02:13:21.000Z","updated":"2022-09-19T12:33:11.830Z","comments":false,"path":"categories/index.html","permalink":"https://www.cicoding.cn/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-09-24T01:42:26.000Z","updated":"2022-09-19T12:33:11.833Z","comments":true,"path":"tags/index.html","permalink":"https://www.cicoding.cn/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2019-09-24T01:45:07.000Z","updated":"2023-06-20T14:28:12.649Z","comments":true,"path":"about/index.html","permalink":"https://www.cicoding.cn/about/index.html","excerpt":"","text":"小小冒险家7年+软件开发架构及管理经验，历任Java高级开发，目前从事架构相关工作。 目前的研究重心：Spring Cloud、Docker、Kubernetes，及其相关生态的技术，并总结项目落地过程中遇到的坑。 拥抱开源，多个项目开源在Github与Git@OSC上，欢迎Star、Follow。 GitHub：http://github.com/zhaokejin Gitee：http://gitee.com/zhaokejin 时光…2014年开始了代码的生涯！一去不回头。。。。 联系方式 QQ：210006540 邮箱：210006540@qq.com"}],"posts":[{"title":"微服务开中常用注解","slug":"microservice-annotation","date":"2023-07-17T02:24:05.000Z","updated":"2023-08-14T09:03:29.552Z","comments":false,"path":"micro-service/microservice-annotation/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice-annotation/","excerpt":"","text":"一、组件注册@SpringBootConfigurationSpringBootConfiguration 是 SpringBoot 项目的配置注解，这也是一个组合注解，SpringBootConfiguration 注解可以用 java 代码的形式实现 Spring 中 xml 配置文件配置的效果，并会将当前类内声明的一个或多个以 @Bean 注解标记的方法的实例纳入到 spring 容器中，并且实例名就是方法名。 SpringBootConfiguration 可以作为 Spring 标准中 @Configuration 注解的替代。SpringBoot 项目中推荐使用@SpringBootConfiguration 替代 @Configuration。 @Scope@Scope注解主要作用是调节Ioc容器中的作用域，在Spring IoC容器中主要有以下五种作用域：基本作用域：singleton(单例)、prototype(多例);Web 作用域(reqeust、session、globalsession)，自定义作用域。 @Scope注解是springIoc容器中的一个作用域，在 Spring IoC 容器中具有以下几种作用域：基本作用域singleton（单例）、prototype(多例)，Web 作用域（reqeust、session、globalsession），自定义作用域 singleton单例模式(默认):全局有且仅有一个实例 prototype原型模式:每次获取Bean的时候会有一个新的实例 request: request表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效 session :session作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效 global session : global session作用域类似于标准的HTTP Session作用域，不过它仅仅在基于portlet的web应用中才有意义 直接使用字符串容易出问题,spring有默认的参数: ConfigurableBeanFactory.SCOPE_PROTOTYPE，即“prototype” ConfigurableBeanFactory.SCOPE_SINGLETON，即“singleton” WebApplicationContext.SCOPE_REQUEST，即“request” WebApplicationContext.SCOPE_SESSION，即“session” 二、常用注解@SpringBootApplication12345678910111213141516@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Configuration@EnableAutoConfiguration@ComponentScanpublic @interface SpringBootApplication &#123; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;;&#125; 定义在main方法入口类处，用于启动sping boot应用项目 @EnableAutoConfiguration让spring boot根据类路径中的jar包依赖当前项目进行自动配置 在src/main/resources的META-INF/spring.factories 12345org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration若有多个自动配置，用“，”隔开 @ImportResource加载xml配置，一般是放在启动main类上 123@ImportResource(\"classpath*:/spring/*.xml\") 单个@ImportResource(&#123;\"classpath*:/spring/1.xml\",\"classpath*:/spring/2.xml\"&#125;) 多个 @Valueapplication.properties定义属性，直接使用@Value注入即可 1234public class A&#123; @Value(\"$&#123;push.start:0&#125;\") 如果缺失，默认值为0 private Long id;&#125; @ConfigurationProperties可以新建一个properties文件，ConfigurationProperties的属性prefix指定properties的配置的前缀，通过location指定properties文件的位置 123456@ConfigurationProperties(prefix=\"person\")public class PersonProperties &#123; private String name ; private int age;&#125; @EnableConfigurationProperties用 @EnableConfigurationProperties注解使 @ConfigurationProperties生效，并从IOC容器中获取bean。 https://blog.csdn.net/u010502101/article/details/78758330 @RestController组合@Controller和@ResponseBody，当你开发一个和页面交互数据的控制时，比如bbs-web的api接口需要此注解 @RequestMapping用来映射web请求(访问路径和参数)、处理类和方法，可以注解在类或方法上。注解在方法上的路径会继承注解在类上的路径。 produces属性: 定制返回的response的媒体类型和字符集，或需返回值是json对象 1@RequestMapping(value=\"/api2/copper\",produces=\"application/json;charset=UTF-8\",method = RequestMethod.POST) @RequestParam获取request请求的参数值 12345public List&lt;CopperVO&gt; getOpList(HttpServletRequest request, @RequestParam(value = \"pageIndex\", required = false) Integer pageIndex, @RequestParam(value = \"pageSize\", required = false) Integer pageSize) &#123; &#125; @ResponseBody支持将返回值放在response体内，而不是返回一个页面。比如Ajax接口，可以用此注解返回数据而不是页面。此注解可以放置在返回值前或方法前。 12345678910另一个玩法，可以不用@ResponseBody。继承FastJsonHttpMessageConverter类并对writeInternal方法扩展，在spring响应结果时，再次拦截、加工结果// stringResult: json返回结果//HttpOutputMessage outputMessage byte[] payload = stringResult.getBytes(); outputMessage.getHeaders().setContentType(META_TYPE); outputMessage.getHeaders().setContentLength(payload.length); outputMessage.getBody().write(payload); outputMessage.getBody().flush(); @Bean@Bean(name=”bean的名字”,initMethod=”初始化时调用方法名字”,destroyMethod=”close”) 定义在方法上，在容器内初始化一个bean实例类。 12345@Bean(destroyMethod=\"close\")@ConditionalOnMissingBeanpublic PersonService registryService() &#123; return new PersonService(); &#125; @Service用于标注业务层组件 @Controller用于标注控制层组件(如struts中的action) @Repository用于标注数据访问组件，即DAO组件 @Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @PostConstructspring容器初始化时，要执行该方法 123@PostConstruct public void init() &#123; &#125; @PathVariable用来获得请求url中的动态参数 12345678910111213@Controller public class TestController &#123; @RequestMapping(value=\"/user/&#123;userId&#125;/roles/&#123;roleId&#125;\",method = RequestMethod.GET) public String getLogin(@PathVariable(\"userId\") String userId, @PathVariable(\"roleId\") String roleId)&#123; System.out.println(\"User Id : \" + userId); System.out.println(\"Role Id : \" + roleId); return \"hello\"; &#125; &#125; @ComponentScan注解会告知Spring扫描指定的包来初始化Spring 1@ComponentScan(basePackages = \"com.bbs.xx\") @EnableZuulProxy路由网关的主要目的是为了让所有的微服务对外只有一个接口，我们只需访问一个网关地址，即可由网关将所有的请求代理到不同的服务中。Spring Cloud是通过Zuul来实现的，支持自动路由映射到在Eureka Server上注册的服务。Spring Cloud提供了注解@EnableZuulProxy来启用路由代理。 @Autowired在默认情况下使用 @Autowired 注释进行自动注入时，Spring 容器中匹配的候选 Bean 数目必须有且仅有一个。当找不到一个匹配的 Bean 时，Spring 容器将抛出 BeanCreationException 异常，并指出必须至少拥有一个匹配的 Bean。 当不能确定 Spring 容器中一定拥有某个类的 Bean 时，可以在需要自动注入该类 Bean 的地方可以使用 @Autowired(required = false)，这等于告诉 Spring: 在找不到匹配 Bean 时也不报错 @Autowired注解注入map、list与@Qualifier在新窗口打开 @Configuration12345678910111213@Configuration(\"name\")//表示这是一个配置信息类,可以给这个配置类也起一个名称@ComponentScan(\"spring4\")//类似于xml中的&lt;context:component-scan base-package=\"spring4\"/&gt;public class Config &#123; @Autowired//自动注入，如果容器中有多个符合的bean时，需要进一步明确 @Qualifier(\"compent\")//进一步指明注入bean名称为compent的bean private Compent compent; @Bean//类似于xml中的&lt;bean id=\"newbean\" class=\"spring4.Compent\"/&gt; public Compent newbean()&#123; return new Compent(); &#125; &#125; @Import导入Config1配置类里实例化的bean 1234567891011121314151617181920@Configurationpublic class CDConfig &#123; @Bean // 将SgtPeppers注册为 SpringContext中的bean public CompactDisc compactDisc() &#123; return new CompactDisc(); // CompactDisc类型的 &#125;&#125;@Configuration@Import(CDConfig.class) //导入CDConfig的配置public class CDPlayerConfig &#123; @Bean(name = \"cDPlayer\") public CDPlayer cdPlayer(CompactDisc compactDisc) &#123; // 这里会注入CompactDisc类型的bean // 这里注入的这个bean是CDConfig.class中的CompactDisc类型的那个bean return new CDPlayer(compactDisc); &#125;&#125; @Order@Order(1)，值越小优先级超高，越先运行 三、条件注解 如果注解指定的条件成立，则触发指定行为，条件注解列表: @ConditionalOnRepositoryType (org.springframework.boot.autoconfigure.data) @ConditionalOnDefaultWebSecurity (org.springframework.boot.autoconfigure.security) @ConditionalOnSingleCandidate (org.springframework.boot.autoconfigure.condition) @ConditionalOnWebApplication (org.springframework.boot.autoconfigure.condition) @ConditionalOnWarDeployment (org.springframework.boot.autoconfigure.condition) @ConditionalOnJndi (org.springframework.boot.autoconfigure.condition) @ConditionalOnResource (org.springframework.boot.autoconfigure.condition) @ConditionalOnExpression (org.springframework.boot.autoconfigure.condition) @ConditionalOnClass (org.springframework.boot.autoconfigure.condition) @ConditionalOnEnabledResourceChain (org.springframework.boot.autoconfigure.web) @ConditionalOnMissingClass (org.springframework.boot.autoconfigure.condition) @ConditionalOnNotWebApplication (org.springframework.boot.autoconfigure.condition) @ConditionalOnProperty (org.springframework.boot.autoconfigure.condition) @ConditionalOnCloudPlatform (org.springframework.boot.autoconfigure.condition) @ConditionalOnBean (org.springframework.boot.autoconfigure.condition) @ConditionalOnMissingBean (org.springframework.boot.autoconfigure.condition) @ConditionalOnMissingFilterBean (org.springframework.boot.autoconfigure.web.servlet) @Profile (org.springframework.context.annotation) @ConditionalOnInitializedRestarter (org.springframework.boot.devtools.restart) @ConditionalOnGraphQlSchema (org.springframework.boot.autoconfigure.graphql) @ConditionalOnJava (org.springframework.boot.autoconfigure.condition) @ConditionalOnMissingClass如果类路径中不存在这个类，则触发指定行为 @ConditionalOnBean如果容器中存在这个Bean（组件），则触发指定行为，@ConditionalOnBean（value=组件类型，name=组件名字）：判断容器中是否有这个类型的组件，并且名字是指定的值 @ConditionalOnMissingBean如果容器中不存在这个Bean（组件），则触发指定行为 场景： 如果存在FastsqlException这个类，给容器中放一个Cat组件，名cat01， 否则，就给容器中放一个Dog组件，名dog01 如果系统中有dog01这个组件，就给容器中放一个 User组件，名zhangsan 否则，就放一个User，名叫lisi @ConditionalOnProperty这个注解能够控制某个 @Configuration 是否生效。具体操作是通过其两个属性name以及havingValue来实现的，其中name用来从application.properties中读取某个属性值，如果该值为空，则返回false;如果值不为空，则将该值与havingValue指定的值进行比较，如果一样则返回true;否则返回false。如果返回值为false，则该configuration不生效；为true则生效。 https://blog.csdn.net/dalangzhonghangxing/article/details/78420057 @ConditionalOnClass如果类路径中存在这个类，则触发指定行为； 该注解的参数对应的类必须存在，否则不解析该注解修饰的配置类； 123456789101112@Configuration@ConditionalOnClass(&#123;Gson.class&#125;)public class GsonAutoConfiguration &#123; public GsonAutoConfiguration() &#123; &#125; @Bean @ConditionalOnMissingBean public Gson gson() &#123; return new Gson(); &#125;&#125; @ConditionalOnMisssingClass1@ConditionalOnMisssingClass(&#123;ApplicationManager.class&#125;) 如果存在它修饰的类的bean，则不需要再创建这个bean； @ConditionOnMissingBean1@ConditionOnMissingBean(name = &quot;example&quot;) 表示如果name为“example”的bean存在，该注解修饰的代码块不执行。 @ConditionalOnExpression12345678@Configuration@ConditionalOnExpression(\"$&#123;enabled:false&#125;\")public class BigpipeConfiguration &#123; @Bean public OrderMessageMonitor orderMessageMonitor(ConfigContext configContext) &#123; return new OrderMessageMonitor(configContext); &#125;&#125; 开关为true的时候才实例化bean 四、属性绑定@ConfigurationProperties 声明组件的属性和配置文件哪些前缀开始项进行绑定 @EnableConfigurationProperties快速注册注解： 场景： SpringBoot默认只扫描自己主程序所在的包。如果导入第三方包，即使组件上标注了 @Component、@ConfigurationProperties 注解，也没用。因为组件都扫描不进来，此时使用这个注解就可以快速进行属性绑定并把组件注册进容器 这个一点倒是很重要，SpringBoot默认扫描当前项目主程序包及其子包，再加上自动配置类，那么属性类是不会扫描到的，此时就算加上@Component注解也是没有任何用处，所以一般是在属性类上面使用 @ConfigurationProperties注解，而在相应的自动配置类上面使用@EnableConfigurationProperties注解，从而让属性类绑定生效 将容器中任意组件（Bean）的属性值和配置文件的配置项的值进行绑定 1、给容器中注册组件（@Component、@Bean) 2、使用 @ConfigurationProperties 声明组件和配置文件的哪些配置项进行绑定 五、缓存注解@EnableCaching开启缓存注解的支持 @Cacheable@Cacheable 注解表示方法的结果应该被缓存起来，下次调用该方法时，如果参数和之前相同，则返回缓存结果。 1234567@Servicepublic class MyService &#123; @Cacheable(\"greetingCache\") public String greeting(String name) &#123; return \"Hello, \" + name + \"!\"; &#125;&#125; @CachePut@CachePut 注解表示方法的结果应该被缓存起来，下次调用该方法时，不会返回缓存结果，而是重新计算结果并缓存起来。 1234567@Servicepublic class MyService &#123; @CachePut(\"greetingCache\") public String greeting(String name) &#123; return \"Hello, \" + name + \"!\"; &#125;&#125; @CacheEvict@CacheEvict 注解表示方法执行后从缓存中删除指定项。 123456@Servicepublic class MyService &#123; @CacheEvict(\"greetingCache\") public void clearGreetingCache() &#123; &#125;&#125; @CacheConfig@CacheConfig是结合@Cacheable使用的来设置过期时间的 @Caching@Caching 注解可以在一个方法或者类上同时指定多个Spring Cache相关的注解。其拥有三个属性：cacheable、put 和 evict，分别用于指定@Cacheable、@CachePut 和 @CacheEvict。对于一个数据变动，更新多个缓存的场景，可以通过 @Caching 来实现： 1234@Caching(cacheable = @Cacheable(cacheNames = &quot;caching&quot;, key = &quot;#age&quot;), evict = @CacheEvict(cacheNames = &quot;t4&quot;, key = &quot;#age&quot;))public String caching(int age) &#123; return &quot;caching: &quot; + age + &quot;--&gt;&quot; + UUID.randomUUID().toString();&#125; 参考： https://www.cnblogs.com/ziyue7575/p/c925cfe466df01c1d352f37da8823946.html https://pdai.tech/md/spring/springboot/springboot-x-hello-anno.html","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cicoding.cn/tags/SpringCloud/"},{"name":"annotation","slug":"annotation","permalink":"https://www.cicoding.cn/tags/annotation/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"Windows 11解决PowerShell因为在此系统上禁止运行脚本。有关详细信息","slug":"win11-PowerShell","date":"2022-09-19T10:31:31.000Z","updated":"2022-09-19T10:32:06.889Z","comments":false,"path":"other/win11-PowerShell/","link":"","permalink":"https://www.cicoding.cn/other/win11-PowerShell/","excerpt":"","text":"Intellij Idea、VScode 等开发工具自带程序终端的时候会报出”系统禁止脚本运行的错误”。 解决 管理员身份运行Windows PowerShell 执行：get-ExecutionPolicy，显示Restricted，表示状态是禁止的; 12Restricted 禁止的RemoteSigned 允许的 执行：set-ExecutionPolicy ​ 3.1 会提示输入参数：RemoteSigned，然后回车 ​ 3.2 或者直接输入 set-executionpolicy remotesigned 回车 这样就能使用了；","categories":[{"name":"PowerShell","slug":"PowerShell","permalink":"https://www.cicoding.cn/categories/PowerShell/"}],"tags":[{"name":"PowerShell","slug":"PowerShell","permalink":"https://www.cicoding.cn/tags/PowerShell/"},{"name":"Windows 11","slug":"Windows-11","permalink":"https://www.cicoding.cn/tags/Windows-11/"}],"keywords":[{"name":"PowerShell","slug":"PowerShell","permalink":"https://www.cicoding.cn/categories/PowerShell/"}]},{"title":"RocketMQ--消息幂等（去重）通用解决方案","slug":"rocketmq-message-dedup","date":"2022-05-19T15:01:02.000Z","updated":"2022-06-14T03:14:48.271Z","comments":false,"path":"rocketmq/rocketmq-message-dedup/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-message-dedup/","excerpt":"","text":"​ 消息中间件是分布式系统常用的组件，无论是异步化、解耦、削峰等都有广泛的应用价值。我们通常会认为，消息中间件是一个可靠的组件——这里所谓的可靠是指，只要我把消息成功投递到了消息中间件，消息就不会丢失，即消息肯定会至少保证消息能被消费者成功消费一次，这是消息中间件最基本的特性之一，也就是我们常说的“AT LEAST ONCE”，即消息至少会被“成功消费一遍”。 ​ 举个例子，一个消息M发送到了消息中间件，消息投递到了消费程序A，A接受到了消息，然后进行消费，但在消费到一半的时候程序重启了，这时候这个消息并没有标记为消费成功，这个消息还会继续投递给这个消费者，直到其消费成功了，消息中间件才会停止投递。 ​ 然而这种可靠的特性导致，消息可能被多次地投递。举个例子，还是刚刚这个例子，程序A接受到这个消息M并完成消费逻辑之后，正想通知消息中间件“我已经消费成功了”的时候，程序就重启了，那么对于消息中间件来说，这个消息并没有成功消费过，所以他还会继续投递。这时候对于应用程序A来说，看起来就是这个消息明明消费成功了，但是消息中间件还在重复投递。 ​ 这在RockectMQ的场景来看，就是同一个messageId的消息重复投递下来了。 ​ 基于消息的投递可靠（消息不丢）是优先级更高的，所以消息不重的任务就会转移到应用程序自我实现，这也是为什么RocketMQ的文档里强调的，消费逻辑需要自我实现幂等。背后的逻辑其实就是：不丢和不重是矛盾的（在分布式场景下），但消息重复是有解决方案的，而消息丢失是很麻烦的。 简单的消息去重解决方案例如：假设我们业务的消息消费逻辑是：插入某张订单表的数据，然后更新库存： 1insert into t_order values ..... update t_inv set count = count-1 where good_id = 'good123'; 要实现消息的幂等，我们可能会采取这样的方案： 1select * from t_order where order_no = 'order123' if(order != null) &#123; return ;//消息重复，直接返回 &#125; 这对于很多情况下，的确能起到不错的效果，但是在并发场景下，还是会有问题。 并发重复消息​ 假设这个消费的所有代码加起来需要1秒，有重复的消息在这1秒内（假设100毫秒）内到达（例如生产者快速重发，Broker重启等），那么很可能，上面去重代码里面会发现，数据依然是空的（因为上一条消息还没消费完，还没成功更新订单状态）， ​ 那么就会穿透掉检查的挡板，最后导致重复的消息消费逻辑进入到非幂等安全的业务代码中，从而引发重复消费的问题（如主键冲突抛出异常、库存被重复扣减而没释放等） 并发去重的解决方案之一要解决上面并发场景下的消息幂等问题，一个可取的方案是开启事务把select 改成 select for update语句，把记录进行锁定。 1select * from t_order where order_no = &apos;THIS_ORDER_NO&apos; for update //开启事务 if(order.status != null) &#123; return ;//消息重复，直接返回 &#125; ​ 但这样消费的逻辑会因为引入了事务包裹而导致整个消息消费可能变长，并发度下降。 当然还有其他更高级的解决方案，例如更新订单状态采取乐观锁，更新失败则消息重新消费之类的。但这需要针对具体业务场景做更复杂和细致的代码开发、库表设计，不在本文讨论的范围。 ​ 但无论是select for update， 还是乐观锁这种解决方案，实际上都是基于业务表本身做去重，这无疑增加了业务开发的复杂度， 一个业务系统里面很大部分的请求处理都是依赖MQ的，如果每个消费逻辑本身都需要基于业务本身而做去重/幂等的开发的话，这是繁琐的工作量。本文希望探索出一个通用的消息幂等处理的方法，从而抽象出一定的工具类用以适用各个业务场景。 Exactly Once​ 在消息中间件里，有一个投递语义的概念，而这个语义里有一个叫”Exactly Once”，即消息肯定会被成功消费，并且只会被消费一次。以下是阿里云里对Exactly Once的解释： Exactly-Once 是指发送到消息系统的消息只能被消费端处理且仅处理一次，即使生产端重试消息发送导致某消息重复投递，该消息在消费端也只被消费一次。 在我们业务消息幂等处理的领域内，可以认为业务消息的代码肯定会被执行，并且只被执行一次，那么我们可以认为是Exactly Once。 但这在分布式的场景下想找一个通用的方案几乎是不可能的。不过如果是针对基于数据库事务的消费逻辑，实际上是可行的。 基于关系数据库事务插入消息表假设我们业务的消息消费逻辑是：更新MySQL数据库的某张订单表的状态： 1update t_order set status = &apos;SUCCESS&apos; where order_no= &apos;order123&apos;; ​ 要实现Exaclty Once即这个消息只被消费一次（并且肯定要保证能消费一次），我们可以这样做：在这个数据库中增加一个消息消费记录表，把消息插入到这个表，并且把原来的订单更新和这个插入的动作放到同一个事务中一起提交，就能保证消息只会被消费一遍了。 开启事务 插入消息表（处理好主键冲突的问题） 更新订单表（原消费逻辑） 提交事务 说明： 这时候如果消息消费成功并且事务提交了，那么消息表就插入成功了，这时候就算RocketMQ还没有收到消费位点的更新再次投递，也会插入消息失败而视为已经消费过，后续就直接更新消费位点了。这保证我们消费代码只会执行一次。 如果事务提交之前服务挂了（例如重启），对于本地事务并没有执行所以订单没有更新，消息表也没插入成功；而对于RocketMQ服务端来说，消费位点也没更新，所以消息还会继续投递下来，投递下来发现这个消息插入消息表也是成功的，所以可以继续消费。这保证了消息不丢失。 ​ 事实上，阿里云ONS的EXACTLY-ONCE语义的实现上，就是类似这个方案基于数据库的事务特性实现的。更多详情可参考：https://help.aliyun.com/document_detail/102777.html 基于这种方式，的确这是有能力拓展到不同的应用场景，因为他的实现方案与具体业务本身无关——而是依赖一个消息表。 但是这里有它的局限性 消息的消费逻辑必须是依赖于关系型数据库事务。如果消费的消费过程中还涉及其他数据的修改，例如Redis这种不支持事务特性的数据源，则这些数据是不可回滚的。 数据库的数据必须是在一个库，跨库无法解决 注：业务上，消息表的设计不应该以消息ID作为标识，而应该以业务的业务主键作为标识更为合理，以应对生产者的重发。阿里云上的消息去重只是RocketMQ的messageId，在生产者因为某些原因手动重发（例如上游针对一个交易重复请求了）的场景下起不到去重/幂等的效果（因消息id不同）。 更复杂的业务场景​ 如上所述，这种方式Exactly Once语义的实现，实际上有很多局限性，这种局限性使得这个方案基本不具备广泛应用的价值。并且由于基于事务，可能导致锁表时间过长等性能问题。 例如我们以一个比较常见的一个订单申请的消息来举例，可能有以下几步（以下统称为步骤X）： 检查库存（RPC） 锁库存（RPC） 开启事务，插入订单表（MySQL） 调用某些其他下游服务（RPC） 更新订单状态 commit 事务（MySQL） ​ 这种情况下，我们如果采取消息表+本地事务的实现方式，消息消费过程中很多子过程是不支持回滚的，也就是说就算我们加了事务，实际上这背后的操作并不是原子性的。怎么说呢，就是说有可能第一条小在经历了第二步锁库存的时候，服务重启了，这时候实际上库存是已经在另外的服务里被锁定了，这并不能被回滚。当然消息还会再次投递下来，要保证消息能至少消费一遍，换句话说，锁库存的这个RPC接口本身依旧要支持“幂等”。 ​ 再者，如果在这个比较耗时的长链条场景下加入事务的包裹，将大大的降低系统的并发。所以通常情况下，我们处理这种场景的消息去重的方法还是会使用一开始说的业务自己实现去重逻辑的方式，如前面加select for update，或者使用乐观锁。 ​ 那我们有没有方法抽取出一个公共的解决方案，能兼顾去重、通用、高性能呢？ 拆解消息执行过程其中一个思路是把上面的几步，拆解成几个不同的子消息，例如： 库存系统消费A：检查库存并做锁库存，发送消息B给订单服务 订单系统消费消息B：插入订单表（MySQL），发送消息C给自己（下游系统）消费 下游系统消费消息C：处理部分逻辑，发送消息D给订单系统 订单系统消费消息D：更新订单状态 注：上述步骤需要保证本地事务和消息是一个事务的（至少是最终一致性的），这其中涉及到分布式事务消息相关的话题，不在本文论述。 可以看到这样的处理方法会使得每一步的操作都比较原子，而原子则意味着是小事务，小事务则意味着使用消息表+事务的方案显得可行。 然而，这太复杂了！这把一个本来连续的代码逻辑割裂成多个系统多次消息交互！那还不如业务代码层面上加锁实现呢。 更通用的解决方案上面消息表+本地事务的方案之所以有其局限性和并发的短板，究其根本是因为它依赖于关系型数据库的事务，且必须要把事务包裹于整个消息消费的环节。 如果我们能不依赖事务而实现消息的去重，那么方案就能推广到更复杂的场景例如：RPC、跨库等。 例如，我们依旧使用消息表，但是不依赖事务，而是针对消息表增加消费状态，是否可以解决问题呢？ 基于消息幂等表的非事务方案 ​ 以上是去事务化后的消息幂等方案的流程，可以看到，此方案是无事务的，而是针对消息表本身做了状态的区分：消费中、消费完成。只有消费完成的消息才会被幂等处理掉。而对于已有消费中的消息，后面重复的消息会触发延迟消费（在RocketMQ的场景下即发送到RETRY TOPIC），之所以触发延迟消费是为了控制并发场景下，第二条消息在第一条消息没完成的过程中，去控制消息不丢（如果直接幂等，那么会丢失消息（同一个消息id的话），因为上一条消息如果没有消费完成的时候，第二条消息你已经告诉broker成功了，那么第一条消息这时候失败broker也不会重新投递了） 上面的流程不再细说，后文有github源码的地址，读者可以参考源码的实现，这里我们回头看看我们一开始想解决的问题是否解决了： 消息已经消费成功了，第二条消息将被直接幂等处理掉（消费成功）。 并发场景下的消息，依旧能满足不会出现消息重复，即穿透幂等挡板的问题。 支持上游业务生产者重发的业务重复的消息幂等问题。 ​ 关于第一个问题已经很明显已经解决了，在此就不讨论了。 ​ 关于第二个问题是如何解决的？主要是依靠插入消息表的这个动作做控制的，假设我们用MySQL作为消息表的存储媒介（设置消息的唯一ID为主键），那么插入的动作只有一条消息会成功，后面的消息插入会由于主键冲突而失败，走向延迟消费的分支，然后后面延迟消费的时候就会变成上面第一个场景的问题。 ​ 关于第三个问题，只要我们设计去重的消息键让其支持业务的主键（例如订单号、请求流水号等），而不仅仅是messageId即可。所以也不是问题。 此方案是否有消息丢失的风险？​ 如果细心的读者可能会发现这里实际上是有逻辑漏洞的，问题出在上面聊到的个三问题中的第2个问题（并发场景），在并发场景下我们依赖于消息状态是做并发控制使得第2条消息重复的消息会不断延迟消费（重试）。但如果这时候第1条消息也由于一些异常原因（例如机器重启了、外部异常导致消费失败）没有成功消费成功呢？也就是说这时候延迟消费实际上每次下来看到的都是消费中的状态，最后消费就会被视为消费失败而被投递到死信Topic中（RocketMQ默认可以重复消费16次）。 ​ 有这种顾虑是正确的！对于此，我们解决的方法是，插入的消息表必须要带一个最长消费过期时间，例如10分钟，意思是如果一个消息处于消费中超过10分钟，就需要从消息表中删除（需要程序自行实现）。所以最后这个消息的流程会是这样的： 更灵活的消息表存储媒介我们这个方案实际上没有事务的，只需要一个存储的中心媒介，那么自然我们可以选择更灵活的存储媒介，例如Redis。使用Redis有两个好处： 性能上损耗更低 上面我们讲到的超时时间可以直接利用Redis本身的ttl实现 当然Redis存储的数据可靠性、一致性等方面是不如MySQL的，需要用户自己取舍。 源码：RocketMQDedupListener以上方案针对RocketMQ的Java实现已经开源放到Github中，具体的使用文档可以参考https://github.com/Jaskey/RocketMQDedupListener ， 以下仅贴一个Readme中利用Redis去重的使用样例，用以意业务中如果使用此工具加入消息去重幂等的是多么简单： 1//利用Redis做幂等表 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;TEST-APP1&quot;); consumer.subscribe(&quot;TEST-TOPIC&quot;, &quot;*&quot;); String appName = consumer.getConsumerGroup();// 大部分情况下可直接使用consumer group名 StringRedisTemplate stringRedisTemplate = null;// 这里省略获取StringRedisTemplate的过程 DedupConfig dedupConfig = DedupConfig.enableDedupConsumeConfig(appName, stringRedisTemplate); DedupConcurrentListener messageListener = new SampleListener(dedupConfig); consumer.registerMessageListener(messageListener); consumer.start(); ​ 以上代码大部分是原始RocketMQ的必须代码，唯一需要修改的仅仅是创建一个DedupConcurrentListener示例，在这个示例中指明你的消费逻辑和去重的业务键（默认是messageId）。 更多使用详情请参考Github上的说明。 这种实现是否一劳永逸？​ 实现到这里，似乎方案挺完美的，所有的消息都能快速的接入去重，且与具体业务实现也完全解耦。那么这样是否就完美的完成去重的所有任务呢？ 很可惜，其实不是的。原因很简单：因为要保证消息至少被成功消费一遍，那么消息就有机会消费到一半的时候失败触发消息重试的可能。还是以上面的订单流程X： 检查库存（RPC） 锁库存（RPC） 开启事务，插入订单表（MySQL） 调用某些其他下游服务（RPC） 更新订单状态 commit 事务（MySQL） 当消息消费到步骤3的时候，我们假设MySQL异常导致失败了，触发消息重试。因为在重试前我们会删除幂等表的记录，所以消息重试的时候就会重新进入消费代码，那么步骤1和步骤2就会重新再执行一遍。如果步骤2本身不是幂等的，那么这个业务消息消费依旧没有做好完整的幂等处理。 本实现方式的价值？​ 那么既然这个并不能完整的完成消息幂等，还有什么价值呢？价值可就大了！虽然这不是解决消息幂等的银弹（事实上，软件工程领域里基本没有银弹），但是他能以便捷的手段解决： 1.各种由于Broker、负载均衡等原因导致的消息重投递的重复问题 2.各种上游生产者导致的业务级别消息重复问题 3.重复消息并发消费的控制窗口问题，就算重复，重复也不可能同一时间进入消费逻辑 一些其他的消息去重的建议​ 也就是说，使用这个方法能保证正常的消费逻辑场景下（无异常，无异常退出），消息的幂等工作全部都能解决，无论是业务重复，还是rocketmq特性带来的重复。 事实上，这已经能解决99%的消息重复问题了，毕竟异常的场景肯定是少数的。那么如果希望异常场景下也能处理好幂等的问题，可以做以下工作降低问题率： 消息消费失败做好回滚处理。如果消息消费失败本身是带回滚机制的，那么消息重试自然就没有副作用了。 消费者做好优雅退出处理。这是为了尽可能避免消息消费到一半程序退出导致的消息重试。 一些无法做到幂等的操作，至少要做到终止消费并告警。例如锁库存的操作，如果统一的业务流水锁成功了一次库存，再触发锁库存，如果做不到幂等的处理，至少要做到消息消费触发异常（例如主键冲突导致消费异常等） 在#3做好的前提下，做好消息的消费监控，发现消息重试不断失败的时候，手动做好#1的回滚，使得下次重试消费成功。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"RocketMQ--消息文件过期原理","slug":"rocketmq-clean-commitlog","date":"2022-05-19T14:26:00.000Z","updated":"2022-06-14T03:10:22.747Z","comments":false,"path":"rocketmq/rocketmq-clean-commitlog/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-clean-commitlog/","excerpt":"","text":"RocketMQ——消息ACK机制及消费进度管理 文中提过，所有的消费均是客户端发起Pull请求的，告诉消息的offset位置，broker去查询并返回。但是有一点需要非常明确的是，消息消费后，消息其实并没有物理地被清除，这是一个非常特殊的设计。本文来探索此设计的一些细节。 消费完后的消息去哪里了？消息的存储是一直存在于CommitLog中的。而由于CommitLog是以文件为单位（而非消息）存在的，CommitLog的设计是只允许顺序写的，且每个消息大小不定长，所以这决定了消息文件几乎不可能按照消息为单位删除（否则性能会极具下降，逻辑也非常复杂）。所以消息被消费了，消息所占据的物理空间并不会立刻被回收。 但消息既然一直没有删除，那RocketMQ怎么知道应该投递过的消息就不再投递？——答案是客户端自身维护——客户端拉取完消息之后，在响应体中，broker会返回下一次应该拉取的位置，PushConsumer通过这一个位置，更新自己下一次的pull请求。这样就保证了正常情况下，消息只会被投递一次。 什么时候清理物理消息文件？那消息文件到底删不删，什么时候删？ 消息存储在CommitLog之后，的确是会被清理的，但是这个清理只会在以下任一条件成立才会批量删除消息文件（CommitLog）： 消息文件过期（默认72小时），且到达清理时点（默认是凌晨4点），删除过期文件。 消息文件过期（默认72小时），且磁盘空间达到了水位线（默认75%），删除过期文件。 磁盘已经达到必须释放的上限（85%水位线）的时候，则开始批量清理文件（无论是否过期），直到空间充足。 注：若磁盘空间达到危险水位线（默认90%），出于保护自身的目的，broker会拒绝写入服务。 这样设计带来的好处消息的物理文件一直存在，消费逻辑只是听客户端的决定而搜索出对应消息进行，这样做，笔者认为，有以下几个好处： 一个消息很可能需要被N个消费组（设计上很可能就是系统）消费，但消息只需要存储一份，消费进度单独记录即可。这给强大的消息堆积能力提供了很好的支持——一个消息无需复制N份，就可服务N个消费组。 由于消费从哪里消费的决定权一直都是客户端决定，所以只要消息还在，就可以消费到，这使得RocketMQ可以支持其他传统消息中间件不支持的回溯消费。即我可以通过设置消费进度回溯，就可以让我的消费组重新像放快照一样消费历史消息；或者我需要另一个系统也复制历史的数据，只需要另起一个消费组从头消费即可（前提是消息文件还存在）。 消息索引服务。只要消息还存在就能被搜索出来。所以可以依靠消息的索引搜索出消息的各种原信息，方便事后排查问题。 注：在消息清理的时候，由于消息文件默认是1GB，所以在清理的时候其实是在删除一个大文件操作，这对于IO的压力是非常大的，这时候如果有消息写入，写入的耗时会明显变高。这个现象可以在凌晨4点（默认删时间时点）后的附近观察得到。 RocketMQ官方建议Linux下文件系统改为Ext4，对于文件删除操作相比Ext3有非常明显的提升。 跳过历史消息的处理由于消息本身是没有过期的概念，只有文件才有过期的概念。那么对于很多业务场景——一个消息如果太老，是无需要被消费的，是不合适的。 这种需要跳过历史消息的场景，在RocketMQ要怎么实现呢？ 对于一个全新的消费组，PushConsumer默认就是跳过以前的消息而从最尾开始消费的，解析请参看RocketMQ——消息ACK机制及消费进度管理相关章节。 但对于已存在的消费组，RocketMQ没有内置的跳过历史消息的实现，但有以下手段可以解决： 自身的消费代码按照日期过滤，太老的消息直接过滤。如： 123456789101112@Overridepublic ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; for(MessageExt msg: msgs)&#123; if(System.currentTimeMillis()-msg.getBornTimestamp()&gt;60*1000) &#123;//一分钟之前的认为过期 continue;//过期消息跳过 &#125; //do consume here &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;&#125; 自身的消费代码代码判断消息的offset和MAX_OFFSET相差很远，认为是积压了很多，直接return CONSUME_SUCCESS过滤。 12345678910111213@Overridepublic ConsumeConcurrentlyStatus consumeMessage(// List&lt;MessageExt&gt; msgs, // ConsumeConcurrentlyContext context) &#123; long offset = msgs.get(0).getQueueOffset(); String maxOffset = msgs.get(0).getProperty(MessageConst.PROPERTY_MAX_OFFSET); long diff = Long. parseLong(maxOffset) - offset; if (diff &gt; 100000) &#123; //消息堆积了10W情况的特殊处理 return ConsumeConcurrentlyStatus. CONSUME_SUCCESS; &#125; //do consume here return ConsumeConcurrentlyStatus. CONSUME_SUCCESS;&#125; 消费者启动前，先调整该消费组的消费进度，再开始消费。可以人工使用控制台命令resetOffsetByTime把消费进度调整到后面，再启动消费。 原理同3，但使用代码来控制。代码中调用内部的运维接口，具体代码实例祥见ResetOffsetByTimeCommand.java","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"Nacos介绍与安装启动","slug":"nacos-installation-and-startup","date":"2021-07-15T12:50:15.000Z","updated":"2022-09-17T14:13:56.142Z","comments":false,"path":"alibaba/nacos-installation-and-startup/","link":"","permalink":"https://www.cicoding.cn/alibaba/nacos-installation-and-startup/","excerpt":"","text":"什么是 Nacos概览欢迎来到 Nacos 的世界！ Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 什么是 Nacos？服务（Service）是 Nacos 世界的一等公民。Nacos 支持几乎所有主流类型的“服务”的发现、配置和管理： Kubernetes Service gRPC &amp; Dubbo RPC Service Spring Cloud RESTful Service Nacos 的关键特性包括: 服务发现和服务健康监测 动态配置服务 动态 DNS 服务 服务及其元数据管理 Nacos 快速开始这个快速开始手册是帮忙您快速在您的电脑上，下载、安装并使用 Nacos。 0.版本选择您可以在Nacos的release notes及博客中找到每个版本支持的功能的介绍，当前推荐的稳定版本为1.4.2或2.0.1。 1.预备环境准备Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+；下载 &amp; 配置。 Maven 3.2.x+；下载 &amp; 配置。 下载编译后压缩包方式您可以从 最新稳定版本 下载 nacos-server-$version.zip 包。 解压nacos-server-1.4.2.zip Windows启动命令(standalone代表着单机模式运行，非集群模式): 12$ cd bin/$ startup.cmd -m standalone 单机模式支持mysql在0.7版本之前，在单机模式时nacos使用嵌入式数据库实现数据的存储，不方便观察数据存储的基本情况。0.7版本增加了支持mysql数据源能力，具体的操作步骤： 1.安装数据库，版本要求：5.6.5+ 2.初始化mysql数据库，数据库初始化文件：nacos-mysql.sql 3.修改conf/application.properties文件，增加支持mysql数据源配置（目前只支持mysql），添加mysql数据源的url、用户名和密码。 12345678910111213#*************** Config Module Related Configurations ***************#### If use MySQL as datasource:spring.datasource.platform=mysql### Count of DB:# 数据库实例数量db.num=1# 数据库连接信息，如果是 MySQL 8.0+ 版本需要添加 serverTimezone=Asia/Shanghai### Connect URL of DB:db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTC&amp;allowPublicKeyRetrieval=truedb.user=rootdb.password=root 配置好数据库然后重启nacos如下: 访问ip:8848/nacoshttp://192.168.2.159:8848/nacos/index.html 输入用户名 nacos 密码 nacos 这样就启动配置成功!","categories":[{"name":"SpringCloud Alibaba","slug":"SpringCloud-Alibaba","permalink":"https://www.cicoding.cn/categories/SpringCloud-Alibaba/"}],"tags":[{"name":"SpringCloud Alibaba","slug":"SpringCloud-Alibaba","permalink":"https://www.cicoding.cn/tags/SpringCloud-Alibaba/"}],"keywords":[{"name":"SpringCloud Alibaba","slug":"SpringCloud-Alibaba","permalink":"https://www.cicoding.cn/categories/SpringCloud-Alibaba/"}]},{"title":"MySQL各存储引擎","slug":"mysql-storage-engines","date":"2021-06-28T13:27:35.000Z","updated":"2022-09-17T14:13:56.163Z","comments":true,"path":"mysql/mysql-storage-engines/","link":"","permalink":"https://www.cicoding.cn/mysql/mysql-storage-engines/","excerpt":"","text":"MySQL中的数据用各种不同的技术存储在文件（或者内存）中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。这些不同的技术以及配套的相关功能在MySQL中被称作存储引擎(也称作表类型)。MySQL默认配置了许多不同的存储引擎，可以预先设置或者在MySQL服务器中启用。你可以选择适用于服务器、数据库和表格的存储引擎，以便在选择如何存储你的信息、如何检索这些信息以及你需要你的数据结合什么性能和功能的时候为你提供最大的灵活性。使用以下命令可以查看MySQL支持的引擎： 1mysql&gt; show engines; 一、InnoDB存储引擎InnoDB是MySQL的默认事务型引擎，也是最重要、使用最广泛的存储引擎。它被设计 用来处理大量的短期(short-lived)事务，短期事务大部分情况是正常提交的，很少会被回滚。InnoDB的性能和自动崩溃恢复特性，使得它在非事务型存储的需求中也很流 行。除非有非常特别的原因需要使用其他的存储引擎，否则应该优先考虑InnoDB引擎。 □D＞如果要学习存储引擎，InnoDB也是一个非常好的值得花最多的时间去深入学习的对象， 收益肯定比将时间平均花在每个存储引擎的学习上要高得多。 InnoDB的历史InnoDB有着复杂的发布历史，了解一下这段历史对于理解InnoDB很有帮助。2008年， 发布了所谓的InnoDB plugin,适用于MySQL 5.1版本，但这是Oracle创建的下一代 InnoDB引擎，其拥有者是InnoDB而不是MySQL。这基于很多原因，这些原因如果要一一道来，恐怕得喝掉好几桶啤酒。MySQL默认还是选择了集成旧的InnoDB引擎。当 然用户可以自行选择使用新的性能更好、扩展性更佳的InnoDB plugin来覆盖旧的版本。 直到最后，在Oracle收购了 Sun公司后发布的MySQL 5.5中才彻底使用InnoDB plugin 替代了旧版本的InnoDB (是的，这也意味着InnoDB plugin已经是原生编译了，而不是编译成一个插件，但名字已经约定俗成很难更改)。 这个现代的InnoDB版本，也就是MySQL 5.1中所谓的InnoDB plugin,支持一些新特性， 诸如利用排序创建索引(building index by sorting)、删除或者增加索引时不需要复制全表数据、新的支持压缩的存储格式、新的大型列值如BLOB的存储方式，以及文件格式管 理等。很多用户在MySQL 5.1中没有使用InnoDB plugin,或许是因为他们没有注意到有这个区别。所以如果你使用的是MySQL 5.1, 一定要使用InnoDB plugin,真的比旧版本的InnoDB要好很多。 InnoDB是一个很重要的存储引擎，很多个人和公司都对其贡献代码，而不仅仅是 Oracle公司的开发团队。一些重要的贡献者包括Google、Yasufumi Kinoshita、Percona,、Facebook等，他们的一些改进被直接移植到官方版本，也有一些由InnoDB团队重新实现。 在过去的几年间，InnoDB的改进速度大大加快，主要的改进集中在可测量性、可扩展性、 可配置化、性能、各种新特性和对Windows的支持等方面。MySQL 5.6实验室预览版 和里程碑版也包含了一系列重要的InnoDB新特性。 为改善InnoDB的性能，Oracle投入了大量的资源，并做了很多卓有成效的工作(外部贡献者对此也提供了很大的帮助)。在本书的第二版中，我们注意到在超过四核CPU的系统中InnoDB表现不佳，而现在已经可以很好地扩展至24核的系统，甚至在某些场景， 32核或者更多核的系统中也表现良好。很多改进将在即将发布的MySQL 5.6中引入， 当然也还有机会做更进一步的改善。 InnoDB概览InnoDB的数据存储在表空间(tablespace)中，表空间是由InnoDB管理的一个黑盒子， 由一系列的数据文件组成。在MySQL 4.1以后的版本中，InnoDB可以将每个表的数据 和索引存放在单独的文件中。InnoDB也可以使用裸设备作为表空间的存储介质，但现代的文件系统使得裸设备不再是必要的选择。 InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别。其默认级别是 REPEATABLE READ (可重复读)，并且通过间隙锁(next-key locking)策略防止幻读的出现。 间隙锁使得InnoDB不仅仅锁定査询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。 - InnoDB表是基于聚簇索引建立的，我们会在后面的章节详细讨论聚簇索引。IimoDB的 索引结构和MySQL的其他存储引擎有很大的不同，聚簇索引对主键査询有很髙的性能。 不过它的二级索引(secondary index,非主键索引)中必须包含主键列，所以如果主键 列很大的话，其他的所有索引都会很大。因此，若表上的索引较多的话，主键应当尽可 能的小。InnoDB的存储格式是平台独立的，也就是说可以将数据和索引文件从Intel平 台复制到PowerPC或者Sun SPARC平台。 InnoDB内部做了很多优化，包括从磁盘读取数据时釆用的可预测性预读，能够自动在 内存中创建hash索引以加速读操作的自适应哈希索引(adaptive hash index),以及能够 加速插入操作的插入缓冲区(insert buffer)等。本书后面将更详细地讨论这些内容。 InnoDB的行为是非常复杂的，不容易理解。如果使用了 InnoDB引擎，笔者强烈建议阅 读官方手册中的”InnoDB事务模型和锁” 一节。如果应用程序基于InnoDB构建，则事 先了解一下InnoDB的MVCC架构带来的一些微妙和细节之处是非常有必要的。存储引 擎要为所有用户甚至包括修改数据的用户维持一致性的视图，是非常复杂的工作。 作为事务型的存储引擎，InnoDB通过一些机制和工具支持真正的热备份，Oracle提供 的MySQL Enterprise Backup. Percona提供的开源的XtraBackup都可以做到这一点。 MySQL的其他存储引擎不支持热备份，要获取一致性视图需要停止对所有表的写入， 而在读写混合场景中，停止写入可能也意味着停止读取。 MylSAM存储引擎在MySQL 5.1及之前的版本，MylSAM是默认的存储引擎。MylSAM提供了大量的特 性，包括全文索引、压缩、空间函数(GIS)等，但MylSAM不支持事务和行级锁，而且有一个毫无疑问的缺陷就是崩溃后无法安全恢复。正是由于MylSAM引擎的缘故，即 使MySQL支持事务已经很长时间了，在很多人的概念中MySQL还是非事务型的数据 库。尽管MylSAM引擎不支持事务、不支持崩溃后的安全恢复，但它绝不是一无是处的。对于只读的数据，或者表比较小、可以忍受修复（repair）操作，则依然可以继续使 用MylSAM （但请不要默认使用MylSAM,而是应当默认使用InnoDB）。 存储MylSAM会将表存储在两个文件中：数据文件和索引文件，分别以.MYD和.MYI为扩展名。MylSAM表可以包含动态或者静态（长度固定）行。MySQL会根据表的定义来 决定采用何种行格式。MylSAM表可以存储的行记录数，一般受限于可用的磁盘空间， 或者操作系统中单个文件的最大尺寸。 在MySQL 5.0中，MylSAM表如果是变长行，则默认配置只能处理256TB的数据，因 .为指向数据记录的指针长度是6个字节。而在更早的版本中，指针长度默认是4字节，所以只能处理4GB的数据。而所有的MySQL版本都支持8字节的指针。要改变 MylSAM表指针的长度（调高或者调低），可以通过修改表的MAX_R0WS和AVG_R0W_ LENGTH选项的值来实现，两者相乘就是表可能达到的最大大小。修改这两个参数会导致 重建整个表和表的所有索引，这可能需要很长的时间才能完成。 MylSAM特性作为MySQL最早的存储引擎之一，MylSAM有一些已经开发出来很多年的特性，可以 满足用户的实际需求。 加锁与并发MylSAM对整张表加锁，而不是针对行。读取时会对需要读到的所有表加共享锁， 写入时则对表加排他锁。但是在表有读取査询的同时，也可以往表中插入新的记录 （这被称为并发插入，CONCURRENT INSERT） o 修复对于MylSAM表，MySQL可以手工或者自动执行检査和修复操作，但这里说的修 复和事务.恢复以及崩溃恢复是不同的概念。执行表的修复可能导致一些数据丢失， 而且修复操作是非常慢的。可以通过CHECK TABLE mytable检査表的错误，如果有 错误可以通过执行REPAIR TABLE mytable进行修复。另外，如果MySQL服务器已 经关闭，也可以通过myisamchk命令行工具进行检査和修复操作。 索引特性对于MylSAM表，即使是BLOB和TEXT等长字段，也可以基于其前500个字符创建 索引。MylSAM也支持全文索引，这是一种基于分词创建的索引，可以支持复杂的 査询。 延迟更新索引键(Delayed Key Write)创建MylSAM表的时候，如果指定了 DELAY_KEY_WRITE选项，在每次修改执行完成 时，不会立刻将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区(in.memory key buffer),只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入到磁 盘。这种方式可以极大地提升写入性能，但是在数据库或者主机崩溃时会造成索引 损坏，需要执行修复操作。延迟更新索引键的特性，可以在全局设置，也可以为单 个表设置。 MylSAM压缩表如果表在创建并导入数据以后，不会再进行修改操作，那么这样的表或许适合釆用- MylSAM压缩表。 可以使用myisampack对MylSAM表进行压缩(也叫打包pack)o压缩表是不能进行修 改的(除非先将表解除压缩，修改数据，然后再次压缩)。压缩表可以极大地减少磁盘 空间占用，因此也可以减少磁盘I/O,从而提升査询性能。压缩表也支持索引，但索引 也是只读的。 以现在的硬件能力，对大多数应用场景，读取压缩表数据时的解压带来的开销影响并不 大，而减少I/O带来的好处则要大得多。压缩时表中的记录是独立压缩的，所以读取单 行的时候不需要去解压整个表(甚至也不解压行所在的整个页面)。 MylSAM性能MylSAM引擎设计简单，数据以紧密格式存储，所以在某些场景下的性能很好。 MylSAM有一些服务器级别的性能扩展限制，比如对索引键缓冲区(key cache)的 Mutex锁，MariaDB基于段(segment)的索引键缓冲区机制来避免该问题。但MylSAM 最典型的性能问题还是表锁的问题，如果你发现所有的査询都长期处于“Locked”状态， 那么毫无疑问表锁就是罪魁祸首。 MySQL内建的其他存储引擎MySQL还有一些有特殊用途的存储引擎。在新版本中，有些可能因为一些原因已经不 再支持;另外还有些会继续支持，但是需要明确地启用后才能使用。 Archive 引擎Archive存储引擎只支持INSERT和SELECT操作，在MySQL 5.1之前也不支持索引。 Archive引擎会缓存所有的写并利用zlib对插入的行进行压缩，所以比MylSAM表的磁 盘I/O更少。但是每次SELECT査询都需要执行全表扫描。所以Archive表适合日志和 数据釆集类应用，这类应用做数据分析时往往需要全表扫描。或者在一些需要更快速的 INSERT操作的场合下也可以使用。 Archive引擎支持行级锁和专用的缓冲区，所以可以实现高并发的插入。在一个査询开 始直到返回表中存在的所有行数之前，Archive引擎会阻止其他的SELECT执行，以实现 一致性读。另外，也实现了批量插入在完成之前对读操作是不可见的。这种机制模仿了 事务和MVCC的一些特性，但Archive引擎不是一个事务型的引擎，而是一个针对高速 插入和压缩做了优化的简单引擎。 Blackhole 引擎Blackhole引擎没有实现任何的存储机制，它会丢弃所有插入的数据，不做任何保存。但 是服务器会记录Blackhole表的日志，所以可以用于复制数据到备库，或者只是简单地 记录到日志。这种特殊的存储引擎可以在一些特殊的复制架构和日志审核时发挥作用。 但这种应用方式我们碰到过很多问题，因此并不推荐。 CSV引擎CSV引擎可以将普通的CSV文件（逗号分割值的文件）作为MySQL的表来处理，但 这种表不支持索引。CSV引擎可以在数据库运行时拷入或者拷出文件。可以将Excel 等电子表格软件中的数据存储为CSV文件，然后复制到MySQL数据目录下，就能在 MySQL中打开使用。同样，如果将数据写入到一个CSV引擎表，其他的外部程序也能 立即从表的数据文件中读取csv格式的数据。因此CSV引擎可以作为一种数据交换的 机制，非常有用。 Federated 引擎Federated引擎是访问其他MySQL服务器的一个代理，它会创建一个到远程MySQL服 务器的客户端连接，并将査询传输到远程服务器执行，然后提取或者发送需要的数据。 最初设计该存储引擎是为了和企业级数据库如Microsoft SQL Server和Oracle的类似特 性竞争的，可以说更多的是一种市场行为。尽管该引擎看起来提供了一种很好的跨服务 器的灵活性，但也经常带来问题，因此默认是禁用的。MariaDB使用了它的一个后续改 进版本，叫做FederatedXo Memory引擎如果需要快速地访问数据，并且这些数据不会被修改，重启以后丢失也没有关系，那么 使用Memory表(以前也叫做HEAP表)是非常有用的。Memory表至少比MylSAM表 要快一个数量级，因为所有的数据都保存在内存中，不需要进行磁盘I/O。Memory表的 结构在重启以后还会保留，但数据会丢失。 Memroy表在很多场景可以发挥好的作用： 用于査找(lookup)或者映射(mapping)表，例如将邮编和州名映射的表。 用于缓存周期性聚合数据(periodically aggregated data)的结果。 用于保存数据分析中产生的中间数据。 Memory表支持Hash索引，因此査找操作非常快。虽然Memory表的速度非常快，但还 是无法取代传统的基于磁盘的表。Memroy表是表级锁，因此并发写入的性能较低。它 不支持BLOB或TEXT类型的列，并且每行的长度是固定的，所以即使指定了 VARCHAR列， 实际存储时也会转换成CHAR,这可能导致部分内存的浪费(其中一些限制在Percona版 本已经解决)。 如果MySQL在执行査询的过程中需要使用临时表来保存中间结果，内部使用的临时表 就是Memory表。如果中间结果太大超出了 Memory表的限制，或者含有BLOB或TEXT 字段，则临时表会转换成MylSAM表。在后续的章节还会继续讨论该问题。 人们经常混淆Memory表和临时表。临时表是指使用CREATE TEMPORARY TABLE语句 创建的表，它可以使用任何存储引擎，因此和Memory表不是一回事。临时表只在 单个连接中可见，当连接断开时，临时表也将不复存在。 Merge引擎Merge引擎是MylSAM引擎的一个变种。Merge表是由多个MylSAM表合并而来的虚 拟表。如果将MySQL用于日志或者数据仓库类应用，该引擎可以发挥作用。但是引入 分区功能后，该引擎已经被放弃(参考第7章)。 NDB集群引擎2003年，当时的MySQL AB公司从索尼爱立信公司收购了 NDB数据库，然后开发了 NDB集群存储引擎，作为SQL和NDB原生协议之间的接口。MySQL服务器、NDB集 群存储引擎，以及分布式的、share.nothing的、容灾的、高可用的NDB数据库的组合， 被称为MySQL集群(MySQL Cluster) 第三方存储引擎OLTP类引擎等不多介绍了。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"MySQL之索引原理分析","slug":"index-principle-of-mysql","date":"2021-06-28T04:27:35.000Z","updated":"2022-09-17T14:13:56.162Z","comments":true,"path":"mysql/index-principle-of-mysql/","link":"","permalink":"https://www.cicoding.cn/mysql/index-principle-of-mysql/","excerpt":"","text":"一步一步推导出 Mysql 索引的底层数据结构。 Mysql 作为互联网中非常热门的数据库，其底层的存储引擎和数据检索引擎的设计非常重要，尤其是 Mysql 数据的存储形式以及索引的设计，决定了 Mysql 整体的数据检索性能。 我们知道，索引的作用是做数据的快速检索，而快速检索的实现的本质是数据结构。通过不同数据结构的选择，实现各种数据快速检索。在数据库中，高效的查找算法是非常重要的，因为数据库中存储了大量数据，一个高效的索引能节省巨大的时间。比如下面这个数据表，如果 Mysql 没有实现索引算法，那么查找 id=7 这个数据，那么只能采取暴力顺序遍历查找，找到 id=7 这个数据需要比较 7 次，如果这个表存储的是 1000W 个数据，查找 id=1000W 这个数据那就要比较 1000W 次，这种速度是不能接受的。 一、Mysql 索引底层数据结构选型 哈希表（Hash） 哈希表是做数据快速检索的有效利器。 哈希算法：也叫散列算法，就是把任意值(key)通过哈希函数变换为固定长度的 key 地址，通过这个地址进行具体数据的数据结构。 考虑这个数据库表 user，表中一共有 7 个数据，我们需要检索 id=7 的数据，SQL 语法是： 1select \\* from user where id=7; 哈希算法首先计算存储 id=7 的数据的物理地址 addr=hash(7)=4231，而 4231 映射的物理地址是 0x77，0x77 就是 id=7 存储的额数据的物理地址，通过该独立地址可以找到对应 user_name=’g’这个数据。这就是哈希算法快速检索数据的计算过程。 但是哈希算法有个数据碰撞的问题，也就是哈希函数可能对不同的 key 会计算出同一个结果，比如 hash(7)可能跟 hash(199)计算出来的结果一样，也就是不同的 key 映射到同一个结果了，这就是碰撞问题。解决碰撞问题的一个常见处理方式就是链地址法，即用链表把碰撞的数据接连起来。计算哈希值之后，还需要检查该哈希值是否存在碰撞数据链表，有则一直遍历到链表尾，直达找到真正的 key 对应的数据为止。 从算法时间复杂度分析来看，哈希算法时间复杂度为 O（1），检索速度非常快。比如查找 id=7 的数据，哈希索引只需要计算一次就可以获取到对应的数据，检索速度非常快。但是 Mysql 并没有采取哈希作为其底层算法，这是为什么呢？ 因为考虑到数据检索有一个常用手段就是范围查找，比如以下这个 SQL 语句： 1select \\* from user where id \\&gt;3; 针对以上这个语句，我们希望做的是找出 id&gt;3 的数据，这是很典型的范围查找。如果使用哈希算法实现的索引，范围查找怎么做呢？一个简单的思路就是一次把所有数据找出来加载到内存，然后再在内存里筛选筛选目标范围内的数据。但是这个范围查找的方法也太笨重了，没有一点效率而言。 所以，使用哈希算法实现的索引虽然可以做到快速检索数据，但是没办法做数据高效范围查找，因此哈希索引是不适合作为 Mysql 的底层索引的数据结构。 二叉查找树(BST) 二叉查找树是一种支持数据快速查找的数据结构，如图下所示: 二叉查找树的时间复杂度是 O(lgn)，比如针对上面这个二叉树结构，我们需要计算比较 3 次就可以检索到 id=7 的数据，相对于直接遍历查询省了一半的时间，从检索效率上看来是能做到高速检索的。此外二叉树的结构能不能解决哈希索引不能提供的范围查找功能呢？ 答案是可以的。观察上面的图，二叉树的叶子节点都是按序排列的，从左到右依次升序排列，如果我们需要找 id&gt;5 的数据，那我们取出节点为 6 的节点以及其右子树就可以了，范围查找也算是比较容易实现。 但是普通的二叉查找树有个致命缺点：极端情况下会退化为线性链表，二分查找也会退化为遍历查找，时间复杂退化为 O（N），检索性能急剧下降。比如以下这个情况，二叉树已经极度不平衡了，已经退化为链表了，检索速度大大降低。此时检索 id=7 的数据的所需要计算的次数已经变为 7 了。 在数据库中，数据的自增是一个很常见的形式，比如一个表的主键是 id，而主键一般默认都是自增的，如果采取二叉树这种数据结构作为索引，那上面介绍到的不平衡状态导致的线性查找的问题必然出现。因此，简单的二叉查找树存在不平衡导致的检索性能降低的问题，是不能直接用于实现 Mysql 底层索引的。 AVL 树和红黑树 二叉查找树存在不平衡问题，因此学者提出通过树节点的自动旋转和调整，让二叉树始终保持基本平衡的状态，就能保持二叉查找树的最佳查找性能了。基于这种思路的自调整平衡状态的二叉树有 AVL 树和红黑树。 首先简单介绍红黑树，这是一颗会自动调整树形态的树结构，比如当二叉树处于一个不平衡状态时，红黑树就会自动左旋右旋节点以及节点变色，调整树的形态，使其保持基本的平衡状态（时间复杂度为 O（logn）），也就保证了查找效率不会明显减低。比如从 1 到 7 升序插入数据节点，如果是普通的二叉查找树则会退化成链表，但是红黑树则会不断调整树的形态，使其保持基本平衡状态，如下图所示。下面这个红黑树下查找 id=7 的所要比较的节点数为 4，依然保持二叉树不错的查找效率。 红黑树拥有不错的平均查找效率，也不存在极端的 O(n)情况，那红黑树作为 Mysql 底层索引实现是否可以呢？其实红黑树也存在一些问题，观察下面这个例子。 红黑树顺序插入 1~7 个节点，查找 id=7 时需要计算的节点数为 4。 红黑树顺序插入 1~16 个节点，查找 id=16 需要比较的节点数为 6 次。观察一下这个树的形态，是不是当数据是顺序插入时，树的形态一直处于“右倾”的趋势呢？从根本上上看，红黑树并没有完全解决二叉查找树虽然这个“右倾”趋势远没有二叉查找树退化为线性链表那么夸张，但是数据库中的基本主键自增操作，主键一般都是数百万数千万的，如果红黑树存在这种问题，对于查找性能而言也是巨大的消耗，我们数据库不可能忍受这种无意义的等待的。 现在考虑另一种更为严格的自平衡二叉树 AVL 树。因为 AVL 树是个绝对平衡的二叉树，因此他在调整二叉树的形态上消耗的性能会更多。 AVL 树顺序插入 1~7 个节点，查找 id=7 所要比较节点的次数为 3。 AVL 树顺序插入 1~16 个节点，查找 id=16 需要比较的节点数为 4。从查找效率而言，AVL 树查找的速度要高于红黑树的查找效率（AVL 树是 4 次比较，红黑树是 6 次比较）。从树的形态看来，AVL 树不存在红黑树的“右倾”问题。也就是说，大量的顺序插入不会导致查询性能的降低，这从根本上解决了红黑树的问题。 总结一下 AVL 树的优点： 不错的查找性能（O（logn）），不存在极端的低效查找的情况。 可以实现范围查找、数据排序。 看起来 AVL 树作为数据查找的数据结构确实很不错，但是 AVL 树并不适合做 Mysql 数据库的索引数据结构，因为考虑一下这个问题： 数据库查询数据的瓶颈在于磁盘 IO，如果使用的是 AVL 树，我们每一个树节点只存储了一个数据，我们一次磁盘 IO 只能取出来一个节点上的数据加载到内存里，那比如查询 id=7 这个数据我们就要进行磁盘 IO 三次，这是多么消耗时间的。所以我们设计数据库索引时需要首先考虑怎么尽可能减少磁盘 IO 的次数。 磁盘 IO 有个有个特点，就是从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的，我们就可以根据这个思路，我们可以在一个树节点上尽可能多地存储数据，一次磁盘 IO 就多加载点数据到内存，这就是 B 树，B+树的的设计原理了。 B 树 下面这个 B 树，每个节点限制最多存储两个 key，一个节点如果超过两个 key 就会自动分裂。比如下面这个存储了 7 个数据 B 树，只需要查询两个节点就可以知道 id=7 这数据的具体位置，也就是两次磁盘 IO 就可以查询到指定数据，优于 AVL 树。 下面是一个存储了 16 个数据的 B 树，同样每个节点最多存储 2 个 key，查询 id=16 这个数据需要查询比较 4 个节点，也就是经过 4 次磁盘 IO。看起来查询性能与 AVL 树一样。 但是考虑到磁盘 IO 读一个数据和读 100 个数据消耗的时间基本一致，那我们的优化思路就可以改为：尽可能在一次磁盘 IO 中多读一点数据到内存。这个直接反映到树的结构就是，每个节点能存储的 key 可以适当增加。 当我们把单个节点限制的 key 个数设置为 6 之后，一个存储了 7 个数据的 B 树，查询 id=7 这个数据所要进行的磁盘 IO 为 2 次。 一个存储了 16 个数据的 B 树，查询 id=7 这个数据所要进行的磁盘 IO 为 2 次。相对于 AVL 树而言磁盘 IO 次数降低为一半。 所以数据库索引数据结构的选型而言，B 树是一个很不错的选择。总结来说，B 树用作数据库索引有以下优点： 优秀检索速度，时间复杂度：B 树的查找性能等于 O（h*logn），其中 h 为树高，n 为每个节点关键词的个数； 尽可能少的磁盘 IO，加快了检索速度； 可以支持范围查找。 B+树 B 树和 B+树有什么不同呢？ 第一，B 树一个节点里存的是数据，而 B+树存储的是索引（地址），所以 B 树里一个节点存不了很多个数据，但是 B+树一个节点能存很多索引，B+树叶子节点存所有的数据。 第二，B+树的叶子节点是数据阶段用了一个链表串联起来，便于范围查找。 通过 B 树和 B+树的对比我们看出，B+树节点存储的是索引，在单个节点存储容量有限的情况下，单节点也能存储大量索引，使得整个 B+树高度降低，减少了磁盘 IO。其次，B+树的叶子节点是真正数据存储的地方，叶子节点用了链表连接起来，这个链表本身就是有序的，在数据范围查找时，更具备效率。因此 Mysql 的索引用的就是 B+树，B+树在查找效率、范围查找中都有着非常不错的性能。 二、Innodb 引擎和 Myisam 引擎的实现Mysql 底层数据引擎以插件形式设计，最常见的是 Innodb 引擎和 Myisam 引擎，用户可以根据个人需求选择不同的引擎作为 Mysql 数据表的底层引擎。我们刚分析了，B+树作为 Mysql 的索引的数据结构非常合适，但是数据和索引到底怎么组织起来也是需要一番设计，设计理念的不同也导致了 Innodb 和 Myisam 的出现，各自呈现独特的性能。 MyISAM 虽然数据查找性能极佳，但是不支持事务处理。Innodb 最大的特色就是支持了 ACID 兼容的事务功能，而且他支持行级锁。Mysql 建立表的时候就可以指定引擎，比如下面的例子，就是分别指定了 Myisam 和 Innodb 作为 user 表和 user2 表的数据引擎。 执行这两个指令后，系统出现了以下的文件，说明这两个引擎数据和索引的组织方式是不一样的。 Innodb 创建表后生成的文件有： frm:创建表的语句 idb:表里面的数据+索引文件 Myisam 创建表后生成的文件有 frm:创建表的语句 MYD:表里面的数据文件（myisam data） MYI:表里面的索引文件（myisam index） 从生成的文件看来，这两个引擎底层数据和索引的组织方式并不一样，MyISAM 引擎把数据和索引分开了，一人一个文件，这叫做非聚集索引方式；Innodb 引擎把数据和索引放在同一个文件里了，这叫做聚集索引方式。下面将从底层实现角度分析这两个引擎是怎么依靠 B+树这个数据结构来组织引擎实现的。 MyISAM 引擎的底层实现（非聚集索引方式） MyISAM 用的是非聚集索引方式，即数据和索引落在不同的两个文件上。MyISAM 在建表时以主键作为 KEY 来建立主索引 B+树，树的叶子节点存的是对应数据的物理地址。我们拿到这个物理地址后，就可以到 MyISAM 数据文件中直接定位到具体的数据记录了。 当我们为某个字段添加索引时，我们同样会生成对应字段的索引树，该字段的索引树的叶子节点同样是记录了对应数据的物理地址，然后也是拿着这个物理地址去数据文件里定位到具体的数据记录。 Innodb 引擎的底层实现（聚集索引方式） InnoDB 是聚集索引方式，因此数据和索引都存储在同一个文件里。首先 InnoDB 会根据主键 ID 作为 KEY 建立索引 B+树，如左下图所示，而 B+树的叶子节点存储的是主键 ID 对应的数据，比如在执行 select * from user_info where id=15 这个语句时，InnoDB 就会查询这颗主键 ID 索引 B+树，找到对应的 user_name=’Bob’。 这是建表的时候 InnoDB 就会自动建立好主键 ID 索引树，这也是为什么 Mysql 在建表时要求必须指定主键的原因。当我们为表里某个字段加索引时 InnoDB 会怎么建立索引树呢？比如我们要给 user_name 这个字段加索引，那么 InnoDB 就会建立 user_name 索引 B+树，节点里存的是 user_name 这个 KEY，叶子节点存储的数据的是主键 KEY。注意，叶子存储的是主键 KEY！拿到主键 KEY 后，InnoDB 才会去主键索引树里根据刚在 user_name 索引树找到的主键 KEY 查找到对应的数据。 问题来了，为什么 InnoDB 只在主键索引树的叶子节点存储了具体数据，但是其他索引树却不存具体数据呢，而要多此一举先找到主键，再在主键索引树找到对应的数据呢? 其实很简单，因为 InnoDB 需要节省存储空间。一个表里可能有很多个索引，InnoDB 都会给每个加了索引的字段生成索引树，如果每个字段的索引树都存储了具体数据，那么这个表的索引数据文件就变得非常巨大（数据极度冗余了）。从节约磁盘空间的角度来说，真的没有必要每个字段索引树都存具体数据，通过这种看似“多此一举”的步骤，在牺牲较少查询的性能下节省了巨大的磁盘空间，这是非常有值得的。 在进行 InnoDB 和 MyISAM 特点对比时谈到，MyISAM 查询性能更好，从上面索引文件数据文件的设计来看也可以看出原因：MyISAM 直接找到物理地址后就可以直接定位到数据记录，但是 InnoDB 查询到叶子节点后，还需要再查询一次主键索引树，才可以定位到具体数据。等于 MyISAM 一步就查到了数据，但是 InnoDB 要两步，那当然 MyISAM 查询性能更高。 本文首先探讨了哪种数据结构更适合作为 Mysql 底层索引的实现，然后再介绍了 Mysql 两种经典数据引擎 MyISAM 和 InnoDB 的底层实现。最后再总结一下什么时候需要给你的表里的字段加索引吧： 较频繁的作为查询条件的字段应该创建索引； 唯一性太差的字段不适合单独创建索引，即使该字段频繁作为查询条件； 更新非常频繁的字段不适合创建索引。 原文链接：https://zhuanlan.zhihu.com/p/113917726","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"},{"name":"原理","slug":"原理","permalink":"https://www.cicoding.cn/tags/原理/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"MySQL索引在什么情况下会失效","slug":"under-what-circumstances-will-mysql-index-fail","date":"2021-06-28T01:27:35.000Z","updated":"2022-09-17T14:13:56.164Z","comments":true,"path":"mysql/under-what-circumstances-will-mysql-index-fail/","link":"","permalink":"https://www.cicoding.cn/mysql/under-what-circumstances-will-mysql-index-fail/","excerpt":"","text":"索引的失效，会大大降低sql的执行效率，日常中又有哪些常见的情况会导致索引失效？ 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如果or的所有字段都有索引还是会走索迎查询，如： select id from t where num=10 or num=20 可以这样查询： select id from t where num=10union allselect id from t where num=20 in 和 not in 也要慎用，否则会导致全表扫描，如： select id from t where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3 下面的查询也将导致全表扫描： select id from t where name like ‘%abc%’ 和 select id from t where name like ‘%abc’ 只有like abc% 索引才有效，若要提高效率，可以考虑全文检索 如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： select id from t where num=@num 可以改为强制查询使用索引： select id from t with(index(索引名)) where num=@num 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where num/2=100 应改为: select id from t where num=100*2 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where substring(name,1,3)=’abc’–name以abc开头的idselect id from t where datediff(day,createdate,’2005-11-30’)=0–‘2005-11-30’生成的id 应改为: select id from t where name like ‘abc%’ select id from t where createdate&gt;=’2005-11-30’ and createdate&lt;’2005-12-1’ 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。对于复合索引：Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。 例如索引是key index （a,b,c）。 可以支持a | a,b| a,b,c 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效 不要写一些没有意义的查询，如需要生成一个空表结构： select col1,col2 into #t from t where 1=0 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(…) 很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b) 用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 原文链接：https://blog.csdn.net/BestDD/article/details/113359124","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"MySQL之索引失效分析及优化相关","slug":"mysql-index-failure","date":"2021-06-27T04:27:35.000Z","updated":"2022-09-17T14:13:56.162Z","comments":true,"path":"mysql/mysql-index-failure/","link":"","permalink":"https://www.cicoding.cn/mysql/mysql-index-failure/","excerpt":"","text":"MySQL索引失效的几种情况： 条件中有or，即使其中有条件带索引也不会使用； 对于多列索引，不使用的第一部分，则不会使用索引； like查询以%开头，索引无效； 当字段类型为字符串时，条件中数据没有使用引号引用。 索引并不是时时都会生效的，比如以下几种情况，将导致索引失效： 如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因) 注意：要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 对于多列索引，不是使用的第一部分，则不会使用索引 like查询是以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效。 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 此外，查看索引的使用情况 show status like ‘Handler_read%’; 大家可以注意： handler_read_key:这个值越高越好，越高表示使用索引查询到的次数 handler_read_rnd_next:这个值越高，说明查询低效 1) 没有查询条件，或者查询条件没有建立索引 2) 在查询条件上没有使用引导列 3) 查询的数量是大表的大部分，应该是30％以上。 4) 索引本身失效 5) 查询条件使用函数在索引列上，或者对索引列进行运算，运算包括(+，-，*，/，! 等) 错误的例子： select * from test where id-1=9; 正确的例子： select * from test where id=10; 6) 对小表查询 7) 提示不使用索引 8) 统计数据不真实 9) CBO计算走索引花费过大的情况。其实也包含了上面的情况，这里指的是表占有的block要比索引小。 10) 隐式转换导致索引失效.这一点应当引起重视.也是开发中经常会犯的错误. 由于表的字段tu_mdn定义为varchar2(20),但在查询时把该字段作为number类型以where条件传给Oracle,这样会导致索引失效. . 错误的例子： select * from test where tu_mdn=13333333333; 正确的例子： select * from test where tu_mdn=’13333333333’; 12) 1,&lt;&gt; 2,单独的&gt;, 13) like “%_” 百分号在前. 14) 表没分析. 15) 单独引用复合索引里非第一位置的索引列. 16) 字符型字段为数字时在where条件里不添加引号. 17) 对索引列进行运算.需要建立函数索引. 18) not in ,not exist. 19) 当变量采用的是times变量，而表的字段采用的是date变量时.或相反情况。 20) B-tree索引 is null不会走,is not null会走,位图索引 is null,is not null 都会走 21) 联合索引 is not null 只要在建立的索引列(不分先后)都会走, in null时 必须要和建立索引第一列一起使用,当建立索引第一位置条件是is null 时,其他建立索引的列可以是is null(但必须在所有列 都满足is null的时候),或者=一个值； 当建立索引的第一位置是=一个值时,其他索引列可以是任何情况(包括is null =一个值),以上两种情况索引都会走。其他情况不会走。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"MySQL索引类型区分","slug":"mysql-index-type-distinction","date":"2021-06-26T13:37:35.000Z","updated":"2022-09-17T14:13:56.162Z","comments":true,"path":"mysql/mysql-index-type-distinction/","link":"","permalink":"https://www.cicoding.cn/mysql/mysql-index-type-distinction/","excerpt":"","text":"存储方式区分1. B-树索引目前大多数索引都是采用B-树来存储，其包含组件有： 叶子节点：包含的条目直接指向表里的数据行。叶子节点之间彼此相连，一个叶子节点有一个指向下一个叶子节点的指针。 分支节点：包含的条目指向索引里其他的分支节点或者叶子节点。 根节点：一个 B-树索引只有一个根节点，实际上就是位于树的最顶端的分支节点。 2. 哈希索引哈希索引也称为散列索引或 HASH 索引。MySQL 目前仅有 MEMORY 存储引擎和 HEAP 存储引擎支持这类索引。其中，MEMORY 存储引擎可以支持 B-树索引和 HASH 索引，且将 HASH 当成默认索引。 哈希索引的最大特点是访问速度快，但也存在下面的一些缺点： MySQL 需要读取表中索引列的值来参与散列计算，散列计算是一个比较耗时的操作。也就是说，相对于 B-树索引来说，建立哈希索引会耗费更多的时间。 不能使用 HASH 索引排序。 HASH 索引只支持等值比较，如”=” “IN()”或”&lt;=&gt;”。 HASH 索引不支持键的部分匹配，因为在计算 HASH 值的时候是通过整个索引值来计算的。 逻辑区分1. 普通索引普通索引是 MySQL 中最基本的索引类型，它没有任何限制，唯一任务就是加快系统对数据的访问速度。允许重复值和空值。 关键字是 INDEX 或 KEY。 2. 唯一索引唯一索引列的值必须唯一，允许有空值。如果是组合索引，则列值的组合必须唯一。 关键字是 UNIQUE。 3. 主键索引主键索引是一种特殊的唯一索引，不允许值重复或者值为空。 关键字是 PRIMARY KEY。 4. 空间索引空间索引是对空间数据类型的字段建立的索引，不允许空值，只能在存储引擎为 MyISAM 的表中创建。 关键字是 SPATIAL。 5. 全文索引全文索引主要用来查找文本中的关键字，只能在 CHAR、VARCHAR 或 TEXT 类型的列上创建。只有 MyISAM 存储引擎支持，允许重复值和空值。 关键字是 FULLTEXT。 实际使用区分1. 单列索引单列索引可以是普通索引，也可以是唯一性索引，还可以是全文索引。只要保证该索引只对应一个字段即可。 2. 组合索引组合索引也称为复合索引或多列索引。相对于单列索引来说，组合索引是将原表的多个列共同组成一个索引。 查询时，字段顺序需与索引顺序一致；LIKE时，首字符不能是 ‘%’，否则会影响索引使用。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"Navicat建表MySQL索引类型","slug":"navicat-mysql-index-type","date":"2021-06-26T13:27:35.000Z","updated":"2022-09-17T14:13:56.164Z","comments":true,"path":"mysql/navicat-mysql-index-type/","link":"","permalink":"https://www.cicoding.cn/mysql/navicat-mysql-index-type/","excerpt":"","text":"mysql索引类型：FULLTEXT、NORMAL、SPATIAL、UNIQUE的详细介绍Normal 普通索引表示普通索引，大多数情况下都可以使用 Unique 唯一索引表示唯一的，不允许重复的索引，如果该字段信息保证不会重复例如身份证号用作索引时，可设置为unique 约束唯一标识数据库表中的每一条记录，即在单表中不能用每条记录是唯一的（例如身份证就是唯一的），Unique(要求列唯一)和Primary Key(primary key = unique + not null 列唯一)约束均为列或列集合中提供了唯一性的保证，Primary Key是拥有自动定义的Unique约束，但是每个表中可以有多个Unique约束，但是只能有一个Primary Key约束。mysql中创建Unique约束 Full Text 全文索引表示全文收索，在检索长文本的时候，效果最好，短文本建议使用Index,但是在检索的时候数据量比较大的时候，现将数据放入一个没有全局索引的表中，然后在用Create Index创建的Full Text索引，要比先为一张表建立Full Text然后在写入数据要快的很多 FULLTEXT 用于搜索很长一篇文章的时候，效果最好。用在比较短的文本，如果就一两行字的，普通的 INDEX 也可以。 SPATIAL 空间索引空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建 btree索引和hash索引的区别1、BTREE（B树（可以是多叉树）） {主流使用}2、HASH（key,value） 这种方式对范围查询支持得不是很好 hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。可 能很多人又有疑问了，既然 Hash 索引的效率要比 B-Tree 高很多，为什么大家不都用 Hash 索引而还要使用 B-Tree 索引呢？任何事物都是有两面性的，Hash 索引也一样，虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些。 （1）Hash 索引仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询。 由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。 （2）Hash 索引无法被用来避免数据的排序操作。 由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算； （3）Hash 索引不能利用部分索引键查询。 对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。 （4）Hash 索引在任何时候都不能避免表扫描。 前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。 （5）Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。 对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下。 在实际操作过程中，应该选取表中哪些字段作为索引？为了使索引的使用效率更高，在创建索引时，必须考虑在哪些字段上创建索引和创建什么类型的索引,有7大原则： 选择唯一性索引 为经常需要排序、分组和联合操作的字段建立索引 为常作为查询条件的字段建立索引 限制索引的数目 尽量使用数据量少的索引 尽量使用前缀来索引 删除不再使用或者很少使用的索引 经常更新修改的字段不要建立索引（针对mysql说，因为字段更改同时索引就要重新建立，排序，而Orcale好像是有这样的机制字段值更改了，它不立刻建立索引，排序索引，而是根据更改个数，时间段去做平衡索引这件事的） 不推荐在同一列建多个索引","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"},{"name":"Navicat","slug":"Navicat","permalink":"https://www.cicoding.cn/tags/Navicat/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"MySQL索引类型","slug":"mysql-index-type","date":"2021-06-25T13:27:35.000Z","updated":"2022-09-17T14:13:56.163Z","comments":true,"path":"mysql/mysql-index-type/","link":"","permalink":"https://www.cicoding.cn/mysql/mysql-index-type/","excerpt":"","text":"一、简介MySQL目前主要有以下几种索引类型：1.普通索引2.唯一索引3.主键索引4.组合索引5.全文索引 二、语句12CREATE TABLE table_name[col_name data type][unique|fulltext][index|key][index_name](col_name[length])[asc|desc] unique|fulltext为可选参数，分别表示唯一索引、全文索引 index和key为同义词，两者作用相同，用来指定创建索引 col_name为需要创建索引的字段列，该列必须从数据表中该定义的多个列中选择 index_name指定索引的名称，为可选参数，如果不指定，默认col_name为索引值 length为可选参数，表示索引的长度，只有字符串类型的字段才能指定索引长度 asc或desc指定升序或降序的索引值存储 三、索引类型1.普通索引是最基本的索引，它没有任何限制。它有以下几种创建方式：（1）直接创建索引 1CREATE INDEX index_name ON table(column(length)) （2）修改表结构的方式添加索引 1ALTER TABLE table_name ADD INDEX index_name ON (column(length)) （3）创建表的时候同时创建索引 12345678CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`), INDEX index_name (title(length))) （4）删除索引 1DROP INDEX index_name ON table 2.唯一索引与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式：（1）创建唯一索引 1CREATE UNIQUE INDEX indexName ON table(column(length)) （2）修改表结构 1ALTER TABLE table_name ADD UNIQUE indexName ON (column(length)) （3）创建表的时候直接指定 1234567CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , UNIQUE indexName (title(length))); 3.主键索引是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引： 12345CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) NOT NULL , PRIMARY KEY (`id`)); 4.组合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合 1ALTER TABLE `table` ADD INDEX name_city_age (name,city,age); 5.全文索引主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。（1）创建表的适合添加全文索引 12345678CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`), FULLTEXT (content)); （2）修改表结构添加全文索引 1ALTER TABLE article ADD FULLTEXT index_content(content) （3）直接创建索引 1CREATE FULLTEXT INDEX index_content ON article(content) 四、缺点 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行insert、update和delete。因为更新表时，不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会增长很快。索引只是提高效率的一个因素，如果有大数据量的表，就需要花时间研究建立最优秀的索引，或优化查询语句。 五、注意事项使用索引时，有以下一些技巧和注意事项： 索引不会包含有null值的列只要列中包含有null值都将不会被包含在索引中，复合索引中只要有一列含有null值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为null。 使用短索引对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个char(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 索引列排序查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 like语句操作一般情况下不推荐使用like操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引而like “aaa%”可以使用索引。 不要在列上进行运算这将导致索引失效而进行全表扫描，例如 1SELECT * FROM table_name WHERE YEAR(column_name)&lt;2017; 不使用not in和&lt;&gt;操作","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://www.cicoding.cn/tags/索引/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"MySQL之索引","slug":"Indexes","date":"2021-06-25T08:17:35.000Z","updated":"2022-09-17T14:13:56.161Z","comments":true,"path":"mysql/Indexes/","link":"","permalink":"https://www.cicoding.cn/mysql/Indexes/","excerpt":"","text":"索引（在MySQL中也叫做“键（key）”）是存储引擎用于快速找到记录的一种数据结构。 这是索引的基本功能，除此之外，本章还将讨论索引其他一些方面有用的属性。索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响愈发重要。在数据量较小且负载较低时，不恰当的索引对性能的影响可能还不明显，但 当数据量逐渐增大时，性能则会急剧下降。不过，索引却经常被忽略，有时候甚至被误解，所以在实际案例中经常会遇到由糟糕索引导致的问题。这也是我们把索引优化放在了靠前的章节，甚至比査询优化还靠前的原因。索引优化应该是对査询性能优化最有效的手段了。索引能够轻易将查询性能提高几个数量级，“最优”的索引有时比一个“好的”索引性能要好两个数量级。创建一个真正“最 优”的索引经常需要重写査询，所以，本章和下一章的关系非常紧密。 索引基础要理解MySQL中索引是如何工作的，最简单的方法就是去看看一本书的“索引”部分: 如果想在一本书中找到某个特定主题，一般会先看书的“索引”，找到对应的页码。 在MySQL中，存储引擎用类似的方法使用索引，其先在索引中找到对应值，然后根据 匹配的索引记录找到对应的数据行。假如要运行下面的査询： mysql&gt; SELECT first_ame FROM sakila.actor WHERE actor_id = 5; 如果在actor_id列上建有索引，则MySQL将使用该索引找到actor_id为5的行，也 就是说，MySQL先在索引上按值进行査找，然后返回所有包含该值的数据行。 索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要，因 为MySQL只能高效地使用索引的最左前缀列。创建一个包含两个列的索引，和创建两 个只包含一列的索引是大不相同的，下面将详细介绍。 如果使用的是ORM,是否还需要关心索引？简而言之：是的，仍然需要理解索引，即使是使用对象关系映射(ORM)工具。 (ORM)工具能够生产符合逻辑的、合法的查询(多数时候)，除非只是生成非常基本 的查询(例如仅是根据主键查询)，否则它很难生成适合索引的查询。无论是多么 复杂的(ORM)工具，在精妙和复杂的索引面前都是“浮云”。读完本章后面的内容 以后，你就会同意这个观点的！很多时候，即使是查询优化技术专家也很难兼顾到 各种情况，更别说(ORM) 了。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cicoding.cn/categories/MySQL/"}]},{"title":"Spring Boot版 Sharding JDBC 垂直拆分（不同的表在不同的库中）+ 读写分离","slug":"sharding-jdbc006","date":"2021-06-10T12:50:15.000Z","updated":"2022-09-17T14:13:56.173Z","comments":false,"path":"sharding-jdbc/sharding-jdbc006/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc006/","excerpt":"","text":"上一篇介绍的了Spring Boot版 Sharding JDBC 垂直拆分（不同的表在不同的库中）例子，接下来我们写demo，介绍Spring Boot版 Sharding JDBC 垂直拆分（不同的表在不同的库中）+ 读写分离。话不多说，直接写代码。 准备 SpringBoot 2.1.12 Sharding-JDBC 4.0.0 Mybatis 3.x Mysql 8.0 lombok 本文场景介绍user表分表分为2个表，2个库 POM文件pom文件引入如下相关依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-example&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;sharding-db-read-write&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sharding-db-read-write&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 相关代码实现Controller代码CicodingController代码1234567891011121314151617181920212223242526272829303132333435package cn.cicoding.controller;import cn.cicoding.model.LouDong;import cn.cicoding.service.LouDongService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class LouDongController &#123; @Autowired private LouDongService louDongService; @GetMapping(\"/lds\") public Object list() &#123; return louDongService.list(); &#125; @GetMapping(\"/ld/add\") public Object add() &#123; for (long i = 0; i &lt; 10; i++) &#123; LouDong louDong = new LouDong(); louDong.setId(i+\"a\"); louDong.setCity(\"深圳\"); louDong.setRegion(\"宝安\"); louDong.setName(\"李四\"); louDong.setLdNum(\"A\"); louDong.setUnitNum(\"2\"); louDongService.addLouDong(louDong); &#125; return \"success\"; &#125; &#125; UserController代码123456789101112131415161718192021222324252627282930313233343536373839404142package cn.cicoding.controller;import cn.cicoding.model.User;import cn.cicoding.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class UserController &#123; @Autowired private UserService userService; @GetMapping(\"/users\") public Object list() &#123; return userService.list(); &#125; @GetMapping(\"/add\") public Object add() &#123; for (long i = 0; i &lt; 100; i++) &#123; User user = new User(); user.setCity(\"深圳\"); user.setName(\"李四\"); userService.add(user); &#125; return \"success\"; &#125; @GetMapping(\"/users/&#123;id&#125;\") public Object get(@PathVariable Long id) &#123; return userService.findById(id); &#125; @GetMapping(\"/users/query\") public Object get(String name) &#123; return userService.findByName(name); &#125; &#125; Service代码CicodingService代码12345678910111213package cn.cicoding.service;import cn.cicoding.model.LouDong;import java.util.List;public interface CicodingService &#123; List&lt;LouDong&gt; list(); Long addLouDong(LouDong louDong); &#125; UserService代码1234567891011121314151617package cn.cicoding.service;import java.util.List;import cn.cicoding.model.User;public interface UserService &#123; List&lt;User&gt; list(); Long add(User user); User findById(Long id); User findByName(String name); &#125; CicodingServiceImpl代码1234567891011121314151617181920212223242526package cn.cicoding.service;import java.util.List;import cn.cicoding.model.LouDong;import cn.cicoding.repository.LouDongRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class CicodingServiceImpl implements CicodingService &#123; @Autowired private LouDongRepository louDongRepository; @Override public List&lt;LouDong&gt; list() &#123; return louDongRepository.list(); &#125; @Override public Long addLouDong(LouDong louDong) &#123; return louDongRepository.addLouDong(louDong); &#125;&#125; UserServiceImpl代码12345678910111213141516171819202122232425262728293031323334package cn.cicoding.service;import java.util.List;import cn.cicoding.model.User;import cn.cicoding.repository.UserRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserRepository userRepository; public List&lt;User&gt; list() &#123; return userRepository.list(); &#125; public Long add(User user) &#123; return userRepository.addUser(user); &#125; @Override public User findById(Long id) &#123; return userRepository.findById(id); &#125; @Override public User findByName(String name) &#123; return userRepository.findByName(name); &#125;&#125; Repository代码CicodingRepository代码1234567891011121314package cn.cicoding.repository;import java.util.List;import cn.cicoding.model.LouDong;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface CicodingRepository &#123; Long addLouDong(LouDong louDong); List&lt;LouDong&gt; list();&#125; UserRepository代码123456789101112131415161718package cn.cicoding.repository;import java.util.List;import cn.cicoding.model.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserRepository &#123; Long addUser(User user); List&lt;User&gt; list(); User findById(Long id); User findByName(String name);&#125; Mapper.xml代码实现CicodingMapper.xml1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.cicoding.repository.CicodingMapper\"&gt; &lt;resultMap id=\"baseResultMap\" type=\"cn.cicoding.model.Cicoding\"&gt; &lt;result column=\"id\" property=\"id\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"city\" property=\"city\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"region\" property=\"region\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"ld_num\" property=\"ldNum\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"unit_num\" property=\"unitNum\" jdbcType=\"VARCHAR\" /&gt; &lt;/resultMap&gt; &lt;insert id=\"addLouDong\"&gt; INSERT INTO loudong ( id, city, region, name, ld_num, unit_num ) VALUES ( #&#123;id,jdbcType=VARCHAR&#125;, #&#123;city,jdbcType=VARCHAR&#125;, #&#123;region,jdbcType=VARCHAR&#125;, #&#123;name,jdbcType=VARCHAR&#125;, #&#123;ldNum,jdbcType=VARCHAR&#125;, #&#123;unitNum,jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;select id=\"list\" resultMap=\"baseResultMap\"&gt; SELECT ld.* FROM loudong ld &lt;/select&gt; &lt;/mapper&gt; UserMapper.xml123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.cicoding.repository.UserRepository\"&gt; &lt;resultMap id=\"baseResultMap\" type=\"cn.cicoding.model.User\"&gt; &lt;result column=\"id\" property=\"id\" jdbcType=\"INTEGER\" /&gt; &lt;result column=\"city\" property=\"city\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" /&gt; &lt;/resultMap&gt; &lt;insert id=\"addUser\"&gt; INSERT INTO user ( city, name ) VALUES ( #&#123;city,jdbcType=VARCHAR&#125;, #&#123;name,jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;select id=\"list\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u &lt;/select&gt; &lt;select id=\"findById\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u WHERE u.id=#&#123;id,jdbcType=INTEGER&#125; &lt;/select&gt; &lt;select id=\"findByName\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u WHERE u.name=#&#123;name,jdbcType=VARCHAR&#125; &lt;/select&gt; &lt;/mapper&gt; 实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445package cn.cicoding.model;import java.io.Serializable;/** * 分表 * @author cicoding * */public class User implements Serializable &#123; private static final long serialVersionUID = -1205226416664488559L; private Long id; private String city = \"\"; private String name = \"\"; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 到这我们完成了基本的代码编写，由于sharding-jdbc是jar包，我们来看主要的配置信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# Spring Boot版 Sharding JDBC 垂直拆分（不同的表在不同的库中）+ 读写分离server.port=8084# mybatis对应的映射文件路径mybatis.mapper-locations=classpath:mapper/*.xml# mybatis对应的实体类mybatis.type-aliases-package=cn.cicoding.modelspring.shardingsphere.datasource.names=ds0,ds0slave,ds1,ds1slave# 数据源spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds0.jdbc-url=jdbc:mysql://localhost:3306/ds_0?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds0.username=rootspring.shardingsphere.datasource.ds0.password=rootspring.shardingsphere.datasource.ds0slave.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds0slave.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds0slave.jdbc-url=jdbc:mysql://localhost:3306/ds0slave?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds0slave.username=rootspring.shardingsphere.datasource.ds0slave.password=rootspring.shardingsphere.datasource.ds1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mysql://localhost:3306/ds_1?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds1.username=rootspring.shardingsphere.datasource.ds1.password=rootspring.shardingsphere.datasource.ds1slave.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.ds1slave.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds1slave.jdbc-url=jdbc:mysql://localhost:3306/ds1slave?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds1slave.username=rootspring.shardingsphere.datasource.ds1slave.password=root# 绑定loudong表所在节点spring.shardingsphere.sharding.tables.loudong.actual-data-nodes=ds1.loudong# 绑定user表所在节点spring.shardingsphere.sharding.tables.user.actual-data-nodes=ds0.userspring.shardingsphere.sharding.tables.user.key-generator.column=idspring.shardingsphere.sharding.tables.user.key-generator.type=SNOWFLAKE# 读写分离spring.shardingsphere.sharding.master-slave-rules.ds0.master-data-source-name=ds0spring.shardingsphere.sharding.master-slave-rules.ds0.slave-data-source-names=ds0slavespring.shardingsphere.sharding.master-slave-rules.ds1.master-data-source-name=ds1spring.shardingsphere.sharding.master-slave-rules.ds1.slave-data-source-names=ds1slave 启动类12345678910111213141516package cn.cicoding;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * Spring Boot版 Sharding JDBC 垂直拆分（不同的表在不同的库中）+ 读写分离 */@SpringBootApplicationpublic class ShardingDbReadWriteApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardingDbReadWriteApplication.class, args); &#125;&#125; 测试演示启动启动类，访问http://localhost:8084/add http://localhost:8084/cis 分别进入不同的库！ 到此我们就实现了sharding-jdbc主从读写分离实现，更多配置请参考此处！","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"SpringBoot原理分析 - 自动装配","slug":"analysis-of-springboot-principle-automatic-assembly","date":"2021-03-11T13:49:48.000Z","updated":"2022-09-17T14:13:56.180Z","comments":false,"path":"springboot/analysis-of-springboot-principle-automatic-assembly/","link":"","permalink":"https://www.cicoding.cn/springboot/analysis-of-springboot-principle-automatic-assembly/","excerpt":"","text":"SpringBoot解决了spring以及springmvc繁琐的配置的痛点，以“约定大于配置”为原则，实现了自动装配。下面来探究下SpringBoot自动装配原理。 一、何为装配把bean放入到Spring的Ioc容器叫做装配，那么在装配Bean的时候，我们首先要知道哪些类需要被装配，实现这一方式的途径总体上说分为两种，一种是传统的xml方式，另一种则是注解方式。下面介绍下通过注解来实现装配。 启动原理 我们发现任何一个springboot的项目都会有如下一个启动类： 123456@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 为了了解SpringBoot原理，我们直接从Annotation 入 手，看看@SpringBootApplication里面，做了什么？ 打开SpringBootApplication这个注解，可以看到它实际上 是一个复合注解 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; ...&#125; SpringBootApplication本质上是由3个注解组成，分别是 @Configuration （@SpringBootConfiguration里面也用的@Configuration） @EnableAutoConfiguration @ComponentScan 我们可以直接用这三个注解也可以启动 springboot 应用， 只是每次配置三个注解比较繁琐，所以直接用一个复合注 解更方便些。 然后仔细观察者三个注解，除了EnableAutoConfiguration 可能稍微陌生一点，其他两个注解使用得都很多 。 @ConfigurationConfiguration这个注解大家应该有用过，它是JavaConfig形式的基于Spring IOC容器的配置类使用的一种注解。因为 SpringBoot 本质上就是一个 spring 应用，所以通过这个注解来加载IOC容器的配置是很正常的。所以在启动类 里面标注了@Configuration，意味着它其实也是一个 IoC 容器的配置类。 传统意义上的 spring 应用都是基于 xml 形式来配置 bean 的依赖关系。然后通过spring容器在启动的时候，把bean进行初始化并且，如果bean之间存在依赖关系，则分析这些已经在IoC容器中的bean根据依赖关系进行组装。 直到 Java5 中，引入了 Annotations 这个特性，Spring 框架也紧随大流并且推出了基于 Java 代码和Annotation元信息的依赖关系绑定描述的方式，也就是JavaConfig。 从spring3开始，spring就支持了两种bean的配置方式， 一种是基于xml文件方式、另一种就是JavaConfig 。 任何一个标注了@Configuration 的 Java 类定义都是一个 JavaConfig 配置类。而在这个配置类中，任何标注了 @Bean 的方法，它的返回值都会作为 Bean 定义注册到 Spring的IOC容器，方法名默认成为这个bean的id @ComponentScan@ComponentScan这个注解是大家接触得最多的了，相当于 xml 配置文件中的&lt;context:component-scan /&gt;。 它的主要作用就是扫描指定路径下的标识了需要装配的类，自动装配到spring的Ioc容器中。 标识需要装配类的形式主要是：@Component、@Repository、@Service、@Controller这类的注解标识的类； ComponentScan 默认会扫描当前package 下的的所有加了相关注解标识的类到IoC容器中。 @EnableAutoConfigurationEnable 并不是新鲜玩意 在 spring3.1 版本中，提供了一系列的@Enable 开 头的注解，Enable主机应该是在JavaConfig框架上更进一步的完善，是的用户在使用spring相关的框架是，避免配置大量的代码从而降低使用的难度 。 比如@EnableScheduling、@EnableCaching、@EnableWebMvc等，@EnableAutoConfiguration的理念和做事方式其实一脉相承，简单概括一下就是，借助@Import的支持，收集和注册特定场景相关的bean定义。 @EnableWebMvc，这个注解引入了MVC 框架在Spring 应用中需要用到的所有 bean @EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器，开启计划任务的支持。 而@EnableAutoConfiguration也是借助@Import的帮助，将所有符合条件的@Configuration 配置都加载到当前SpringBoot创建并使用的IoC容器中。仅此而已！ @EnableAutoConfiguration会根据类路径中的jar依赖为项目进行自动配置，如：添加了spring-boot-starter-web依赖，会自动添加Tomcat和Spring MVC的依赖，Spring Boot会对Tomcat和Spring MVC进行自动配置。 @EnableAutoConfiguration作为一个复合Annotation，其自身定义关键信息如下： 123456789@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ...&#125; @Import(AutoConfigurationImportSelector.class)从名字来看，可以猜到它是基于ImportSelector来实现基于动态bean的加载功能。要知道Springboot @Enable*注解的工作原理ImportSelector接口selectImports返回的数组（类的全类名）都会被纳入到 spring容器中。 那么可以猜想到这里的实现原理也一定是一样的，定位到 AutoConfigurationImportSelector这个类中的 selectImports方法 。 本质上来说，其实EnableAutoConfiguration会帮助 springboot应用把所有符合@Configuration配置都加载到当前SpringBoot创建的IoC容器，而这里面借助了Spring框架提供的一个工具类SpringFactoriesLoader的支持。以及用到了Spring提供的条件注解 @Conditional，选择性的针对需要加载的bean进行条件过滤 AutoConfigurationImportSelector 我们来看下AutoConfigurationImportSelector源码下的selectImports方法 1234567891011121314@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; //加载spring-autoconfigure-metadata.properties配置文件中的数据 AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); //通过getAutoConfigurationEntry获取需要动态加载的class AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); //返回需要交给spring进行注入的类 return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());&#125; AutoConfigurationMetadataLoader 的源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final class AutoConfigurationMetadataLoader &#123; protected static final String PATH = \"META-INF/\" + \"spring-autoconfigure-metadata.properties\"; private AutoConfigurationMetadataLoader() &#123; &#125; public static AutoConfigurationMetadata loadMetadata(ClassLoader classLoader) &#123; return loadMetadata(classLoader, PATH); &#125; static AutoConfigurationMetadata loadMetadata(ClassLoader classLoader, String path) &#123; try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null) ? classLoader.getResources(path) : ClassLoader.getSystemResources(path); Properties properties = new Properties(); while (urls.hasMoreElements()) &#123; properties.putAll(PropertiesLoaderUtils.loadProperties(new UrlResource(urls.nextElement()))); &#125; return loadMetadata(properties); &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(\"Unable to load @ConditionalOnClass location [\" + path + \"]\", ex); &#125; &#125; static AutoConfigurationMetadata loadMetadata(Properties properties) &#123; return new PropertiesAutoConfigurationMetadata(properties); &#125; /** * &#123;@link AutoConfigurationMetadata&#125; implementation backed by a properties file. */ private static class PropertiesAutoConfigurationMetadata implements AutoConfigurationMetadata &#123; private final Properties properties; PropertiesAutoConfigurationMetadata(Properties properties) &#123; this.properties = properties; &#125; @Override public boolean wasProcessed(String className) &#123; return this.properties.containsKey(className); &#125; @Override public Integer getInteger(String className, String key) &#123; return getInteger(className, key, null); &#125; @Override public Integer getInteger(String className, String key, Integer defaultValue) &#123; String value = get(className, key); return (value != null) ? Integer.valueOf(value) : defaultValue; &#125; @Override public Set&lt;String&gt; getSet(String className, String key) &#123; return getSet(className, key, null); &#125; @Override public Set&lt;String&gt; getSet(String className, String key, Set&lt;String&gt; defaultValue) &#123; String value = get(className, key); return (value != null) ? StringUtils.commaDelimitedListToSet(value) : defaultValue; &#125; @Override public String get(String className, String key) &#123; return get(className, key, null); &#125; @Override public String get(String className, String key, String defaultValue) &#123; String value = this.properties.getProperty(className + \".\" + key); return (value != null) ? value : defaultValue; &#125; &#125;&#125; 上述selectImports方法就返回了需要springboot自动装配的一些bean，通过String[]的形式返回需要装配的bean的name，但是这个方法的在真正返回需要装配的bean的name之前，还做了很多操作。做了些动态过滤的操作。 第一步是通过loadMetadata加载当前classpath下的spring-autoconfigure-metadata.properties文件，这个文件里面配置了所有动态加载的条件。第二步是通过getAutoConfigurationEntry获取需要动态加载的class，这一步具体源码如下： 12345678910111213141516protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); //下面这一步是去加载classpath下的spring.factories文件中的实例 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125; getCandidateConfigurations这个详细源码如下： 1234567protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you \" + \"are using a custom packaging, make sure that file is correct.\"); return configurations;&#125; Spring 工厂加载机制Spring 工厂加载机制，即 Spring Factories Loader，核心逻辑是使用 SpringFactoriesLoader加载由用户实现的类，并配置在约定好的META-INF/spring.factories 路径下，该机制可以为框架上下文动态的增加扩展。该机制类似于 Java SPI，给用户提供可扩展的钩子，从而达到对框架的自定义扩展功能。 这里SpringFactoriesLoader 的作用就是从classpath/META-INF/spring.factories文件中，根据key来 加载对应的类到spring IoC容器中。 可以看出这里就是加载当前classpath下的所有的spring.factories文件中的内容。下面就是spring.factories中EnableAutoConfiguration的配置。这些如果没有AutoConfigurationImportSelector的过滤操作，这里所有配置的值，都会在getCandidateConfigurations方法中会返回给IOC容器，springboot会自动装载这些类。 1234567891011121314151617181920212223# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.cloud.CloudServiceConnectorsAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\ SpringBoot项目启动时，就是加载上述XXAutoConfiguration从而实现自动装配。 总结：@EnableAutoConfiguration作用就是从classpath中搜寻所有的META-INF/spring.factories配置文件，并将其中org.springframework.boot.autoconfigure.EnableutoConfiguration对应的配置项通过反射实例化为对应的标注了@Configuration的JavaConfig形式的IoC容器配置类，然后汇总为一个并加载到IoC容器。这些功能配置类要生效的话，会去classpath中找是否有该类的依赖类（也就是pom.xml必须有对应功能的jar包才行）并且配置类里面注入了默认属性值类，功能类可以引用并赋默认值。生成功能类的原则是自定义优先，没有自定义时才会使用自动装配类。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"SpringBoot之Tomcat自动配置","slug":"tomcat-auto-configuration-in-springboot","date":"2021-03-11T13:34:57.000Z","updated":"2022-09-17T14:13:56.184Z","comments":false,"path":"springboot/tomcat-auto-configuration-in-springboot/","link":"","permalink":"https://www.cicoding.cn/springboot/tomcat-auto-configuration-in-springboot/","excerpt":"","text":"准备工作我们知道SpringBoot的自动装配的秘密在org.springframework.boot.autoconfigure包下的spring.factories文件中，而嵌入Tomcat的原理就在这个文件中加载的一个配置类：org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Configuration@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@ConditionalOnClass(ServletRequest.class)@ConditionalOnWebApplication(type = Type.SERVLET)@EnableConfigurationProperties(ServerProperties.class)@Import(&#123; ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class, ServletWebServerFactoryConfiguration.EmbeddedTomcat.class, ServletWebServerFactoryConfiguration.EmbeddedJetty.class, ServletWebServerFactoryConfiguration.EmbeddedUndertow.class &#125;)public class ServletWebServerFactoryAutoConfiguration &#123; @Bean public ServletWebServerFactoryCustomizer servletWebServerFactoryCustomizer( ServerProperties serverProperties) &#123; return new ServletWebServerFactoryCustomizer(serverProperties); &#125; @Bean @ConditionalOnClass(name = \"org.apache.catalina.startup.Tomcat\") public TomcatServletWebServerFactoryCustomizer tomcatServletWebServerFactoryCustomizer( ServerProperties serverProperties) &#123; return new TomcatServletWebServerFactoryCustomizer(serverProperties); &#125; /** * Registers a &#123;@link WebServerFactoryCustomizerBeanPostProcessor&#125;. Registered via * &#123;@link ImportBeanDefinitionRegistrar&#125; for early registration. */ public static class BeanPostProcessorsRegistrar implements ImportBeanDefinitionRegistrar, BeanFactoryAware &#123; private ConfigurableListableBeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; if (beanFactory instanceof ConfigurableListableBeanFactory) &#123; this.beanFactory = (ConfigurableListableBeanFactory) beanFactory; &#125; &#125; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; if (this.beanFactory == null) &#123; return; &#125; registerSyntheticBeanIfMissing(registry, \"webServerFactoryCustomizerBeanPostProcessor\", WebServerFactoryCustomizerBeanPostProcessor.class); registerSyntheticBeanIfMissing(registry, \"errorPageRegistrarBeanPostProcessor\", ErrorPageRegistrarBeanPostProcessor.class); &#125; private void registerSyntheticBeanIfMissing(BeanDefinitionRegistry registry, String name, Class&lt;?&gt; beanClass) &#123; if (ObjectUtils.isEmpty( this.beanFactory.getBeanNamesForType(beanClass, true, false))) &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(beanClass); beanDefinition.setSynthetic(true); registry.registerBeanDefinition(name, beanDefinition); &#125; &#125; &#125;&#125; 首先看一下上方的几个注解 @AutoConfigureOrder这个注解是决定配置类的加载顺序的，当注解里的值越小越先加载，而Ordered.HIGHEST_PRECEDENCE的值是Integer.MIN_VALUE也就是说这个类肯定是最先加载的那一批 @ConditionalOnXXX在之前的文章中已经无数次提到了，就不再阐述了 @EnableConfigurationProperties开启ServerProperties类的属性值配置。而这个类里面包含的就是Web服务的配置 1234567891011121314151617181920212223242526272829303132333435@ConfigurationProperties(prefix = \"server\", ignoreUnknownFields = true)public class ServerProperties &#123; private Integer port; private InetAddress address; @NestedConfigurationProperty private final ErrorProperties error = new ErrorProperties(); private Boolean useForwardHeaders; private String serverHeader; private int maxHttpHeaderSize = 0; // bytes private Duration connectionTimeout; @NestedConfigurationProperty private Ssl ssl; @NestedConfigurationProperty private final Compression compression = new Compression(); @NestedConfigurationProperty private final Http2 http2 = new Http2(); private final Servlet servlet = new Servlet(); private final Tomcat tomcat = new Tomcat(); private final Jetty jetty = new Jetty(); private final Undertow undertow = new Undertow();&#125; 这个类的代码太多了，这里就不一一贴出来了，我们平常在application.properties中配置的server.xxx就是这个类中属性 @Import引入了4个类，看都是什么吧 BeanPostProcessorsRegistrar 123456789101112131415161718192021222324252627public static class BeanPostProcessorsRegistrar implements ImportBeanDefinitionRegistrar, BeanFactoryAware &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; if (this.beanFactory == null) &#123; return; &#125; registerSyntheticBeanIfMissing(registry, \"webServerFactoryCustomizerBeanPostProcessor\", WebServerFactoryCustomizerBeanPostProcessor.class); registerSyntheticBeanIfMissing(registry, \"errorPageRegistrarBeanPostProcessor\", ErrorPageRegistrarBeanPostProcessor.class); &#125; private void registerSyntheticBeanIfMissing(BeanDefinitionRegistry registry, String name, Class&lt;?&gt; beanClass) &#123; if (ObjectUtils.isEmpty( this.beanFactory.getBeanNamesForType(beanClass, true, false))) &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(beanClass); beanDefinition.setSynthetic(true); registry.registerBeanDefinition(name, beanDefinition); &#125; &#125; &#125; 这个类注册了两个bean：WebServerFactoryCustomizerBeanPostProcessor和ErrorPageRegistrarBeanPostProcessor关于这两个bean的作用稍后再详细介绍 EmbeddedTomcat 1234567891011@Configuration@ConditionalOnClass(&#123; Servlet.class, Tomcat.class, UpgradeProtocol.class &#125;)@ConditionalOnMissingBean(value = ServletWebServerFactory.class, search = SearchStrategy.CURRENT)public static class EmbeddedTomcat &#123; @Bean public TomcatServletWebServerFactory tomcatServletWebServerFactory() &#123; return new TomcatServletWebServerFactory(); &#125;&#125; 这个类会在存在Tomcat相关jar包时添加一个TomcatServletWebServerFactorybean 其他两个相信大家都知道怎么回事了 除了这些这个类还注入了两个类ServletWebServerFactoryCustomizer和TomcatServletWebServerFactoryCustomizer 现在前期准备工作已经做好了，看一下这个Tomcat是如何启动的吧 启动启动入口在ServletWebServerApplicationContext中的onRefresh方法 123456789protected void onRefresh() &#123; super.onRefresh(); try &#123; createWebServer(); &#125; catch (Throwable ex) &#123; throw new ApplicationContextException(\"Unable to start web server\", ex); &#125;&#125; Tomcat的启动就在createWebServer方法里面了 12345678910111213141516171819private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); //第一次访问的时候两个对象都为空 if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = getWebServerFactory(); this.webServer = factory.getWebServer(getSelfInitializer()); &#125; else if (servletContext != null) &#123; try &#123; getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException(\"Cannot initialize servlet context\", ex); &#125; &#125; initPropertySources();&#125; 首先看一下getWebServerFactory 1234567891011121314151617protected ServletWebServerFactory getWebServerFactory() &#123; // 这里获取的beanname就是上方注册的tomcatServletWebServerFactory了 String[] beanNames = getBeanFactory() .getBeanNamesForType(ServletWebServerFactory.class); if (beanNames.length == 0) &#123; throw new ApplicationContextException( \"Unable to start ServletWebServerApplicationContext due to missing \" + \"ServletWebServerFactory bean.\"); &#125; if (beanNames.length &gt; 1) &#123; throw new ApplicationContextException( \"Unable to start ServletWebServerApplicationContext due to multiple \" + \"ServletWebServerFactory beans : \" + StringUtils.arrayToCommaDelimitedString(beanNames)); &#125; return getBeanFactory().getBean(beanNames[0], ServletWebServerFactory.class);&#125; 准备环境里注册的bean现在出来一个了。注意，上方还注册了一个后置处理器EmbeddedServletContainerCustomizerBeanPostProcessor，获取beantomcatServletWebServerFactory的时候就会执行后置处理器的postProcessBeforeInitialization方法 123456789101112131415161718192021222324252627282930public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof WebServerFactory) &#123; postProcessBeforeInitialization((WebServerFactory) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization(WebServerFactory webServerFactory) &#123; LambdaSafe .callbacks(WebServerFactoryCustomizer.class, getCustomizers(), webServerFactory) .withLogger(WebServerFactoryCustomizerBeanPostProcessor.class) .invoke((customizer) -&gt; customizer.customize(webServerFactory));&#125;private Collection&lt;WebServerFactoryCustomizer&lt;?&gt;&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;&gt;(getWebServerFactoryCustomizerBeans()); this.customizers.sort(AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;@SuppressWarnings(&#123; \"unchecked\", \"rawtypes\" &#125;)private Collection&lt;WebServerFactoryCustomizer&lt;?&gt;&gt; getWebServerFactoryCustomizerBeans() &#123; return (Collection) this.beanFactory .getBeansOfType(WebServerFactoryCustomizer.class, false, false).values();&#125; 这个处理器的作用是获得所有定制器，然后执行定制器的方法 接着往下看这个时候就可以启动Tomcat了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public WebServer getWebServer(ServletContextInitializer... initializers) &#123; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat);&#125;protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123; return new TomcatWebServer(tomcat, getPort() &gt;= 0);&#125;public TomcatWebServer(Tomcat tomcat, boolean autoStart) &#123; Assert.notNull(tomcat, \"Tomcat Server must not be null\"); this.tomcat = tomcat; this.autoStart = autoStart; initialize();&#125;private void initialize() throws WebServerException &#123; TomcatWebServer.logger.info(\"Tomcat initialized with port(s): \" + getPortsDescription(false)); synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123; // Remove service connectors so that protocol binding doesn't // happen when the service is started. removeServiceConnectors(); &#125; &#125;); // Start the server to trigger initialization listeners this.tomcat.start(); // We can re-throw failure exception directly in the main thread rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; // Naming is not enabled. Continue &#125; // Unlike Jetty, all Tomcat threads are daemon threads. We create a // blocking non-daemon to stop immediate shutdown startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; throw new WebServerException(\"Unable to start embedded Tomcat\", ex); &#125; &#125;&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"SpringBoot健康检查实现原理","slug":"Implementation-principle-of-springboot-health-check","date":"2021-03-11T13:31:19.000Z","updated":"2022-09-17T14:13:56.178Z","comments":false,"path":"springboot/Implementation-principle-of-springboot-health-check/","link":"","permalink":"https://www.cicoding.cn/springboot/Implementation-principle-of-springboot-health-check/","excerpt":"","text":"SpringBoot自动装配的套路，直接看spring.factories文件，当我们使用的时候只需要引入如下依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 然后在org.springframework.boot.spring-boot-actuator-autoconfigure包下去就可以找到这个文件 自动装配查看这个文件发现引入了很多的配置类，这里先关注一下XXXHealthIndicatorAutoConfiguration系列的类，这里咱们拿第一个RabbitHealthIndicatorAutoConfiguration为例来解析一下。看名字就知道这个是RabbitMQ的健康检查的自动配置类 12345678910111213141516171819202122@Configuration@ConditionalOnClass(RabbitTemplate.class)@ConditionalOnBean(RabbitTemplate.class)@ConditionalOnEnabledHealthIndicator(\"rabbit\")@AutoConfigureBefore(HealthIndicatorAutoConfiguration.class)@AutoConfigureAfter(RabbitAutoConfiguration.class)public class RabbitHealthIndicatorAutoConfiguration extends CompositeHealthIndicatorConfiguration&lt;RabbitHealthIndicator, RabbitTemplate&gt; &#123; private final Map&lt;String, RabbitTemplate&gt; rabbitTemplates; public RabbitHealthIndicatorAutoConfiguration( Map&lt;String, RabbitTemplate&gt; rabbitTemplates) &#123; this.rabbitTemplates = rabbitTemplates; &#125; @Bean @ConditionalOnMissingBean(name = \"rabbitHealthIndicator\") public HealthIndicator rabbitHealthIndicator() &#123; return createHealthIndicator(this.rabbitTemplates); &#125;&#125; 按照以往的惯例，先解析注解 @ConditionalOnXXX系列又出现了，前两个就是说如果当前存在RabbitTemplate这个bean也就是说我们的项目中使用到了RabbitMQ才能进行下去 @ConditionalOnEnabledHealthIndicator这个注解很明显是SpringBoot actuator自定义的注解，看一下吧 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495@Conditional(OnEnabledHealthIndicatorCondition.class)public @interface ConditionalOnEnabledHealthIndicator &#123; String value();&#125;class OnEnabledHealthIndicatorCondition extends OnEndpointElementCondition &#123; OnEnabledHealthIndicatorCondition() &#123; super(\"management.health.\", ConditionalOnEnabledHealthIndicator.class); &#125;&#125;public abstract class OnEndpointElementCondition extends SpringBootCondition &#123; private final String prefix; private final Class&lt;? extends Annotation&gt; annotationType; protected OnEndpointElementCondition(String prefix, Class&lt;? extends Annotation&gt; annotationType) &#123; this.prefix = prefix; this.annotationType = annotationType; &#125; @Override public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; AnnotationAttributes annotationAttributes = AnnotationAttributes .fromMap(metadata.getAnnotationAttributes(this.annotationType.getName())); String endpointName = annotationAttributes.getString(\"value\"); ConditionOutcome outcome = getEndpointOutcome(context, endpointName); if (outcome != null) &#123; return outcome; &#125; return getDefaultEndpointsOutcome(context); &#125; protected ConditionOutcome getEndpointOutcome(ConditionContext context, String endpointName) &#123; Environment environment = context.getEnvironment(); String enabledProperty = this.prefix + endpointName + \".enabled\"; if (environment.containsProperty(enabledProperty)) &#123; boolean match = environment.getProperty(enabledProperty, Boolean.class, true); return new ConditionOutcome(match, ConditionMessage.forCondition(this.annotationType).because( this.prefix + endpointName + \".enabled is \" + match)); &#125; return null; &#125; protected ConditionOutcome getDefaultEndpointsOutcome(ConditionContext context) &#123; boolean match = Boolean.valueOf(context.getEnvironment() .getProperty(this.prefix + \"defaults.enabled\", \"true\")); return new ConditionOutcome(match, ConditionMessage.forCondition(this.annotationType).because( this.prefix + \"defaults.enabled is considered \" + match)); &#125;&#125;public abstract class SpringBootCondition implements Condition &#123; private final Log logger = LogFactory.getLog(getClass()); @Override public final boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; String classOrMethodName = getClassOrMethodName(metadata); try &#123; ConditionOutcome outcome = getMatchOutcome(context, metadata); logOutcome(classOrMethodName, outcome); recordEvaluation(context, classOrMethodName, outcome); return outcome.isMatch(); &#125; catch (NoClassDefFoundError ex) &#123; throw new IllegalStateException( \"Could not evaluate condition on \" + classOrMethodName + \" due to \" + ex.getMessage() + \" not \" + \"found. Make sure your own configuration does not rely on \" + \"that class. This can also happen if you are \" + \"@ComponentScanning a springframework package (e.g. if you \" + \"put a @ComponentScan in the default package by mistake)\", ex); &#125; catch (RuntimeException ex) &#123; throw new IllegalStateException( \"Error processing condition on \" + getName(metadata), ex); &#125; &#125; private void recordEvaluation(ConditionContext context, String classOrMethodName, ConditionOutcome outcome) &#123; if (context.getBeanFactory() != null) &#123; ConditionEvaluationReport.get(context.getBeanFactory()) .recordConditionEvaluation(classOrMethodName, this, outcome); &#125; &#125;&#125; 上方的入口方法是SpringBootCondition类的matches方法，getMatchOutcome 这个方法则是子类OnEndpointElementCondition的，这个方法首先会去环境变量中查找是否存在management.health.rabbit.enabled属性，如果没有的话则去查找management.health.defaults.enabled属性，如果这个属性还没有的话则设置默认值为true 当这里返回true时整个RabbitHealthIndicatorAutoConfiguration类的自动配置才能继续下去 @AutoConfigureBefore既然这样那就先看看类HealthIndicatorAutoConfiguration都是干了啥再回来吧 123456789101112131415161718192021222324252627@Configuration@EnableConfigurationProperties(&#123; HealthIndicatorProperties.class &#125;)public class HealthIndicatorAutoConfiguration &#123; private final HealthIndicatorProperties properties; public HealthIndicatorAutoConfiguration(HealthIndicatorProperties properties) &#123; this.properties = properties; &#125; @Bean @ConditionalOnMissingBean(&#123; HealthIndicator.class, ReactiveHealthIndicator.class &#125;) public ApplicationHealthIndicator applicationHealthIndicator() &#123; return new ApplicationHealthIndicator(); &#125; @Bean @ConditionalOnMissingBean(HealthAggregator.class) public OrderedHealthAggregator healthAggregator() &#123; OrderedHealthAggregator healthAggregator = new OrderedHealthAggregator(); if (this.properties.getOrder() != null) &#123; healthAggregator.setStatusOrder(this.properties.getOrder()); &#125; return healthAggregator; &#125;&#125; 首先这个类引入了配置文件HealthIndicatorProperties这个配置类是系统状态相关的配置 1234567@ConfigurationProperties(prefix = \"management.health.status\")public class HealthIndicatorProperties &#123; private List&lt;String&gt; order = null; private final Map&lt;String, Integer&gt; httpMapping = new HashMap&lt;&gt;();&#125; 接着就是注册了2个beanApplicationHealthIndicator和OrderedHealthAggregator 这两个bean的作用稍后再说，现在回到RabbitHealthIndicatorAutoConfiguration类 @AutoConfigureAfter这个对整体逻辑没影响，暂且不提 类中注册了一个beanHealthIndicator这个bean的创建逻辑是在父类中的 1234567891011121314151617181920212223242526272829303132333435public abstract class CompositeHealthIndicatorConfiguration&lt;H extends HealthIndicator, S&gt; &#123; @Autowired private HealthAggregator healthAggregator; protected HealthIndicator createHealthIndicator(Map&lt;String, S&gt; beans) &#123; if (beans.size() == 1) &#123; return createHealthIndicator(beans.values().iterator().next()); &#125; CompositeHealthIndicator composite = new CompositeHealthIndicator( this.healthAggregator); for (Map.Entry&lt;String, S&gt; entry : beans.entrySet()) &#123; composite.addHealthIndicator(entry.getKey(), createHealthIndicator(entry.getValue())); &#125; return composite; &#125; @SuppressWarnings(\"unchecked\") protected H createHealthIndicator(S source) &#123; Class&lt;?&gt;[] generics = ResolvableType .forClass(CompositeHealthIndicatorConfiguration.class, getClass()) .resolveGenerics(); Class&lt;H&gt; indicatorClass = (Class&lt;H&gt;) generics[0]; Class&lt;S&gt; sourceClass = (Class&lt;S&gt;) generics[1]; try &#123; return indicatorClass.getConstructor(sourceClass).newInstance(source); &#125; catch (Exception ex) &#123; throw new IllegalStateException(\"Unable to create indicator \" + indicatorClass + \" for source \" + sourceClass, ex); &#125; &#125;&#125; 首先这里注入了一个对象HealthAggregator，这个对象就是刚才注册的OrderedHealthAggregator 第一个createHealthIndicator方法执行逻辑为：如果传入的beans的size 为1,则调用createHealthIndicator创建HealthIndicator 否则创建CompositeHealthIndicator,遍历传入的beans,依次创建HealthIndicator,加入到CompositeHealthIndicator中 第二个createHealthIndicator的执行逻辑为：获得CompositeHealthIndicatorConfiguration中的泛型参数根据泛型参数H对应的class和S对应的class,在H对应的class中找到声明了参数为S类型的构造器进行实例化 最后这里创建出来的bean为RabbitHealthIndicator 回忆起之前学习健康检查的使用时，如果我们需要自定义健康检查项时一般的操作都是实现HealthIndicator接口，由此可以猜测RabbitHealthIndicator应该也是这样做的。观察这个类的继承关系可以发现这个类继承了一个实现实现此接口的类AbstractHealthIndicator，而RabbitMQ的监控检查流程则如下代码所示 12345678910111213141516171819202122232425 //这个方法是AbstractHealthIndicator的public final Health health() &#123; Health.Builder builder = new Health.Builder(); try &#123; doHealthCheck(builder); &#125; catch (Exception ex) &#123; if (this.logger.isWarnEnabled()) &#123; String message = this.healthCheckFailedMessage.apply(ex); this.logger.warn(StringUtils.hasText(message) ? message : DEFAULT_MESSAGE, ex); &#125; builder.down(ex); &#125; return builder.build(); &#125;//下方两个方法是由类RabbitHealthIndicator实现的protected void doHealthCheck(Health.Builder builder) throws Exception &#123; builder.up().withDetail(\"version\", getVersion()); &#125; private String getVersion() &#123; return this.rabbitTemplate.execute((channel) -&gt; channel.getConnection() .getServerProperties().get(\"version\").toString()); &#125; 健康检查上方一系列的操作之后，其实就是搞出了一个RabbitMQ的HealthIndicator实现类，而负责检查RabbitMQ健康不健康也是这个类来负责的。由此我们可以想象到如果当前环境存在MySQL、Redis、ES等情况应该也是这么个操作 那么接下来无非就是当有调用方访问如下地址时，分别调用整个系统的所有的HealthIndicator的实现类的health方法即可了 1http://ip:port/actuator/health HealthEndpointAutoConfiguration上边说的这个操作过程就在类HealthEndpointAutoConfiguration中，这个配置类同样也是在spring.factories文件中引入的 12345678@Configuration@EnableConfigurationProperties(&#123;HealthEndpointProperties.class, HealthIndicatorProperties.class&#125;)@AutoConfigureAfter(&#123;HealthIndicatorAutoConfiguration.class&#125;)@Import(&#123;HealthEndpointConfiguration.class, HealthEndpointWebExtensionConfiguration.class&#125;)public class HealthEndpointAutoConfiguration &#123; public HealthEndpointAutoConfiguration() &#123; &#125;&#125; 这里重点的地方在于引入的HealthEndpointConfiguration这个类 1234567891011@Configurationclass HealthEndpointConfiguration &#123; @Bean @ConditionalOnMissingBean @ConditionalOnEnabledEndpoint public HealthEndpoint healthEndpoint(ApplicationContext applicationContext) &#123; return new HealthEndpoint(HealthIndicatorBeansComposite.get(applicationContext)); &#125;&#125; 这个类只是构建了一个类HealthEndpoint，这个类我们可以理解为一个SpringMVC的Controller，也就是处理如下请求的 1http://ip:port/actuator/health 那么首先看一下它的构造方法传入的是个啥对象吧 1234567891011public static HealthIndicator get(ApplicationContext applicationContext) &#123; HealthAggregator healthAggregator = getHealthAggregator(applicationContext); Map&lt;String, HealthIndicator&gt; indicators = new LinkedHashMap&lt;&gt;(); indicators.putAll(applicationContext.getBeansOfType(HealthIndicator.class)); if (ClassUtils.isPresent(\"reactor.core.publisher.Flux\", null)) &#123; new ReactiveHealthIndicators().get(applicationContext) .forEach(indicators::putIfAbsent); &#125; CompositeHealthIndicatorFactory factory = new CompositeHealthIndicatorFactory(); return factory.createHealthIndicator(healthAggregator, indicators); &#125; 跟我们想象中的一样，就是通过Spring容器获取所有的HealthIndicator接口的实现类，我这里只有几个默认的和RabbitMQ 然后都放入了其中一个聚合的实现类CompositeHealthIndicator中 既然HealthEndpoint构建好了，那么只剩下最后一步处理请求了 1234567891011@Endpoint(id = \"health\")public class HealthEndpoint &#123; private final HealthIndicator healthIndicator; @ReadOperation public Health health() &#123; return this.healthIndicator.health(); &#125;&#125; 刚刚我们知道，这个类是通过CompositeHealthIndicator构建的，所以health方法的实现就在这个类中 123456789public Health health() &#123; Map&lt;String, Health&gt; healths = new LinkedHashMap&lt;&gt;(); for (Map.Entry&lt;String, HealthIndicator&gt; entry : this.indicators.entrySet()) &#123; //循环调用 healths.put(entry.getKey(), entry.getValue().health()); &#125; //对结果集排序 return this.healthAggregator.aggregate(healths); &#125; 至此SpringBoot的健康检查实现原理全部解析完成","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"SpringBoot源码解析创建SpringApplication对象实例","slug":"creating-springapplication-object-instance-by-analyzing-springboot-source-code","date":"2021-03-10T08:23:15.000Z","updated":"2022-09-17T14:13:56.180Z","comments":false,"path":"springboot/creating-springapplication-object-instance-by-analyzing-springboot-source-code/","link":"","permalink":"https://www.cicoding.cn/springboot/creating-springapplication-object-instance-by-analyzing-springboot-source-code/","excerpt":"","text":"上篇文章中的main方法来分析SpringApplication这个类 123456@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 点击run方法一路跟踪下来，发现首先做的是实例化SpringApplication对象实例 123456789101112131415161718192021public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args); &#125; public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args); &#125; public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources); &#125;public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = deduceWebApplicationType(); setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &#125; 首先看一下deduceWebApplicationType方法 123456789101112private WebApplicationType deduceWebApplicationType() &#123; if (ClassUtils.isPresent(\"org.springframework.web.reactive.DispatcherHandler\", (ClassLoader)null) &amp;&amp; !ClassUtils.isPresent(\"org.springframework.web.servlet.DispatcherServlet\", (ClassLoader)null)) &#123; return WebApplicationType.REACTIVE; &#125; for (String className : \"javax.servlet.Servlet\", org.springframework.web.context.ConfigurableWebApplicationContext\") &#123; if (!ClassUtils.isPresent(className, null)) &#123; return WebApplicationType.NONE; &#125; &#125; return WebApplicationType.SERVLET; &#125; &#125; 大抵意思就是根据当前项目中是否存在上方的几个类来推断出当前的web环境，这里因为SpringBoot默认使用的web框架是SpringMVC，所以最后返回结果为WebApplicationType.SERVLET 加载所有的ApplicationContextInitializer和ApplicationListener的实现类 1234567private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); Set&lt;String&gt; names = new LinkedHashSet(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = this.createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &#125; 可以看到主要还是用的SpringFactoriesLoader这个类去加载这两个接口的实现类，加载到类以后使用反射的方式构造出这些类的实例，然后根据这些实现类上的Order注解的值进行排序 关于这些实现类的具体作用请关注后续的文章 最后一行的意义是找到入口方法main所在的类，赋值给全局变量mainApplicationClass","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"SpringBoot到底run了什么","slug":"what-exactly-does-springapplication-run","date":"2021-03-10T01:23:15.000Z","updated":"2022-09-17T14:13:56.184Z","comments":false,"path":"springboot/what-exactly-does-springapplication-run/","link":"","permalink":"https://www.cicoding.cn/springboot/what-exactly-does-springapplication-run/","excerpt":"","text":"我们详细描述了SpringApplication对象实例的创建过程，本篇文章继续看run方法的执行逻辑吧 123456789101112131415public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //后面还有，本篇文章就解析到这。。。。&#125; 第一行使用了StopWatch来记录开始时间 设置了java.awt.headless环境变量，在网上了解了一下这个变量的相关信息 Headless模式是系统的一种配置模式。在系统可能缺少显示设备、键盘或鼠标这些外设的情况下可以使用该模式 个人理解为是一些图形相关的组件能否使用的开关，欢迎各位大佬指正 接着遍历所有构造SpringApplication实例时加载的SpringApplicationRunListener，调用它们的started方法 这里构造时仅仅加载了一个EventPublishingRunListener类，所以咱们就来解析一下这个东东 1234public void starting() &#123; this.initialMulticaster.multicastEvent( new ApplicationStartingEvent(this.application, this.args));&#125; 可以看到这里调用了SimpleApplicationEventMulticaster类的multicastEvent方法并且传入了ApplicationStartingEvent对象，看名字就知道了这个是SpringBoot启动事件 123456789101112public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); &#125; &#125;&#125; 其中获取监听器使用的是getApplicationListeners方法，这个方法中主要就是从最启动时获取的所有监听器和这个事件做了下匹配，返回通过匹配的监听器集合 接着就是看是否设置线程池参数，如果有线程池则使用线程池的线程进行操作，否则将同步调用监听器 把所有的命令行启动参数封装成ConfigurableEnvironment对象 准备运行时环境 123456789101112private ConfigurableEnvironment prepareEnvironment( SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); if (!this.webEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()) .convertToStandardEnvironmentIfNecessary(environment); &#125; return environment;&#125; 获取或创建环境getOrCreateEnvironment方法名就很直观，有就直接获取，没有就新建 123456789private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; if (this.webApplicationType == WebApplicationType.SERVLET) &#123; return new StandardServletEnvironment(); &#125; return new StandardEnvironment();&#125; 上篇文章中说过了，咱们是Servlet环境，所以当前方法是返回一个StandardServletEnvironment对象，这个对象的构造过程中调用了customizePropertySources方法（它父类的父类调用的） 12345678910111213protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new StubPropertySource(\"servletConfigInitParams\")); propertySources.addLast(new StubPropertySource(\"servletContextInitParams\")); if (JndiLocatorDelegate.isDefaultJndiEnvironmentAvailable()) &#123; propertySources.addLast(new JndiPropertySource(\"jndiProperties\")); &#125; super.customizePropertySources(propertySources);&#125; //这是它父类的protected void customizePropertySources(MutablePropertySources propertySources) &#123; propertySources.addLast(new MapPropertySource(\"systemProperties\", getSystemProperties())); propertySources.addLast(new SystemEnvironmentPropertySource(\"systemEnvironment\", getSystemEnvironment()));&#125; 可以看出StandardServletEnvironment往propertySources中添加了两个StubPropertySource对象，而它的父类添加了一个包含java系统属性和一个操作系统环境变量的对象 配置 configureEnvironment1234567protected void configureEnvironment(ConfigurableEnvironment environment, String[] args) &#123; // 配置PropertySources configurePropertySources(environment, args); // 配置Profiles configureProfiles(environment, args);&#125; 分别看一下两个方法 配置PropertySources12345678910111213141516171819202122232425protected void configurePropertySources(ConfigurableEnvironment environment, String[] args) &#123; MutablePropertySources sources = environment.getPropertySources(); if (this.defaultProperties != null &amp;&amp; !this.defaultProperties.isEmpty()) &#123; // 存在默认配置将其放到最后位置 sources.addLast( new MapPropertySource(\"defaultProperties\", this.defaultProperties)); &#125; // 如果存在命令行参数则将原有的替换掉 if (this.addCommandLineProperties &amp;&amp; args.length &gt; 0) &#123; String name = CommandLinePropertySource.COMMAND_LINE_PROPERTY_SOURCE_NAME; if (sources.contains(name)) &#123; PropertySource&lt;?&gt; source = sources.get(name); CompositePropertySource composite = new CompositePropertySource(name); composite.addPropertySource(new SimpleCommandLinePropertySource( \"springApplicationCommandLineArgs\", args)); composite.addPropertySource(source); sources.replace(name, composite); &#125; else &#123; // 将其放到第一位置 sources.addFirst(new SimpleCommandLinePropertySource(args)); &#125; &#125;&#125; 这里就体现出了这个命令行参数比应用配置文件的优先级高的情况了 配置Profiles从PropertySources中查找spring.profiles.active属性，存在则将其值添加activeProfiles集合中 123456protected void configureProfiles(ConfigurableEnvironment environment, String[] args) &#123; environment.getActiveProfiles(); Set&lt;String&gt; profiles = new LinkedHashSet&lt;&gt;(this.additionalProfiles); profiles.addAll(Arrays.asList(environment.getActiveProfiles())); environment.setActiveProfiles(StringUtils.toStringArray(profiles));&#125; 发布EnvirongmentPreparedEvent事件绑定环境12345678protected void bindToSpringApplication(ConfigurableEnvironment environment) &#123; try &#123; Binder.get(environment).bind(\"spring.main\", Bindable.ofInstance(this)); &#125; catch (Exception ex) &#123; throw new IllegalStateException(\"Cannot bind to SpringApplication\", ex); &#125;&#125; 转换环境如果web环境变更为NONE则将StandardServletEnvironment转换为StandardEnvironment ConfigurationPropertySources.attach(environment)123456789101112131415public static void attach(Environment environment) &#123; Assert.isInstanceOf(ConfigurableEnvironment.class, environment); MutablePropertySources sources = ((ConfigurableEnvironment) environment) .getPropertySources(); PropertySource&lt;?&gt; attached = sources.get(\"configurationProperties\"); if (attached != null &amp;&amp; attached.getSource() != sources) &#123; sources.remove(\"configurationProperties\"); attached = null; &#125; if (attached == null) &#123; sources.addFirst(new ConfigurationPropertySourcesPropertySource( \"configurationProperties\", new SpringConfigurationPropertySources(sources))); &#125;&#125; 最终这个sources对象的第一个位置放的是它自己，循环引用，这个具体的含义 12345678910111213141516171819202122232425262728public ConfigurableApplicationContext run(String... args) &#123; //。。。 //接上文继续 configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, exceptionReporters, ex); throw new IllegalStateException(ex); &#125; listeners.running(context); return context;&#125; 获取系统属性spring.beaninfo.ignore 123456789private void configureIgnoreBeanInfo(ConfigurableEnvironment environment) &#123; if (System.getProperty( CachedIntrospectionResults.\"spring.beaninfo.ignore\") == null) &#123; Boolean ignore = environment.getProperty(\"spring.beaninfo.ignore\", Boolean.class, Boolean.TRUE); System.setProperty(CachedIntrospectionResults.\"spring.beaninfo.ignore\", ignore.toString()); &#125;&#125; 但是这个属性的作用还真不知道。。 打印banner 根据当前环境创建ApplicationContext 123456789101112131415161718192021222324protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( \"Unable create a default ApplicationContext, \" + \"please specify an ApplicationContextClass\", ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; 基于咱们的Servlet环境，所以创建的ApplicationContext为AnnotationConfigServletWebServerApplicationContext 加载SpringBootExceptionReporter，这个类里包含了SpringBoot启动失败后异常处理相关的组件 123456789private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; prepareContext 这一块还是比较长的 123456789101112131415161718192021222324private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; context.getBeanFactory().registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; context.getBeanFactory().registerSingleton(\"springBootBanner\", printedBanner); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context);&#125; 第一行，将context中相关的environment全部替换 12345public void setEnvironment(ConfigurableEnvironment environment) &#123; super.setEnvironment(environment); // 设置context的environment this.reader.setEnvironment(environment); // 实例化context的reader属性的conditionEvaluator属性 this.scanner.setEnvironment(environment); // 设置context的scanner属性的environment属性&#125; 上下文后处理 1234567891011121314151617protected void postProcessApplicationContext(ConfigurableApplicationContext context) &#123; if (this.beanNameGenerator != null) &#123; context.getBeanFactory().registerSingleton( AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; if (context instanceof GenericApplicationContext) &#123; ((GenericApplicationContext) context) .setResourceLoader(this.resourceLoader); &#125; if (context instanceof DefaultResourceLoader) &#123; ((DefaultResourceLoader) context) .setClassLoader(this.resourceLoader.getClassLoader()); &#125; &#125;&#125; 这一块默认beanNameGenerator和resourceLoader都是空的，只有当我们自定义这两个对象时才会把容器内的bean替换 执行所有的ApplicationContextInitializer的initialize方法 12345678protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument( initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, \"Unable to call initializer.\"); initializer.initialize(context); &#125;&#125; listeners.contextPrepared(context)这是个空方法，没有实现，一个Spring的扩展点 打印profile 注册bean：springApplicationArguments 发布事件 12345678910public void contextLoaded(ConfigurableApplicationContext context) &#123; for (ApplicationListener&lt;?&gt; listener : this.application.getListeners()) &#123; if (listener instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) listener).setApplicationContext(context); &#125; context.addApplicationListener(listener); &#125; this.initialMulticaster.multicastEvent( new ApplicationPreparedEvent(this.application, this.args, context));&#125; 这里不仅发布了ApplicationPreparedEvent事件，还往实现了ApplicationContextAware接口的监听器中注入了context容器 load，其实就是创建了一个BeanDefinitionLoader对象 123456789101112131415161718protected void load(ApplicationContext context, Object[] sources) &#123; if (logger.isDebugEnabled()) &#123; logger.debug( \"Loading source \" + StringUtils.arrayToCommaDelimitedString(sources)); &#125; BeanDefinitionLoader loader = createBeanDefinitionLoader( getBeanDefinitionRegistry(context), sources); if (this.beanNameGenerator != null) &#123; loader.setBeanNameGenerator(this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; loader.setResourceLoader(this.resourceLoader); &#125; if (this.environment != null) &#123; loader.setEnvironment(this.environment); &#125; loader.load();&#125; 容器的初始化refreshContext这个方法最后还是调用的AbstractApplicationContext类的refresh方法，由于篇幅过长这里就不展开了，感兴趣的同学可以参考这篇文章：基于注解的SpringIOC源码解析 123456789101112131415161718192021222324252627282930313233343536373839404142434445public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 记录容器的启动时间、标记“已启动”状态、检查环境变量 prepareRefresh(); // 初始化BeanFactory容器、注册BeanDefinition ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean prepareBeanFactory(beanFactory); try &#123; // 扩展点 postProcessBeanFactory(beanFactory); // 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 方法 invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessor 的实现类 registerBeanPostProcessors(beanFactory); // 初始化MessageSource initMessageSource(); // 初始化事件广播器 initApplicationEventMulticaster(); // 扩展点 onRefresh(); // 注册事件监听器 registerListeners(); // 初始化所有的 singleton beans finishBeanFactoryInitialization(beanFactory); // 广播事件 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // 销毁已经初始化的的Bean destroyBeans(); // 设置 'active' 状态 cancelRefresh(ex); throw ex; &#125; finally &#123; // 清除缓存 resetCommonCaches(); &#125; &#125;&#125; afterRefresh 这里没有任何实现，Spring留给我们的扩展点 停止之前启动的计时装置，然后发送ApplicationStartedEvent事件 调用系统中ApplicationRunner以及CommandLineRunner接口的实现类，关于这两个接口的使用可以参考我的这篇文章：Java项目启动时执行指定方法的几种方式 1234567891011121314private void callRunners(ApplicationContext context, ApplicationArguments args) &#123; List&lt;Object&gt; runners = new ArrayList&lt;&gt;(); runners.addAll(context.getBeansOfType(ApplicationRunner.class).values()); runners.addAll(context.getBeansOfType(CommandLineRunner.class).values()); AnnotationAwareOrderComparator.sort(runners); for (Object runner : new LinkedHashSet&lt;&gt;(runners)) &#123; if (runner instanceof ApplicationRunner) &#123; callRunner((ApplicationRunner) runner, args); &#125; if (runner instanceof CommandLineRunner) &#123; callRunner((CommandLineRunner) runner, args); &#125; &#125;&#125; 异常处理 发送ApplicationReadyEvent事件","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"Java项目启动时执行指定方法的几种方式","slug":"run-specifies-the-method-on-startup","date":"2021-03-10T00:23:15.000Z","updated":"2022-09-17T14:13:56.180Z","comments":false,"path":"springboot/run-specifies-the-method-on-startup/","link":"","permalink":"https://www.cicoding.cn/springboot/run-specifies-the-method-on-startup/","excerpt":"","text":"很多时候我们都会碰到需要在程序启动时去执行的方法，比如说去读取某个配置，预加载缓存，定时任务的初始化等。这里给出几种解决方案供大家参考。 1. 使用@PostConstruct注解 这个注解呢，可以在Spring加载这个类的时候执行一次。来看一下下方代码。 1234567891011121314151617181920@Componentpublic class Test &#123; /** *我第二个执行 */ @Autowired private T t; public Test() &#123; System.out.println(\"我最先执行\"); &#125; /** *我第三个个执行 */ @PostConstruct private void init() &#123; //假装有代码 &#125;&#125; 上方就是@PostConstruct注解的使用方法了，同时也表示了此类被加载时的执行顺序。 2. CommandLineRunner接口 使用CommandLineRunner接口类似于Main方法启动，可以接受一个字符串数组的命令行参数，来看一下实现 1234567@Componentpublic class MyCommandLineRunner implements CommandLineRunner&#123; @Override public void run(String... args) throws Exception&#123; //假装有代码 &#125;&#125; 3. ApplicationRunner 接口 此种方式与实现CommandLineRunner接口的区别就是他的参数是ApplicationArguments 12345678@Order(value = 1)@Componentpublic class MyApplicationRunner implements ApplicationRunner&#123; @Override public void run(ApplicationArguments args) throws Exception&#123; //假装有代码 &#125;&#125; 我们可以看到，此类相比较于第二种方式还增加一个@Order注解，这个注解其实第二种方式也是能加的。 它的作用就是控制类的加载顺序，这个顺序是从小到大的。比如说启动时先去加载Order的value等于1的类，然后去加载等于2的类。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"RocketMQ--消息ACK机制及消费进度管理","slug":"rocketmq-consume-offset-management","date":"2021-02-06T12:26:00.000Z","updated":"2022-06-14T03:07:56.814Z","comments":false,"path":"rocketmq/rocketmq-consume-offset-management/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-consume-offset-management/","excerpt":"","text":"RokectMQ——水平扩展及负载均衡详解 中剖析过，consumer的每个实例是靠队列分配来决定如何消费消息的。那么消费进度具体是如何管理的，又是如何保证消息成功消费的?（RocketMQ有保证消息肯定消费成功的特性,失败则重试）？ 本文将详细解析消息具体是如何ack的，又是如何保证消费肯定成功的。 由于以上工作所有的机制都实现在PushConsumer中，所以本文的原理均只适用于RocketMQ中的PushConsumer即Java客户端中的DefaultPushConsumer。 若使用了PullConsumer模式，类似的工作如何ack，如何保证消费等均需要使用方自己实现。 注：广播消费和集群消费的处理有部分区别，以下均特指集群消费（CLSUTER），广播（BROADCASTING）下部分可能不适用。 保证消费成功PushConsumer为了保证消息肯定消费成功，只有使用方明确表示消费成功，RocketMQ才会认为消息消费成功。中途断电，抛出异常等都不会认为成功——即都会重新投递。 消费的时候，我们需要注入一个消费回调，具体sample代码如下： 12345678consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.println(Thread.currentThread().getName() + &quot; Receive New Messages: &quot; + msgs); doMyJob();//执行真正消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;); 业务实现消费回调的时候，当且仅当此回调函数返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS，RocketMQ才会认为这批消息（默认是1条）是消费完成的。（具体如何ACK见后面章节） 如果这时候消息消费失败，例如数据库异常，余额不足扣款失败等一切业务认为消息需要重试的场景，只要返回ConsumeConcurrentlyStatus.RECONSUME_LATER，RocketMQ就会认为这批消息消费失败了。 为了保证消息是肯定被至少消费成功一次，RocketMQ会把这批消息重发回Broker（topic不是原topic而是这个消费租的RETRY topic），在延迟的某个时间点（默认是10秒，业务可设置）后，再次投递到这个ConsumerGroup。而如果一直这样重复消费都持续失败到一定次数（默认16次），就会投递到DLQ死信队列。应用可以监控死信队列来做人工干预。 注： 如果业务的回调没有处理好而抛出异常，会认为是消费失败当ConsumeConcurrentlyStatus.RECONSUME_LATER处理。 当使用顺序消费的回调MessageListenerOrderly时，由于顺序消费是要前者消费成功才能继续消费，所以没有RECONSUME_LATER的这个状态，只有SUSPEND_CURRENT_QUEUE_A_MOMENT来暂停队列的其余消费，直到原消息不断重试成功为止才能继续消费。 启动的时候从哪里消费当新实例启动的时候，PushConsumer会拿到本消费组broker已经记录好的消费进度（consumer offset），按照这个进度发起自己的第一次Pull请求。 如果这个消费进度在Broker并没有存储起来，证明这个是一个全新的消费组，这时候客户端有几个策略可以选择： 123CONSUME_FROM_LAST_OFFSET //默认策略，从该队列最尾开始消费，即跳过历史消息CONSUME_FROM_FIRST_OFFSET //从队列最开始开始消费，即历史消息（还储存在broker的）全部消费一遍CONSUME_FROM_TIMESTAMP//从某个时间点开始消费，和setConsumeTimestamp()配合使用，默认是半个小时以前 所以，社区中经常有人问：“为什么我设了CONSUME_FROM_LAST_OFFSET，历史的消息还是被消费了”？ 原因就在于只有全新的消费组才会使用到这些策略，老的消费组都是按已经存储过的消费进度继续消费。 对于老消费组想跳过历史消息需要自身做过滤，或者使用先修改消费进度。示例代码请参看：RocketMQ——消息文件过期原理 消息ACK机制RocketMQ是以consumer group+queue为单位是管理消费进度的，以一个consumer offset标记这个这个消费组在这条queue上的消费进度。 如果某已存在的消费组出现了新消费实例的时候，依靠这个组的消费进度，就可以判断第一次是从哪里开始拉取的。 每次消息成功后，本地的消费进度会被更新，然后由定时器定时同步到broker，以此持久化消费进度。 但是每次记录消费进度的时候，只会把一批消息中最小的offset值为消费进度值，如下图： 这钟方式和传统的一条message单独ack的方式有本质的区别。性能上提升的同时，会带来一个潜在的重复问题——由于消费进度只是记录了一个下标，就可能出现拉取了100条消息如 2101-2200的消息，后面99条都消费结束了，只有2101消费一直没有结束的情况。 在这种情况下，RocketMQ为了保证消息肯定被消费成功，消费进度职能维持在2101，直到2101也消费结束了，本地的消费进度才能标记2200消费结束了（注：consumerOffset=2201）。 在这种设计下，就有消费大量重复的风险。如2101在还没有消费完成的时候消费实例突然退出（机器断电，或者被kill）。这条queue的消费进度还是维持在2101，当queue重新分配给新的实例的时候，新的实例从broker上拿到的消费进度还是维持在2101，这时候就会又从2101开始消费，2102-2200这批消息实际上已经被消费过还是会投递一次。 对于这个场景，RocketMQ暂时无能为力，所以业务必须要保证消息消费的幂等性，这也是RocketMQ官方多次强调的态度。 实际上，从源码的角度上看，RocketMQ可能是考虑过这个问题的，截止到3.2.6的版本的源码中，可以看到为了缓解这个问题的影响面，DefaultMQPushConsumer中有个配置consumeConcurrentlyMaxSpan 1234/** * Concurrently max span offset.it has no effect on sequential consumption */private int consumeConcurrentlyMaxSpan = 2000; 这个值默认是2000，当RocketMQ发现本地缓存的消息的最大值-最小值差距大于这个值（2000）的时候，会触发流控——也就是说如果头尾都卡住了部分消息，达到了这个阈值就不再拉取消息。 但作用实际很有限，像刚刚这个例子，2101的消费是死循环，其他消费非常正常的话，是无能为力的。一旦退出，在不人工干预的情况下，2101后所有消息全部重复! Ack卡进度解决方案实际上对于卡住进度的场景，可以选择弃车保帅的方案：把消息卡住那些消息，先ack掉，让进度前移。但要保证这条消息不会因此丢失，ack之前要把消息sendBack回去，这样这条卡住的消息就会必然重复，但会解决潜在的大量重复的场景。 这也是我们公司自己定制的解决方案。 部分源码如下： 1234567891011121314151617181920212223242526class ConsumeRequestWithUnAck implements Runnable &#123; final ConsumeRequest consumeRequest; final long resendAfterIfStillUnAck;//n毫秒没有消费完，就重发 ConsumeRequestWithUnAck(ConsumeRequest consumeRequest,long resendAfterIfStillUnAck) &#123; this.consumeRequest = consumeRequest; this.resendAfterIfStillUnAck = resendAfterIfStillUnAck; &#125; @Override public void run() &#123; //每次消费前，计划延时任务，超时则ack并重发 final WeakReference&lt;ConsumeRequest&gt; crReff = new WeakReference&lt;&gt;(this.consumeRequest); ScheduledFuture scheduledFuture=null; if(!ConsumeDispatcher.this.ackAndResendScheduler.isShutdown()) &#123; scheduledFuture= ConsumeDispatcher.this.ackAndResendScheduler.schedule(new ConsumeTooLongChecker(crReff),resendAfterIfStillUnAck,TimeUnit.MILLISECONDS); &#125; try&#123; this.consumeRequest.run();//正常执行并更新offset &#125; finally &#123; if (scheduledFuture != null) scheduledFuture.cancel(false);//消费结束后,取消任务 &#125; &#125;&#125; 定义了一个装饰器，把原来的ConsumeRequest对象包了一层。 装饰器中，每条消息消费前都会调度一个调度器，定时触发，触发的时候如果发现消息还存在，就执行sendback并ack的操作。 后来RocketMQ显然也发现了这个问题，RocketMQ在3.5.8之后也是采用这样的方案去解决这个问题。只是实现方式上有所不同（事实上我认为RocketMQ的方案还不够完善） 在pushConsumer中 有一个consumeTimeout字段（默认15分钟），用于设置最大的消费超时时间。消费前会记录一个消费的开始时间，后面用于比对。 消费者启动的时候，会定期扫描所有消费的消息，达到这个timeout的那些消息，就会触发sendBack并ack的操作。这里扫描的间隔也是consumeTimeout（单位分钟）的间隔。 核心源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//ConsumeMessageConcurrentlyService.javapublic void start() &#123; this.CleanExpireMsgExecutors.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; cleanExpireMsg(); &#125; &#125;, this.defaultMQPushConsumer.getConsumeTimeout(), this.defaultMQPushConsumer.getConsumeTimeout(), TimeUnit.MINUTES);&#125;//ConsumeMessageConcurrentlyService.javaprivate void cleanExpireMsg() &#123; Iterator&lt;Map.Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.defaultMQPushConsumerImpl.getRebalanceImpl().getProcessQueueTable().entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next(); ProcessQueue pq = next.getValue(); pq.cleanExpiredMsg(this.defaultMQPushConsumer); &#125;&#125;//ProcessQueue.javapublic void cleanExpiredMsg(DefaultMQPushConsumer pushConsumer) &#123; if (pushConsumer.getDefaultMQPushConsumerImpl().isConsumeOrderly()) &#123; return; &#125; int loop = msgTreeMap.size() &lt; 16 ? msgTreeMap.size() : 16; for (int i = 0; i &lt; loop; i++) &#123; MessageExt msg = null; try &#123; this.lockTreeMap.readLock().lockInterruptibly(); try &#123; if (!msgTreeMap.isEmpty() &amp;&amp; System.currentTimeMillis() - Long.parseLong(MessageAccessor.getConsumeStartTimeStamp(msgTreeMap.firstEntry().getValue())) &gt; pushConsumer.getConsumeTimeout() * 60 * 1000) &#123; msg = msgTreeMap.firstEntry().getValue(); &#125; else &#123; break; &#125; &#125; finally &#123; this.lockTreeMap.readLock().unlock(); &#125; &#125; catch (InterruptedException e) &#123; log.error(\"getExpiredMsg exception\", e); &#125; try &#123; pushConsumer.sendMessageBack(msg, 3); log.info(\"send expire msg back. topic=&#123;&#125;, msgId=&#123;&#125;, storeHost=&#123;&#125;, queueId=&#123;&#125;, queueOffset=&#123;&#125;\", msg.getTopic(), msg.getMsgId(), msg.getStoreHost(), msg.getQueueId(), msg.getQueueOffset()); try &#123; this.lockTreeMap.writeLock().lockInterruptibly(); try &#123; if (!msgTreeMap.isEmpty() &amp;&amp; msg.getQueueOffset() == msgTreeMap.firstKey()) &#123; try &#123; msgTreeMap.remove(msgTreeMap.firstKey()); &#125; catch (Exception e) &#123; log.error(\"send expired msg exception\", e); &#125; &#125; &#125; finally &#123; this.lockTreeMap.writeLock().unlock(); &#125; &#125; catch (InterruptedException e) &#123; log.error(\"getExpiredMsg exception\", e); &#125; &#125; catch (Exception e) &#123; log.error(\"send expired msg exception\", e); &#125; &#125;&#125; 通过这个逻辑对比我定制的时间，可以看出有几个不太完善的问题： 消费timeout的时间非常不精确。由于扫描的间隔是15分钟，所以实际上触发的时候，消息是有可能卡住了接近30分钟（15*2）才被清理。 由于定时器一启动就开始调度了，中途这个consumeTimeout再更新也不会生效。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"Spring是如何解决循环依赖的","slug":"how-does-spring-solve-cyclic-dependency","date":"2020-11-08T14:11:23.000Z","updated":"2022-09-17T14:13:56.174Z","comments":true,"path":"spring/how-does-spring-solve-cyclic-dependency/","link":"","permalink":"https://www.cicoding.cn/spring/how-does-spring-solve-cyclic-dependency/","excerpt":"","text":"循环依赖就是N个类中循环嵌套引用，如果在日常开发中我们用new 对象的方式发生这种循环依赖的话程序会在运行时一直循环调用，直至内存溢出报错。下面说一下Spring是如果解决的。 首先，需要明确的是spring对循环依赖的处理有三种情况： ①构造器的循环依赖：这种依赖spring是处理不了的，直 接抛出BeanCurrentlylnCreationException异常。 ②单例模式下的setter循环依赖：通过“三级缓存”处理循环依赖。 ③非单例循环依赖：无法处理。 spring单例对象的初始化大略分为三步： createBeanInstance：实例化，其实也就是调用对象的构造方法实例化对象 populateBean：填充属性，这一步主要是多bean的依赖属性进行填充 initializeBean：调用spring xml中的init 方法。 从上面讲述的单例bean初始化步骤我们可以知道，循环依赖主要发生在第一、第二步。也就是构造器循环依赖和field循环依赖。 接下来，我们具体看看spring是如何处理三种循环依赖的。 1、构造器循环依赖this .singletonsCurrentlylnCreation.add(beanName）将当前正要创建的bean 记录在缓存中 Spring 容器将每一个正在创建的bean 标识符放在一个“当前创建bean 池”中， bean 标识 柏：在创建过程中将一直保持在这个池中，因此如果在创建bean 过程中发现自己已经在“当前 创建bean 池” 里时，将抛出BeanCurrentlylnCreationException 异常表示循环依赖；而对于创建 完毕的bean 将从“ 当前创建bean 池”中清除掉。 2、setter循环依赖Spring为了解决单例的循环依赖问题，使用了三级缓存。 123456/** Cache of singleton objects: bean name –&gt; bean instance */private final Map singletonObjects = new ConcurrentHashMap(256);/** Cache of singleton factories: bean name –&gt; ObjectFactory */private final Map&gt; singletonFactories = new HashMap&gt;(16);/** Cache of early singleton objects: bean name –&gt; bean instance */private final Map earlySingletonObjects = new HashMap(16); 这三级缓存的作用分别是： singletonFactories ： 进入实例化阶段的单例对象工厂的cache （三级缓存） earlySingletonObjects ：完成实例化但是尚未初始化的，提前暴光的单例对象的Cache （二级缓存） singletonObjects：完成初始化的单例对象的cache（一级缓存） 我们在创建bean的时候，会首先从cache中获取这个bean，这个缓存就是sigletonObjects。主要的调用方法是： 123456789101112131415161718192021protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); //isSingletonCurrentlyInCreation()判断当前单例bean是否正在创建中 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); //allowEarlyReference 是否允许从singletonFactories中通过getObject拿到对象 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); //从singletonFactories中移除，并放入earlySingletonObjects中。 //其实也就是从三级缓存移动到了二级缓存 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125; 从上面三级缓存的分析，我们可以知道，Spring解决循环依赖的诀窍就在于singletonFactories这个三级cache。这个cache的类型是ObjectFactory，定义如下： 123public interface ObjectFactory&lt;T&gt; &#123; T getObject() throws BeansException;&#125; 这个接口在AbstractBeanFactory里实现，并在核心方法doCreateBean（）引用下面的方法: 12345678910protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125;&#125; 这段代码发生在createBeanInstance之后，populateBean（）之前，也就是说单例对象此时已经被创建出来(调用了构造器)。这个对象已经被生产出来了，此时将这个对象提前曝光出来，让大家使用。 这样做有什么好处呢？让我们来分析一下“A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了初始化的第一步，并且将自己提前曝光到singletonFactories中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，进去了一级缓存singletonObjects中，而且更加幸运的是，由于B拿到了A的对象引用，所以B现在hold住的A对象完成了初始化。 3、非单例循环依赖对于“prototype”作用域bean, Spring 容器无法完成依赖注入，因为Spring 容器不进行缓 存“prototype”作用域的bean ，因此无法提前暴露一个创建中的bean 。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"循环依赖","slug":"循环依赖","permalink":"https://www.cicoding.cn/tags/循环依赖/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"SpringCloud Alibaba微服务学习之旅","slug":"microservice-alibaba","date":"2020-11-08T14:04:13.000Z","updated":"2022-09-17T14:13:56.155Z","comments":true,"path":"micro-service/microservice-alibaba/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice-alibaba/","excerpt":"","text":"微服务Nacos介绍与安装启动","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Alibaba","slug":"Alibaba","permalink":"https://www.cicoding.cn/tags/Alibaba/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"Springboot 框架 gateway 前后端分离 实现 zuul Ribbon 负载均衡 脱离Eureka实现","slug":"spring-cloud-gateway-zuul-Ribbon-eureka","date":"2020-09-03T08:29:15.000Z","updated":"2022-09-17T14:13:56.186Z","comments":false,"path":"springcloud/spring-cloud-gateway-zuul-Ribbon-eureka/","link":"","permalink":"https://www.cicoding.cn/springcloud/spring-cloud-gateway-zuul-Ribbon-eureka/","excerpt":"","text":"项目后台框架是使用的springboot ，前端使用的是angularJS，中间使用gateway做一层转发。其实也是微服务的思想。那么在gateway这层怎么实现负载均衡。就使用到了zuul，那么可以使用zuul 的Ribbon来实现负载均衡。 123456789101112131415zuul: host: connect-timeout-millis: 5000 socket-timeout-millis: 20000 routes: platform-service: path: /api/** url: http://localhost:8010 stripPrefix: false sensitiveHeaders: image-detect-service: path: /ids/** url: http://localhost:8011 stripPrefix: false sensitiveHeaders: 这个是我们项目原先做了一个配置。主要是zuul实现转发(未使用Ribbon，未使用Eureka)，其中routes下面的 platform-service和image-detect-service是后台的两个独立的项目，他们的RestApi路径使用了不同的标识(这是我们自己定义的规范)。反正实现的效果就是，如果路径是api开头就转发到8010端口，如果是路径是/ids开头那么就转发到8011端口另外一个项目。重写了zuul中的pro前置过滤器能够实现。 接下来实现负载均衡 (接下来我们只对platform-service这个项目进行负载均衡) 首先我们将platform-service这个项目启用两个不同的端口发布起来 先在idea中dev.yml将server:port 修改为8012通过mvn clean compile install -DskipTests将项目编译，然后再target文件夹，将war包拷贝出来，在war包这个文件夹打开cmd命令行，执行 java -jar xxx.war发布 ,然后再在idea中奖port修改为8010，通过idea发布。这样platform-service就在8010和8012发布起来了。 修改配置： 1234567891011121314151617181920212223zuul: host: connect-timeout-millis: 5000 socket-timeout-millis: 20000 routes: platform-service: path: /api/**# url: http://localhost:8010 //注释掉这个url stripPrefix: false sensitiveHeaders: image-detect-service: path: /ids/** url: http://localhost:8011 stripPrefix: false sensitiveHeaders:platform-service: //添加服务配置 ribbon: listofServers: http://localhost:8010，http://localhost:20001ribbon: eureka: enabled: false //声明不依赖eureka 添加的配置 platform-service 是和zuul：rotes：platform-service中同名的。 listOfServices是platfor-service项目的服务列表地址和端口，多个的话使用,将其分割。 ribbon:eureka:enabled：false这个设置的是禁用eureka。 现在就ok了，启动项目访问测试，会发现调用不同的端口访问platform-service，也可以将8010的端口关闭，它会直接去访问8012端口的项目，这就是ribbon实现负载均衡和nginx实现的负载均衡不一样，如果是nginx实现的，如果你upstream的服务宕机了，那么不会自动的去寻找下一个服务。这时候ribbon默认的启动的策略是RoundRobinRule 也就是轮询策略。 我也是最近在研究ribbon负载均衡和集群.现在能够实现负载均衡了。那么在接下来我们在研究怎么去更换策略，如何使用自定义策略实现 “同一个ip下的同一个用户的所有请求被代理到同一个实例”，在接下来的研究中，我会在后面慢慢分享","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}]},{"title":"Java 14的新增功能","slug":"what-is-new-in-java-14","date":"2020-08-20T08:29:15.000Z","updated":"2022-09-17T14:13:56.152Z","comments":false,"path":"java/what-is-new-in-java-14/","link":"","permalink":"https://www.cicoding.cn/java/what-is-new-in-java-14/","excerpt":"","text":"Java 14 reached General Availability on 17 March 2020, download Java 14 here. Java 14 features. JEP 305: Pattern Matching for instanceof (Preview) (developer feature) JEP 343: Packaging Tool (Incubator) JEP 345: NUMA-Aware Memory Allocation for G1 JEP 349: JFR Event Streaming JEP 352: Non-Volatile Mapped Byte Buffers JEP 358: Helpful NullPointerExceptions JEP 359: Records (Preview) (developer feature) JEP 361: Switch Expressions (Standard) (developer feature) JEP 362: Deprecate the Solaris and SPARC Ports JEP 363: Remove the Concurrent Mark Sweep (CMS) Garbage Collector JEP 364: ZGC on macOS JEP 365: ZGC on Windows JEP 366: Deprecate the ParallelScavenge + SerialOld GC Combination JEP 367: Remove the Pack200 Tools and API JEP 368: Text Blocks (Second Preview) (developer feature) JEP 370: Foreign-Memory Access API (Incubator) (developer feature) JEP 305: Pattern Matching for instanceof (Preview)Before Java 14, we use instanceof-and-cast to check the object’s type and cast to a variable. 12345678if (obj instanceof String) &#123; // instanceof String s = (String) obj; // cast if(\"jdk14\".equalsIgnoreCase(s))&#123; //... &#125;&#125;else &#123; System.out.println(\"not a string\");&#125; Now Java 14, we can refactor above code like this: 1234567if (obj instanceof String s) &#123; // instanceof, cast and bind variable in one line. if(\"jdk4\".equalsIgnoreCase(s))&#123; //... &#125;&#125;else &#123; System.out.println(\"not a string\");&#125; if obj is an instance of String, then it is cast to String and assigned to the binding variable s. JEP 343: Packaging Tool (Incubator)New jpackage tool to package a Java application into a platform-specific package. Linux: deb and rpm macOS: pkg and dmg Windows: msi and exe For example, package the JAR file into an exe file on Windows. P.S Update jpackage example here JEP 345: NUMA-Aware Memory Allocation for G1New NUMA-aware memory allocation mode, improves the G1 performance on large machines. Add +XX:+UseNUMA option to enable it. JEP 349: JFR Event StreamingImproved the existing JFR to support event streaming, it means now we can stream the JFR events in real-time, without the need to dump the recorded events to disk and parse it manually. The JDK Flight Recorder (JFR) is a tool for collecting diagnostic and profiling data about a running Java application. Normally, we start a recording, stop it, dump the recorded events to disk for parsing, it works well for profiling, analysis, or debugging. Related JEP 328: Flight Recorder P.S Update JFR Event Streaming example here_ JEP 352: Non-Volatile Mapped Byte BuffersImproved FileChannel API to create MappedByteBuffer that access to non-volatile memory (NVM) – a memory that can retrieve stored data even after having been power cycled. For example, this feature ensures that any changes which might still be in the cache are written back to memory. P.S Only Linux/x64 and Linux/AArch64 OS support this! JEP 358: Helpful NullPointerExceptionsImproved the description of NullPointerExceptions by telling which variable was null. Add -XX:+ShowCodeDetailsInExceptionMessages option to enable this feature. A simple Java file that throws an NullPointerException. Test.java 1234567891011121314151617import java.util.Locale;public class Test &#123; public static void main(String[] args) &#123; String input = null; String result = showUpperCase(input); // NullPointerException System.out.println(result); &#125; public static String showUpperCase(String str)&#123; return str.toUpperCase(Locale.US); &#125;&#125; Before Java 14. 12345$ /usr/lib/jvm/jdk-14/bin/java TestException in thread \"main\" java.lang.NullPointerException at Test.showUpperCase(Test.java:15) at Test.main(Test.java:9) Java 14 with -XX:+ShowCodeDetailsInExceptionMessages option. 123456$ /usr/lib/jvm/jdk-14/bin/java -XX:+ShowCodeDetailsInExceptionMessages TestException in thread \"main\" java.lang.NullPointerException: Cannot invoke \"String.toUpperCase(java.util.Locale)\" because \"&lt;parameter1&gt;\" is null at Test.showUpperCase(Test.java:15) at Test.main(Test.java:9) P.S Please enable this feature by default 🙂 JEP 359: Records (Preview)A new class called record (aka data class), it is a final class, not abstract, and all of its fields are final as well. The record will automatically generate the tedious constructors, public get, equals(), hashCode(), toString() during compile time. P.S No setters, all fields are final. A record or data class, create the class name and variables, and we can start using it. Point.java 1record Point(int x, int y) &#123; &#125; Test.java 123456789101112131415161718192021222324252627public class Test &#123; public static void main(String[] args) &#123; Point p1 = new Point(10, 20); System.out.println(p1.x()); // 10 System.out.println(p1.y()); // 20 Point p2 = new Point(11, 22); System.out.println(p2.x()); // 11 System.out.println(p2.y()); // 22 Point p3 = new Point(10, 20); System.out.println(p3.x()); // 10 System.out.println(p3.y()); // 20 System.out.println(p1.hashCode()); // 330 System.out.println(p2.hashCode()); // 363 System.out.println(p3.hashCode()); // 330 System.out.println(p1.equals(p2)); // false System.out.println(p1.equals(p3)); // true System.out.println(p1.equals(p3)); // true &#125;&#125; Test it with --enable-preview. 1234$ /usr/lib/jvm/jdk-14/bin/javac --enable-preview --release 14 Point.java$ /usr/lib/jvm/jdk-14/bin/javac --enable-preview --release 14 Test.java$ /usr/lib/jvm/jdk-14/bin/java --enable-preview Test Output 123456789101112102011221020330363330falsetruetrue Further eadingFor more record examples, please refer to this Java 14 Record data class P.S Update record or data class example here JEP 361: Switch Expressions (Standard)The switch expression was a preview feature in Java 12 and Java 13; now it is officially JDK standard feature, it means from Java 14 and onward, we can return value via switch expressions without specifying the --enable-preview option. See a recap; we can use yield to return a value from a switch. 123456789101112131415private static int getValueViaYield(String mode) &#123; int result = switch (mode) &#123; case \"a\", \"b\": yield 1; case \"c\": yield 2; case \"d\", \"e\", \"f\": // do something here... System.out.println(\"Supports multi line block!\"); yield 3; default: yield -1; &#125;; return result; &#125; Or via a label rules or arrows. 12345678910111213private static int getValueViaArrow(String mode) &#123; int result = switch (mode) &#123; case \"a\", \"b\" -&gt; 1; case \"c\" -&gt; 2; case \"d\", \"e\", \"f\" -&gt; &#123; // do something here... System.out.println(\"Supports multi line block!\"); yield 3; &#125; default -&gt; -1; &#125;; return result; &#125; Refer examples in this Java 13 Switch Expression. JEP 362: Deprecate the Solaris and SPARC PortsDropping support for Solaris/SPARC, Solaris/x64, and Linux/SPARC ports, fewer platforms support means faster delivery for new features. JEP 363: Remove the Concurrent Mark Sweep (CMS) Garbage CollectorJava 9 – JEP 291 deprecated this Concurrent Mark Sweep (CMS) Garbage Collector, and now it is officially removed. 123/usr/lib/jvm/jdk-14/bin/java -XX:+UseConcMarkSweepGC TestOpenJDK 64-Bit Server VM warning: Ignoring option UseConcMarkSweepGC; support was removed in 14.0 JEP 364: ZGC on macOS (Experimental)Java 11 – JEP 333 introduced the Z Garbage Collector (ZGC) on Linux, and now it ports to macOS. JEP 365: ZGC on Windows (Experimental)Java 11 – JEP 333 introduced the Z Garbage Collector (ZGC) on Linux, and now it ports to Windows version &gt;= 1803. JEP 366: Deprecate the ParallelScavenge + SerialOld GC CombinationDue to less use and high maintenance effort, Java 14 deprecates the combination of the parallel young generation and serial old generation GC algorithms. 123/usr/lib/jvm/jdk-14/bin/java -XX:-UseParallelOldGC TestOpenJDK 64-Bit Server VM warning: Option UseParallelOldGC was deprecated in version 14.0 and will likely be removed in a future release. JEP 367: Remove the Pack200 Tools and APIJava 11 – JEP 336 deprecated the pack200 and unpack200 tools, and the Pack200 API in the java.util.jar package, and now it is officially removed. JEP 368: Text Blocks (Second Preview)The first preview appeared in Java 13 – JEP 354, now added two more new escape sequences: \\&lt;end-of-line&gt; suppresses the line termination. \\s is translated into a single space. Test.java 123456789101112131415161718192021222324252627282930313233public class Test &#123; public static void main(String[] args) &#123; String html = \"&lt;html&gt;\\n\" + \" &lt;body&gt;\\n\" + \" &lt;p&gt;Hello, World&lt;/p&gt;\\n\" + \" &lt;/body&gt;\\n\" + \"&lt;/html&gt;\\n\"; String java13 = \"\"\" &lt;html&gt; &lt;body&gt; &lt;p&gt;Hello, World&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; \"\"\"; String java14 = \"\"\" &lt;html&gt; &lt;body&gt;\\ &lt;p&gt;Hello, '\\s' World&lt;/p&gt;\\ &lt;/body&gt; &lt;/html&gt; \"\"\"; System.out.println(html); System.out.println(java13); System.out.println(java14); &#125;&#125; 12$ /usr/lib/jvm/jdk-14/bin/javac --enable-preview --release 14 Test.java$ /usr/lib/jvm/jdk-14/bin/java --enable-preview Test Output 123456789101112131415html&gt; &lt;body&gt; &lt;p&gt;Hello, World&lt;/p&gt; &lt;/body&gt;&lt;/html&gt;&lt;html&gt; &lt;body&gt; &lt;p&gt;Hello, World&lt;/p&gt; &lt;/body&gt;&lt;/html&gt;&lt;html&gt; &lt;body&gt; &lt;p&gt;Hello, ' ' World&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; Further ReadingFor more Java text blocks examples, please refer to this Java multi-line string, text blocks JEP 370: Foreign-Memory Access API (Incubator)An incubator module, allow Java API to access foreign memory outside of the Java heap. Test.java 12345678910111213141516171819202122232425import jdk.incubator.foreign.*;import java.lang.invoke.VarHandle;import java.nio.ByteOrder;public class Test &#123; public static void main(String[] args) &#123; VarHandle intHandle = MemoryHandles.varHandle(int.class, ByteOrder.nativeOrder()); try (MemorySegment segment = MemorySegment.allocateNative(1024)) &#123; MemoryAddress base = segment.baseAddress(); System.out.println(base); // print memory address intHandle.set(base, 999); // set value 999 into the foreign memory System.out.println(intHandle.get(base)); // get the value from foreign memory &#125; &#125;&#125; Compile and run with incubator module jdk.incubator.foreign. 12345678910$ /usr/lib/jvm/jdk-14/bin/javac --add-modules jdk.incubator.foreign Test.javawarning: using incubating module(s): jdk.incubator.foreign1 warning$ /usr/lib/jvm/jdk-14/bin/java --add-modules jdk.incubator.foreign TestWARNING: Using incubator modules: jdk.incubator.foreignMemoryAddress&#123; region: MemorySegment&#123; id=0x4aac6dca limit: 1024 &#125; offset=0x0 &#125;999 Further Reading – jdk.incubator.foreign Javadoc 123$ git clone https://github.com/mkyong/core-java$ cd java-14 References OpenJDK 14 Project Java 14 Arrives with a Host of New Features Java version history Wikipedia – Non-volatile memory (NVM) Wikipedia – Non-uniform memory access (NUMA) Data Classes and Sealed Types for Java jdk.incubator.foreign Java 13 Switch Expressions Java 13 Text blocks","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}]},{"title":"RocketMQ--水平扩展及负载均衡详解","slug":"rocketmq-rebalance","date":"2020-08-16T12:36:00.000Z","updated":"2022-06-14T02:59:07.563Z","comments":false,"path":"rocketmq/rocketmq-rebalance/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-rebalance/","excerpt":"","text":"RocketMQ是一个分布式具有高度可扩展性的消息中间件。本文旨在探索在broker端，生产端，以及消费端是如何做到横向扩展以及负载均衡的。 Broker端水平扩展Broker负载均衡Broker是以group为单位提供服务。一个group里面分master和slave,master和slave存储的数据一样，slave从master同步数据（同步双写或异步复制看配置）。 通过nameserver暴露给客户端后，只是客户端关心（注册或发送）一个个的topic路由信息。路由信息中会细化为message queue的路由信息。而message queue会分布在不同的broker group。所以对于客户端来说，分布在不同broker group的message queue为成为一个服务集群，但客户端会把请求分摊到不同的queue。 而由于压力分摊到了不同的queue,不同的queue实际上分布在不同的Broker group，也就是说压力会分摊到不同的broker进程，这样消息的存储和转发均起到了负载均衡的作用。 Broker一旦需要横向扩展，只需要增加broker group，然后把对应的topic建上，客户端的message queue集合即会变大，这样对于broker的负载则由更多的broker group来进行分担。 并且由于每个group下面的topic的配置都是独立的，也就说可以让group1下面的那个topic的queue数量是4，其他group下的topic queue数量是2，这样group1则得到更大的负载。 commit log虽然每个topic下面有很多message queue，但是message queue本身并不存储消息。真正的消息存储会写在CommitLog的文件，message queue只是存储CommitLog中对应的位置信息，方便通过message queue找到对应存储在CommitLog的消息。 不同的topic，message queue都是写到相同的CommitLog 文件，也就是说CommitLog完全的顺序写。 具体如下图： ProducerProducer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图： Consumer负载均衡集群模式在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。 而每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时候会按照queue的数量和实例的数量平均分配queue给每个实例。 默认的分配算法是AllocateMessageQueueAveragely，如下图： 还有另外一种平均的算法是AllocateMessageQueueAveragelyByCircle，也是平均分摊每一条queue，只是以环状轮流分queue的形式，如下图： 需要注意的是，集群模式下，queue都是只允许分配只一个实例，这是由于如果多个实例同时消费一个queue的消息，由于拉取哪些消息是consumer主动控制的，那样会导致同一个消息在不同的实例下被消费多次，所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。 通过增加consumer实例去分摊queue的消费，可以起到水平扩展的消费能力的作用。而有实例下线的时候，会重新触发负载均衡，这时候原来分配到的queue将分配到其他实例上继续消费。 但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。 广播模式由于广播模式下要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。 在实现上，其中一个不同就是在consumer分配queue的时候，会所有consumer都分到所有的queue。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"JVM之调优","slug":"JVM-tuning","date":"2020-08-16T08:29:15.000Z","updated":"2022-09-17T14:13:56.151Z","comments":false,"path":"java/JVM-tuning/","link":"","permalink":"https://www.cicoding.cn/java/JVM-tuning/","excerpt":"","text":"JVM 调优概述性能定义 吞吐量 - 指不考虑 GC 引起的停顿时间或内存消耗，垃圾收集器能支撑应用达到的最高性能指标。 延迟 - 其度量标准是缩短由于垃圾啊收集引起的停顿时间或者完全消除因垃圾收集所引起的停顿，避免应用运行时发生抖动。 内存占用 - 垃圾收集器流畅运行所需要的内存数量。 调优原则GC 优化的两个目标： 将进入老年代的对象数量降到最低 减少 Full GC 的执行时间 GC 优化的基本原则是：将不同的 GC 参数应用到两个及以上的服务器上然后比较它们的性能，然后将那些被证明可以提高性能或减少 GC 执行时间的参数应用于最终的工作服务器上。 将进入老年代的对象数量降到最低除了可以在 JDK7 及更高版本中使用的 G1 收集器以外，其他分代 GC 都是由 Oracle JVM 提供的。关于分代 GC，就是对象在 Eden 区被创建，随后被转移到 Survivor 区，在此之后剩余的对象会被转入老年代。也有一些对象由于占用内存过大，在 Eden 区被创建后会直接被传入老年代。老年代 GC 相对来说会比新生代 GC 更耗时，因此，减少进入老年代的对象数量可以显著降低 Full GC 的频率。你可能会以为减少进入老年代的对象数量意味着把它们留在新生代，事实正好相反，新生代内存的大小是可以调节的。 降低 Full GC 的时间Full GC 的执行时间比 Minor GC 要长很多，因此，如果在 Full GC 上花费过多的时间（超过 1s），将可能出现超时错误。 如果通过减小老年代内存来减少 Full GC 时间，可能会引起 OutOfMemoryError 或者导致 Full GC 的频率升高。 另外，如果通过增加老年代内存来降低 Full GC 的频率，Full GC 的时间可能因此增加。 因此，你需要把老年代的大小设置成一个“合适”的值。 GC 优化需要考虑的 JVM 参数 GC 优化时最常用的参数是-Xms,-Xmx和-XX:NewRatio。-Xms和-Xmx参数通常是必须的，所以NewRatio的值将对 GC 性能产生重要的影响。 有些人可能会问如何设置永久代内存大小，你可以用-XX:PermSize和-XX:MaxPermSize参数来进行设置，但是要记住，只有当出现OutOfMemoryError错误时你才需要去设置永久代内存。 GC 优化的过程GC 优化的过程和大多数常见的提升性能的过程相似，下面是笔者使用的流程： 1.监控 GC 状态你需要监控 GC 从而检查系统中运行的 GC 的各种状态。 2.分析监控结果后决定是否需要优化 GC在检查 GC 状态后，你需要分析监控结构并决定是否需要进行 GC 优化。如果分析结果显示运行 GC 的时间只有 0.1-0.3 秒，那么就不需要把时间浪费在 GC 优化上，但如果运行 GC 的时间达到 1-3 秒，甚至大于 10 秒，那么 GC 优化将是很有必要的。 但是，如果你已经分配了大约 10GB 内存给 Java，并且这些内存无法省下，那么就无法进行 GC 优化了。在进行 GC 优化之前，你需要考虑为什么你需要分配这么大的内存空间，如果你分配了 1GB 或 2GB 大小的内存并且出现了OutOfMemoryError，那你就应该执行堆快照（heap dump）来消除导致异常的原因。 注意：堆快照（heap dump）是一个用来检查 Java 内存中的对象和数据的内存文件。该文件可以通过执行 JDK 中的jmap命令来创建。在创建文件的过程中，所有 Java 程序都将暂停，因此，不要在系统执行过程中创建该文件。你可以在互联网上搜索 heap dump 的详细说明。 3.设置 GC 类型/内存大小如果你决定要进行 GC 优化，那么你需要选择一个 GC 类型并且为它设置内存大小。此时如果你有多个服务器，请如上文提到的那样，在每台机器上设置不同的 GC 参数并分析它们的区别。 4.分析结果在设置完 GC 参数后就可以开始收集数据，请在收集至少 24 小时后再进行结果分析。如果你足够幸运，你可能会找到系统的最佳 GC 参数。如若不然，你还需要分析输出日志并检查分配的内存，然后需要通过不断调整 GC 类型/内存大小来找到系统的最佳参数。 5.如果结果令人满意，将参数应用到所有服务器上并结束 GC 优化如果 GC 优化的结果令人满意，就可以将参数应用到所有服务器上，并停止 GC 优化。 在下面的章节中，你将会看到上述每一步所做的具体工作。 命令jmapjmap 即 JVM Memory Map。 jmap 用于生成 heap dump 文件。 如果不使用这个命令，还可以使用 -XX:+HeapDumpOnOutOfMemoryError 参数来让虚拟机出现 OOM 的时候，自动生成 dump 文件。 jmap 不仅能生成 dump 文件，还可以查询 finalize 执行队列、Java 堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。 命令格式： 1jmap [option] LVMID option 参数： dump - 生成堆转储快照 finalizerinfo - 显示在 F-Queue 队列等待 Finalizer 线程执行 finalizer 方法的对象 heap - 显示 Java 堆详细信息 histo - 显示堆中对象的统计信息 permstat - to print permanent generation statistics F - 当-dump 没有响应时，强制生成 dump 快照 示例：jmap -dump PID 生成堆快照 dump 堆到文件，format 指定输出格式，live 指明是活着的对象，file 指定文件名 1$ jmap -dump:live,format=b,file=dump.hprof 28920 Dumping heap to /home/xxx/dump.hprof ... Heap dump file created dump.hprof 这个后缀是为了后续可以直接用 MAT(Memory Anlysis Tool)打开。 示例：jmap -heap 查看指定进程的堆信息 注意：使用 CMS GC 情况下，jmap -heap 的执行有可能会导致 java 进程挂起。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849jmap -heap PID[root@chances bin]# ./jmap -heap 12379Attaching to process ID 12379, please wait...Debugger attached successfully.Server compiler detected.JVM version is 17.0-b16 using thread-local object allocation.Parallel GC with 6 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 83886080 (80.0MB) NewSize = 1310720 (1.25MB) MaxNewSize = 17592186044415 MB OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 20971520 (20.0MB) MaxPermSize = 88080384 (84.0MB) Heap Usage:PS Young GenerationEden Space: capacity = 9306112 (8.875MB) used = 5375360 (5.1263427734375MB) free = 3930752 (3.7486572265625MB) 57.761608714788736% usedFrom Space: capacity = 9306112 (8.875MB) used = 3425240 (3.2665634155273438MB) free = 5880872 (5.608436584472656MB) 36.80634834397007% usedTo Space: capacity = 9306112 (8.875MB) used = 0 (0.0MB) free = 9306112 (8.875MB) 0.0% usedPS Old Generation capacity = 55967744 (53.375MB) used = 48354640 (46.11457824707031MB) free = 7613104 (7.2604217529296875MB) 86.39733629427693% usedPS Perm Generation capacity = 62062592 (59.1875MB) used = 60243112 (57.452308654785156MB) free = 1819480 (1.7351913452148438MB) 97.06831451706046% used jstackjstack 用于生成 java 虚拟机当前时刻的线程快照。 线程快照是当前 java 虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过 jstack 来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果 java 程序崩溃生成 core 文件，jstack 工具可以用来获得 core 文件的 java stack 和 native stack 的信息，从而可以轻松地知道 java 程序是如何崩溃和在程序何处发生问题。另外，jstack 工具还可以附属到正在运行的 java 程序中，看到当时运行的 java 程序的 java stack 和 native stack 的信息, 如果现在运行的 java 程序呈现 hung 的状态，jstack 是非常有用的。 命令格式： 1jstack [option] LVMID option 参数： -F - 当正常输出请求不被响应时，强制输出线程堆栈 -l - 除堆栈外，显示关于锁的附加信息 -m - 如果调用到本地方法的话，可以显示 C/C++的堆栈 jpsjps(JVM Process Status Tool)，显示指定系统内所有的 HotSpot 虚拟机进程。 命令格式： 1jps [options] [hostid] option 参数： -l - 输出主类全名或 jar 路径 -q - 只输出 LVMID -m - 输出 JVM 启动时传递给 main()的参数 -v - 输出 JVM 启动时显示指定的 JVM 参数 其中[option]、[hostid]参数也可以不写。 1$ jps -l -m 28920 org.apache.catalina.startup.Bootstrap start 11589 org.apache.catalina.startup.Bootstrap start 25816 sun.tools.jps.Jps -l -m jstatjstat(JVM statistics Monitoring)，是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT 编译等运行数据。 命令格式： 1jstat [option] LVMID [interval] [count] 参数： [option] - 操作参数 LVMID - 本地虚拟机进程 ID [interval] - 连续输出的时间间隔 [count] - 连续输出的次数 jhatjhat(JVM Heap Analysis Tool)，是与 jmap 搭配使用，用来分析 jmap 生成的 dump，jhat 内置了一个微型的 HTTP/HTML 服务器，生成 dump 的分析结果后，可以在浏览器中查看。 注意：一般不会直接在服务器上进行分析，因为 jhat 是一个耗时并且耗费硬件资源的过程，一般把服务器生成的 dump 文件复制到本地或其他机器上进行分析。 命令格式： 1jhat [dumpfile] jinfojinfo(JVM Configuration info)，用于实时查看和调整虚拟机运行参数。 之前的 jps -v 口令只能查看到显示指定的参数，如果想要查看未被显示指定的参数的值就要使用 jinfo 口令 命令格式： 1jinfo [option] [args] LVMID option 参数： -flag : 输出指定 args 参数的值 -flags : 不需要 args 参数，输出所有 JVM 参数的值 -sysprops : 输出系统属性，等同于 System.getProperties() HotSpot VM 参数JVM 内存配置 GC 类型配置 辅助配置 典型配置堆大小设置年轻代的设置很关键。 JVM 中最大堆大小有三方面限制： 相关操作系统的数据模型（32-bt 还是 64-bit）限制； 系统的可用虚拟内存限制； 系统的可用物理内存限制。 1整个堆大小 = 年轻代大小 + 年老代大小 + 持久代大小 持久代一般固定大小为 64m。使用 -XX:PermSize 设置。 官方推荐年轻代占整个堆的 3/8。使用 -Xmn 设置。 回收器选择JVM 给了三种选择：串行收集器、并行收集器、并发收集器。 JVM 实战分析 GC 日志获取 GC 日志获取 GC 日志有两种方式： 使用命令动态查看 在容器中设置相关参数打印 GC 日志 jstat -gc 统计垃圾回收堆的行为： 1jstat -gc 1262 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 26112.0 24064.0 6562.5 0.0 564224.0 76274.5 434176.0 388518.3 524288.0 42724.7 320 6.417 1 0.398 6.815 也可以设置间隔固定时间来打印： 1$ jstat -gc 1262 2000 20 这个命令意思就是每隔 2000ms 输出 1262 的 gc 情况，一共输出 20 次 Tomcat 设置示例： 12345JAVA_OPTS=\"-server -Xms2000m -Xmx2000m -Xmn800m -XX:PermSize=64m -XX:MaxPermSize=256m -XX:SurvivorRatio=4 -verbose:gc -Xloggc:CATALINAHOME/logs/gc.log−Djava.awt.headless=true−XX:+PrintGCTimeStamps−XX:+PrintGCDetails−Dsun.rmi.dgc.server.gcInterval=600000−Dsun.rmi.dgc.client.gcInterval=600000−XX:+UseConcMarkSweepGC−XX:MaxTenuringThreshold=15\" −Xms2000m−Xmx2000m−Xmn800m−XX:PermSize=64m−XX:MaxPermSize=256m&lt;/code&gt;Xms，即为jvm启动时得JVM初始堆大小,Xmx为jvm的最大堆大小，xmn为新生代的大小，permsize为永久代的初始大小，MaxPermSize为永久代的最大空间。−XX:SurvivorRatio=4&lt;/code&gt;SurvivorRatio为新生代空间中的Eden区和救助空间Survivor区的大小比值，默认是8，则两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10。调小这个参数将增大survivor区，让对象尽量在survitor区呆长一点，减少进入年老代的对象。去掉救助空间的想法是让大部分不能马上回收的数据尽快进入年老代，加快年老代的回收频率，减少年老代暴涨的可能性，这个是通过将−XX:SurvivorRatio设置成比较大的值（比如65536)来做到。 −verbose:gc−Xloggc:CATALINA_HOME/logs/gc.log 将虚拟机每次垃圾回收的信息写到日志文件中，文件名由 file 指定，文件格式是平文件，内容和-verbose:gc 输出内容相同。 -Djava.awt.headless=true Headless 模式是系统的一种配置模式。在该模式下，系统缺少了显示设备、键盘或鼠标。 -XX:+PrintGCTimeStamps -XX:+PrintGCDetails 设置 gc 日志的格式 -Dsun.rmi.dgc.server.gcInterval=600000 -Dsun.rmi.dgc.client.gcInterval=600000 指定 rmi 调用时 gc 的时间间隔 -XX:+UseConcMarkSweepGC -XX:MaxTenuringThreshold=15 采用并发 gc 方式，经过 15 次 minor gc 后进入年老代 如何分析 GC 日志Young GC 回收日志: 12016-07-05T10:43:18.093+0800: 25.395: [GC [PSYoungGen: 274931K-&gt;10738K(274944K)] 371093K-&gt;147186K(450048K), 0.0668480 secs] [Times: user=0.17 sys=0.08, real=0.07 secs] Full GC 回收日志: 12016-07-05T10:43:18.160+0800: 25.462: [Full GC [PSYoungGen: 10738K-&gt;0K(274944K)] [ParOldGen: 136447K-&gt;140379K(302592K)] 147186K-&gt;140379K(577536K) [PSPermGen: 85411K-&gt;85376K(171008K)], 0.6763541 secs] [Times: user=1.75 sys=0.02, real=0.68 secs] 通过上面日志分析得出，PSYoungGen、ParOldGen、PSPermGen 属于 Parallel 收集器。其中 PSYoungGen 表示 gc 回收前后年轻代的内存变化；ParOldGen 表示 gc 回收前后老年代的内存变化；PSPermGen 表示 gc 回收前后永久区的内存变化。young gc 主要是针对年轻代进行内存回收比较频繁，耗时短；full gc 会对整个堆内存进行回城，耗时长，因此一般尽量减少 full gc 的次数 通过两张图非常明显看出 gc 日志构成： OutOfMemory(OOM)分析OutOfMemory ，即内存溢出，是一个常见的 JVM 问题。那么分析 OOM 的思路是什么呢？ 首先，要知道有三种 OutOfMemoryError： OutOfMemoryError:Java heap space - 堆空间溢出 OutOfMemoryError:PermGen space - 方法区和运行时常量池溢出 OutOfMemoryError:unable to create new native thread - 线程过多 OutOfMemoryError:PermGen spaceOutOfMemoryError:PermGen space 表示方法区和运行时常量池溢出。 原因： Perm 区主要用于存放 Class 和 Meta 信息的，Class 在被 Loader 时就会被放到 PermGen space，这个区域称为年老代。GC 在主程序运行期间不会对年老区进行清理，默认是 64M 大小。 当程序程序中使用了大量的 jar 或 class，使 java 虚拟机装载类的空间不够，超过 64M 就会报这部分内存溢出了，需要加大内存分配，一般 128m 足够。 解决方案： （1）扩大永久代空间 JDK7 以前使用 -XX:PermSize 和 -XX:MaxPermSize 来控制永久代大小。 JDK8 以后把原本放在永久代的字符串常量池移出, 放在 Java 堆中(元空间 Metaspace)中，元数据并不在虚拟机中，使用的是本地的内存。使用 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 控制元空间大小。 注意：-XX:PermSize 一般设为 64M （2）清理应用程序中 WEB-INF/lib 下的 jar，用不上的 jar 删除掉，多个应用公共的 jar 移动到 Tomcat 的 lib 目录，减少重复加载。 OutOfMemoryError:Java heap spaceOutOfMemoryError:Java heap space 表示堆空间溢出。 原因：JVM 分配给堆内存的空间已经用满了。 问题定位 （1）使用 jmap 或 -XX:+HeapDumpOnOutOfMemoryError 获取堆快照。 （2）使用内存分析工具（visualvm、mat、jProfile 等）对堆快照文件进行分析。 （3）根据分析图，重点是确认内存中的对象是否是必要的，分清究竟是是内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。 内存泄露 内存泄漏是指由于疏忽或错误造成程序未能释放已经不再使用的内存的情况。 内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。 内存泄漏随着被执行的次数越多-最终会导致内存溢出。 而因程序死循环导致的不断创建对象-只要被执行到就会产生内存溢出。 内存泄漏常见几个情况： 静态集合类 声明为静态（static）的 HashMap、Vector 等集合 通俗来讲 A 中有 B，当前只把 B 设置为空，A 没有设置为空，回收时 B 无法回收-因被 A 引用。 监听器 监听器被注册后释放对象时没有删除监听器 物理连接 DataSource.getConnection()建立链接，必须通过 close()关闭链接 内部类和外部模块等的引用 发现它的方式同内存溢出，可再加个实时观察 jstat -gcutil 7362 2500 70 重点关注： FGC — 从应用程序启动到采样时发生 Full GC 的次数。 FGCT — 从应用程序启动到采样时 Full GC 所用的时间（单位秒）。 FGC 次数越多，FGCT 所需时间越多-可非常有可能存在内存泄漏。 解决方案 （1）检查程序，看是否有死循环或不必要地重复创建大量对象。有则改之。 下面是一个重复创建内存的示例： 12345678910111213141516171819202122232425262728293031323334public class OOM &#123; public static void main(String[] args) &#123; Integer sum1=300000; Integer sum2=400000; OOM oom = new OOM(); System.out.println(“往ArrayList中加入30w内容”); oom.javaHeapSpace(sum1); oom.memoryTotal(); System.out.println(“往ArrayList中加入40w内容”); oom.javaHeapSpace(sum2); oom.memoryTotal();&#125; public void javaHeapSpace(Integer sum)&#123; Random random = new Random(); ArrayList openList = new ArrayList(); for(int i=0;i&lt;sum;i++)&#123; String charOrNum = String.valueOf(random.nextInt(10)); openList.add(charOrNum); &#125;&#125; public void memoryTotal()&#123; Runtime run = Runtime.getRuntime(); long max = run.maxMemory(); long total = run.totalMemory(); long free = run.freeMemory(); long usable = max - total + free; System.out.println(&quot;最大内存 = &quot; + max); System.out.println(&quot;已分配内存 = &quot; + total); System.out.println(&quot;已分配内存中的剩余空间 = &quot; + free); System.out.println(&quot;最大可用内存 = &quot; + usable); &#125;&#125; 执行结果： 123456789往ArrayList中加入30w内容 最大内存 = 20447232 已分配内存 = 20447232 已分配内存中的剩余空间 = 4032576 最大可用内存 = 4032576 往ArrayList中加入40w内容 Exception in thread “main”java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:2245) at java.util.Arrays.copyOf(Arrays.java:2219) at java.util.ArrayList.grow(ArrayList.java:242) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:216) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:208) at java.util.ArrayList.add(ArrayList.java:440) at pers.qingqian.study.seven.OOM.javaHeapSpace(OOM.java:36) at pers.qingqian.study.seven.OOM.main(OOM.java:26) （2）扩大堆内存空间 使用 -Xms 和 -Xmx 来控制堆内存空间大小。 OutOfMemoryError: GC overhead limit exceeded原因：JDK6 新增错误类型，当 GC 为释放很小空间占用大量时间时抛出；一般是因为堆太小，导致异常的原因，没有足够的内存。 解决方案： 查看系统是否有使用大内存的代码或死循环； 通过添加 JVM 配置，来限制使用内存： 12&lt;jvm-arg&gt;-XX:-UseGCOverheadLimit&lt;/jvm-arg&gt;#### OutOfMemoryError：unable to create new native thread 原因：线程过多 那么能创建多少线程呢？这里有一个公式： (MaxProcessMemory - JVMMemory - ReservedOsMemory) / (ThreadStackSize) = Number of threads MaxProcessMemory 指的是一个进程的最大内存 JVMMemory JVM内存 ReservedOsMemory 保留的操作系统内存 ThreadStackSize 线程栈的大小 当发起一个线程的创建时，虚拟机会在 JVM 内存创建一个 Thread 对象同时创建一个操作系统线程，而这个系统线程的内存用的不是 JVMMemory，而是系统中剩下的内存： (MaxProcessMemory - JVMMemory - ReservedOsMemory) 结论：你给 JVM 内存越多，那么你能用来创建的系统线程的内存就会越少，越容易发生 java.lang.OutOfMemoryError: unable to create new native thread。 CPU 过高定位步骤： （1）执行 top -c 命令，找到 cpu 最高的进程的 id （2）jstack PID 导出 Java 应用程序的线程堆栈信息。 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556`jstack 6795 &quot;Low Memory Detector&quot; daemon prio=10 tid=0x081465f8 nid=0x7 runnable [0x00000000…0x00000000]“CompilerThread0” daemon prio=10 tid=0x08143c58 nid=0x6 waiting on condition [0x00000000…0xfb5fd798]“Signal Dispatcher” daemon prio=10 tid=0x08142f08 nid=0x5 waiting on condition [0x00000000…0x00000000]“Finalizer” daemon prio=10 tid=0x08137ca0 nid=0x4 in Object.wait() [0xfbeed000…0xfbeeddb8] at java.lang.Object.wait(Native Method) - waiting on &amp;lt;0xef600848&amp;gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;a java.lang.ref.ReferenceQueue&lt;span class=&quot;nv&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; at java.lang.ref.ReferenceQueue.remove&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ReferenceQueue.java:116&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; - locked &amp;lt;0xef600848&amp;gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;a java.lang.ref.ReferenceQueue&lt;span class=&quot;nv&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; at java.lang.ref.ReferenceQueue.remove&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ReferenceQueue.java:132&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; at java.lang.ref.Finalizer&lt;span class=&quot;nv&quot;&gt;$FinalizerThread&lt;/span&gt;.run&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Finalizer.java:159&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Reference Handler&quot;&lt;/span&gt; daemon &lt;span class=&quot;nv&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0x081370f0 &lt;span class=&quot;nv&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0x3 in Object.wait&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0xfbf4a000..0xfbf4aa38&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; at java.lang.Object.wait&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Native Method&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; - waiting on &amp;lt;0xef600758&amp;gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;a java.lang.ref.Reference&lt;span class=&quot;nv&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; at java.lang.Object.wait&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Object.java:474&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; at java.lang.ref.Reference&lt;span class=&quot;nv&quot;&gt;$ReferenceHandler&lt;/span&gt;.run&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Reference.java:116&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; top - 14:20:09 up 611 days, 2:56, 1 user, load average: 13.19, 7.76, 7.82Threads: 6991 total, 17 running, 6974 sleeping, 0 stopped, 0 zombie%Cpu(s): 90.4 us, 2.1 sy, 0.0 ni, 7.0 id, 0.0 wa, 0.0 hi, 0.4 si, 0.0 stKiB Mem: 32783044 total, 32505008 used, 278036 free, 120304 buffersKiB Swap: 0 total, 0 used, 0 free. 4497428 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND6800 root 20 0 27.299g 0.021t 7172 S 54.7 70.1 187:55.61 java6803 root 20 0 27.299g 0.021t 7172 S 54.4 70.1 187:52.59 java6798 root 20 0 27.299g 0.021t 7172 S 53.7 70.1 187:55.08 java6801 root 20 0 27.299g 0.021t 7172 S 53.7 70.1 187:55.25 java6797 root 20 0 27.299g 0.021t 7172 S 53.1 70.1 187:52.78 java6804 root 20 0 27.299g 0.021t 7172 S 53.1 70.1 187:55.76 java6802 root 20 0 27.299g 0.021t 7172 S 52.1 70.1 187:54.79 java6799 root 20 0 27.299g 0.021t 7172 S 51.8 70.1 187:53.36 java6807 root 20 0 27.299g 0.021t 7172 S 13.6 70.1 48:58.60 java11014 root 20 0 27.299g 0.021t 7172 R 8.4 70.1 8:00.32 java10642 root 20 0 27.299g 0.021t 7172 R 6.5 70.1 6:32.06 java6808 root 20 0 27.299g 0.021t 7172 S 6.1 70.1 159:08.40 java11315 root 20 0 27.299g 0.021t 7172 S 3.9 70.1 5:54.10 java12545 root 20 0 27.299g 0.021t 7172 S 3.9 70.1 6:55.48 java23353 root 20 0 27.299g 0.021t 7172 S 3.9 70.1 2:20.55 java24868 root 20 0 27.299g 0.021t 7172 S 3.9 70.1 2:12.46 java9146 root 20 0 27.299g 0.021t 7172 S 3.6 70.1 7:42.72 java - locked &amp;lt;0xef600758&amp;gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;a java.lang.ref.Reference&lt;span class=&quot;nv&quot;&gt;$Lock&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;VM Thread&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0x08134878 &lt;span class=&quot;nv&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0x2 runnable &lt;span class=&quot;s2&quot;&gt;&quot;VM Periodic Task Thread&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;prio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;tid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0x08147768 &lt;span class=&quot;nv&quot;&gt;nid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0x8 waiting on condition&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在打印的堆栈日志文件中，tid 和 nid 的含义：&lt;/p&gt;&lt;p&gt;&amp;lt;pre style=&quot;margin: 0px; padding: 0px; white-space: pre-wrap; overflow-wrap: break-word;&quot;&amp;gt;&lt;code&gt;nid : 对应的 Linux 操作系统下的 tid 线程号，也就是前面转化的 16 进制数字 tid: 这个应该是 jvm 的 jmm 内存规范中的唯一地址定位&lt;/code&gt; &amp;lt;/pre&amp;gt;&lt;/p&gt;&lt;p&gt;在 CPU 过高的情况下，查找响应的线程，一般定位都是用 nid 来定位的。而如果发生死锁之类的问题，一般用 tid 来定位。&lt;/p&gt;&lt;p&gt;（3）定位 CPU 高的线程打印其 nid&lt;/p&gt;&lt;p&gt;查看线程下具体进程信息的命令如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-css&quot;&gt;&lt;span class=&quot;nt&quot;&gt;top&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;6735&lt;/span&gt; 由此可以看出占用 CPU 较高的线程，但是这些还不高，无法直接定位到具体的类。nid 是 16 进制的，所以我们要获取线程的 16 进制 ID： 12printf “%x\\n” 6800输出结果:45cd 然后根据输出结果到 jstack 打印的堆栈日志中查定位： 12345678910111213141516171819202122232425&lt;pre style=“margin: 0px; padding: 0px; white-space: pre-wrap; overflow-wrap: break-word;”&gt;`“catalina-exec-5692” daemon prio=10 tid=0x00007f3b05013800 nid=0x45cd waiting on condition [0x00007f3ae08e3000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000006a7800598&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizerConditionObject&lt;/span&gt;&lt;spanclass=&quot;o&quot;&gt;)&lt;/span&gt;atjava.util.concurrent.locks.LockSupport.parkNanos&lt;spanclass=&quot;o&quot;&gt;(&lt;/span&gt;LockSupport.java:226&lt;spanclass=&quot;o&quot;&gt;)&lt;/span&gt;atjava.util.concurrent.locks.AbstractQueuedSynchronizer&lt;spanclass=&quot;nv&quot;&gt; ConditionObject&lt;/span&gt;&lt;spanclass=&quot;o&quot;&gt;)&lt;/span&gt;atjava.util.concurrent.locks.LockSupport.parkNanos&lt;spanclass=&quot;o&quot;&gt;(&lt;/span&gt;LockSupport.java:226&lt;spanclass=&quot;o&quot;&gt;)&lt;/span&gt;atjava.util.concurrent.locks.AbstractQueuedSynchronizer&lt;spanclass=&quot;nv&quot;&gt;ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082) at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467) at org.apache.tomcat.util.threads.TaskQueue.poll(TaskQueue.java:86) at org.apache.tomcat.util.threads.TaskQueue.poll(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) at java.util.concurrent.ThreadPoolExecutorWorker&lt;/span&gt;.run&lt;spanclass=&quot;o&quot;&gt;(&lt;/span&gt;ThreadPoolExecutor.java:615&lt;spanclass=&quot;o&quot;&gt;)&lt;/span&gt;atorg.apache.tomcat.util.threads.TaskThread&lt;spanclass=&quot;nv&quot;&gt; Worker&lt;/span&gt;.run&lt;spanclass=&quot;o&quot;&gt;(&lt;/span&gt;ThreadPoolExecutor.java:615&lt;spanclass=&quot;o&quot;&gt;)&lt;/span&gt;atorg.apache.tomcat.util.threads.TaskThread&lt;spanclass=&quot;nv&quot;&gt;WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745)","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}]},{"title":"maven-metadata.xml使用","slug":"maven-metadata-xml","date":"2020-07-24T08:55:15.000Z","updated":"2023-06-20T06:34:39.686Z","comments":false,"path":"maven/maven-metadata-xml/","link":"","permalink":"https://www.cicoding.cn/maven/maven-metadata-xml/","excerpt":"","text":"maven-metadata.xml使用最近在开发过程中，发现工程中的一些包有问题，主要分为以下两种： 1、最新包（版本号未变，只是被更新了）少了一个方法 2、jar包被更新了，但是无法更新最新的包下来 首先先确定一下更新包会导致更新哪些文件？下面都以a-1.0.1-snapshot.jar包为例 当你更新了a-snapshot.jar的内容，并上传到maven服务器时，会更新一个元数据文件maven-metadata.xml，这个文件内容类似如下 12345678910111213141516171819202122232425&lt;!--?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?--&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;metadata modelVersion=&quot;1.1.0&quot;&gt; &lt;groupId&gt;com.my.testu&lt;/groupId&gt; &lt;artifactId&gt;a&lt;/artifactId&gt; &lt;version&gt;1.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20160909.081828&lt;/timestamp&gt; &lt;buildNumber&gt;34&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20160909081828&lt;/lastUpdated&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;1.0.1-20160909.081828-34&lt;/value&gt; &lt;updated&gt;20160909081828&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;snapshotVersion&gt; &lt;extension&gt;pom&lt;/extension&gt; &lt;value&gt;1.0.1-20160909.081828-34&lt;/value&gt; &lt;updated&gt;20160909081828&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/versioning&gt;&lt;/metadata&gt; 这个文件是很重要的，你的每次提交都会更新这个文件，当从maven下载jar包时，也会根据这个文件进行jar包的查找。若这时你去更新jar包，会下载最新包a-1.0.1-20160909.081828-24.jar，下载到本地后会复制一份重命名为a-1.0.1-snapshot.jar。 对于刚才说的第二个问题，就是因为maven-metadata.xml文件中的timestamp和updated不一致，导致找不到最新包，一般可能会报错Missing artifact 从现在看，想解决这两个问题，就是需要制定相同版本号下某个更新之后的jar包，并不一定是最新包。 既然maven-metadata.xml文件在maven服务器上可以指定下载哪个jar包，那么本地是否也可以指定呢？答案是肯定的，本地jar包一般到在.m2/repository路径下，在jar包所在的目录下一般会存在maven-metadata.xml这个文件，可以复制一份重命名为maven-metadata-local.xml。 在咱们使用maven更新工程的jar包时，其实maven是会比较服务器上的maven-metadata.xml和本地的maven-metadata-local.xml中的lastUpdated时间戳值，哪个值更大，就以哪个文件为准。这里需要注意的是，若是maven-metadata-local.xml文件的值大，这时候就中止下载了，直接使用本地的jar包，所以你得自己准备好自己想用的jar包。 以下是maven-metadata.xml中versionging下一些节点值的说明 snapshot：当前版本下的最新快照信息 ​ timestamp：快照的时间戳 ​ buildNumer：构件号 lastUpdated：metadata文件被更新的时间 snapshotVersion：当前版本下可用的子快照版本信息 ​ value：子快照版本的信息 ​ updated：这个子快照版本的更新时间","categories":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/tags/Maven/"}],"keywords":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}]},{"title":"Maven仓库理解和优先级","slug":"maven-warehouse-understanding-and-priority","date":"2020-07-20T08:29:15.000Z","updated":"2023-06-20T06:34:39.687Z","comments":false,"path":"maven/maven-warehouse-understanding-and-priority/","link":"","permalink":"https://www.cicoding.cn/maven/maven-warehouse-understanding-and-priority/","excerpt":"","text":"前言使用 maven 也有一段时间了，有时候在配置 repository,mirror,profile的时候，总会导致 jar 拉取不到。所以认真的分析了 maven 获取 jar 包时候的优先级。 Maven 仓库的分类仓库分类：本地仓库和远程仓库。Maven根据坐标寻找构件的时候，它先会查看本地仓库，如果本地仓库存在构件，则直接使用；如果没有，则从远程仓库查找，找到后，下载到本地。 1）本地仓库默认情况下，每个用户在自己的用户目录下都有一个路径名为.m2/repository/的仓库目录。我们也可以在 settings.xml 文件配置本地仓库的地址 2）远程仓库本地仓库好比书房，而远程仓库就像是书店。对于Maven来说，每个用户只有一个本地仓库，但是可以配置多个远程仓库。下· 我们可以在 pom 文件配置多个 repository，但是随着项目越来也多我们每次都要在 pom 文件配置比较麻烦，所以我们可以在settings 文件配置 profile （私服）。这样我们每次创建新项目的时候就可以不用配置 repository。 3）中央仓库Maven必须要知道至少一个可用的远程仓库，中央仓库就是这样一个默认的远程仓库，Maven 默认有一个 super pom 文件。maven super pom 文件位置D:\\apache-maven-3.0.4\\lib 下的 maven-model-builder-3.0.4.jar 中的 org/apache/maven/model/pom-4.0.0.xml 12345678910111213··· 省略其他 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;··· 这个时候我们就明白了，我们在 settings 文件配置一个 mirror 的 mirrorOf 为 central 的镜像就会替代 ‘中央仓库’ 的原因了。 Maven 镜像镜像（Mirroring）是冗余的一种类型，一个磁盘上的数据在另一个磁盘上存在一个完全相同的副本即为镜像。为什么配置镜像? 1.一句话，你有的我也有，你没有的我也有。（拥有远程仓库的所有 jar，包括远程仓库没有的 jar）2.还是一句话，我跑的比你快。（有时候远程仓库获取 jar 的速度可能比镜像慢，这也是为什么我们一般要配置中央仓库的原因，外国的 maven 仓库一般获取速度比较慢） 如果你配置 maven 镜像不是为了以上两点，那基本就不用配置镜像了。注意:当远程仓库被镜像匹配到的，则在获取 jar 包将从镜像仓库获取，而不是我们配置的 repository 仓库, repository 将失去作用 mirrorOf 标签mirrorOf 标签里面放置的是 repository 配置的 id,为了满足一些复杂的需求，Maven还支持更高级的镜像配置： 1234external:* = 不在本地仓库的文件才从该镜像获取repo,repo1 = 远程仓库 repo 和 repo1 从该镜像获取*,!repo1 = 所有远程仓库都从该镜像获取，除 repo1 远程仓库以外* = 所用远程仓库都从该镜像获取 私服私服是一种特殊的远程Maven仓库，它是架设在局域网内的仓库服务，私服一般被配置为互联网远程仓库的镜像，供局域网内的Maven用户使用。当Maven需要下载构件的时候，先向私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，同时缓存在私服之上，然后为Maven下载请求提供下载服务，另外，对于自定义或第三方的jar可以从本地上传到私服，供局域网内其他maven用户使用。优点主要有： 123451. 节省外网宽带2. 加速Maven构建3. 部署第三方构件：可以将公司项目的 jar 发布到私服上，方便项目与项目之间的调用4. 提高稳定性、增强控制：原因是外网不稳定5. 降低中央仓库的负荷：原因是中央仓库访问量太大 上面大概介绍了 Maven 仓库概念，接下来我们进入正题 Maven 仓库优先级为了方便测试，我准备了以下几个仓库 172.16.xxx.xxx 远程仓库 （私服） dev.xxx.wiki 远程仓库 （远程） localhost 仓库 是我自己在本机搭建的一个仓库 （镜像） maven.aliyun.com 中央仓库（中央） 本地仓库优先级Maven 本地仓库拥有该包，而远程、镜像、中央、私服都不包含该包。我们来看下 Maven 是怎么获取的 123456789101112131415161718192021222324.......// 使用本地仓库，优先级(priority)为 10[DEBUG] Using local repository at E:\\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\\OperSource[INFO] Scanning for projects..........[INFO] Installing C:\\Users\\swipal\\Desktop\\abc\\demo\\target\\demo-1.0-SNAPSHOT.jar to E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\_remote.repositories[INFO] Installing C:\\Users\\swipal\\Desktop\\abc\\demo\\pom.xml to E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\\OperSource\\com\\cjf\\demo\\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 1.874 s[INFO] Finished at: 2017-07-07T10:37:32+08:00[INFO] Final Memory: 23M/219M[INFO] ------------------------------------------------------------------------Process finished with exit code 0 从上面可以看出 Maven 一开始就使用本地仓库，并将本地仓库的优先级定制为 10 , 最后 jar 包也在本地仓库找到，Maven 成功打包。 远程仓库优先级前面我们知道了，本地仓库的优先级是最高的，现在我们继续研究远程仓库的优先级（以下的所有例子，都默认本地仓库不拥有我们需要的包） 这一次我们默认配置 profile（私服）为 172.16.xxx.xxx 远程仓库, repository 为 dev.xxx.wiki 远程仓库,mirror 为本地 localhost 仓库，还配置了一个 mirrorOf 为 central 远程仓库为 maven.aliyun.com 的中央仓库, 以下是配置信息settings.xml 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253······&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;localhost&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo&lt;/mirrorOf&gt; &lt;!--拦截 pom 文件配置的 repository--&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;localhost2&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;mirrorOf&gt;foo2&lt;/mirrorOf&gt; &lt;!--配置一个拦截 foo2 的远程仓库的镜像--&gt; &lt;url&gt;http://localhost:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;!--覆盖 Maven 默认的配置的中央仓库--&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;!--配置私服--&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://172.16.xxx.xxx:8081/nexus/content/groups/public&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt;&lt;/activeProfiles&gt;······ pom.xml 文件 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;!--xxx-cif-api 存在 172.16.xxx.xxx 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xxx.cif&lt;/groupId&gt; &lt;artifactId&gt;xxx-cif-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--Chapter1 存在 localhost 仓库--&gt; &lt;dependency&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--配置远程仓库--&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;foo&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://dev.xxx.wiki:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 以下是 Maven 拉取包的日志 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108······· 省略部分日志信息[DEBUG] Using local repository at E:\\OperSource[DEBUG] Using manager EnhancedLocalRepositoryManager with priority 10.0 for E:\\OperSource[INFO] Scanning for projects...// 从这里可以看出我们配置的镜像替代了我们在 pom 配置的远程仓库[DEBUG] Using mirror localhost (http://localhost:8081/repository/maven-public/) for foo (http://dev.xxx.wiki:8081/nexus/content/groups/public/).替代了默认的中央仓库[DEBUG] Using mirror alimaven (http://maven.aliyun.com/nexus/content/groups/public/) for central (https://repo.maven.apache.org/maven2).// 从这里可以看出 Maven 使用哪些 dependencies 和 plugins 的地址，我们可以看出优先级最高的是 172.16.xxx.xxx,然后就是 localhost 最后才是 maven.aliyun.com// 注意：alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases) 从这里可以看出中央仓库只能获取 releases 包，所有的 snapshots 包都不从中央仓库获取。（可以看前面 central 的配置信息）[DEBUG] === PROJECT BUILD PLAN ================================================[DEBUG] Project: com.cjf:demo:1.0-SNAPSHOT[DEBUG] Dependencies (collect): [][DEBUG] Dependencies (resolve): [compile, runtime, test][DEBUG] Repositories (dependencies): [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public/, default, releases+snapshots), localhost (http://localhost:8081/repository/maven-public/, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] Repositories (plugins) : [public (http://172.16.xxx.xxx:8081/nexus/content/groups/public, default, releases+snapshots), alimaven (http://maven.aliyun.com/nexus/content/groups/public/, default, releases)][DEBUG] =======================================================================// 寻找本地是否有 maven-metadata.xml 配置文件 ，从这里可以看出寻找不到（后面会详细讲该文件作用）[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\\OperSource)// 由于寻找不到 Maven 只能从我们配置的远程仓库寻找，由于 Maven 也不知道那个仓库才有，所以同时寻找两个仓库[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\cif\\xxx-cif-api\\0.0.1-SNAPSHOT\\resolver-status.properties// 从这里可以看出在 172.16.xxx.xxx 找到 xxx-cif-api 的 maven-metadata.xml 文件并下载下来Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/maven-metadata.xml (781 B at 7.0 KB/sec)// 追踪文件，resolver-status.properties 配置了 jar 包下载地址和时间[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\cif\\xxx-cif-api\\0.0.1-SNAPSHOT\\resolver-status.properties[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in localhost (http://localhost:8081/repository/maven-public/)// 在 localhost 远程仓库寻找不到 xxx-cif-api 的 maven-metadata.xml[DEBUG] Could not find metadata com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in local (E:\\OperSource)// 跳过的远程请求 [DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.[DEBUG] Skipped remote request for com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml, already updated during this session.// 默认以后获取 xxx-cif-api 的时候将不在从 localhost 寻找了，除非强制获取才会再次从 localhost 寻找这个包[DEBUG] Failure to find com.xxx.cif:xxx-cif-api:0.0.1-SNAPSHOT/maven-metadata.xml in http://localhost:8081/repository/maven-public/ was cached in the local repository, resolution will not be reattempted until the update interval of localhost has elapsed or updates are forced// 将 172.16.xxx.xxx 优先级升为 0 ，并下载 xxx-cif-api 的 pom 文件[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pomDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.pom (930 B at 82.6 KB/sec)// _remote.repositories 记录的以后使用那个远程仓库获取 （ps:这个文件作用我要不是很清楚作用，以上观点是自己推测出来的。）[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\cif\\xxx-cif-api\\0.0.1-SNAPSHOT\\_remote.repositories[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\cif\\xxx-cif-api\\0.0.1-SNAPSHOT\\xxx-cif-api-0.0.1-20170515.040917-89.pom.lastUpdated// 后面获取 Chapter1 包的流程跟 com.xxx.cif 是一样的，不过最后是在 localhost 寻找到而已，所以这分日志就不贴出来了。// 最后在下载包的时候，都到对应的仓库下载[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://172.16.xxx.xxx:8081/nexus/content/groups/public/Downloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jarDownloading: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jarDownloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/util/xxx-util/0.0.1-SNAPSHOT/xxx-util-0.0.1-20170514.091041-31.jar (26 KB at 324.2 KB/sec)Downloaded: http://172.16.xxx.xxx:8081/nexus/content/groups/public/com/xxx/cif/xxx-cif-api/0.0.1-SNAPSHOT/xxx-cif-api-0.0.1-20170515.040917-89.jar (68 KB at 756.6 KB/sec)[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\cif\\xxx-cif-api\\0.0.1-SNAPSHOT\\_remote.repositories[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\cif\\xxx-cif-api\\0.0.1-SNAPSHOT\\xxx-cif-api-0.0.1-20170515.040917-89.jar.lastUpdated[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\util\\xxx-util\\0.0.1-SNAPSHOT\\_remote.repositories[DEBUG] Writing tracking file E:\\OperSource\\com\\xxx\\util\\xxx-util\\0.0.1-SNAPSHOT\\xxx-util-0.0.1-20170514.091041-31.jar.lastUpdated[DEBUG] Using transporter WagonTransporter with priority -1.0 for http://localhost:8081/repository/maven-public/[DEBUG] Using connector BasicRepositoryConnector with priority 0.0 for http://localhost:8081/repository/maven-public/Downloading: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jarDownloaded: http://localhost:8081/repository/maven-public/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170708.092339-1.jar (8 KB at 167.0 KB/sec)[DEBUG] Writing tracking file E:\\OperSource\\com\\cjf\\Chapter1\\0.0.1-SNAPSHOT\\_remote.repositories[DEBUG] Writing tracking file E:\\OperSource\\com\\cjf\\Chapter1\\0.0.1-SNAPSHOT\\Chapter1-0.0.1-20170708.092339-1.jar.lastUpdated[INFO] Installing C:\\Users\\swipal\\Desktop\\abc\\demo\\target\\demo-1.0-SNAPSHOT.jar to E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\demo-1.0-SNAPSHOT.jar[DEBUG] Writing tracking file E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\_remote.repositories[INFO] Installing C:\\Users\\swipal\\Desktop\\abc\\demo\\pom.xml to E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\demo-1.0-SNAPSHOT.pom[DEBUG] Writing tracking file E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\_remote.repositories[DEBUG] Installing com.cjf:demo:1.0-SNAPSHOT/maven-metadata.xml to E:\\OperSource\\com\\cjf\\demo\\1.0-SNAPSHOT\\maven-metadata-local.xml[DEBUG] Installing com.cjf:demo/maven-metadata.xml to E:\\OperSource\\com\\cjf\\demo\\maven-metadata-local.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 10.549 s[INFO] Finished at: 2017-07-09T18:13:20+08:00[INFO] Final Memory: 26M/219M[INFO] ------------------------------------------------------------------------······· 好了，看了这么多的配置文件信息和日志信息，我们也总结一下 Maven 远程仓库优先级了。 主要有以下几点：1.从日志信息我们得出这几种maven仓库的优先级别为 本地仓库 &gt; 私服 （profile）&gt; 远程仓库（repository）和 镜像 （mirror） &gt; 中央仓库 （central） 2.镜像是一个特殊的配置，其实镜像等同与远程仓库，没有匹配远程仓库的镜像就毫无作用（如 foo2）。3.总结上面所说的，Maven 仓库的优先级就是 私服和远程仓库 的对比，没有其它的仓库类型。为什么这么说是因为，镜像等同远程，而中央其实也是 maven super xml 配置的一个repository 的一个而且。所以 maven 仓库真正的优先级为 本地仓库 &gt; 私服（profile）&gt; 远程仓库（repository） maven-metadata.xml 文件Maven Repository Metadata 可用于表示： 1231. 一个没有版本的工件：它提供有关该工件的可用版本的信息2. 快照伪像：它提供有关快照的精确信息3. 包含Maven插件工件的组：它提供了有关此组中可用插件的信息。 元数据文件名是： 12远程存储库中的 maven-metadata.xml，maven-metadata- &lt;repo-id&gt;.xml在本地存储库中，用于具有repo-id标识符的存储库中的元标记。 以上是 Maven 官网对该文件的解释。 作用问题：有时候我们更新最新包的时候，会发现最新的包被拉取下来的，但是项目使用的包还是旧的包。所以我们要分析下是什么原因导致的。 首先我们先大概的了解下 maven-metadata.xml 文件。 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;metadata modelVersion=&quot;1.1.0&quot;&gt; &lt;groupId&gt;com.cjf&lt;/groupId&gt; &lt;artifactId&gt;Chapter1&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;!--当前版本下的最新快照信息--&gt; &lt;timestamp&gt;20170710.071727&lt;/timestamp&gt; &lt;!--快照的时间戳--&gt; &lt;buildNumber&gt;6&lt;/buildNumber&gt; &lt;!--构件号--&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20170710071727&lt;/lastUpdated&gt;&lt;!--metadata文件被更新的时间--&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;!--当前版本下可用的子快照版本信息--&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt;&lt;!--子快照版本的信息--&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;!--这个子快照版本的更新时间--&gt; &lt;/snapshotVersion&gt; &lt;snapshotVersion&gt; &lt;extension&gt;pom&lt;/extension&gt; &lt;value&gt;0.0.1-20170710.071727-6&lt;/value&gt; &lt;updated&gt;20170710071727&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; 其中 lastUpdated 是最中要的一个属性，Maven 更新工程的 jar包时，会比较 lastUpdated 时间戳值，哪个值更大，就以哪个文件为准。 接下来我们看下 Maven 为我们生成了那些文件我们可以看到 maven-metadata.xml 一共有三个 1231. maven-metadata-local.xml 本地的元数据, Maven install 的时候就会生成。2. maven-metadata-snapshots.xml Maven deploy 时会生成3. maven-metadata-localhost.xml 远程仓库获取的时候生成 (repository 的 id = localhost) 以上的文件其实都是 Maven 的过渡文件而已 例如 maven-metadata-snapshots 就是 Maven deploy 先从远程仓库对应包的 maven-metadata.xml 下载下来，然后修改快照信息后在上传到远程仓库上。 例如 maven-metadata-localhost 的作用是在 Maven 在拉取包的时候，会先跟本地 maven-metadata-local 比较下 lastUpdated 时间戳值，值大用哪个。如果是 Mavne 强制更新 的时候(没有强制更新是不会) 会下载远程的 maven-metadata.xml 比较远程，本地，和之前远程保存下来的 maven-metadata 文件。 所以有时候 maven 库上的 jar 包已经更新，而我们总是拉取不到 maven 的包原因就是本地的 maven-metadata-local 的 lastUpdated 比较大。 我们验证下 Maven deploy 例子 1234567891011121314151617181920212223[INFO] --- maven-deploy-plugin:2.8.2:deploy (default-deploy) @ Chapter1 ---// 先从远程下载快照 maven-metadata.xmlDownloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 3.3 KB/sec)// 将项目的 jar 和 pom 文件更新到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jarUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.jar (8 KB at 14.1 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pomUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/Chapter1-0.0.1-20170710.121310-15.pom (2 KB at 2.0 KB/sec)Downloading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlDownloaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 1.6 KB/sec)// 上传 maven-metadata.xml 到远程仓库Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/0.0.1-SNAPSHOT/maven-metadata.xml (768 B at 1.0 KB/sec)Uploading: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xmlUploaded: http://localhost:8081/repository/maven-snapshots/com/cjf/Chapter1/maven-metadata.xml (275 B at 0.4 KB/sec)[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.231 s[INFO] Finished at: 2017-07-10T20:13:13+08:00[INFO] Final Memory: 19M/226M[INFO] ------------------------------------------------------------------------","categories":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/tags/Maven/"}],"keywords":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}]},{"title":"Hexo博客之文章置顶+置顶标签","slug":"hexo-top-top-lable","date":"2020-07-20T08:29:15.000Z","updated":"2022-09-17T14:13:56.167Z","comments":false,"path":"other/hexo-top-top-lable/","link":"","permalink":"https://www.cicoding.cn/other/hexo-top-top-lable/","excerpt":"","text":"博文置顶一种方法是手动对相关文件进行修改，具体可参考这篇文章。 另一种方法就是，目前已经有修改后支持置顶的仓库，可以直接用以下命令安装。 12$ npm uninstall hexo-generator-index --save$ npm install hexo-generator-index-pin-top --save --registry=https://registry.npm.taobao.org 然后在需要置顶的文章的Front-matter中加上top: true即可。比如下面这篇文章： 1234title: hexo+GitHub博客搭建实战date: 2020-02-08 12:00:25categories: 博客搭建系列top: true 到目前为止，置顶功能已经可以实现了。所有相关博文到这边就结束了。 不过置顶的文章显示在最上面之后，如果没有明确的置顶标志，是不是感觉有点怪怪的呢？ 设置置顶标志打开：/blog/themes/next/layout/_macro 目录下的post.swig文件，定位到标签下，插入如下代码： 12345&#123;% if post.top %&#125; &lt;i class=\"fa fa-thumb-tack\"&gt;&lt;/i&gt; &lt;font color=7D26CD&gt;置顶&lt;/font&gt; &lt;span class=\"post-meta-divider\"&gt;|&lt;/span&gt;&#123;% endif %&#125; 效果展示： http://www.cicoding.cn/","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.cicoding.cn/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.cicoding.cn/tags/Hexo/"}],"keywords":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.cicoding.cn/categories/Hexo/"}]},{"title":"SpringBoot配置logback-spring","slug":"springboot-config-logback-spring","date":"2020-07-10T13:29:15.000Z","updated":"2022-09-17T14:13:56.182Z","comments":false,"path":"springboot/springboot-config-logback-spring/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-config-logback-spring/","excerpt":"","text":"几种常见的日志 Log4j：是最早的日志框架，是apach旗下的，可以单独使用，也可配合日志框架JCL使用； Log4j2：apach旗下的关于log4j的升级版； Logback：是基于slf4j接口实现的一套日志框架组件；（Logback是由log4j创始人设计的又一个开源日志组件。） JUL(java utillog)：仿log4j实现的日志框架，是sun旗下的，(也就是在我们普遍使用的jdk中)； Commons loggin：是一套日志接口（apache）； Slf4j：也是一套日志接口； Commons Logging和Slf4j是日志门面(门面模式是软件工程中常用的一种软件设计模式，也被称为正面模式、外观模式。它为子系统中的一组接口提供一个统一的高层接 口，使 得子系统更容易使用)。log4j和Logback则是具体的日志实现方案。可以简单的理解为接口与接口的实现，调用这只需要关注接口而无需关注具体的实现，做到解耦； 比较常用的组合使用方式是Slf4j与Logback组合使用，Commons Logging与Log4j组合使用。 ​ 下面我们介绍SpringBoot默认日志框架logback的配置； ​ SpringBoot如果不使用外部Tomcat的话，日志是需要自己配置的，不然的话就只有控制台的日志，但是日志又是我们在项目上了生产环境，出问题时，检查问题的唯一途径，所以我们要配置详细的日志。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;property name=\"server_name\" value=\"operation\" /&gt; &lt;property name=\"log_dir\" value=\"/data/logs/operation-service\" /&gt; &lt;property name=\"maxFileSize\" value=\"50MB\" /&gt; &lt;property name=\"maxHistory\" value=\"180\" /&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%date&#123;yyyy-MM-dd HH:mm:ss&#125; | %highlight(%-5level) | %boldYellow(%thread) | %boldGreen(%logger) | %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- info日志 appender --&gt; &lt;appender name=\"INFO\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 按天回滚 daily --&gt; &lt;fileNamePattern&gt;$&#123;log_dir&#125;/$&#123;server_name&#125;-info-%d&#123;yyyy-MM-dd&#125;-%i.log&lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 180天 --&gt; &lt;maxHistory&gt;$&#123;maxHistory&#125;&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- maxFileSize:这是活动文件的大小，默认值是10MB，这里设置为50MB --&gt; &lt;maxFileSize&gt;$&#123;maxFileSize&#125;&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%date&#123;yyyy-MM-dd HH:mm:ss&#125; | %highlight(%-5level) | %boldYellow(%thread) | %boldGreen(%logger) | %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 只打印info日志 --&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 出错日志 appender --&gt; &lt;appender name=\"ERROR\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 按天回滚 daily --&gt; &lt;fileNamePattern&gt;$&#123;log_dir&#125;/$&#123;server_name&#125;-error-%d&#123;yyyy-MM-dd&#125;-%i.log&lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 180天 --&gt; &lt;maxHistory&gt;$&#123;maxHistory&#125;&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- maxFileSize:这是活动文件的大小，默认值是10MB，这里设置为50MB --&gt; &lt;maxFileSize&gt;$&#123;maxFileSize&#125;&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%date&#123;yyyy-MM-dd HH:mm:ss&#125; | %highlight(%-5level) | %boldYellow(%thread) | %boldGreen(%logger) | %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;!-- 只打印错误日志 --&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!--mybatis sql日志 日志的级别需要是DEBUG--&gt; &lt;!--日志打印的包的范围，及分类日志文件存储 --&gt; &lt;logger name=\"com.cicoding\" level=\"DEBUG\" additivity=\"false\"&gt;&lt;/logger&gt; &lt;!--控制台和日志文件输出级别--&gt; &lt;root level=\"INFO\" additivity = \"false\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;appender-ref ref=\"INFO\" /&gt; &lt;appender-ref ref=\"ERROR\" /&gt; &lt;/root&gt;&lt;/configuration&gt; 颜色配置打印：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文档如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文档是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。 当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan=\"true\" scanPeriod=\"10 seconds\"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义后，可以使“$&#123;&#125;”来使用变量。 --&gt; &lt;property name=\"log.path\" value=\"D:/data/logs/base-data-service\" /&gt; &lt;!--0. 日志格式和颜色渲染 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\" /&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\" /&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\" /&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(---)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt; &lt;!--1. 输出到控制台--&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/Pattern&gt; &lt;!-- 设置字符集 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--2. 输出到文档--&gt; &lt;!-- 2.1 level为 DEBUG 日志，时间滚动输出 --&gt; &lt;appender name=\"DEBUG_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/web_debug.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-debug-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录debug级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.2 level为 INFO 日志，时间滚动输出 --&gt; &lt;appender name=\"INFO_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/web_info.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录info级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.3 level为 WARN 日志，时间滚动输出 --&gt; &lt;appender name=\"WARN_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/web_warn.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-warn-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录warn级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.4 level为 ERROR 日志，时间滚动输出 --&gt; &lt;appender name=\"ERROR_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/web_error.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录ERROR级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、 以及指定&lt;appender&gt;。&lt;logger&gt;仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 &lt;logger name=\"org.springframework.web\" level=\"info\"/&gt; &lt;logger name=\"org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor\" level=\"INFO\"/&gt; --&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种把&lt;root level=\"info\"&gt;改成&lt;root level=\"DEBUG\"&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别： 【logging.level.org.mybatis=debug logging.level.dao=debug】 --&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL。默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger。 --&gt; &lt;!-- 4. 最终的策略 --&gt; &lt;!-- 4.1 开发环境:打印控制台--&gt; &lt;springProfile name=\"dev\"&gt; &lt;logger name=\"com.crecgec\" level=\"debug\"/&gt; &lt;/springProfile&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"DEBUG_FILE\" /&gt; &lt;appender-ref ref=\"INFO_FILE\" /&gt; &lt;appender-ref ref=\"WARN_FILE\" /&gt; &lt;appender-ref ref=\"ERROR_FILE\" /&gt; &lt;/root&gt; &lt;!-- 4.2 生产环境:输出到文档 &lt;springProfile name=\"pro\"&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"DEBUG_FILE\" /&gt; &lt;appender-ref ref=\"INFO_FILE\" /&gt; &lt;appender-ref ref=\"ERROR_FILE\" /&gt; &lt;appender-ref ref=\"WARN_FILE\" /&gt; &lt;/root&gt; &lt;/springProfile&gt; --&gt;&lt;/configuration&gt;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"},{"name":"logback","slug":"logback","permalink":"https://www.cicoding.cn/tags/logback/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"Springboot2.x处理404、500等异常","slug":"springboot-2-config-404-or-500-exception","date":"2020-07-10T08:29:15.000Z","updated":"2022-09-17T14:13:56.180Z","comments":false,"path":"springboot/springboot-2-config-404-or-500-exception/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-2-config-404-or-500-exception/","excerpt":"","text":"404错误1404错误是不经过Controller的，所以使用@ControllerAdvice或@RestControllerAdvice无法获取到404错误 springboot2处理404错误的两种方式 第一种：直接配置12#出现错误时, 直接抛出异常spring.mvc.throw-exception-if-no-handler-found=true 这种方式不太适用实际开发，比如和swagger集成时，访问/swagger-ui.html会出现404异常 第二种：继承ErrorController来处理错误1234567891011121314151617181920212223242526272829303132import org.springframework.boot.web.servlet.error.ErrorController;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Controllerpublic class MyErrorController implements ErrorController &#123; @RequestMapping(\"/error\") public String handleError(HttpServletRequest request)&#123; //获取statusCode:401,404,500 Integer statusCode = (Integer) request.getAttribute(\"javax.servlet.error.status_code\"); if(statusCode == 500)&#123; return \"/error/500\"; &#125;else if(statusCode == 404)&#123; //对应的是/error/404.html、/error/404.jsp等，文件位于/templates下面 return \"/error/404\"; &#125;else if(statusCode == 403)&#123; return \"/403\"; &#125;else&#123; return \"/500\"; &#125; &#125; @Override public String getErrorPath() &#123; return \"/error\"; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import com.bettn.common.util.Result;import com.bettn.common.util.WebUtils;import org.apache.shiro.ShiroException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseStatus;import org.springframework.web.bind.annotation.RestControllerAdvice;import org.springframework.web.method.HandlerMethod;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.NoHandlerFoundException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * 全局异常捕获处理 */@RestControllerAdvicepublic class ExceptionControllerAdvice &#123; private static final Logger logger= LoggerFactory.getLogger(ExceptionControllerAdvice.class); // 捕捉shiro的异常 @ExceptionHandler(ShiroException.class) public Result handle401() &#123; return new Result(401,\"您没有权限访问！\",null); &#125; // 捕捉其他所有异常 @ExceptionHandler(Exception.class) public Object globalException(HttpServletRequest request, HandlerMethod handlerMethod, Throwable ex) &#123; if(WebUtils.isAjax(handlerMethod))&#123; return new Result(getStatus(request).value(), \"访问出错，无法访问: \" + ex.getMessage(), null); &#125;else &#123; ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName(\"/error/500\"); //这里需要在templates文件夹下新建一个/error/500.html文件用作错误页面 modelAndView.addObject(\"errorMsg\",ex.getMessage()); return modelAndView; &#125; &#125; /** * 判断是否是Ajax请求 * * @param request * @return */ public boolean isAjax(HttpServletRequest request) &#123; return (request.getHeader(\"X-Requested-With\") != null &amp;&amp; \"XMLHttpRequest\".equals(request.getHeader(\"X-Requested-With\").toString())); &#125;// @ExceptionHandler(Exception.class)// public Result globalException(HttpServletRequest request, Throwable ex) &#123;// return new Result(getStatus(request).value(),\"访问出错，无法访问: \" + ex.getMessage(),null);// &#125; /** * 获取响应状态码 * @param request * @return */ private HttpStatus getStatus(HttpServletRequest request) &#123; Integer statusCode = (Integer) request.getAttribute(\"javax.servlet.error.status_code\"); if (statusCode == null) &#123; return HttpStatus.INTERNAL_SERVER_ERROR; &#125; return HttpStatus.valueOf(statusCode); &#125; /** * 捕捉404异常,这个方法只在配置 * spring.mvc.throw-exception-if-no-handler-found=true来后起作用 * */ @ResponseStatus(HttpStatus.NOT_FOUND) @ExceptionHandler(NoHandlerFoundException.class) public Result handle(HttpServletRequest request,NoHandlerFoundException e) &#123; System.out.println(12); return new Result(404,\"没有【\"+request.getMethod()+\"】\"+request.getRequestURI()+\"方法可以访问\",null); &#125;&#125; 这个异常类与ExceptionControllerAdvice连用，ExceptionControllerAdvice类除了不能处理404异常以外，其他异常都可以处理，其中 globalException异常这个方法会捕获500错误，导致MyErrorController无法捕获到500错误，从而跳转到500页面,也就是说MyErrorController在这个项目中 只能捕获404异常 500异常捕获1500异常分为ajax和直接跳转500页面 具体的异常捕获，代码如何下： 12345678910111213// 捕捉其他所有异常@ExceptionHandler(Exception.class)public Object globalException(HttpServletRequest request, HandlerMethod handlerMethod, Throwable ex) &#123; if(WebUtils.isAjax(handlerMethod))&#123; return new Result(getStatus(request).value(), \"访问出错，无法访问: \" + ex.getMessage(), null); &#125;else &#123; ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName(\"/error/500\"); //这里需要在templates文件夹下新建一个/error/500.html文件用作错误页面 modelAndView.addObject(\"errorMsg\",ex.getMessage()); return modelAndView; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import javax.servlet.http.Cookie;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.core.annotation.AnnotationUtils;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.method.HandlerMethod;public class WebUtils extends org.springframework.web.util.WebUtils &#123; /** * 判断是否ajax请求 * spring ajax 返回含有 ResponseBody 或者 RestController注解 * @param handlerMethod HandlerMethod * @return 是否ajax请求 */ public static boolean isAjax(HandlerMethod handlerMethod) &#123; ResponseBody responseBody = handlerMethod.getMethodAnnotation(ResponseBody.class); if (null != responseBody) &#123; return true; &#125; // 获取类上面的Annotation，可能包含组合注解，故采用spring的工具类 Class&lt;?&gt; beanType = handlerMethod.getBeanType(); responseBody = AnnotationUtils.getAnnotation(beanType, ResponseBody.class); if (null != responseBody) &#123; return true; &#125; return false; &#125; public static String getCookieValue(HttpServletRequest request, String cookieName) &#123; Cookie cookie=getCookie(request, cookieName); return cookie==null?null:cookie.getValue(); &#125; public static void removeCookie(HttpServletResponse response, String cookieName) &#123; setCookie(response, cookieName, null, 0); &#125; public static void setCookie(HttpServletResponse response, String cookieName, String cookieValue, int defaultMaxAge) &#123; Cookie cookie=new Cookie(cookieName,cookieValue); cookie.setHttpOnly(true); cookie.setPath(\"/\"); cookie.setMaxAge(defaultMaxAge); response.addCookie(cookie); &#125;&#125; TIP404、500页面需要放在/templates下，且确认配置了视图，如jsp、thymeleaf等，否则也会出现找不到页面，例如集成thymeleaf 依赖1234567891011&lt;!-- thymeleaf模板引擎和shiro框架的整合,这个是与shiro集成的，一般不整合shiro就不需要这个依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.theborakompanioni&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-extras-shiro&lt;/artifactId&gt; &lt;version&gt;$&#123;thymeleaf.extras.shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- SpringBoot集成thymeleaf模板 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 配置1234567spring: # 模板引擎 thymeleaf: mode: HTML5 encoding: utf-8 # 禁用缓存 cache: false 404、500页面地址(目录结构)src/main/resources/templates/error/404.htmlsrc/main/resources/templates/error/500.html 1234567891011121314151617181920&lt;!DOCTYPE HTML&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;title&gt;500&lt;/title&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;&lt;/head&gt;&lt;body&gt;&lt;!--直接使用$&#123;el&#125;无法解析出el的值$&#123;errorMsg&#125;--&gt;&lt;h3&gt;糟糕! 服务器出错啦~~(&gt;_&lt;)~~&lt;/h3&gt;&lt;div&gt; 异常信息如下:&lt;br/&gt; &lt;p th:text=\"$&#123;errorMsg&#125;\"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"Nexus3.x","slug":"Nexus3-x","permalink":"https://www.cicoding.cn/categories/Nexus3-x/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/tags/Maven/"},{"name":"Nexus3.x","slug":"Nexus3-x","permalink":"https://www.cicoding.cn/tags/Nexus3-x/"}],"keywords":[{"name":"Nexus3.x","slug":"Nexus3-x","permalink":"https://www.cicoding.cn/categories/Nexus3-x/"}]},{"title":"SpringBoot源码系列","slug":"springboot-source-code","date":"2020-07-10T07:22:15.000Z","updated":"2022-09-17T14:13:56.183Z","comments":false,"path":"springboot/springboot-source-code/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-source-code/","excerpt":"","text":"SpringBoot源码SpringBoot到底run了什么 SpringBoot源码解析创建SpringApplication对象实例 SpringBoot健康检查实现原理 SpringBoot之Tomcat自动配置 SpringBoot原理分析 - 自动装配","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"RocketMQ--权限控制","slug":"rocketmq-acl-user-guide","date":"2020-07-06T13:26:00.000Z","updated":"2022-06-14T02:55:44.551Z","comments":false,"path":"rocketmq/rocketmq-acl-user-guide/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-acl-user-guide/","excerpt":"","text":"1. 权限控制 1.1 权限控制特性介绍权限控制（ACL）主要为RocketMQ提供Topic资源级别的用户访问控制。用户在使用RocketMQ权限控制时，可以在Client客户端通过 RPCHook注入AccessKey和SecretKey签名；同时，将对应的权限控制属性（包括Topic访问权限、IP白名单和AccessKey和SecretKey签名等）设置在distribution/conf/plain_acl.yml的配置文件中。Broker端对AccessKey所拥有的权限进行校验，校验不过，抛出异常； ACL客户端可以参考：org.apache.rocketmq.example.simple包下面的AclClient代码。 1.2 权限控制的定义与属性值1.2.1 权限定义对RocketMQ的Topic资源访问权限控制定义主要如下表所示，分为以下四种 权限 含义 DENY 拒绝 ANY PUB 或者 SUB 权限 PUB 发送权限 SUB 订阅权限 1.2.2 权限定义的关键属性 字段 取值 含义 globalWhiteRemoteAddresses ;192.168..*;192.168.0.1 全局IP白名单 accessKey 字符串 Access Key secretKey 字符串 Secret Key whiteRemoteAddress ;192.168..*;192.168.0.1 用户IP白名单 admin true;false 是否管理员账户 defaultTopicPerm DENY;PUB;SUB;PUB\\ SUB 默认的Topic权限 defaultGroupPerm DENY;PUB;SUB;PUB\\ SUB 默认的ConsumerGroup权限 topicPerms topic=权限 各个Topic的权限 groupPerms group=权限 各个ConsumerGroup的权限 具体可以参考distribution/conf/plain_acl.yml配置文件 1.3 支持权限控制的集群部署在distribution/conf/plain_acl.yml配置文件中按照上述说明定义好权限属性后，打开aclEnable开关变量即可开启RocketMQ集群的ACL特性。这里贴出Broker端开启ACL特性的properties配置文件内容： 123456789101112131415brokerClusterName=DefaultClusterbrokerName=broker-abrokerId=0deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHstorePathRootDir=/data/rocketmq/rootdir-a-mstorePathCommitLog=/data/rocketmq/commitlog-a-mautoCreateSubscriptionGroup=true## if acl is open,the flag will be trueaclEnable=truelistenPort=10911brokerIP1=XX.XX.XX.XX1namesrvAddr=XX.XX.XX.XX:9876 1.4 权限控制主要流程ACL主要流程分为两部分，主要包括权限解析和权限校验。 1.4.1 权限解析Broker端对客户端的RequestCommand请求进行解析，拿到需要鉴权的属性字段。 主要包括： （1）AccessKey：类似于用户名，代指用户主体，权限数据与之对应； （2）Signature：客户根据 SecretKey 签名得到的串，服务端再用SecretKey进行签名验证； 1.4.2 权限校验Broker端对权限的校验逻辑主要分为以下几步： （1）检查是否命中全局 IP 白名单；如果是，则认为校验通过；否则走 2； （2）检查是否命中用户 IP 白名单；如果是，则认为校验通过；否则走 3； （3）校验签名，校验不通过，抛出异常；校验通过，则走 4； （4）对用户请求所需的权限 和 用户所拥有的权限进行校验；不通过，抛出异常； 用户所需权限的校验需要注意已下内容： （1）特殊的请求例如 UPDATE_AND_CREATE_TOPIC 等，只能由 admin 账户进行操作； （2）对于某个资源，如果有显性配置权限，则采用配置的权限；如果没有显性配置权限，则采用默认的权限； 1.5 热加载修改后权限控制定义RocketMQ的权限控制存储的默认实现是基于yml配置文件。用户可以动态修改权限控制定义的属性，而不需重新启动Broker服务节点。 1.6 权限控制的使用限制(1)如果ACL与高可用部署(Master/Slave架构)同时启用，那么需要在Broker Master节点的distribution/conf/plain_acl.yml配置文件中 设置全局白名单信息，即为将Slave节点的ip地址设置至Master节点plain_acl.yml配置文件的全局白名单中。 (2)如果ACL与高可用部署(多副本Dledger架构)同时启用，由于出现节点宕机时，Dledger Group组内会自动选主，那么就需要将Dledger Group组 内所有Broker节点的plain_acl.yml配置文件的白名单设置所有Broker节点的ip地址。 特别注意在[4.5.0]版本中即使使用上面所述的白名单也无法解决开启ACL的问题，解决该问题的PR链接","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"Spring Boot Bean definition overriding","slug":"SpringBoot-Bean-definition-overriding","date":"2020-06-19T03:29:15.000Z","updated":"2022-09-17T14:13:56.180Z","comments":false,"path":"springboot/SpringBoot-Bean-definition-overriding/","link":"","permalink":"https://www.cicoding.cn/springboot/SpringBoot-Bean-definition-overriding/","excerpt":"","text":"在本文中，我将讨论棘手的Spring Boot bean定义覆盖机制。 为了使您对该主题更加清楚，让我们从小测验开始。请看下一个简单的例子。 因此，我们有2种配置，它们使用名称beanName实例化bean，在主应用程序中，我们仅打印该bean的值（非常重要的是，它们都具有相同的名称）。 那么您认为将要印刷什么？ 示例112345678910111213141516171819202122232425262728@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = SpringApplication.run(Application.class, args); System.out.println(applicationContext.getBean(&quot;beanName&quot;)); &#125;&#125;@Configurationclass config1 &#123; @Primary @Order(Ordered.HIGHEST_PRECEDENCE) @Bean String beanName() &#123; return &quot;BEAN1&quot;; &#125;&#125;@Configurationclass config2 &#123; @Bean String beanName() &#123; return &quot;BEAN2&quot;; &#125;&#125; 可能的答案： “ BEAN1 ”将被打印。可能是因为它具有@Primary注释，甚至还有@Order “ BEAN2 ”将被打印。 异常会被抛出，因为它不允许有几个豆同名。 还有其他版本吗？ 正确答案奇怪的是，正确答案对于spring boot 1.*和spring boot 2.*版本会有所不同。 如果您使用spring boot 1- 运行此代码，“ BEAN2”将被打印在控制台中。用spring boot 2- exception将被抛出。你知道正确的答案吗？如果是，则可能是您在Pivotal工作：) 让我们一个一个地走：对于spring boot 1。如果我们查看日志，则会在此找到下一行： 12345INFO --- [main] o.s.b.f.s.DefaultListableBeanFactory:Overriding bean definition for bean &apos;beanName&apos; with a different definition:replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=true; factoryBeanName=config1; factoryMethodName=beanName; initMethodName=null; destroyMethodName=(inferred);defined in class path resource [com/example/test/config1.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=config2; factoryMethodName=beanName; initMethodName=null; destroyMethodName=(inferred);defined in class path resource [com/example/test/config2.class]] 因此，config1bean被覆盖，config2 并打印了“ BEAN2”。 对于spring boot 2。如果我们查看日志，则会在此找到下一行： 123456789101112***************************APPLICATION FAILED TO START***************************Description:The bean &apos;beanName&apos;, defined in class path resource [com/example/test/config2.class],could not be registered. A bean with that name hasalready been defined in class path resource [com/example/test/config1.class]and overriding is disabled.Action:Consider renaming one of the beans or enabling overridingby setting spring.main.allow-bean-definition-overriding=true 因此，在spring boot 2默认情况下，行为已更改，并且Bean覆盖已不再是有效情况。如果要修复此问题并使其与之相似，spring boot 1则应添加下一个配置： spring.main.allow-bean-definition-overriding=true 从现在开始，他们以相同的方式工作。 但这还不是终点。让我们检查示例2： 示例21234567891011121314151617181920212223242526@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = SpringApplication.run(Application.class, args); System.out.println(applicationContext.getBean(&quot;beanName&quot;)); &#125;&#125;@Configurationclass config1 &#123; @Bean String beanName() &#123; return &quot;BEAN1&quot;; &#125;&#125;@Configurationclass a_config2 &#123; @Bean String beanName() &#123; return &quot;BEAN2&quot;; &#125;&#125; 因此完全相同，但是第二个配置类的名称有所不同：现在是a_config2，但也可以这么说config0。 现在，如果我们运行此代码，结果将为BEAN1 那怎么可能呢？答案。 Spring完全忽略了具有相同名称（如@Primary和）的bean的任何其他注释@Order。在这种情况下，他们不会进行任何更改。 Spring以无法预测的方式处理@Configurations。在示例2中，它按NAME的顺序对配置类进行排序，因此基于该类可以覆盖另一个，这在示例1和示例2中可以看到。 在更复杂的应用程序中，可能有其他配置xml loaded with @Import(Configuration.class)/groovy/whatever。在这种情况下，行为将再次有所不同。我不知道哪一个将被最新加载并覆盖前一个。而且我在Spring文档中没有找到任何对此的有力解释。 我发现，@Import总是总是首先加载，而XML配置总是最新，因此它将覆盖其他所有内容。在这种情况下，名称无关紧要。 请检查最新示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@SpringBootApplication@ImportResource(&quot;classpath:config.xml&quot;)@Import(Config0.class)public class Application &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = SpringApplication.run(Application.class, args); System.out.println(applicationContext.getBean(&quot;beanName&quot;)); &#125;&#125;@Configurationclass config1 &#123; @Bean String beanName() &#123; return &quot;BEAN1&quot;; &#125;&#125;@Configurationclass config2 &#123; @Bean String beanName() &#123; return &quot;BEAN2&quot;; &#125;&#125;//separate java config which is loaded by @Import@Configurationclass Config0 &#123; @Bean String beanName() &#123; return &quot;BEAN0&quot;; &#125;&#125;//separate xml config which is loaded by @ImportResource&lt;?xml version = &quot;1.0&quot; encoding = &quot;UTF-8&quot;?&gt;&lt;beans xmlns = &quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi = &quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation = &quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd&quot;&gt; &lt;bean id = &quot;beanName&quot; class = &quot;java.lang.String&quot;&gt; &lt;constructor-arg value=&quot;XML_BEAN&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; 因此，这里的输出将是：“ XML_BEAN” 因此，几乎不可能预测哪个bean会覆盖另一个bean，尤其是当您具有复杂的上下文且内部有许多不同的配置并且确实令人困惑时。 摘要从此示例中可以看到，这种行为是完全不可预测的，在这里犯错误是非常容易的。我在这里只能看到一条规则： 与另一个名称相同（稍后处理）的Bean会覆盖较旧的Bean，但尚不清楚以后将处理哪个。 导致我们如此困惑的机制称为bean覆盖。当Spring遇到一个声明与上下文中已经存在的另一个bean同名的bean时，使用它。 我面对这个问题的真实例子。我们有一个针对Spring RestTemplate的自定义配置。名称只是restTemplate。在一段时间之后，我们从外部依赖项的配置中获得了另外一个名称完全相同的restTemplate。当然发生了，外部restTemplate用我们的自定义“调整”覆盖了我们自己的模板。 经过调查，我发现春季如何处理此类情况。 解决方案 首先，我强烈建议您启用此配置： spring.main.allow-bean-definition-overriding=false 它会立即为您提供一个信息，说明您具有相同名称的bean，并且它们之间存在冲突。 如果此代码是您的代码，并且可以以任何方式更改Bean的名称-只需执行此操作并注入所需的代码即可。而且您将永远不会面对这个问题。 如果出于某些原因，第2点对您而言不是一种情况-我建议您尝试排除错误的bean。如您所见，很难预测哪个bean将被覆盖，因此从上下文中删除它会更好。 这是一个例子： 123456789101112131415161718192021222324252627@SpringBootApplication@ComponentScan(excludeFilters = @ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, classes = config2.class))public class Application &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = SpringApplication.run(Application.class, args); System.out.println(applicationContext.getBean(&quot;beanName&quot;)); &#125;&#125;@Configurationclass config1 &#123; @Bean String beanName() &#123; return &quot;BEAN1&quot;; &#125;&#125;@Configurationclass config2 &#123; @Bean String beanName() &#123; return &quot;BEAN2&quot;; &#125;&#125; 因此，在这种情况下，不会扫描config2.class，因此我们只有一个beanName，结果将是“ BEAN1”。 PS：如果您发现一些空白或有任何需要补充或讨论的地方-请随时发表评论。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"Feign调用全局异常处理解决","slug":"feign-calls-global-exception-handling","date":"2020-06-17T08:29:15.000Z","updated":"2022-09-17T14:13:56.154Z","comments":false,"path":"micro-service/feign-calls-global-exception-handling/","link":"","permalink":"https://www.cicoding.cn/micro-service/feign-calls-global-exception-handling/","excerpt":"","text":"异常信息形如：TestService#addRecord(ParamVO) failed and no fallback available.； 对于failed and no fallback available.这种异常信息，是因为项目开启了熔断： 1feign.hystrix.enabled: true 当调用服务时抛出了异常，却没有定义fallback方法，就会抛出上述异常。由此引出了第一个解决方式。 解决方案： 自定义Feign解析器： 123456789101112131415161718192021222324252627282930import com.alibaba.fastjson.JSONException;import com.alibaba.fastjson.JSONObject;import com.crecgec.baseboot.jsoncore.exception.BaseException;import feign.Response;import feign.Util;import feign.codec.ErrorDecoder;import org.springframework.context.annotation.Configuration;import java.io.IOException;@Configurationpublic class FeignErrorDecoder implements ErrorDecoder &#123; @Override public Exception decode(String methodKey, Response response) &#123; try &#123; // 这里直接拿到我们抛出的异常信息 String message = Util.toString(response.body().asReader()); try &#123; JSONObject jsonObject = JSONObject.parseObject(message); return new BaseException(jsonObject.getString(\"resultMsg\"), jsonObject.getInteger(\"resultCode\")); &#125; catch (JSONException e) &#123; e.printStackTrace(); &#125; &#125; catch (IOException ignored) &#123; &#125; return decode(methodKey, response); &#125;&#125; 定义系统的异常类 1234567891011121314151617181920212223242526272829303132333435public class BaseException extends RuntimeException &#123; private int status ; public int getStatus() &#123; return status; &#125; public void setStatus(int status) &#123; this.status = status; &#125; public BaseException() &#123; &#125; public BaseException(String message, int status) &#123; super(message); this.status = status; &#125; public BaseException(String message) &#123; super(message); &#125; public BaseException(String message, Throwable cause) &#123; super(message, cause); &#125; public BaseException(Throwable cause) &#123; super(cause); &#125; public BaseException(String message, Throwable cause, boolean enableSuppression, boolean writableStackTrace) &#123; super(message, cause, enableSuppression, writableStackTrace); &#125;&#125; 统一异常拦截转换对应的异常信息返回前端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ResultSet &#123; /** * 返回的状态码 */ private Integer resultCode; /** * 返回的消息 */ private String resultMsg; /** * 返回的数据 */ private Object data; public ResultSet() &#123; &#125; public ResultSet(Integer resultCode, String resultMsg) &#123; this.resultCode = resultCode; this.resultMsg = resultMsg; &#125; public ResultSet(Integer resultCode, String resultMsg, Object data) &#123; this.resultCode = resultCode; this.resultMsg = resultMsg; this.data = data; &#125; public Integer getResultCode() &#123; return resultCode; &#125; public void setResultCode(Integer resultCode) &#123; this.resultCode = resultCode; &#125; public String getResultMsg() &#123; return resultMsg; &#125; public void setResultMsg(String resultMsg) &#123; this.resultMsg = resultMsg; &#125; public Object getData() &#123; return data; &#125; public void setData(Object data) &#123; this.data = data; &#125;&#125; 全局异常类处理配置： 123456789101112131415161718192021@ExceptionHandler(value = BaseException.class)public ResultSet defaultErrorHandler(HttpServletRequest req, HttpServletResponse resp, BaseException e) &#123; ResultSet resultSet = new ResultSet(); if (e.getStatus() == 400) &#123; resultSet.setResultCode(-1); resultSet.setResultMsg(e.getMessage()); resultSet.setData(null); resp.setStatus(400); &#125; else &#123; resp.setStatus(500); if(logger.isErrorEnabled())&#123; logger.error(\"系统异常，请联系系统开发人员进行处理\", e); &#125; resultSet.setResultCode(-1); resultSet.setResultMsg(e.getMessage()); resultSet.setData(null); &#125; return resultSet;&#125; 这样就能完成了feign接收异常处理的自定义异常信息！","categories":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/categories/Feign/"}],"tags":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/tags/Feign/"}],"keywords":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/categories/Feign/"}]},{"title":"Java 13的新增功能","slug":"what-is-new-in-java-13","date":"2020-04-16T05:29:15.000Z","updated":"2022-09-17T14:13:56.151Z","comments":false,"path":"java/what-is-new-in-java-13/","link":"","permalink":"https://www.cicoding.cn/java/what-is-new-in-java-13/","excerpt":"","text":"Java 13已于2019年9月17日正式发布，请在此处下载Java 13。 Java 13中的一些新功能 JEP 350：动态CDS档案 JEP-351：ZGC：取消提交未使用的内存 JEP-353：重新实现旧版套接字API JEP-354：开关表达式（预览）（开发人员功能） JEP-355：文本块（预览）（开发人员功能） 1. JEP 350动态CDS档案该JEP 通过简化创建CDS档案的过程，增强了Java 10中引入的JEP 310应用程序类数据共享。 如果程序存在，则将创建CDS存档 -XX:ArchiveClassesAtExit 1$ java -XX:ArchiveClassesAtExit=hello.jsa -cp hello.jar Hello 使用上面的CDS档案运行程序。 1$ bin/java -XX:SharedArchiveFile=hello.jsa -cp hello.jar Hello 类数据共享（CDS）背后的思想是通过一次创建类数据存档然后再使用它来提高启动性能的功能，因此JVM无需再次创建它。 请阅读以下文章，以了解有关CDS的更多信息： cl4cds 通过应用程序类数据共享缩短Java 13的启动时间 2. JEP 351 ZGC：取消提交未使用的内存该JEP 333位：Z垃圾收集器是用Java 11推出时，清理堆回忆，当提供一个短暂的停顿时间。但是，即使长时间未使用该内存，它也不会将未使用的堆内存返回给操作系统。 该JEP通过将未使用的堆内存返回给操作系统来增强ZGC。 3. JEP-353重新实现旧版套接字API的底层实现java.net.Socket和java.net.ServerSocket非常古老，可以追溯到JDK 1.0，它是传统的Java和C代码的混合，是很难维护和调试。该JEP为Socket API引入了新的基础实现，它是Java 13中的默认实现。 在Java 13之前，它将PlainSocketImpl用作SocketImpl ServerSocket.java 123456public class ServerSocket implements java.io.Closeable &#123; /** * The implementation of this Socket. */ private SocketImpl impl;&#125; 在Java 13中，它引入了一个新NioSocketImpl类来代替PlainSocketImpl。但是，如果出现问题，我们仍然可以PlainSocketImpl通过设置jdk.net.usePlainSocketImpl系统属性来切换回旧的实现 查看一个简单的Socket示例。 JEP353.java 12345678910111213141516171819import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;public class JEP353 &#123; public static void main(String[] args) &#123; try (ServerSocket serverSocket = new ServerSocket(8888))&#123; boolean running = true; while(running)&#123; Socket clientSocket = serverSocket.accept(); //do something with clientSocket &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 跟踪上述Socket类的类加载。在Java 13中，默认实现是NioSocketImpl 终奌站 123456789101112131415161718192021222324252627282930D:\\test&gt;javac JEP353.javaD:\\test&gt;java JEP353D:\\test&gt;java -XX:+TraceClassLoading JEP353 | findStr Socket[0.040s][info ][class,load] java.net.ServerSocket source: jrt:/java.base[0.040s][info ][class,load] jdk.internal.access.JavaNetSocketAccess source: jrt:/java.base[0.040s][info ][class,load] java.net.ServerSocket$1 source: jrt:/java.base[0.040s][info ][class,load] java.net.SocketOptions source: jrt:/java.base[0.040s][info ][class,load] java.net.SocketImpl source: jrt:/java.base[0.044s][info ][class,load] java.net.SocketImpl$$Lambda$1/0x0000000800ba0840 source: java.net.SocketImpl[0.047s][info ][class,load] sun.net.PlatformSocketImpl source: jrt:/java.base[0.047s][info ][class,load] sun.nio.ch.NioSocketImpl source: jrt:/java.base[0.047s][info ][class,load] sun.nio.ch.SocketDispatcher source: jrt:/java.base[0.052s][info ][class,load] java.net.SocketAddress source: jrt:/java.base[0.052s][info ][class,load] java.net.InetSocketAddress source: jrt:/java.base[0.052s][info ][class,load] java.net.InetSocketAddress$InetSocketAddressHolder source: jrt:/java.base[0.053s][info ][class,load] sun.net.ext.ExtendedSocketOptions source: jrt:/java.base[0.053s][info ][class,load] jdk.net.ExtendedSocketOptions source: jrt:/jdk.net[0.053s][info ][class,load] java.net.SocketOption source: jrt:/java.base[0.053s][info ][class,load] jdk.net.ExtendedSocketOptions$ExtSocketOption source: jrt:/jdk.net[0.053s][info ][class,load] jdk.net.SocketFlow source: jrt:/jdk.net[0.053s][info ][class,load] jdk.net.ExtendedSocketOptions$PlatformSocketOptions source: jrt:/jdk.net[0.053s][info ][class,load] jdk.net.ExtendedSocketOptions$PlatformSocketOptions$1 source: jrt:/jdk.net[0.054s][info ][class,load] jdk.net.ExtendedSocketOptions$1 source: jrt:/jdk.net[0.054s][info ][class,load] sun.nio.ch.NioSocketImpl$FileDescriptorCloser source: jrt:/java.base[0.055s][info ][class,load] java.net.Socket source: jrt:/java.base 我们可以PlainSocketImpl通过设置Djdk.net.usePlainSocketImpl系统属性来切换回。 1234567891011121314151617181920212223242526272829D:\\test&gt;java -Djdk.net.usePlainSocketImpl -XX:+TraceClassLoading JEP353 | findStr Socket[0.041s][info ][class,load] java.net.ServerSocket source: jrt:/java.base[0.041s][info ][class,load] jdk.internal.access.JavaNetSocketAccess source: jrt:/java.base[0.041s][info ][class,load] java.net.ServerSocket$1 source: jrt:/java.base[0.041s][info ][class,load] java.net.SocketOptions source: jrt:/java.base[0.041s][info ][class,load] java.net.SocketImpl source: jrt:/java.base[0.045s][info ][class,load] java.net.SocketImpl$$Lambda$1/0x0000000800ba0840 source: java.net.SocketImpl[0.048s][info ][class,load] sun.net.PlatformSocketImpl source: jrt:/java.base[0.048s][info ][class,load] java.net.AbstractPlainSocketImpl source: jrt:/java.base[0.048s][info ][class,load] java.net.PlainSocketImpl source: jrt:/java.base[0.048s][info ][class,load] java.net.AbstractPlainSocketImpl$1 source: jrt:/java.base[0.050s][info ][class,load] sun.net.ext.ExtendedSocketOptions source: jrt:/java.base[0.050s][info ][class,load] jdk.net.ExtendedSocketOptions source: jrt:/jdk.net[0.050s][info ][class,load] java.net.SocketOption source: jrt:/java.base[0.051s][info ][class,load] jdk.net.ExtendedSocketOptions$ExtSocketOption source: jrt:/jdk.net[0.051s][info ][class,load] jdk.net.SocketFlow source: jrt:/jdk.net[0.051s][info ][class,load] jdk.net.ExtendedSocketOptions$PlatformSocketOptions source: jrt:/jdk.net[0.051s][info ][class,load] jdk.net.ExtendedSocketOptions$PlatformSocketOptions$1 source: jrt:/jdk.net[0.051s][info ][class,load] jdk.net.ExtendedSocketOptions$1 source: jrt:/jdk.net[0.051s][info ][class,load] java.net.StandardSocketOptions source: jrt:/java.base[0.051s][info ][class,load] java.net.StandardSocketOptions$StdSocketOption source: jrt:/java.base[0.053s][info ][class,load] sun.net.ext.ExtendedSocketOptions$$Lambda$2/0x0000000800ba1040 source: sun.net.ext.ExtendedSocketOptions[0.056s][info ][class,load] java.net.SocketAddress source: jrt:/java.base[0.056s][info ][class,load] java.net.InetSocketAddress source: jrt:/java.base[0.058s][info ][class,load] java.net.InetSocketAddress$InetSocketAddressHolder source: jrt:/java.base[0.059s][info ][class,load] java.net.SocketCleanable source: jrt:/java.base 4. JEP-354开关表达式（预览）该JEP增强了以前的Java 12 JEP 325 Switch表达式，因此可以用作语句（不返回内容）或表达式（返回内容）。引入了新的关键字“ yield”以从开关返回值。 PS这是Java 13中的预览语言功能 在Java 12传统switch语句之前，我们可以返回如下值： 123456789101112131415161718private static String getText(int number) &#123; String result = \"\"; switch (number) &#123; case 1, 2: result = \"one or two\"; break; case 3: result = \"three\"; break; case 4, 5, 6: result = \"four or five or six\"; break; default: result = \"unknown\"; break; &#125;; return result; &#125; 在Java 12中，我们可以用来break从中返回值switch。 12345678910111213private static String getText(int number) &#123; String result = switch (number) &#123; case 1, 2: break \"one or two\"; case 3: break \"three\"; case 4, 5, 6: break \"four or five or six\"; default: break \"unknown\"; &#125;; return result; &#125; 在Java 13中，上面的Java 12 value break不再被编译，我们应该使用它yield来返回一个值。 123456789101112private static String getText(int number) &#123; return switch (number) &#123; case 1, 2: yield \"one or two\"; case 3: yield \"three\"; case 4, 5, 6: yield \"four or five or six\"; default: yield \"unknown\"; &#125;; &#125; switchJava 13仍支持Java 12 规则标签或箭头语法。 12345678private static String getText(int number) &#123; return switch (number) &#123; case 1, 2 -&gt; \"one or two\"; case 3 -&gt; \"three\"; case 4, 5, 6 -&gt; \"four or five or six\"; default -&gt; \"unknown\"; &#125;; &#125; 注意有关完整示例，请阅读此Java 13开关表达式 5. JEP-355文本块（预览）该JEP最终引入了多行字符串文字，文本块。 PS这是Java 13中的预览语言功能 在Java 13之前 1234567891011String html =\"&lt;html&gt;\\n\" + \" &lt;body&gt;\\n\" + \" &lt;p&gt;Hello, World&lt;/p&gt;\\n\" + \" &lt;/body&gt;\\n\" + \"&lt;/html&gt;\\n\"; String json =\"&#123;\\n\" + \" \\\"name\\\":\\\"mkyong\\\",\\n\" + \" \\\"age\\\":38\\n\" + \"&#125;\\n\"; 现在Java 13 1234567891011121314String html = \"\"\" &lt;html&gt; &lt;body&gt; &lt;p&gt;Hello, World&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; \"\"\";String json = \"\"\" &#123; \"name\":\"mkyong\", \"age\":38 &#125; \"\"\"; 要启用Java 13预览功能： 12javac --enable-preview --release 13 Example.javajava --enable-preview Example 参考文献 OpenJDK 13项目 Oracle – Java 13的到来！ cl4cds 具有应用程序类的Java 13-数据共享 Java 13文本块 JEP 325开关表达式 JEP 333：Z垃圾收集器 JEP 350：动态CDS档案 JEP-351：ZGC：取消提交未使用的内存 JEP-353：重新实现旧版套接字API JEP-354：开关表达式（预览） JEP-355：文本块（预览） Java版本历史","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}]},{"title":"Sharding-JDBC 垂直拆分（不同的表在不同的库中）","slug":"sharding-jdbc005","date":"2020-03-14T09:25:15.000Z","updated":"2022-09-17T14:13:56.172Z","comments":false,"path":"sharding-jdbc/sharding-jdbc005/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc005/","excerpt":"","text":"上一篇介绍的了Sharding-JDBC不分库，只分表例子，接下来我们写demo，介绍SpringBoot使用Sharding-JDBC垂直拆分（不同的表在不同的库中）。话不多说，直接写代码。 准备 SpringBoot 2.1.12 Sharding-JDBC 4.0.0 Mybatis 3.x Mysql 8.0 lombok 本文场景介绍一个数据库，将user表分表分为四个一样的表，根据取模算法分别向user0-3的表里插入数据。 POM文件pom文件引入如下相关依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-example&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-db-sharding&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sharding-jdbc-db-sharding&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 相关代码实现Controller代码CicodingController代码1234567891011121314151617181920212223242526272829303132333435package cn.cicoding.controller;import cn.cicoding.entity.Cicoding;import cn.cicoding.service.CicodingService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class CicodingController &#123; @Autowired private CicodingService cicodingService; @GetMapping(\"/cis\") public Object list() &#123; return cicodingService.list(); &#125; @GetMapping(\"/ci/add\") public Object add() &#123; for (long i = 0; i &lt; 10; i++) &#123; Cicoding cicoding = new Cicoding(); cicoding.setId(i+\"a\"); cicoding.setCity(\"深圳\"); cicoding.setRegion(\"宝安\"); cicoding.setName(\"李四\"); cicoding.setLdNum(\"A\"); cicoding.setUnitNum(\"2\"); cicodingService.addCicoding(cicoding); &#125; return \"success\"; &#125; &#125; UserController代码123456789101112131415161718192021222324252627282930313233343536373839404142package cn.cicoding.controller;import cn.cicoding.entity.User;import cn.cicoding.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class UserController &#123; @Autowired private UserService userService; @GetMapping(\"/users\") public Object list() &#123; return userService.list(); &#125; @GetMapping(\"/add\") public Object add() &#123; for (long i = 0; i &lt; 100; i++) &#123; User user = new User(); user.setCity(\"深圳\"); user.setName(\"李四\"); userService.add(user); &#125; return \"success\"; &#125; @GetMapping(\"/users/&#123;id&#125;\") public Object get(@PathVariable Long id) &#123; return userService.findById(id); &#125; @GetMapping(\"/users/query\") public Object get(String name) &#123; return userService.findByName(name); &#125; &#125; Service代码CicodingService代码12345678910111213package cn.cicoding.service;import java.util.List;import cn.cicoding.entity.Cicoding;public interface CicodingService &#123; List&lt;Cicoding&gt; list(); Long addCicoding(Cicoding cicoding); &#125; UserService代码1234567891011121314151617package cn.cicoding.service;import cn.cicoding.entity.User;import java.util.List;public interface UserService &#123; List&lt;User&gt; list(); Long add(User user); User findById(Long id); User findByName(String name); &#125; CicodingServiceImpl代码1234567891011121314151617181920212223242526package cn.cicoding.service;import java.util.List;import cn.cicoding.entity.Cicoding;import cn.cicoding.repository.CicodingRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class CicodingServiceImpl implements CicodingService &#123; @Autowired private CicodingRepository cicodingRepository; @Override public List&lt;Cicoding&gt; list() &#123; return cicodingRepository.list(); &#125; @Override public Long addCicoding(Cicoding cicoding) &#123; return cicodingRepository.addCicoding(cicoding); &#125;&#125; UserServiceImpl代码12345678910111213141516171819202122232425262728293031323334package cn.cicoding.service;import java.util.List;import cn.cicoding.entity.User;import cn.cicoding.repository.UserRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserRepository userRepository; public List&lt;User&gt; list() &#123; return userRepository.list(); &#125; public Long add(User user) &#123; return userRepository.addUser(user); &#125; @Override public User findById(Long id) &#123; return userRepository.findById(id); &#125; @Override public User findByName(String name) &#123; return userRepository.findByName(name); &#125;&#125; Repository代码CicodingRepository代码123456789101112131415package cn.cicoding.repository;import java.util.List;import cn.cicoding.entity.Cicoding;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface CicodingRepository &#123; Long addCicoding(Cicoding cicoding); List&lt;Cicoding&gt; list();&#125; UserRepository代码123456789101112131415161718package cn.cicoding.repository;import java.util.List;import cn.cicoding.entity.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserRepository &#123; Long addUser(User user); List&lt;User&gt; list(); User findById(Long id); User findByName(String name);&#125; Mapper.xml代码实现CicodingMapper.xml1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.cicoding.repository.CicodingRepository\"&gt; &lt;resultMap id=\"baseResultMap\" type=\"cn.cicoding.entity.Cicoding\"&gt; &lt;result column=\"id\" property=\"id\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"city\" property=\"city\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"region\" property=\"region\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"ld_num\" property=\"ldNum\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"unit_num\" property=\"unitNum\" jdbcType=\"VARCHAR\" /&gt; &lt;/resultMap&gt; &lt;insert id=\"addCicoding\"&gt; INSERT INTO cicoding ( id, city, region, name, ld_num, unit_num ) VALUES ( #&#123;id,jdbcType=VARCHAR&#125;, #&#123;city,jdbcType=VARCHAR&#125;, #&#123;region,jdbcType=VARCHAR&#125;, #&#123;name,jdbcType=VARCHAR&#125;, #&#123;ldNum,jdbcType=VARCHAR&#125;, #&#123;unitNum,jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;select id=\"list\" resultMap=\"baseResultMap\"&gt; SELECT ld.* FROM cicoding ld &lt;/select&gt; &lt;/mapper&gt; UserMapper.xml123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.cicoding.repository.UserRepository\"&gt; &lt;resultMap id=\"baseResultMap\" type=\"cn.cicoding.entity.User\"&gt; &lt;result column=\"id\" property=\"id\" jdbcType=\"INTEGER\" /&gt; &lt;result column=\"city\" property=\"city\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" /&gt; &lt;/resultMap&gt; &lt;insert id=\"addUser\"&gt; INSERT INTO user ( city, name ) VALUES ( #&#123;city,jdbcType=VARCHAR&#125;, #&#123;name,jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;select id=\"list\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u &lt;/select&gt; &lt;select id=\"findById\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u WHERE u.id=#&#123;id,jdbcType=INTEGER&#125; &lt;/select&gt; &lt;select id=\"findByName\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u WHERE u.name=#&#123;name,jdbcType=VARCHAR&#125; &lt;/select&gt; &lt;/mapper&gt; 实体类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677Cicodingpackage cn.cicoding.entity;import lombok.Data;/** * 不分表 * @author zhaokejin * */@Datapublic class Cicoding &#123; private String id; private String city; private String region; private String name; private String ldNum; private String unitNum; &#125;User package cn.cicoding.entity;import java.io.Serializable;/** * 分表 * @author zhaokejin * */public class User implements Serializable &#123; private static final long serialVersionUID = -1205226416664488559L; private Long id; private String city = \"\"; private String name = \"\"; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 到这我们完成了基本的代码编写，由于sharding-jdbc是jar包，我们来看主要的配置信息 123456789101112131415161718192021222324252627282930313233#Sharding JDBC 垂直拆分（不同的表在不同的库中）server.port=8084# mybatis对应的映射文件路径mybatis.mapper-locations=classpath:mapper/*.xml# mybatis对应的实体类mybatis.type-aliases-package=cn.cicoding.modelspring.shardingsphere.datasource.names=ds0,ds1# 数据源spring.shardingsphere.datasource.ds0.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.ds0.jdbc-url=jdbc:mysql://localhost:3309/ds0?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds0.username=rootspring.shardingsphere.datasource.ds0.password=rootspring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mysql://localhost:3309/ds1?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds1.username=rootspring.shardingsphere.datasource.ds1.password=root# 绑定cicoding表所在节点spring.shardingsphere.sharding.tables.cicoding.actual-data-nodes=ds1.cicoding# 绑定user表所在节点spring.shardingsphere.sharding.tables.user.actual-data-nodes=ds0.userspring.shardingsphere.sharding.tables.user.key-generator.column=idspring.shardingsphere.sharding.tables.user.key-generator.type=SNOWFLAKE# 显示SQLspring.shardingsphere.props.sql.show=true 启动类12345678910111213141516package cn.cicoding;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * Sharding JDBC 垂直拆分（不同的表在不同的库中） */@SpringBootApplicationpublic class ShardingJdbcDbShardingApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardingJdbcDbShardingApplication.class, args); &#125;&#125; 测试演示启动启动类，访问http://localhost:8084/add http://localhost:8084/cis 分别进入不同的库！ 到此我们就实现了sharding-jdbc主从读写分离实现，更多配置请参考此处！","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"Sharding-JDBC不分库，只分表例子","slug":"sharding-jdbc004","date":"2020-03-14T09:20:15.000Z","updated":"2022-09-17T14:13:56.172Z","comments":false,"path":"sharding-jdbc/sharding-jdbc004/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc004/","excerpt":"","text":"上一篇介绍的了Sharding-jdbc的读写分离，接下来我们写demo，介绍SpringBoot使用Sharding-JDBC不分库，只分表例子。话不多说，直接写代码。 准备 SpringBoot 2.1.12 Sharding-JDBC 4.0.0 Mybatis 3.x Mysql 8.0 lombok 本文场景介绍一个数据库，将user表分表分为四个一样的表，根据取模算法分别向user0-3的表里插入数据。 POM文件pom文件引入如下相关依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-example&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-table&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sharding-jdbc-table&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 相关代码实现Controller代码12345678910111213141516171819202122232425262728293031323334353637383940414243package cn.cicoding.controller;import cn.cicoding.model.User;import cn.cicoding.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class UserController &#123; @Autowired private UserService userService; @GetMapping(\"/users\") public Object list() &#123; return userService.list(); &#125; @GetMapping(\"/add\") public Object add() &#123; for (long i = 0; i &lt; 100; i++) &#123; User user = new User(); user.setId(i); user.setCity(\"深圳\"); user.setName(\"李四\"+ i); userService.add(user); &#125; return \"success\"; &#125; @GetMapping(\"/users/&#123;id&#125;\") public Object get(@PathVariable Long id) &#123; return userService.findById(id); &#125; @GetMapping(\"/users/query\") public Object get(String name) &#123; return userService.findByName(name); &#125;&#125; Service代码1234567891011121314151617package cn.cicoding.service;import cn.cicoding.model.User;import java.util.List;public interface UserService &#123; List&lt;User&gt; list(); Long add(User user); User findById(Long id); User findByName(String name); &#125; ServiceImpl代码123456789101112131415161718192021222324252627282930313233343536package cn.cicoding.service.impl;import cn.cicoding.dao.UserDaoMapper;import cn.cicoding.model.User;import cn.cicoding.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserDaoMapper userDao; public List&lt;User&gt; list() &#123; List&lt;User&gt; list = userDao.list(); return list; &#125; public Long add(User user) &#123; return userDao.addUser(user); &#125; @Override public User findById(Long id) &#123; return userDao.findById(id); &#125; @Override public User findByName(String name) &#123; return userDao.findByName(name); &#125;&#125; Dao代码1234567891011121314151617package cn.cicoding.dao;import cn.cicoding.model.User;import org.apache.ibatis.annotations.Mapper;import java.util.List;@Mapperpublic interface UserDaoMapper &#123; Long addUser(User user); List&lt;User&gt; list(); User findById(Long id); User findByName(String name);&#125; Mapper.xml代码实现12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.cicoding.dao.UserDaoMapper\"&gt; &lt;insert id=\"addUser\"&gt; INSERT INTO user ( id, city, name ) VALUES ( #&#123;id,jdbcType=INTEGER&#125;, #&#123;city,jdbcType=VARCHAR&#125;, #&#123;name,jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;select id=\"list\" resultType=\"cn.cicoding.model.User\"&gt; SELECT u.* FROM user u &lt;/select&gt; &lt;select id=\"findById\" resultType=\"cn.cicoding.model.User\"&gt; SELECT u.* FROM user u WHERE u.id=#&#123;id,jdbcType=INTEGER&#125; &lt;/select&gt; &lt;select id=\"findByName\" resultType=\"cn.cicoding.model.User\"&gt; SELECT u.* FROM user u WHERE u.name=#&#123;name,jdbcType=VARCHAR&#125; &lt;/select&gt; &lt;/mapper&gt; 实体类12345678910111213141516171819package cn.cicoding.model;import lombok.Data;import java.io.Serializable;@Datapublic class User implements Serializable &#123; private static final long serialVersionUID = -1205226416664488559L; private Long id; private String city = \"\"; private String name = \"\"; &#125; 到这我们完成了基本的代码编写，由于sharding-jdbc是jar包，我们来看主要的配置信息 1234567891011121314151617181920212223242526272829#使用取模的方式来实现表分片server.port=8084# mybatis对应的映射文件路径mybatis.mapper-locations=classpath:mapper/*.xml# mybatis对应的实体类mybatis.type-aliases-package=cn.cicoding.modelspring.shardingsphere.datasource.names=dsspring.shardingsphere.datasource.ds.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.ds.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.ds.jdbc-url=jdbc:mysql://localhost:3309/ds_0?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.ds.username=rootspring.shardingsphere.datasource.ds.password=root# 展示sql打印spring.shardingsphere.props.sql.show=true# 自定义分表算法#spring.shardingsphere.sharding.tables.user.table-strategy.standard.sharding-column=id#spring.shardingsphere.sharding.tables.user.table-strategy.standard.precise-algorithm-class-name=com.example.MyCustomShardingAlgorithm# 分表配置spring.shardingsphere.sharding.tables.user.actual-data-nodes=ds.user_$-&gt;&#123;0..3&#125;# inline 表达式 （id类型转换 -&gt; id.longValue() -&gt; user_$&#123;id.longValue() % 4&#125;）spring.shardingsphere.sharding.tables.user.table-strategy.inline.sharding-column=idspring.shardingsphere.sharding.tables.user.table-strategy.inline.algorithm-expression=user_$-&gt;&#123;id % 4&#125;spring.shardingsphere.sharding.tables.user.key-generator.column=idspring.shardingsphere.sharding.tables.user.key-generator.type=SNOWFLAKE 启动类12345678910111213package cn.cicoding;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ShardingJdbcDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardingJdbcDemoApplication.class, args); &#125;&#125; 测试演示启动启动类，访问http://localhost:8084/add 查看数据库中user_0，user_1，user_2，user_3中每个数据库库中都有数据，且id都相差4 我们看到DataSources是master节点主库 我们再次访问http://localhost:8084/users 看到数据库中的数据user_0，user_1，user_2，user_3中都查询出来了，实现了不分库分表策略！ 到此我们就实现了sharding-jdbc主从读写分离实现，更多配置请参考此处！","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"Sharding-JDBC读写分离案例","slug":"sharding-jdbc003","date":"2020-03-14T09:18:15.000Z","updated":"2022-09-17T14:13:56.172Z","comments":false,"path":"sharding-jdbc/sharding-jdbc003/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc003/","excerpt":"","text":"​ 前面我们介绍的了Sharding-jdbc的简介和对比其他的分库分表，接下来我们写demo，介绍SpringBoot使用Sharding-JDBC进行读写分离。话不多说，直接写代码。 准备 SpringBoot 2.1.12 Sharding-JDBC 4.0.0 Mybatis 3.x Mysql 8.0 lombok（暂时没使用） 本文场景介绍主从两个库： 主库负责写入master 从库负责查询slave POM文件pom文件引入如下相关依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;shardingsphere-example&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-read-write&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sharding-jdbc-read-write&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 相关代码实现Controller代码1234567891011121314151617181920212223242526272829package cn.cicoding.controller;import cn.cicoding.model.User;import cn.cicoding.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class UserController &#123; @Autowired private UserService userService; @GetMapping(\"/users\") public Object list() &#123; return userService.list(); &#125; @GetMapping(\"/add\") public Object add() &#123; User user = new User(); user.setId(100L); user.setCity(\"深圳\"); user.setName(\"李四\"); return userService.add(user); &#125; &#125; Service代码12345678910111213package cn.cicoding.service;import cn.cicoding.model.User;import java.util.List;public interface UserService &#123; List&lt;User&gt; list(); Long add(User user); &#125; ServiceImpl代码12345678910111213141516171819202122232425262728package cn.cicoding.service;import java.util.List;import cn.cicoding.model.User;import cn.cicoding.dao.UserRepository;import org.apache.shardingsphere.api.hint.HintManager;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserRepository userRepository; public List&lt;User&gt; list() &#123; // 强制路由主库// HintManager.getInstance().setMasterRouteOnly(); return userRepository.list(); &#125; public Long add(User user) &#123; return userRepository.addUser(user); &#125;&#125; Dao代码123456789101112131415package cn.cicoding.dao;import java.util.List;import cn.cicoding.model.User;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface UserRepository &#123; Long addUser(User user); List&lt;User&gt; list(); &#125; Mapper.xml代码实现1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.cicoding.dao.UserRepository\"&gt; &lt;resultMap id=\"baseResultMap\" type=\"cn.cicoding.model.User\"&gt; &lt;result column=\"id\" property=\"id\" jdbcType=\"INTEGER\" /&gt; &lt;result column=\"city\" property=\"city\" jdbcType=\"VARCHAR\" /&gt; &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" /&gt; &lt;/resultMap&gt; &lt;insert id=\"addUser\"&gt; INSERT INTO user ( id, city, name ) VALUES ( #&#123;id,jdbcType=INTEGER&#125;, #&#123;city,jdbcType=VARCHAR&#125;, #&#123;name,jdbcType=VARCHAR&#125; ) &lt;/insert&gt; &lt;select id=\"list\" resultMap=\"baseResultMap\"&gt; SELECT u.* FROM user u &lt;/select&gt;&lt;/mapper&gt; 实体类123456789101112131415161718192021222324252627282930313233343536373839package cn.cicoding.model;import java.io.Serializable;public class User implements Serializable &#123; private static final long serialVersionUID = -1205226416664488559L; private Long id; private String city = \"\"; private String name = \"\"; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 到这我们完成了基本的代码编写，由于sharding-jdbc是jar包，我们来看主要的配置信息 1234567891011121314151617181920212223242526272829303132#使用取模的方式来实现表分片server.port=8084# mybatis对应的映射文件路径mybatis.mapper-locations=classpath:mapper/*.xml# mybatis对应的实体类mybatis.type-aliases-package=cn.cicoding.modelspring.shardingsphere.datasource.names=master,slave# 主数据源spring.shardingsphere.datasource.master.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.master.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.master.jdbc-url=jdbc:mysql://localhost:3309/sharding-jdbc-read-write_0?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.master.username=rootspring.shardingsphere.datasource.master.password=root# 从数据源spring.shardingsphere.datasource.slave.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.slave.driver-class-name=com.mysql.cj.jdbc.Driverspring.shardingsphere.datasource.slave.jdbc-url=jdbc:mysql://localhost:3309/sharding-jdbc-read-write_1?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.shardingsphere.datasource.slave.username=rootspring.shardingsphere.datasource.slave.password=root# 读写分离配置spring.shardingsphere.masterslave.load-balance-algorithm-type=round_robinspring.shardingsphere.masterslave.name=dataSourcespring.shardingsphere.masterslave.master-data-source-name=masterspring.shardingsphere.masterslave.slave-data-source-names=slave# 显示SQLspring.shardingsphere.props.sql.show=true 启动类12345678910111213package cn.cicoding;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ShardingJdbcReadWriteApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ShardingJdbcReadWriteApplication.class, args); &#125;&#125; 测试演示启动启动类，访问http://localhost:8084/add 查看控制台 1234567892020-02-06 12:13:02.445 INFO 22628 --- [nio-8084-exec-6] ShardingSphere-SQL : Rule Type: master-slave2020-02-06 12:13:02.445 INFO 22628 --- [nio-8084-exec-6] ShardingSphere-SQL : SQL: INSERT INTO user ( id, city, name ) VALUES ( ?, ?, ? ) ::: DataSources: master 我们看到DataSources是master节点主库 我们再次访问http://localhost:8084/users 查看控制台日志 122020-02-06 12:13:59.848 INFO 22628 --- [nio-8084-exec-8] ShardingSphere-SQL : Rule Type: master-slave2020-02-06 12:13:59.848 INFO 22628 --- [nio-8084-exec-8] ShardingSphere-SQL : SQL: SELECT u.* FROM user u ::: DataSources: slave 我们看到DataSources是slave节点从库 到此我们就实现了sharding-jdbc主从读写分离实现，更多配置请参考此处！ 源码分析我们看到读写分离配置 spring.shardingsphere.masterslave.load-balance-algorithm-type源码位置： https://github.com/apache/incubator-shardingsphere/blob/4.0.0/sharding-core/sharding-core-api/src/main/java/org/apache/shardingsphere/api/config/masterslave/MasterSlaveRuleConfiguration.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the \"License\"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.shardingsphere.api.config.masterslave;import com.google.common.base.Preconditions;import com.google.common.base.Strings;import lombok.Getter;import org.apache.shardingsphere.api.config.RuleConfiguration;import java.util.List;/** * Master-slave rule configuration. * * @author zhangliang * @author panjuan */@Getterpublic class MasterSlaveRuleConfiguration implements RuleConfiguration &#123; private final String name; private final String masterDataSourceName; private final List&lt;String&gt; slaveDataSourceNames; private final LoadBalanceStrategyConfiguration loadBalanceStrategyConfiguration; public MasterSlaveRuleConfiguration(final String name, final String masterDataSourceName, final List&lt;String&gt; slaveDataSourceNames) &#123; this(name, masterDataSourceName, slaveDataSourceNames, null); &#125; public MasterSlaveRuleConfiguration(final String name, final String masterDataSourceName, final List&lt;String&gt; slaveDataSourceNames, final LoadBalanceStrategyConfiguration loadBalanceStrategyConfiguration) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(name), \"Name is required.\"); Preconditions.checkArgument(!Strings.isNullOrEmpty(masterDataSourceName), \"MasterDataSourceName is required.\"); Preconditions.checkArgument(null != slaveDataSourceNames &amp;&amp; !slaveDataSourceNames.isEmpty(), \"SlaveDataSourceNames is required.\"); this.name = name; this.masterDataSourceName = masterDataSourceName; this.slaveDataSourceNames = slaveDataSourceNames; this.loadBalanceStrategyConfiguration = loadBalanceStrategyConfiguration; &#125;&#125; MasterSlaveRuleConfiguration定义了name、masterDataSourceName、slaveDataSourceNames、loadBalanceStrategyConfiguration属性,供我们读写分离配置使用！ 我们看一下round_robin定义的属性配置： MasterSlaveLoadBalanceAlgorithm源码位置： https://github.com/apache/incubator-shardingsphere/blob/4.0.0/sharding-core/sharding-core-api/src/main/java/org/apache/shardingsphere/spi/masterslave/MasterSlaveLoadBalanceAlgorithm.java 1234567891011121314151617181920212223package org.apache.shardingsphere.spi.masterslave;import org.apache.shardingsphere.spi.TypeBasedSPI;import java.util.List;/** * Master-slave database load-balance algorithm. * * @author zhangliang */public interface MasterSlaveLoadBalanceAlgorithm extends TypeBasedSPI &#123; /** * Get data source. * * @param name master-slave logic data source name * @param masterDataSourceName name of master data sources * @param slaveDataSourceNames names of slave data sources * @return name of selected data source */ String getDataSource(String name, String masterDataSourceName, List&lt;String&gt; slaveDataSourceNames);&#125; MasterSlaveLoadBalanceAlgorithm接口继承了TypeBasedSPI接口，它定义了getDataSource方法；它有两个实现类分别是RandomMasterSlaveLoadBalanceAlgorithm、RoundRobinMasterSlaveLoadBalanceAlgorithm RandomMasterSlaveLoadBalanceAlgorithm源码位置： https://github.com/apache/incubator-shardingsphere/blob/4.0.0/sharding-core/sharding-core-common/src/main/java/org/apache/shardingsphere/core/strategy/masterslave/RandomMasterSlaveLoadBalanceAlgorithm.java 12345678910111213141516171819202122232425262728293031package org.apache.shardingsphere.core.strategy.masterslave;import lombok.Getter;import lombok.Setter;import org.apache.shardingsphere.spi.masterslave.MasterSlaveLoadBalanceAlgorithm;import java.util.List;import java.util.Properties;import java.util.concurrent.ThreadLocalRandom;/** * Random slave database load-balance algorithm. * * @author zhangliang */@Getter@Setterpublic final class RandomMasterSlaveLoadBalanceAlgorithm implements MasterSlaveLoadBalanceAlgorithm &#123; private Properties properties = new Properties(); @Override public String getType() &#123; return \"RANDOM\"; &#125; @Override public String getDataSource(final String name, final String masterDataSourceName, final List&lt;String&gt; slaveDataSourceNames) &#123; return slaveDataSourceNames.get(ThreadLocalRandom.current().nextInt(slaveDataSourceNames.size())); &#125;&#125; RandomMasterSlaveLoadBalanceAlgorithm使用Random().nextInt来进行随机 RoundRobinMasterSlaveLoadBalanceAlgorithm源码位置： https://github.com/apache/incubator-shardingsphere/blob/4.0.0/sharding-core/sharding-core-common/src/main/java/org/apache/shardingsphere/core/strategy/masterslave/RoundRobinMasterSlaveLoadBalanceAlgorithm.java 12345678910111213141516171819202122232425262728293031323334353637package org.apache.shardingsphere.core.strategy.masterslave;import lombok.Getter;import lombok.Setter;import org.apache.shardingsphere.spi.masterslave.MasterSlaveLoadBalanceAlgorithm;import java.util.List;import java.util.Properties;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.atomic.AtomicInteger;/** * Round-robin slave database load-balance algorithm. * * @author zhangliang */@Getter@Setterpublic final class RoundRobinMasterSlaveLoadBalanceAlgorithm implements MasterSlaveLoadBalanceAlgorithm &#123; private static final ConcurrentHashMap&lt;String, AtomicInteger&gt; COUNTS = new ConcurrentHashMap&lt;&gt;(); private Properties properties = new Properties(); @Override public String getType() &#123; return \"ROUND_ROBIN\"; &#125; @Override public String getDataSource(final String name, final String masterDataSourceName, final List&lt;String&gt; slaveDataSourceNames) &#123; AtomicInteger count = COUNTS.containsKey(name) ? COUNTS.get(name) : new AtomicInteger(0); COUNTS.putIfAbsent(name, count); count.compareAndSet(slaveDataSourceNames.size(), 0); return slaveDataSourceNames.get(Math.abs(count.getAndIncrement()) % slaveDataSourceNames.size()); &#125;&#125; 我们看一下sharding-jdbc的路由策略 MasterSlaveRouter源码位置： https://github.com/apache/incubator-shardingsphere/blob/4.0.0/sharding-core/sharding-core-route/src/main/java/org/apache/shardingsphere/core/route/router/masterslave/MasterSlaveRouter.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package org.apache.shardingsphere.core.route.router.masterslave;import lombok.RequiredArgsConstructor;import org.apache.shardingsphere.api.hint.HintManager;import org.apache.shardingsphere.sql.parser.SQLParseEngine;import org.apache.shardingsphere.sql.parser.sql.statement.SQLStatement;import org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement;import org.apache.shardingsphere.core.route.SQLLogger;import org.apache.shardingsphere.core.rule.MasterSlaveRule;import java.util.ArrayList;import java.util.Collection;import java.util.Collections;/** * Master slave router interface. * * @author zhangliang * @author panjuan */@RequiredArgsConstructorpublic final class MasterSlaveRouter &#123; private final MasterSlaveRule masterSlaveRule; private final SQLParseEngine parseEngine; private final boolean showSQL; /** * Route Master slave. * * @param sql SQL * @param useCache use cache or not * @return data source names */ // TODO for multiple masters may return more than one data source public Collection&lt;String&gt; route(final String sql, final boolean useCache) &#123; Collection&lt;String&gt; result = route(parseEngine.parse(sql, useCache)); if (showSQL) &#123; SQLLogger.logSQL(sql, result); &#125; return result; &#125; private Collection&lt;String&gt; route(final SQLStatement sqlStatement) &#123; if (isMasterRoute(sqlStatement)) &#123; MasterVisitedManager.setMasterVisited(); return Collections.singletonList(masterSlaveRule.getMasterDataSourceName()); &#125; return Collections.singletonList(masterSlaveRule.getLoadBalanceAlgorithm().getDataSource( masterSlaveRule.getName(), masterSlaveRule.getMasterDataSourceName(), new ArrayList&lt;&gt;(masterSlaveRule.getSlaveDataSourceNames()))); &#125; private boolean isMasterRoute(final SQLStatement sqlStatement) &#123; return containsLockSegment(sqlStatement) || !(sqlStatement instanceof SelectStatement) || MasterVisitedManager.isMasterVisited() || HintManager.isMasterRouteOnly(); &#125; private boolean containsLockSegment(final SQLStatement sqlStatement) &#123; return sqlStatement instanceof SelectStatement &amp;&amp; ((SelectStatement) sqlStatement).getLock().isPresent(); &#125;&#125; MasterSlaveRouter的route方法使用masterSlaveRule来进行路由 MasterSlaveRule源码位置： https://github.com/apache/incubator-shardingsphere/blob/4.0.0/sharding-core/sharding-core-common/src/main/java/org/apache/shardingsphere/core/rule/MasterSlaveRule.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package org.apache.shardingsphere.core.rule;import lombok.Getter;import org.apache.shardingsphere.api.config.masterslave.LoadBalanceStrategyConfiguration;import org.apache.shardingsphere.api.config.masterslave.MasterSlaveRuleConfiguration;import org.apache.shardingsphere.spi.algorithm.masterslave.MasterSlaveLoadBalanceAlgorithmServiceLoader;import org.apache.shardingsphere.spi.masterslave.MasterSlaveLoadBalanceAlgorithm;import java.util.List;/** * Databases and tables master-slave rule. * * @author zhangliang * @author panjuan */@Getterpublic class MasterSlaveRule implements BaseRule &#123; private final String name; private final String masterDataSourceName; private final List&lt;String&gt; slaveDataSourceNames; private final MasterSlaveLoadBalanceAlgorithm loadBalanceAlgorithm; private final MasterSlaveRuleConfiguration ruleConfiguration; public MasterSlaveRule(final String name, final String masterDataSourceName, final List&lt;String&gt; slaveDataSourceNames, final MasterSlaveLoadBalanceAlgorithm loadBalanceAlgorithm) &#123; this.name = name; this.masterDataSourceName = masterDataSourceName; this.slaveDataSourceNames = slaveDataSourceNames; this.loadBalanceAlgorithm = null == loadBalanceAlgorithm ? new MasterSlaveLoadBalanceAlgorithmServiceLoader().newService() : loadBalanceAlgorithm; ruleConfiguration = new MasterSlaveRuleConfiguration(name, masterDataSourceName, slaveDataSourceNames, new LoadBalanceStrategyConfiguration(this.loadBalanceAlgorithm.getType(), this.loadBalanceAlgorithm.getProperties())); &#125; public MasterSlaveRule(final MasterSlaveRuleConfiguration config) &#123; name = config.getName(); masterDataSourceName = config.getMasterDataSourceName(); slaveDataSourceNames = config.getSlaveDataSourceNames(); loadBalanceAlgorithm = createMasterSlaveLoadBalanceAlgorithm(config.getLoadBalanceStrategyConfiguration()); ruleConfiguration = config; &#125; private MasterSlaveLoadBalanceAlgorithm createMasterSlaveLoadBalanceAlgorithm(final LoadBalanceStrategyConfiguration loadBalanceStrategyConfiguration) &#123; MasterSlaveLoadBalanceAlgorithmServiceLoader serviceLoader = new MasterSlaveLoadBalanceAlgorithmServiceLoader(); return null == loadBalanceStrategyConfiguration ? serviceLoader.newService() : serviceLoader.newService(loadBalanceStrategyConfiguration.getType(), loadBalanceStrategyConfiguration.getProperties()); &#125; /** * Judge whether contain data source name. * * @param dataSourceName data source name * @return contain or not. */ public boolean containDataSourceName(final String dataSourceName) &#123; return masterDataSourceName.equals(dataSourceName) || slaveDataSourceNames.contains(dataSourceName); &#125;&#125; MasterSlaveRule内置了loadBalanceAlgorithm、masterSlaveRuleConfiguration 至此我们完成了主从主写的分离！","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"Sharding-JDBC、Mycat、drds对比","slug":"sharding-jdbc002","date":"2020-03-14T09:14:15.000Z","updated":"2022-09-17T14:13:56.172Z","comments":false,"path":"sharding-jdbc/sharding-jdbc002/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc002/","excerpt":"","text":"DRDS简介分布式关系型数据库服务（Distributed Relational Database Service，简称 DRDS）是阿里巴巴致力于解决单机数据库服务瓶颈问题而自主研发推出的分布式数据库产品。DRDS 高度兼容 MySQL 协议和语法，支持自动化水平拆分、在线平滑扩缩容、弹性扩展、透明读写分离，具备数据库全生命周期运维管控能力。DRDS 前身为淘宝 TDDL，是近千核心应用首选组件。 DRDS的架构图： 这里我们不对DRDS做详细介绍，毕竟我们没有阿里云提供商！我们只对Sharding-JDBC、Mycat做分析区别！DRDS简单介绍。 Mycat和Sharding-jdbc的区别1）mycat是一个中间件的第三方应用，sharding-jdbc是一个jar包 2）使用mycat时不需要改代码，而使用sharding-jdbc时需要修改代码 Mycat(proxy中间件层): Sharding-jdbc(TDDL为代表的应用层): 可以看出sharding-jdbc作为一个组件集成在应用内，而mycat则作为一个独立的应用需要单独部署，drds则是阿里云的一个独立产品，不过需要结合rds一起使用。从架构上看sharding-jdbc更符合分布式架构的设计，直连数据库，没有中间应用，理论性能是最高的（实际性能需要结合具体的代码实现，理论性能可以理解为上限，通过不断优化代码实现，逐渐接近理论性能）。同时缺点也很明显，由于作为组件存在，需要集成在应用内，意味着作为使用方，必须要集成到代码里，使得开发成本相对较高；另一方面，由于需要集成在应用内，使得需要针对不同语言（java、C、PHP……）有不同的实现（事实上sharding-jdbc目前只支持java），这样组件本身的维护成本也会很高。最终将应用场景限定在由java开发的应用这一种场景下。sharding-jdbc后续发展为Sharding-Sphere，包含sharding-jdbc、Sharding-Proxy、Sharding-Sidecar Sharding-JDBC Sharding-Proxy Sharding-Sidecar Database Any MySQL/PostgreSQL MySQL/PostgreSQL Connections Count Cost High Low High Supported Languages Java Only Any Any Performance Low loss Relatively High loss Low loss Decentralization Yes No No Static Entry No Yes No 来源：https://github.com/sharding-sphere/sharding-sphere ​ mycat是支持SQL92标准，遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理。作为对比可以参考上表中的Sharding-Proxy，需要单独部署，由于遵守Mysql原生协议，应用时不需要特殊处理，和使用MySQL是一样的，所以应用场景不受限制；但是mycat不支持二维路由，仅支持单库多表或多库单表，同时由于自定义连接池，这样就会存在mycat自身维护一个连接池，MySQL也有一个连接池，任何一个连接池上限都会成为性能的瓶颈，而mycat的连接池设计也略显粗暴，当请求链接数大于设置连接池上限时直接抛出异常，因此在配置mycat连接池的大小是，需要结合场景做合理设置。总的来说，mycat以逻辑表的形式屏蔽掉应用处理分库分表的复杂逻辑，遵守Mysql原生协议，跨语言，跨平台，有着更为通用的应用场景。 ​ DRDS 兼容 MySQL 协议和语法，支持分库分表、平滑扩容、服务升降配、透明读写分离和分布式事务等特性，具备分布式数据库全生命周期的运维管控能力。可以看成mycat的商业化产品，也就是mycat所有的优点它都有，而且作为一个商业化产品使用上更为简单透明，功能也更为丰富；如果不差钱而且正准备对数据做重构，那么drds是一个不错的选择，之所以说准备做数据重构时考虑用drds，是因为drds不是一个简单的做sharding路由，即使原来使用的是rds，也无法通过drds做路由，唯一的办法新建drds实例，定义路由规则（drds支持二维路由），导入历史数据，然后就可以开心的使用drds了。 然后做个简单总结 Sharding-JDBC mycat drds 性能 高 中 高 应用场景限制 java应用 无 无 是否支持自定义sharding路由 是 是 是 最大支持sharding路由维度 2 1 2 分布式事务 开发中（4.0.0支持） 支持弱xa、支持XA分布式事务（1.6.5） 支持以下分布式事务策略：FREE、2PC、XA、FLEXIBLE 限制 不支持子语句,不支持UNION 和 UNION ALL,不支持批量插入,不支持DISTINCT聚合 详见《MYCAT权威指南》——5.6 Mycat 目前存在的限制 未明确说明 是否开源 是 是 否 至此我们总结了这三个的区别!下一篇我们开始读写分离demo例子！ 参考文献： https://www.cnblogs.com/leeSmall/p/9539370.html https://blog.csdn.net/jornada_/article/details/82947677","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"Spring Boot Admin2.X监控的服务context-path问题","slug":"springboot-admin-context-path","date":"2020-03-14T08:54:05.000Z","updated":"2022-09-17T14:13:56.161Z","comments":false,"path":"micro-service/springboot-admin-context-path/","link":"","permalink":"https://www.cicoding.cn/micro-service/springboot-admin-context-path/","excerpt":"","text":"在使用Spring Boot Admin进行监控时，如果被监控的服务没有加context-path的话是不会有任何问题的，一旦服务加了context-path的配置，监控就会失败。 下图是正常情况的显示： 我们给被监控的服务增加一个context-path： 1server.servlet.context-path=/yinjihuan 当被监控的服务增加了context-path之后，这边就会报异常了，如下图： 原因是什么呢？这是因为加了context-path后actuator的访问路径都发生变化了，默认的路径都访问不到，拿不到数据导致的。 如何解决呢？大家看上面贴的图片，右上角显示了健康状态监测的地址： 123http://192.168.31.244:8083/http://192.168.31.244:8083/actuatorhttp://192.168.31.244:8083/actuator/health 在没加context-path之前，就是这个地址去访问的，加了之后访问的时候就要把context-path给加上，也就是变成了下面的信息： 123http://192.168.31.244:8083/yinjihuanhttp://192.168.31.244:8083/yinjihuan/actuatorhttp://192.168.31.244:8083/yinjihuan/actuator/health 关键是如何去修改这个地址啊，我们想想看，Spring Boot Admin只是一个展示平台，本身是不存储信息的，我们用的是整合了Eureka的方式，所以信息都是从Eureka过来的，查看下Eureka中服务的信息就知道了。 通过eureka部署的地址+/eureka/apps/服务名称查看，如下图： 可以看到在instance下面有homePageUrl,statusPageUrl,healthCheckUrl的值是没加上context-path的，于是我把这三个值改过来： 123eureka.instance.home-page-url-path=$&#123;server.servlet.context-path&#125;eureka.instance.health-check-url-path=$&#123;server.servlet.context-path&#125;/actuator/healtheureka.instance.status-page-url-path=$&#123;server.servlet.context-path&#125;/actuator/info 然后发现确实不报错了，显示如下： 问题是还有很多的监控信息不见了，现在只有一个Metadata和Health信息，还是没有完全改好。 大概意思是将这个路径追加到服务URL中，用于访问端点信息，这个配置是需要增加到服务的metadata中的，如下: 1eureka.instance.metadata-map.management.context-path=$&#123;server.servlet.context-path&#125;/actuator 加了这句之后数据就能全部出来了，问题到此全部解决。 还有一种方式就是通过源码的方式来解决，给大家提供点思路，当报错的时候，我们可以抓包，看页面是从哪个地址获取的数据，比如： 主要是applications这个地址，可以看到重要的信息是endpoints里面的数据，这些端点信息和对应的url就是最终显示的数据来源，当加了context-path之后这些地址还是之前的，所以获取不到数据，那么为什么需要配置management.context-path就可以解决呢？ 大家可以一步步跟进去看源码，我直接告诉大家这块的代码在哪里 de.codecentric.boot.admin.server.services.endpoints.QueryIndexEndpointStrategy.detectEndpoints(Instance) 这个方法里面： 这边就是获取所有Endpoints的方法，instance.getRegistration().getManagementUrl()就是我们需要改正确的地址，只有这个地址正确了才能获取到正确的Endpoints信息。 原文链接：https://www.cnblogs.com/yinjihuan/p/10487835.html","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"SpringCloud如何使用Feign构造多参数的请求","slug":"microservice13","date":"2020-03-14T08:46:05.000Z","updated":"2022-09-17T14:13:56.160Z","comments":false,"path":"micro-service/microservice13/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice13/","excerpt":"","text":"Spring Cloud中,如何使用Feign构造多参数的请求，以GET及POST请求为例讲解，其他方式（例如DELETE、PUT等）的请求原理相通，读者可自行研究。 GET请求多参数的URL假设需请求的URL包含多个参数，例如http://microservice-provider-user/get?id=1&amp;username=张三 ，该如何使用Feign构造呢？ 我们知道，Spring Cloud为Feign添加了Spring MVC的注解支持，那么我们不妨按照Spring MVC的写法尝试一下： 12345@FeignClient(\"microservice-provider-user\")public interface UserFeignClient &#123; @RequestMapping(value = \"/get\", method = RequestMethod.GET) public User get0(User user);&#125; 然而，这种写法并不正确，控制台会输出类似如下的异常。 12feign.FeignException: status 405 reading UserFeignClient#get0(User); content:&#123;&quot;timestamp&quot;:1482676142940,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;exception&quot;:&quot;org.springframework.web.HttpRequestMethodNotSupportedException&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/get&quot;&#125; 由异常可知，尽管我们指定了GET方法，Feign依然会使用POST方法发送请求。 正确写法如下方法一12345@FeignClient(name = \"microservice-provider-user\")public interface UserFeignClient &#123; @RequestMapping(value = \"/get\", method = RequestMethod.GET) public User get1(@RequestParam(\"id\") Long id, @RequestParam(\"username\") String username);&#125; 这是最为直观的方式，URL有几个参数，Feign接口中的方法就有几个参数。使用@RequestParam注解指定请求的参数是什么。 方法二多参数的URL也可使用Map来构建。当目标URL参数非常多的时候，可使用这种方式简化Feign接口的编写。 12345@FeignClient(name = \"microservice-provider-user\")public interface UserFeignClient &#123; @RequestMapping(value = \"/get\", method = RequestMethod.GET) public User get2(@RequestParam Map&lt;String, Object&gt; map);&#125; 在调用时，可使用类似以下的代码。 123456public User get(String username, String password) &#123; HashMap&lt;String, Object&gt; map = Maps.newHashMap(); map.put(&quot;id&quot;, &quot;1&quot;); map.put(&quot;username&quot;, &quot;张三&quot;); return this.userFeignClient.get2(map);&#125; POST请求包含多个参数下面来讨论如何使用Feign构造包含多个参数的POST请求。假设服务提供者的Controller是这样编写的： 1234567@RestControllerpublic class UserController &#123; @PostMapping(&quot;/post&quot;) public User post(@RequestBody User user) &#123; ... &#125;&#125; 我们要如何使用Feign去请求呢？答案非常简单，示例： 12345@FeignClient(name = &quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @RequestMapping(value = &quot;/post&quot;, method = RequestMethod.POST) public User post(@RequestBody User user);&#125; PS 除本节讲解的方式外，我们也可编写自己的编码器来构造多参数的请求，但这种方式编码成本较高，代码可重用性较低，故此不再赘述。 拓展阅读 希望Feign能够支持参数请求使用POJO的Issue：https://github.com/spring-cloud/spring-cloud-netflix/issues/1253 建议使用Feign原生的注解的Issue：https://github.com/spring-cloud/spring-cloud-netflix/issues/659 建议增强Feign的功能：https://github.com/spring-cloud/spring-cloud-netflix/issues/1360 建议支持可选的Request Body（目前Feign当POST一个null时，会报异常）：https://github.com/spring-cloud/spring-cloud-netflix/issues/1047","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/tags/Feign/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cicoding.cn/tags/SpringCloud/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"Feign使用常见问题总结","slug":"microservice12","date":"2020-03-14T08:36:05.000Z","updated":"2022-09-17T14:13:56.160Z","comments":false,"path":"micro-service/microservice12/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice12/","excerpt":"","text":"本文介绍了spring cloud Feign使用中遇到的问题总结，分享给大家，具体如下： 一、FeignClient接口如使用@PathVariable ，必须指定value属性代码示例： 123456@FeignClient(&quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @RequestMapping(value = &quot;/simple/&#123;id&#125;&quot;, method = RequestMethod.GET) public User findById(@PathVariable(&quot;id&quot;) Long id); ...&#125; 其中的@PathVariable(&quot;id&quot;) 中的”id”，也就是value属性，必须指定，不能省略。 二、构造多参数请求详见：如何使用Feign构造多参数的请求 三、如需产生Hystrix Stream监控信息，需要做一些额外操作Feign本身已经整合了Hystrix，可直接使用@FeignClient(value = &quot;microservice-provider-user&quot;, fallback = XXX.class) 来指定fallback类，fallback类继承@FeignClient所标注的接口即可。 但是假设如需使用Hystrix Stream进行监控，默认情况下，访问http://IP:PORT/actuator/hystrix.stream 是会返回404，这是因为Feign虽然整合了Hystrix，但并没有整合Hystrix的监控。如何添加监控支持呢？需要以下几步： 第一步：添加依赖，示例： 12345&lt;!-- 整合hystrix，其实feign中自带了hystrix，引入该依赖主要是为了使用其中的hystrix-metrics-event-stream，用于dashboard --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 第二步：在启动类上添加@EnableCircuitBreaker 注解，示例： 123456789@SpringBootApplication@EnableFeignClients@EnableDiscoveryClient@EnableCircuitBreakerpublic class MovieFeignHystrixApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MovieFeignHystrixApplication.class, args); &#125;&#125; 第三步：在application.yml中添加如下内容，暴露hystrix.stream端点： 12345management: endpoints: web: exposure: include: &apos;hystrix.stream&apos; 这样，访问任意Feign Client接口的API后，再访问http://IP:PORT/actuator/hystrix.stream ，就会展示一大堆Hystrix监控数据了。 四、Java代码自定义Feign Client的注意点与坑代码示例： 12345678910111213141516171819202122@FeignClient(name = &quot;microservice-provider-user&quot;, configuration = UserFeignConfig.class)public interface UserFeignClient &#123; @GetMapping(&quot;/users/&#123;id&#125;&quot;) User findById(@PathVariable(&quot;id&quot;) Long id);&#125;/** * 该Feign Client的配置类，注意： * 1. 该类可以独立出去； * 2. 该类上也可添加@Configuration声明是一个配置类； * 配置类上也可添加@Configuration注解，声明这是一个配置类； * 但此时千万别将该放置在主应用程序上下文@ComponentScan所扫描的包中， * 否则，该配置将会被所有Feign Client共享，无法实现细粒度配置！ * 个人建议：像我一样，不加@Configuration注解 * * @author zkj */class UserFeignConfig &#123; @Bean public Logger.Level logger() &#123; return Logger.Level.FULL; &#125;&#125; 配置类上也可添加@Configuraiton 注解，声明这是一个配置类；但此时千万别将该放置在主应用程序上下文@ComponentScan 所扫描的包中，否则，该配置将会被所有Feign Client共享（相当于变成了通用配置，其实本质还是Spring父子上下文扫描包重叠导致的问题），无法实现细粒度配置！ 个人建议：像我一样，不加@Configuration注解，省得进坑。 最佳实践：尽量用配置属性自定义Feign的配置 五、首次请求失败详见：Spring Cloud中，如何解决Feign/Ribbon第一次请求失败的问题？ 六、@FeignClient 注解属性1@FeignClient(name = &quot;microservice-provider-user&quot;) 在早期的Spring Cloud版本中，无需提供name属性，从Brixton版开始，@FeignClient必须提供name属性，否则应用将无法正常启动！ 另外，name、url等属性支持占位符。例如： 1@FeignClient(name = &quot;$&#123;feign.name&#125;&quot;, url = &quot;$&#123;feign.url&#125;&quot;) 七、类级别的@RequestMapping会被Spring MVC加载12345@RequestMapping(&quot;/users&quot;)@FeignClient(name = &quot;microservice-user&quot;)public class TestFeignClient &#123; // ...&#125; 类上的@RequestMapping 注解也会被Spring MVC加载。该问题现已经被解决，早期的版本有两种解决方案： 方案1：不在类上加@RequestMapping 注解； 方案2：添加如下代码： 12345678910111213141516171819@Configuration@ConditionalOnClass(&#123; Feign.class &#125;)public class FeignMappingDefaultConfiguration &#123; @Bean public WebMvcRegistrations feignWebRegistrations() &#123; return new WebMvcRegistrationsAdapter() &#123; @Override public RequestMappingHandlerMapping getRequestMappingHandlerMapping() &#123; return new FeignFilterRequestMappingHandlerMapping(); &#125; &#125;; &#125; private static class FeignFilterRequestMappingHandlerMapping extends RequestMappingHandlerMapping &#123; @Override protected boolean isHandler(Class&lt;?&gt; beanType) &#123; return super.isHandler(beanType) &amp;&amp; !beanType.isInterface(); &#125; &#125;&#125; 相关Issue：https://github.com/spring-cloud/spring-cloud-netflix/issues/466","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/tags/Feign/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"SpringBoot2.X使用Redis实现分布式锁机制","slug":"springboot-redis-distributed-lock","date":"2020-03-07T07:22:15.000Z","updated":"2022-09-17T14:13:56.183Z","comments":false,"path":"springboot/springboot-redis-distributed-lock/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-redis-distributed-lock/","excerpt":"","text":"我们工作中经常会使用分布式锁，今天就在这记录一下，Spring Cloud官方 说自己实现了 Global Locks ，但又无法找到任何相关文档的原因——人家早把相关代码搬迁到Spring Integration了。 对Spring Integration不是很熟悉，简单介绍一下——官方说法，这是一个 企业集成模式 的实现；通俗地说，Spring Integration的定位是一个轻量级的ESB，尽管它做了很多ESB不做的事情。顺便说一下，Spring Cloud Stream的底层也是Spring Integration。 Spring Integration提供的全局锁目前为如下存储提供了实现： Gemfire JDBC Redis Zookeeper 它们使用相同的API抽象——这正是Spring最擅长的。这意味着，不论使用哪种存储，你的编码体验是一样的，有一天想更换实现，只需要修改依赖和配置就可以了，无需修改代码。 redis实现分布式锁，实现了Lock接口，和ReentrantLock，有可重入，阻塞等功能 使用依赖 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-integration&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.integration&lt;/groupId&gt; &lt;artifactId&gt;spring-integration-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 写配置： 注：这里我们也可以使用redis集群链接或者哨兵模式 1234spring: redis: port: 6379 host: localhost 初始化 1234567@Configurationpublic class RedisLockConfiguration &#123; @Bean public RedisLockRegistry redisLockRegistry(RedisConnectionFactory redisConnectionFactory) &#123; return new RedisLockRegistry(redisConnectionFactory, \"spring-cloud\"); &#125;&#125; 举例子 12345678910111213141516171819202122232425@RestControllerpublic class RedisController &#123; @Autowired private RedisLockRegistry redisLockRegistry; @RequestMapping(\"/redisLock\") public String redisLock(Integer id)&#123; //redis的key冒号：连接 //registryKey和lockKey自动冒号连接，最终key为REDIS_LOCK:USER_ID:1，值为uuid Lock lock = redisLockRegistry.obtain(\"USER_ID:\" + id); for (int i = 0; i &lt; 3; i++) &#123; new Thread(() -&gt; &#123; lock.lock(); System.out.println(Thread.currentThread().getName() + \" begin \" + new Date()); // 自己的业务逻辑 System.out.println(Thread.currentThread().getName() + \" end \" + new Date()); lock.unlock(); &#125;).start(); &#125; return \"ok\"; &#125;&#125; 源码分析ExpirableLockRegistry接口，添加一个过期释放锁的方法 12345678910public interface ExpirableLockRegistry extends LockRegistry &#123; /** * Remove locks last acquired more than 'age' ago that are not currently locked. * @param age the time since the lock was last obtained. * @throws IllegalStateException if the registry configuration does not support this feature. */ void expireUnusedOlderThan(long age);&#125; LockRegistry接口，只有一个获取锁的方法 1234567891011@FunctionalInterfacepublic interface LockRegistry &#123; /** * Obtains the lock associated with the parameter object. * @param lockKey The object with which the lock is associated. * @return The associated lock. */ Lock obtain(Object lockKey);&#125; RedisLockRegistry构造器 1234567891011121314151617181920212223242526272829303132333435363738394041424344private static final long DEFAULT_EXPIRE_AFTER = 60000L;private final String registryKey;private final StringRedisTemplate redisTemplate;private final RedisScript&lt;Boolean&gt; obtainLockScript;private final long expireAfter;private static final String OBTAIN_LOCK_SCRIPT = \"local lockClientId = redis.call('GET', KEYS[1])\\n\" + \"if lockClientId == ARGV[1] then\\n\" + \" redis.call('PEXPIRE', KEYS[1], ARGV[2])\\n\" + \" return true\\n\" + \"elseif not lockClientId then\\n\" + \" redis.call('SET', KEYS[1], ARGV[1], 'PX', ARGV[2])\\n\" + \" return true\\n\" + \"end\\n\" + \"return false\"; /** * Constructs a lock registry with the default (60 second) lock expiration. * @param connectionFactory The connection factory. * @param registryKey The key prefix for locks. */public RedisLockRegistry(RedisConnectionFactory connectionFactory, String registryKey) &#123; this(connectionFactory, registryKey, DEFAULT_EXPIRE_AFTER);&#125;/** * Constructs a lock registry with the supplied lock expiration. * @param connectionFactory The connection factory. * @param registryKey The key prefix for locks. * @param expireAfter The expiration in milliseconds. */public RedisLockRegistry(RedisConnectionFactory connectionFactory, String registryKey, long expireAfter) &#123; Assert.notNull(connectionFactory, \"'connectionFactory' cannot be null\"); Assert.notNull(registryKey, \"'registryKey' cannot be null\"); this.redisTemplate = new StringRedisTemplate(connectionFactory); this.obtainLockScript = new DefaultRedisScript&lt;&gt;(OBTAIN_LOCK_SCRIPT, Boolean.class); this.registryKey = registryKey; this.expireAfter = expireAfter;&#125; 获取锁 1234567private final Map&lt;String, RedisLock&gt; locks = new ConcurrentHashMap&lt;&gt;();@Overridepublic Lock obtain(Object lockKey) &#123; Assert.isInstanceOf(String.class, lockKey); String path = (String) lockKey; return this.locks.computeIfAbsent(path, RedisLock::new);&#125; Map 1234567891011121314151617181920212223default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) &#123; V newValue; if ((newValue = mappingFunction.apply(key)) != null) &#123; put(key, newValue); return newValue; &#125; &#125; return v;&#125;default V putIfAbsent(K key, V value) &#123; V v = get(key); if (v == null) &#123; v = put(key, value); &#125; return v;&#125; 每个lockKey创建一个锁，缓存起来computeIfAbsent和putIfAbsent的区别是，前者是一个函数式接口，创建对象，作为缓存的值，后者是直接传进来值 上锁1234567891011121314151617181920212223242526272829303132333435@Overridepublic void lock() &#123; this.localLock.lock(); while (true) &#123; try &#123; while (!obtainLock()) &#123; Thread.sleep(100); //NOSONAR &#125; break; &#125; catch (InterruptedException e) &#123; /* * This method must be uninterruptible so catch and ignore * interrupts and only break out of the while loop when * we get the lock. */ &#125; catch (Exception e) &#123; this.localLock.unlock(); rethrowAsLockException(e); &#125; &#125;&#125; private final String clientId = UUID.randomUUID().toString();private boolean obtainLock() &#123; boolean success = RedisLockRegistry.this.redisTemplate.execute(RedisLockRegistry.this.obtainLockScript, Collections.singletonList(this.lockKey), RedisLockRegistry.this.clientId, String.valueOf(RedisLockRegistry.this.expireAfter)); if (success) &#123; this.lockedAt = System.currentTimeMillis(); &#125; return success;&#125; 先用ReentrantLock加锁，再用redis调用lua脚本 12345678910private static final String OBTAIN_LOCK_SCRIPT = \"local lockClientId = redis.call('GET', KEYS[1])\\n\" + \"if lockClientId == ARGV[1] then\\n\" + \" redis.call('PEXPIRE', KEYS[1], ARGV[2])\\n\" + \" return true\\n\" + \"elseif not lockClientId then\\n\" + \" redis.call('SET', KEYS[1], ARGV[1], 'PX', ARGV[2])\\n\" + \" return true\\n\" + \"end\\n\" + \"return false\"; 如果lockKey没有值，设置值，过期时间60秒。否则是线程重入锁，刷新过期时间60秒redis加锁成功后，每个线程保存加锁时间 如果加锁失败，100毫秒重试，一直循环到获取锁，所以锁是可重入的。 释放锁RedisLockRegistry.RedisLock 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic void unlock() &#123; if (!this.localLock.isHeldByCurrentThread()) &#123; throw new IllegalStateException(\"You do not own lock at \" + this.lockKey); &#125; if (this.localLock.getHoldCount() &gt; 1) &#123; this.localLock.unlock(); return; &#125; try &#123; if (Thread.currentThread().isInterrupted()) &#123; RedisLockRegistry.this.executor.execute(this::removeLockKey); &#125; else &#123; removeLockKey(); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Released lock; \" + this); &#125; &#125; catch (Exception e) &#123; ReflectionUtils.rethrowRuntimeException(e); &#125; finally &#123; this.localLock.unlock(); &#125;&#125;private void removeLockKey() &#123; if (RedisUtils.isUnlinkAvailable(RedisLockRegistry.this.redisTemplate)) &#123; RedisLockRegistry.this.redisTemplate.unlink(this.lockKey); &#125; else &#123; RedisLockRegistry.this.redisTemplate.delete(this.lockKey); &#125;&#125; ReentrantLock保存了上锁的线程，和线程的重入次数，如果是重入锁，计数器减一，即aqs的state减一，否则redis删除key，然后释放ReentrantLock锁。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"Sharding-JDBC系列教程","slug":"sharding-jdbc000","date":"2020-02-29T06:41:15.000Z","updated":"2022-09-17T14:13:56.170Z","comments":false,"path":"sharding-jdbc/sharding-jdbc000/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc000/","excerpt":"","text":"Sharding-JDBC系列Sharding-JDBC简介 Sharding-JDBC、Mycat、drds对比 Sharding-JDBC读写分离案例 Sharding-JDBC不分库，只分表例子 Sharding-JDBC 垂直拆分（不同的表在不同的库中） Spring Boot版 Sharding JDBC 垂直拆分（不同的表在不同的库中）+ 读写分离","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"Sharding-JDBC简介","slug":"sharding-jdbc001","date":"2020-02-28T13:49:15.000Z","updated":"2022-09-17T14:13:56.172Z","comments":false,"path":"sharding-jdbc/sharding-jdbc001/","link":"","permalink":"https://www.cicoding.cn/sharding-jdbc/sharding-jdbc001/","excerpt":"","text":"概述 ShardingSphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。 ShardingSphere定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的计算和存储能力，而并非实现一个全新的关系型数据库。 它与NoSQL和NewSQL是并存而非互斥的关系。NoSQL和NewSQL作为新技术探索的前沿，放眼未来，拥抱变化，是非常值得推荐的。反之，也可以用另一种思路看待问题，放眼未来，关注不变的东西，进而抓住事物本质。 关系型数据库当今依然占有巨大市场，是各个公司核心业务的基石，未来也难于撼动，我们目前阶段更加关注在原有基础上的增量，而非颠覆。 ShardingSphere目前已经进入Apache孵化器， 欢迎通过shardingsphere的dev邮件列表与我们讨论。 简介Sharding-JDBC 定位为轻量级Java框架，在Java的JDBC层提供的额外服务。 它使用客户端直连数据库，以jar包形式提供服务，无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。 适用于任何基于Java的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使用JDBC。 基于任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP等。 支持任意实现JDBC规范的数据库。目前支持MySQL，Oracle，SQLServer和PostgreSQL。 Sharding-Proxy 定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。 目前先提供MySQL版本，它可以使用任何兼容MySQL协议的访问客户端(如：MySQL Command Client, MySQL Workbench等)操作数据，对DBA更加友好。 向应用程序完全透明，可直接当做MySQL使用。 适用于任何兼容MySQL协议的客户端。 Sharding-Sidecar（TBD）定位为Kubernetes或Mesos的云原生数据库代理，以DaemonSet的形式代理所有对数据库的访问。 通过无中心、零侵入的方案提供与数据库交互的的啮合层，即Database Mesh，又可称数据网格。 Database Mesh的关注重点在于如何将分布式的数据访问应用与数据库有机串联起来，它更加关注的是交互，是将杂乱无章的应用与数据库之间的交互有效的梳理。使用Database Mesh，访问数据库的应用和数据库终将形成一个巨大的网格体系，应用和数据库只需在网格体系中对号入座即可，它们都是被啮合层所治理的对象。 Sharding-JDBC Sharding-Proxy Sharding-Sidecar 数据库 任意 MySQL MySQL 连接消耗数 高 低 高 异构语言 仅Java 任意 任意 性能 损耗低 损耗略高 损耗低 无中心化 是 否 是 静态入口 无 有 无 混合架构Sharding-JDBC采用无中心化架构，适用于Java开发的高性能的轻量级OLTP应用；Sharding-Proxy提供静态入口以及异构语言的支持，适用于OLAP应用以及对分片数据库进行管理和运维的场景。 ShardingSphere是多接入端共同组成的生态圈。 通过混合使用Sharding-JDBC和Sharding-Proxy，并采用同一注册中心统一配置分片策略，能够灵活的搭建适用于各种场景的应用系统，架构师可以更加自由的调整适合于当前业务的最佳系统架构。 功能列表数据分片 分库 &amp; 分表 读写分离 分布式主键 分布式事务(Doing) XA强一致事务 柔性事务 数据库治理 配置动态化 熔断 &amp; 禁用 调用链路追踪 弹性伸缩 (Planning) 规划线路图 我们接下来将使用SpringBoot 2.1.x和sharding-jdbc 4.0.0版本进行演示学习demo！ 对springboot不了解的可以学习一下我的博客！https://blog.csdn.net/zhaokejin521/category_7280457.html 参考文档： https://shardingsphere.apache.org/document/legacy/3.x/document/cn/overview/","categories":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}],"tags":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/tags/Sharding-JDBC/"}],"keywords":[{"name":"Sharding-JDBC","slug":"Sharding-JDBC","permalink":"https://www.cicoding.cn/categories/Sharding-JDBC/"}]},{"title":"JRebel最新激活破解方式","slug":"jrebel-activation","date":"2020-02-04T12:19:50.000Z","updated":"2023-06-20T06:38:19.038Z","comments":false,"path":"other/jrebel-activation/","link":"","permalink":"https://www.cicoding.cn/other/jrebel-activation/","excerpt":"","text":"由于服务器到期，JRebel服务于2022年9月25日停止服务！ 服务器地址监听服务器地址： http://jrebel.cicoding.cn GUID生成器： http://jrebel.cicoding.cn/guid 监听配置格式： http://jrebel.cicoding.cn/GUID 生成的如下： http://jrebel.cicoding.cn/4B068EB5-0941-4645-1E98-FC077D530A61 打开IDEA中Settings如下： 找到File -&gt; Settings -&gt; JRebel &amp; XRebel 点击Chanage license，填写URL和邮箱地址 点击Chanage license！ 就监听成功激活成功了！鼓掌！ 然后就可以启动使用了！ 点击下方打赏继续运行！！！","categories":[{"name":"JRebel","slug":"JRebel","permalink":"https://www.cicoding.cn/categories/JRebel/"}],"tags":[{"name":"JRebel","slug":"JRebel","permalink":"https://www.cicoding.cn/tags/JRebel/"}],"keywords":[{"name":"JRebel","slug":"JRebel","permalink":"https://www.cicoding.cn/categories/JRebel/"}]},{"title":"SpringBoot定时器任务Quartz","slug":"springboot-quartz","date":"2020-02-04T08:01:57.000Z","updated":"2023-06-20T06:38:19.042Z","comments":false,"path":"other/springboot-quartz/","link":"","permalink":"https://www.cicoding.cn/other/springboot-quartz/","excerpt":"","text":"SpringBoot定时器任务Quartz源码技术选型1、后端 核心框架：SpringBoot 2.x集成运行框架：Tomcat布局框架：Thymeleaf持久层框架：MyBatis数据处理框架：Mapper数据库连接池：Alibaba Druid日志管理：Log4j2、前端JQ框架：jQuery数据表格：BootStrap-Table 我们来看实例：正在打印定时任务的数据！30秒一次停止定时任务则不打印了 获取源码联系群主！","categories":[{"name":"Quartz","slug":"Quartz","permalink":"https://www.cicoding.cn/categories/Quartz/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"},{"name":"Quartz","slug":"Quartz","permalink":"https://www.cicoding.cn/tags/Quartz/"}],"keywords":[{"name":"Quartz","slug":"Quartz","permalink":"https://www.cicoding.cn/categories/Quartz/"}]},{"title":"聊聊Spring Cloud Gateway网关路由","slug":"spring-cloud-gateway-route-forwarding","date":"2020-01-31T13:21:18.000Z","updated":"2022-09-17T14:13:56.186Z","comments":false,"path":"springcloud/spring-cloud-gateway-route-forwarding/","link":"","permalink":"https://www.cicoding.cn/springcloud/spring-cloud-gateway-route-forwarding/","excerpt":"","text":"简介Spring Cloud Gateway是Spring Cloud官方推出的第二代网关框架，取代Zuul网关。网关作为流量的，在微服务系统中有着非常作用。网关常见的功能有 协议转换，路由转发 流量聚合，对流量进行监控，日志输出 可以在网关层做权限的判断 限流，作为整个系统的前端工程，对流量进行控制 作为系统的前端边界，外部流量只能通过网关才能访问系统 缓存 如上图所示，客户端向Spring Cloud Gateway发出请求。 如果Gateway Handler Mapping确定请求与路由匹配（这个时候就用到predicate），则将其发送到Gateway web handler处理。 Gateway web handler处理请求时会经过一系列的过滤器链。 过滤器链被虚线划分的原因是过滤器链可以在发送代理请求之前或之后执行过滤逻辑。 先执行所有“pre”过滤器逻辑，然后进行代理请求。 在发出代理请求之后，收到代理服务的响应之后执行“post”过滤器逻辑。这跟zuul的处理过程很类似。在执行所有“pre”过滤器逻辑时，往往进行了鉴权、限流、日志输出等功能，以及请求头的更改、协议的转换；转发之后收到响应之后，会执行所有“post”过滤器的逻辑，在这里可以响应数据进行了修改，比如响应头、协议的转换等。 增新一个项目 分别是服务提供方provider，消费方comsumer,注册中心eureka，网关gateway provider12345678@RequestMapping(&quot;/hello&quot;)@RestControllerpublic class HelloController &#123; @GetMapping(&quot;&quot;) public String hello(@RequestParam String name) &#123; return &quot;Hello, &quot; + name + &quot;!&quot;; &#125;&#125; comsumer使用Feign调用 123456789101112131415@CommonsLog@RequestMapping(&quot;/hello&quot;)@RestControllerpublic class HelloController &#123; @Autowired HelloFeignService helloRemote; @GetMapping(&quot;/&#123;name&#125;&quot;) public String index(@PathVariable(&quot;name&quot;) String name) &#123; log.info(&quot;the name is &quot; + name); return helloRemote.hello(name) + &quot;\\n&quot; + new Date().toString(); &#125; &#125; 增加 Hystrix 断路器 1234567891011@FeignClient(name = &quot;producer&quot;, fallback = HelloFeignProviderHystrix.class)public interface HelloFeignService &#123; /** * @param name * @return */ @GetMapping(&quot;/hello/&quot;) String hello(@RequestParam(value = &quot;name&quot;) String name);&#125; gatewaySpring Cloud gateway内置了很多校验条件谓语(predicate)来实现路由功能。有两种方式配置,一种是配置文件application的方式,一种是代码配置 a.application配置:1234567891011121314151617181920212223spring: application: name: sc-gateway-server cloud: gateway: discovery: locator: # 是否可以通过其他服务的serviceId来转发到具体的服务实例。默认为false # 为true,自动创建路由,路由访问方式：http://Gateway_HOST:Gateway_PORT/大写的serviceId/**，其中微服务应用名默认大写访问 enabled: true routes: - id: host_route uri: http://httpbin.org:80/get predicates: - Host=**.csdn.** # 请求域名携带csdn的,则转发 - id: query_route uri: http://httpbin.org:80/get predicates: - Query=username, zzz* # 请求参数含有username,且值满足zzz开头的,则转发(对值的匹配可以省略) - id: header_route uri: http://httpbin.org:80/get predicates: - Header=request, \\d+ # 如果请求头含有request,且为数字,则转发 b.代码配置gateway也提供了代码的方式配置,比如我们注释掉上面的application配置,然后建一个配置类 12345678910111213@Configurationpublic class GateWayConfig &#123; @Bean public RouteLocator routeLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(r -&gt; r.path(&quot;/fluent/**&quot;) .uri(&quot;http://httpbin.org:80/get&quot;)) .build(); &#125;&#125; 在上面的代码中，我们使用了一个router，该router使用host去断言请求是否进入该路由，当请求的host有“/fluent/**”，都会进入该router，重定向到了“http://httpbin.org:80/get”。 Spring Cloud Gateway内置了许多Predict,这些Predict的源码在org.springframework.cloud.gateway.handler.predicate包中。 列举各种Predicate如下图： 启动项目 输入URL 可以看到转到了 comsumer 的地址返回了provider的内容 项目地址：https://github.com/codeyuyu/SpringCloudTc.git 作者：codeyuyu链接：http://www.imooc.com/article/284048","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"https://www.cicoding.cn/tags/Spring-Cloud-Gateway/"}],"keywords":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/categories/Spring-Cloud/"}]},{"title":"Spring Cloud Gateway的PrefixPath及StripPrefix功能","slug":"spring-cloud-gateway-prefixPath-stripprefix","date":"2020-01-31T13:19:18.000Z","updated":"2022-09-17T14:13:56.186Z","comments":false,"path":"springcloud/spring-cloud-gateway-prefixPath-stripprefix/","link":"","permalink":"https://www.cicoding.cn/springcloud/spring-cloud-gateway-prefixPath-stripprefix/","excerpt":"","text":"序本文主要研究一下spring cloud gateway的PrefixPath及StripPrefix功能 PrefixPathGatewayFilterFactoryspring-cloud-gateway-core-2.0.0.RC2-sources.jar!/org/springframework/cloud/gateway/filter/factory/PrefixPathGatewayFilterFactory.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class PrefixPathGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;PrefixPathGatewayFilterFactory.Config&gt; &#123; private static final Log log = LogFactory.getLog(PrefixPathGatewayFilterFactory.class); public static final String PREFIX_KEY = &quot;prefix&quot;; public PrefixPathGatewayFilterFactory() &#123; super(Config.class); &#125; @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Arrays.asList(PREFIX_KEY); &#125; @Override public GatewayFilter apply(Config config) &#123; return (exchange, chain) -&gt; &#123; boolean alreadyPrefixed = exchange.getAttributeOrDefault(GATEWAY_ALREADY_PREFIXED_ATTR, false); if (alreadyPrefixed) &#123; return chain.filter(exchange); &#125; exchange.getAttributes().put(GATEWAY_ALREADY_PREFIXED_ATTR, true); ServerHttpRequest req = exchange.getRequest(); addOriginalRequestUrl(exchange, req.getURI()); String newPath = config.prefix + req.getURI().getRawPath(); ServerHttpRequest request = req.mutate() .path(newPath) .build(); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, request.getURI()); if (log.isTraceEnabled()) &#123; log.trace(&quot;Prefixed URI with: &quot;+config.prefix+&quot; -&gt; &quot;+request.getURI()); &#125; return chain.filter(exchange.mutate().request(request).build()); &#125;; &#125; public static class Config &#123; private String prefix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; &#125;&#125; 可以看到这里使用config的prefix构造newPath，然后构造新的ServerHttpRequest 实例12345678spring: cloud: gateway: routes: - id: prefixpath_route uri: http://example.org filters: - PrefixPath=/mypath 比如：请求/hello，最后转发到目标服务的路径变为/mypath/hello StripPrefixGatewayFilterFactoryspring-cloud-gateway-core-2.0.0.RC2-sources.jar!/org/springframework/cloud/gateway/filter/factory/StripPrefixGatewayFilterFactory.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * This filter removes the first part of the path, known as the prefix, from the request * before sending it downstream * @author Ryan Baxter */public class StripPrefixGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;StripPrefixGatewayFilterFactory.Config&gt; &#123; public static final String PARTS_KEY = &quot;parts&quot;; public StripPrefixGatewayFilterFactory() &#123; super(Config.class); &#125; @Override public List&lt;String&gt; shortcutFieldOrder() &#123; return Arrays.asList(PARTS_KEY); &#125; @Override public GatewayFilter apply(Config config) &#123; return (exchange, chain) -&gt; &#123; ServerHttpRequest request = exchange.getRequest(); addOriginalRequestUrl(exchange, request.getURI()); String path = request.getURI().getRawPath(); String newPath = &quot;/&quot; + Arrays.stream(StringUtils.tokenizeToStringArray(path, &quot;/&quot;)) .skip(config.parts).collect(Collectors.joining(&quot;/&quot;)); ServerHttpRequest newRequest = request.mutate() .path(newPath) .build(); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, newRequest.getURI()); return chain.filter(exchange.mutate().request(newRequest).build()); &#125;; &#125; public static class Config &#123; private int parts; public int getParts() &#123; return parts; &#125; public void setParts(int parts) &#123; this.parts = parts; &#125; &#125;&#125; 可以看到这里的parts指定要去除的前缀的个数，然后使用stream的skip来去除掉相应前缀，然后得到newPath，构造newRequest 实例12345678910spring: cloud: gateway: routes: - id: nameRoot uri: http://nameservice predicates: - Path=/name/** filters: - StripPrefix=2 比如，请求/name/bar/foo，去除掉前面两个前缀之后，最后转发到目标服务的路径为/foo 小结PrefixPathGatewayFilterFactory及StripPrefixGatewayFilterFactory是一对针对请求url前缀进行处理的filter工厂，前者添加prefix，后者去除prefix。 doc 112.5 PrefixPath GatewayFilter Factory https://www.jianshu.com/p/9a5b5e111626 112.18 StripPrefix GatewayFilter Factory","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Gateway","slug":"Spring-Cloud-Gateway","permalink":"https://www.cicoding.cn/tags/Spring-Cloud-Gateway/"}],"keywords":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/categories/Spring-Cloud/"}]},{"title":"Windows安装RabbitMQ","slug":"windows-install-rabbitmq","date":"2020-01-31T12:53:18.000Z","updated":"2022-09-17T14:13:56.150Z","comments":true,"path":"install/windows-install-rabbitmq/","link":"","permalink":"https://www.cicoding.cn/install/windows-install-rabbitmq/","excerpt":"","text":"1.Windows下安装RabbitMQ需要以下几个步骤 (1)：下载erlang，原因在于RabbitMQ服务端代码是使用并发式语言erlang编写的，下载地址：http://www.erlang.org/downloads , 双击.exe文件进行安装就好，安装完成之后创建一个名为ERLANG_HOME的环境变量，其值指向erlang的安装目录，同时将%ERLANG_HOME%\\bin加入到Path中，最后打开命令行，输入erl，如果出现erlang的版本信息就表示erlang语言环境安装成功； (2)：下载RabbitMQ，下载地址：http://www.rabbitmq.com/ 同样双击.exe进行安装就好(这里需要注意一点，默认的安装目录是C:/Program Files/….，这个目录中是存在空格符的，我们需要改变安装目录，貌似RabbitMQ安装目录中是不允许有空格的，我之前踩过这个大坑)； 可以忽略直接访问http://localhost:15672 (3)：安装RabbitMQ-Plugins，这个相当于是一个管理界面，方便我们在浏览器界面查看RabbitMQ各个消息队列以及exchange的工作情况，安装方法是：打开命令行cd进入rabbitmq的sbin目录(我的目录是：E:\\software\\rabbitmq\\rabbitmq_server-3.6.5\\sbin)，输入：rabbitmq-plugins enable rabbitmq_management命令，稍等会会发现出现plugins安装成功的提示，默认是安装6个插件，如果你在安装插件的过程中出现了下面的错误： 解决方法是：首先在命令行输入：rabbitmq-service stop，接着输入rabbitmq-service remove，再接着输入rabbitmq-service install，接着输入rabbitmq-service start，最后重新输入rabbitmq-plugins enable rabbitmq_management试试，我是这样解决的； (4)：插件安装完之后，在浏览器输入http://localhost:15672 进行验证，你会看到下面界面，输入用户名：guest，密码：guest你就可以进入管理界面，当然用户名密码你都可以变的； 快速下载：百度网盘链接：https://pan.baidu.com/s/1MrCIRB24hzrnKPCRBWbPPw提取码：log4erlang和RabbitMQ版本测试通过！","categories":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://www.cicoding.cn/tags/Windows/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://www.cicoding.cn/tags/RabbitMQ/"}],"keywords":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}]},{"title":"SpringBoot应用docker化并发布到远程服务器","slug":"docker-of-springboot-and-publish-to-remote-server","date":"2020-01-29T12:48:43.000Z","updated":"2022-09-17T14:13:56.174Z","comments":true,"path":"spring/docker-of-springboot-and-publish-to-remote-server/","link":"","permalink":"https://www.cicoding.cn/spring/docker-of-springboot-and-publish-to-remote-server/","excerpt":"","text":"docker开启远程访问接口docker得环境搭建这里就不重复了，还不会得可以自行去百度，也就几个命令。 想要将本地镜像推送到阿里云得docker容器上，需要开启远程访问权限 首先编辑docker的宿主机文件/lib/systemd/system/docker.service 1vi /lib/systemd/system/docker.service 修改以ExecStart开头的行,我这里是腾讯云服务器center os 7 ,修改后为： 修改后保存文件，然后通知和重启服务 12systemctl daemon-reloadservice docker restart 可是执行 service docker restart 重启docker会报错查看：https://blog.csdn.net/hdu09075340/article/details/101060655 重启完成以后可以在本机验证，通过curl命令可以查看版本信息 1curl http://localhost:2375/version 开启白名单，让客户端能够远程访问我们在远程机器开启了端口，但是一般得云服务器都需要设置端口白名单才可以访问，具体设置端口白名单这里就不介绍了，设置完成以后，可以通过外网ip在windows机器浏览器进行访问 本地docker项目发布镜像到远程服务器不以实战为目的得技术就是耍流氓，假设现在有个需求：作为码农得我开发了一个博客系统，现在开发完毕之后想部署到远程服务器上去。 传统部署方案服务器上装jdk,装tomcat等—&gt;项目打包-&gt;ftp上传-&gt;启动项目 docker部署方案docker部署方案：项目集成docker插件-&gt;本地打包-&gt;项目构建镜像到远程机器-&gt;远程服务器下载镜像并启动 通过两套发布流程比较我们就能知道各自得优劣了，这里不再累赘，开始进行第二种方案实战！ 首先进行本地环境变量配置 如图，配置DOCKER_HOST得远程tcp连接。 将项目导入到idea里面，我们看看主要得docker相关配置 Dockerfile文件1234FROM openjdk:8-jdk-alpineVOLUME /tmpADD demo-1.0.0-SNAPSHOT.jar app.jarENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] maven依赖1234567891011121314151617&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;dockerHost&gt;http://10.254.193.119:2375&lt;/dockerHost&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 使用idea自带得docker插件进行构建镜像首先对项目进行打包 打包完成以后，点击docker:build 构建成功后日志如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181D:\\devsoft\\Java\\jdk1.8.0_121\\bin\\java.exe -Dmaven.multiModuleProjectDirectory=D:\\Learning-materials\\microservices\\springcloud-greenwich-github\\MicroservicesGreenwich\\demo -Dmaven.home=D:\\devsoft\\apache-maven-3.5.0 -Dclassworlds.conf=D:\\devsoft\\apache-maven-3.5.0\\bin\\m2.conf &quot;-Dmaven.ext.class.path=D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2\\plugins\\maven\\lib\\maven-event-listener.jar&quot; &quot;-javaagent:D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2\\lib\\idea_rt.jar=53271:D:\\Program Files\\JetBrains\\IntelliJ IDEA 2019.2\\bin&quot; -Dfile.encoding=UTF-8 -classpath D:\\devsoft\\apache-maven-3.5.0\\boot\\plexus-classworlds-2.5.2.jar org.codehaus.classworlds.Launcher -Didea.version2019.2 -s D:\\devsoft\\apache-maven-3.5.0\\conf\\settings.xml com.spotify:docker-maven-plugin:1.0.0:build[INFO] Scanning for projects...[INFO] [INFO] ------------------------------------------------------------------------[INFO] Building demo 1.0.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- docker-maven-plugin:1.0.0:build (default-cli) @ demo ---[INFO] Using authentication suppliers: [ConfigFileRegistryAuthSupplier][INFO] Copying D:\\Learning-materials\\microservices\\springcloud-greenwich-github\\MicroservicesGreenwich\\demo\\target\\demo-1.0.0-SNAPSHOT.jar -&gt; D:\\Learning-materials\\microservices\\springcloud-greenwich-github\\MicroservicesGreenwich\\demo\\target\\docker\\demo-1.0.0-SNAPSHOT.jar[INFO] Copying src\\main\\docker\\Dockerfile -&gt; D:\\Learning-materials\\microservices\\springcloud-greenwich-github\\MicroservicesGreenwich\\demo\\target\\docker\\Dockerfile[INFO] Building image demo-docker/demoStep 1/4 : FROM openjdk:8-jdk-alpinePulling from library/openjdke7c96db7181b: Already exists f910a506b6cb: Pulling fs layer c2274a1a0e27: Pulling fs layer f910a506b6cb: Downloading [==================================================&gt;] 238B/238Bf910a506b6cb: Verifying Checksum f910a506b6cb: Download complete f910a506b6cb: Extracting [==================================================&gt;] 238B/238Bf910a506b6cb: Extracting [==================================================&gt;] 238B/238Bf910a506b6cb: Pull complete c2274a1a0e27: Downloading [&gt; ] 524.5kB/70.73MBc2274a1a0e27: Downloading [=&gt; ] 2.1MB/70.73MBc2274a1a0e27: Downloading [==&gt; ] 3.675MB/70.73MBc2274a1a0e27: Downloading [===&gt; ] 4.725MB/70.73MBc2274a1a0e27: Downloading [====&gt; ] 6.825MB/70.73MBc2274a1a0e27: Downloading [=====&gt; ] 8.4MB/70.73MBc2274a1a0e27: Downloading [=======&gt; ] 9.975MB/70.73MBc2274a1a0e27: Downloading [========&gt; ] 11.55MB/70.73MBc2274a1a0e27: Downloading [=========&gt; ] 13.12MB/70.73MBc2274a1a0e27: Downloading [==========&gt; ] 14.7MB/70.73MBc2274a1a0e27: Downloading [===========&gt; ] 16.27MB/70.73MBc2274a1a0e27: Downloading [============&gt; ] 17.85MB/70.73MBc2274a1a0e27: Downloading [=============&gt; ] 19.42MB/70.73MBc2274a1a0e27: Downloading [==============&gt; ] 20.47MB/70.73MBc2274a1a0e27: Downloading [===============&gt; ] 22.05MB/70.73MBc2274a1a0e27: Downloading [================&gt; ] 23.62MB/70.73MBc2274a1a0e27: Downloading [=================&gt; ] 25.2MB/70.73MBc2274a1a0e27: Downloading [==================&gt; ] 26.77MB/70.73MBc2274a1a0e27: Downloading [====================&gt; ] 28.35MB/70.73MBc2274a1a0e27: Downloading [=====================&gt; ] 29.92MB/70.73MBc2274a1a0e27: Downloading [=====================&gt; ] 30.97MB/70.73MBc2274a1a0e27: Downloading [=======================&gt; ] 32.55MB/70.73MBc2274a1a0e27: Downloading [=======================&gt; ] 33.6MB/70.73MBc2274a1a0e27: Downloading [========================&gt; ] 34.12MB/70.73MBc2274a1a0e27: Downloading [========================&gt; ] 35.17MB/70.73MBc2274a1a0e27: Downloading [=========================&gt; ] 35.7MB/70.73MBc2274a1a0e27: Downloading [=========================&gt; ] 36.22MB/70.73MBc2274a1a0e27: Downloading [=========================&gt; ] 36.75MB/70.73MBc2274a1a0e27: Downloading [==========================&gt; ] 37.27MB/70.73MBc2274a1a0e27: Downloading [==========================&gt; ] 37.8MB/70.73MBc2274a1a0e27: Downloading [===========================&gt; ] 38.32MB/70.73MBc2274a1a0e27: Downloading [===========================&gt; ] 38.85MB/70.73MBc2274a1a0e27: Downloading [===========================&gt; ] 39.37MB/70.73MBc2274a1a0e27: Downloading [============================&gt; ] 39.9MB/70.73MBc2274a1a0e27: Downloading [============================&gt; ] 40.42MB/70.73MBc2274a1a0e27: Downloading [============================&gt; ] 40.95MB/70.73MBc2274a1a0e27: Downloading [=============================&gt; ] 41.47MB/70.73MBc2274a1a0e27: Downloading [=============================&gt; ] 42MB/70.73MBc2274a1a0e27: Downloading [==============================&gt; ] 42.52MB/70.73MBc2274a1a0e27: Downloading [==============================&gt; ] 43.05MB/70.73MBc2274a1a0e27: Downloading [==============================&gt; ] 43.57MB/70.73MBc2274a1a0e27: Downloading [===============================&gt; ] 44.1MB/70.73MBc2274a1a0e27: Downloading [===============================&gt; ] 44.62MB/70.73MBc2274a1a0e27: Downloading [===============================&gt; ] 45.15MB/70.73MBc2274a1a0e27: Downloading [================================&gt; ] 45.67MB/70.73MBc2274a1a0e27: Downloading [================================&gt; ] 46.2MB/70.73MBc2274a1a0e27: Downloading [=================================&gt; ] 46.72MB/70.73MBc2274a1a0e27: Downloading [=================================&gt; ] 47.25MB/70.73MBc2274a1a0e27: Downloading [=================================&gt; ] 47.77MB/70.73MBc2274a1a0e27: Downloading [==================================&gt; ] 48.3MB/70.73MBc2274a1a0e27: Downloading [==================================&gt; ] 48.82MB/70.73MBc2274a1a0e27: Downloading [==================================&gt; ] 49.35MB/70.73MBc2274a1a0e27: Downloading [===================================&gt; ] 49.87MB/70.73MBc2274a1a0e27: Downloading [===================================&gt; ] 50.4MB/70.73MBc2274a1a0e27: Downloading [===================================&gt; ] 50.92MB/70.73MBc2274a1a0e27: Downloading [====================================&gt; ] 51.45MB/70.73MBc2274a1a0e27: Downloading [====================================&gt; ] 51.97MB/70.73MBc2274a1a0e27: Downloading [=====================================&gt; ] 52.5MB/70.73MBc2274a1a0e27: Downloading [=====================================&gt; ] 53.02MB/70.73MBc2274a1a0e27: Downloading [=====================================&gt; ] 53.55MB/70.73MBc2274a1a0e27: Downloading [======================================&gt; ] 54.07MB/70.73MBc2274a1a0e27: Downloading [======================================&gt; ] 54.6MB/70.73MBc2274a1a0e27: Downloading [======================================&gt; ] 55.12MB/70.73MBc2274a1a0e27: Downloading [=======================================&gt; ] 55.65MB/70.73MBc2274a1a0e27: Downloading [=======================================&gt; ] 56.17MB/70.73MBc2274a1a0e27: Downloading [========================================&gt; ] 56.7MB/70.73MBc2274a1a0e27: Downloading [========================================&gt; ] 57.22MB/70.73MBc2274a1a0e27: Downloading [========================================&gt; ] 57.75MB/70.73MBc2274a1a0e27: Downloading [=========================================&gt; ] 58.27MB/70.73MBc2274a1a0e27: Downloading [=========================================&gt; ] 58.8MB/70.73MBc2274a1a0e27: Downloading [=========================================&gt; ] 59.32MB/70.73MBc2274a1a0e27: Downloading [==========================================&gt; ] 59.85MB/70.73MBc2274a1a0e27: Downloading [==========================================&gt; ] 60.37MB/70.73MBc2274a1a0e27: Downloading [===========================================&gt; ] 60.9MB/70.73MBc2274a1a0e27: Downloading [===========================================&gt; ] 61.42MB/70.73MBc2274a1a0e27: Downloading [===========================================&gt; ] 61.95MB/70.73MBc2274a1a0e27: Downloading [============================================&gt; ] 62.47MB/70.73MBc2274a1a0e27: Downloading [============================================&gt; ] 63MB/70.73MBc2274a1a0e27: Downloading [============================================&gt; ] 63.52MB/70.73MBc2274a1a0e27: Downloading [=============================================&gt; ] 64.05MB/70.73MBc2274a1a0e27: Downloading [=============================================&gt; ] 64.57MB/70.73MBc2274a1a0e27: Downloading [==============================================&gt; ] 65.1MB/70.73MBc2274a1a0e27: Downloading [==============================================&gt; ] 65.62MB/70.73MBc2274a1a0e27: Downloading [==============================================&gt; ] 66.15MB/70.73MBc2274a1a0e27: Downloading [===============================================&gt; ] 66.67MB/70.73MBc2274a1a0e27: Downloading [===============================================&gt; ] 67.2MB/70.73MBc2274a1a0e27: Downloading [===============================================&gt; ] 67.72MB/70.73MBc2274a1a0e27: Downloading [================================================&gt; ] 68.25MB/70.73MBc2274a1a0e27: Downloading [================================================&gt; ] 68.77MB/70.73MBc2274a1a0e27: Downloading [================================================&gt; ] 69.3MB/70.73MBc2274a1a0e27: Downloading [=================================================&gt; ] 69.82MB/70.73MBc2274a1a0e27: Downloading [=================================================&gt; ] 70.35MB/70.73MBc2274a1a0e27: Verifying Checksum c2274a1a0e27: Download complete c2274a1a0e27: Extracting [&gt; ] 557.1kB/70.73MBc2274a1a0e27: Extracting [=&gt; ] 1.671MB/70.73MBc2274a1a0e27: Extracting [=&gt; ] 2.785MB/70.73MBc2274a1a0e27: Extracting [===&gt; ] 4.456MB/70.73MBc2274a1a0e27: Extracting [====&gt; ] 6.128MB/70.73MBc2274a1a0e27: Extracting [======&gt; ] 8.913MB/70.73MBc2274a1a0e27: Extracting [=======&gt; ] 11.14MB/70.73MBc2274a1a0e27: Extracting [=========&gt; ] 13.93MB/70.73MBc2274a1a0e27: Extracting [===========&gt; ] 16.15MB/70.73MBc2274a1a0e27: Extracting [=============&gt; ] 18.94MB/70.73MBc2274a1a0e27: Extracting [===============&gt; ] 21.73MB/70.73MBc2274a1a0e27: Extracting [================&gt; ] 23.95MB/70.73MBc2274a1a0e27: Extracting [==================&gt; ] 26.18MB/70.73MBc2274a1a0e27: Extracting [====================&gt; ] 28.41MB/70.73MBc2274a1a0e27: Extracting [=====================&gt; ] 30.64MB/70.73MBc2274a1a0e27: Extracting [=======================&gt; ] 32.87MB/70.73MBc2274a1a0e27: Extracting [========================&gt; ] 35.09MB/70.73MBc2274a1a0e27: Extracting [==========================&gt; ] 37.32MB/70.73MBc2274a1a0e27: Extracting [===========================&gt; ] 39.55MB/70.73MBc2274a1a0e27: Extracting [=============================&gt; ] 42.34MB/70.73MBc2274a1a0e27: Extracting [===============================&gt; ] 45.12MB/70.73MBc2274a1a0e27: Extracting [=================================&gt; ] 47.91MB/70.73MBc2274a1a0e27: Extracting [===================================&gt; ] 49.58MB/70.73MBc2274a1a0e27: Extracting [====================================&gt; ] 51.81MB/70.73MBc2274a1a0e27: Extracting [======================================&gt; ] 54.03MB/70.73MBc2274a1a0e27: Extracting [=======================================&gt; ] 56.26MB/70.73MBc2274a1a0e27: Extracting [=========================================&gt; ] 58.49MB/70.73MBc2274a1a0e27: Extracting [==========================================&gt; ] 60.72MB/70.73MBc2274a1a0e27: Extracting [============================================&gt; ] 62.95MB/70.73MBc2274a1a0e27: Extracting [=============================================&gt; ] 64.62MB/70.73MBc2274a1a0e27: Extracting [==============================================&gt; ] 65.73MB/70.73MBc2274a1a0e27: Extracting [===============================================&gt; ] 66.85MB/70.73MBc2274a1a0e27: Extracting [================================================&gt; ] 68.52MB/70.73MBc2274a1a0e27: Extracting [=================================================&gt; ] 70.19MB/70.73MBc2274a1a0e27: Extracting [==================================================&gt;] 70.73MB/70.73MBc2274a1a0e27: Pull complete Digest: sha256:94792824df2df33402f201713f932b58cb9de94a0cd524164a0f2283343547b3Status: Downloaded newer image for openjdk:8-jdk-alpine ---&gt; a3562aa0b991Step 2/4 : VOLUME /tmp ---&gt; Running in 9866501a71d4Removing intermediate container 9866501a71d4 ---&gt; f4247134db56Step 3/4 : ADD demo-1.0.0-SNAPSHOT.jar app.jar ---&gt; 9fe41d8b6c79Step 4/4 : ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] ---&gt; Running in 619d8b8027efRemoving intermediate container 619d8b8027ef ---&gt; 5567045a3623ProgressMessage&#123;id=null, status=null, stream=null, error=null, progress=null, progressDetail=null&#125;Successfully built 5567045a3623Successfully tagged demo-docker/demo:latest[INFO] Built demo-docker/demo[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 58.843 s[INFO] Finished at: 2020-01-16T15:58:07+08:00[INFO] Final Memory: 27M/459M[INFO] ------------------------------------------------------------------------ 此时我们登录远程机器，查看镜像是否发布上来。 可以看到已经构建成镜像并上传到镜像仓库了，并且image id 都一致。那么此时已经大功告成了！镜像都有了，直接一条命令构建容器并启动就可以了！激动人心得时刻即将到来！ 1docker run -p 8181:8080 --name demo -d 5567045a3623 正常启动，查看项目允许日志 1docker logs -f demo 至此大功告成！鼓掌！","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"为什么Spring不建议使用field方式注入","slug":"why-spring-does-not-recommend-field-injection","date":"2020-01-29T12:44:43.000Z","updated":"2022-09-17T14:13:56.178Z","comments":true,"path":"spring/why-spring-does-not-recommend-field-injection/","link":"","permalink":"https://www.cicoding.cn/spring/why-spring-does-not-recommend-field-injection/","excerpt":"","text":"前言使用Spring框架最核心的两个功能就是IOC和AOP。IOC也就是控制反转，我们将类的实例化、依赖关系等都交由Spring来处理，以达到解耦合、利用复用、利于测试、设计出更优良程序的目的。而对用户来说，操作最对的便是注解。在Spring中提供了三类注解方式，下面我们就逐一分析。最后，你会发现，你最常用、看起来最方便的形式确实最不推荐的一种形式。 常见的注入方式Field注入123456@Controllerpublic class FooController &#123; @Autowired // @Resource private FooService fooService;&#125; 此种注解方式，应用最广泛： 注入简单，只需在字段上添加@Autowired或@Resource； 减少大量冗余代码，美观； 新增Field时不需要过多代码修改； 构造函数注入1234567891011121314@Controllerpublic class FooController &#123; private final FooService fooService; private final FooService1 fooService1; @Autowired public FooController(FooService fooService,FooService1 fooService1) &#123; this.fooService = fooService; this.fooService1 = fooService1; &#125;&#125; 或 123456789@Controllerpublic class FooController &#123; private final FooService fooService; // 当只有一个参数时可不写@Autowired public FooController(FooService fooService) &#123; this.fooService = fooService; &#125;&#125; Spring4.x推荐的注入方式。对比Field注入： 代码臃肿 新增Field修改麻烦 当Field多余5个时不符合构造方法的基本规范，显得笨重、臃肿； setter注入12345678910@Controllerpublic class FooController &#123; private FooService fooService; @Autowired public void setFooService(FooService fooService) &#123; this.fooService = fooService; &#125;&#125; Spring3.x推荐的注入方式，但并没有被广泛应用，当初推荐的理由： 解决了构造器注入的笨重； 可以让类在之后重新配置或者重新注入。 为什么Spring4.x推荐构造函数注入在上面的分析看来，构造函数注入好像并没有显现出来它的优势，但问什么Spring4.x会推翻之前推荐的setter注入，采用构造函数注入呢？官方的理由汇总如下： 依赖不可变：加入了final来约束修饰Field，这条是很显然的； 依赖不可为空：在实例化的时候会检查构造函数参数是否为空，如果为空（未找到改类型的实例对象）则会抛出异常。 单一职责：当使用构造函数注入时，如果参数过多，你会发现当前类的职责过大，需要进行拆分。而使用Field注入时，你并不会意识到此问题。 更利于单元测试：按照其他两种方式注入，当单元测试时需要初始化整个spring的环境，而采用构造方法注入时，只需要初始化需要的类即可，即可以直接实例化需要的类。 避免IOC容器以外环境调用时潜在的NPE（空指针异常）。 避免循环依赖。 保证返回客户端（调用）的代码的时候是完全初始化的状态。 疑问如果有大量依赖需要注入，怎么办？如果有大量依赖需要注入说明该类的职责过于复杂，需要遵从单一性原则进行拆分； 其他注入方式是否合理？存在即合理，根据具体情况可以采用最适合的方式。比如，可以同时使用@Qualifier来达到一些约束限定的目的。也可以使用setter注入和构造函数注入相结合的方式来进行注入。 参考文档 剔除Intellij中Mybatis的Mapper自动注入警告 idea mybatis 注入 mapper 提示错误 【Spring】浅谈spring为什么推荐使用构造器注入 你可能使用了Spring最不推荐的注解方式","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring 注释 @Autowired 和@Resource 的区别","slug":"spring-autowired-resource","date":"2020-01-29T11:49:49.000Z","updated":"2022-09-17T14:13:56.175Z","comments":true,"path":"spring/spring-autowired-resource/","link":"","permalink":"https://www.cicoding.cn/spring/spring-autowired-resource/","excerpt":"","text":"一、@Autowired和@Resource都可以用来装配bean，都可以写在字段上，或者方法上。 二、@Autowired属于Spring的；@Resource为JSR-250标准的注释，属于J2EE的。 三、@Autowired默认按类型装配，默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，例如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下： 12@Autowired() @Qualifier(&quot;baseDao&quot;)private BaseDao baseDao; 四、@Resource，默认安装名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 例如： 12@Resource(name=&quot;baseDao&quot;)private BaseDao baseDao; 五、推荐使用：@Resource注解在字段上，这样就不用写setter方法了，并且这个注解是属于J2EE的，减少了与spring的耦合。这样代码看起就比较优雅。 1、@Resource后面没有任何内容，默认通过name属性去匹配bean，找不到再按type去匹配 2、指定了name或者type则根据指定的类型去匹配bean 3、指定了name和type则根据指定的name和type去匹配bean，任何一个不匹配都将报错 然后，区分一下@Autowired和@Resource两个注解的区别： 1、@Autowired默认按照byType方式进行bean匹配，@Resource默认按照byName方式进行bean匹配 2、@Autowired是Spring的注解，@Resource是J2EE的注解，这个看一下导入注解的时候这两个注解的包名就一清二楚了 Spring属于第三方的，J2EE是Java自己的东西，因此，建议使用@Resource注解，以减少代码和Spring之间的耦合。 个人见解： 1、@Autowired和@Resource都是基于@service、@controller、@repository以及xml配置中 2、@Autowired和@Resource匹配的内容取决于@service()括号内的内容或 spring的xml配置里 的id（xml配置优先） 3、如果使用@Resource，请最好这么写@Resource（name=”BWM”）,因为他是默认按name匹配的，不填写就按type匹配 4、如果使用@Autowired，请最好不要加@Qualifier(“BWM”)，因为他是默认按type匹配的，填写就按name匹配 5、其实@Autowired + @Qualifier(“BWM”) == @Resource（name=”BWM”），@Autowired ==@Resource（）或@Resource，用哪个都可以， 6、最好不要这么写 @Resource（）+ @Qualifier(“BWM”) ，虽然也可以，但是感觉不伦不类，前者属于j2EE,后者属于spring 7、当 一个接口有两个以上实现类的时候才会用到@Autowired + @Qualifier(“BWM”) 或 @Resource（name=”BWM”），这时， 如果使用的是xml，则不用担心，因为你一定会写id； 如果使用的是@Service(),请注意：最好在括号内写上name，和@Autowired +@Qualifier(“BWM”)或Resource（name=”BWM”）成对出现，增强可读性，避免出错， 因为有一种特殊情况会使你出错，spring@Service生成bean的命名规则：当类的名字是以两个或以上连续的大写字母开头的话，bean的名字会与类名保持一致，首字母不小写 8、当一个接口只有一个实现类，@Autowired和@Resource没有区别，但是最好用@Autowired，原因请看下文 9、@Resource默认按name匹配，，当有一个接口有多个实现类的时候，引用都是一个接口，不好区分，才使用name区分，这种情况使用@Resource和@Autowired都可以，推荐使用@Resource，且都是按name匹配，一般不用type匹配，引用的是同一个接口，同一个type 还有一种方式：使用byType类型时，使用@Service+@Primary组合，一个接口当有多个实现类，，@Primary强制指定一个实现类 10、@Autowired默认按type匹配，，当有一个接口只有有一个实现类的时候，引用是一个接口，只有一个实现类，没必要使用name区分，这种情况使用@Resource和@Autowired都可以，推荐使用@Autowired，一般都是按type匹配，也可以按name匹配，比较麻烦不推荐 （比如：一个与世隔绝的村子，只有一个姓李的人，大家叫他“老李”，都知道他是谁，就没必要叫名字。但是这个村要是有2-100姓李的，你叫“老李”，大家就不知道是叫谁了，这时候就要加名字。type=姓 name=名；如果有个姓李的，十分厉害，十分有名，那可能叫“老李”，就特指他一个人，优先级最高 ，等价于@Primary） 总结： 当一个接口只有一个实现类，推荐使用@Autowired，默认byType注入，不一定 真的byType，可以修改为byName，@Resource同理； 当一个接口有多个实现类，推荐使用@Resource，默认byName注入； 具体情况具体分析 ： 比如当一个接口有多个实现类，用@Primary 告诉spring 在犹豫的时候（byName是不会犹豫的，会确定一个唯一实现类，@Primary没有意义）优先选择哪一个具体的实现。spring优先注入@Primary修饰的那个；或者使用@Qualifier来标注需要注入的类。 @Service是注入，生成bean实例，既有type也有name. @Service标注名称，如@Service（“Benz”），则bean的名称就是Benz，如果不标注，@Service（），spring会默认注入一个beanName，要注意特殊情况，看上文 @Autowired和@Resource只是查找匹配，然后给属性赋值。private Car car； 123456789101112131415@Servicepublic class CarFactory &#123; @Resource(name=&quot;benz&quot;)//byName匹配，此时beanName=benz;如果将（name=&quot;benz&quot;）去掉，beanName=car,即属性名；只要byName匹配不到，就会使用byType匹配 private Car car; public String toString()&#123; return car.carName(); &#125; public void Test()&#123; System.out.println(&quot;it is ok!&quot;); &#125; &#125; 如果@Resource(name=”benz”)换成@Autowired+@Qualifier（“benz”）,此时也是按照byName,此时beanName=benz,如果再去掉@Qualifier（“benz”），就是byType匹配，beanType=XXX.Car.class 注意 ：@Autowired和@Resource只是匹配beanName,决定注入beanName的是@service()括号内的name（没有的话spring会自动生成一个，有一个特殊情况请看上文）或 spring的xml配置里 的id=name（xml配置优先） 参考链接： https://www.cnblogs.com/StarkMorgan/p/10408255.html https://www.cnblogs.com/leiOOlei/p/3713779.html","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring:@Profile，AOP","slug":"spring-profile-aop","date":"2020-01-28T10:49:49.000Z","updated":"2022-09-17T14:13:56.177Z","comments":true,"path":"spring/spring-profile-aop/","link":"","permalink":"https://www.cicoding.cn/spring/spring-profile-aop/","excerpt":"","text":"Profile： 可以根据当前的环境，动态激活和切换一系列的组件功能 指定组件在那个环境下才能被注册到容器中，不指定任何环境下都能注册到 1.加了环境标识的bean只有环境激活的时候才能注册到容器中 默认是default ，@Profile(“default”) 才能加入到环境中 2.还可以下载类上，只有在当时的环境下，整个类的方法才会生效 3.默认没标识的bean在，任何环境下都是加载的 1234db.user=rootdb.password=1234db.jdbcUrl=jdbc:mysql://localhost:3306/usersdb.drivetClass=com.mysql.jdbc.Driver 12345678910111213141516171819202122232425262728293031323334@PropertySource(&quot;classpath:/db.properties&quot;)@Configurationpublic class MainConfigProfile &#123; @Value(&quot;$&#123;db.user&#125;&quot;) private String user; @Value(&quot;$&#123;db.password&#125;&quot;) private String pwd; @Value(&quot;$&#123;db.jdbcUrl&#125;&quot;) private String jdbcUrl; @Value(&quot;$&#123;db.drivetClass&#125;&quot;) private String DriverClass; @Profile(&quot;test&quot;) @Bean(&quot;testDatasource&quot;) public ComboPooledDataSource datasource() throws Exception&#123; ComboPooledDataSource datasource = new ComboPooledDataSource(); datasource.setUser(user); datasource.setPassword(pwd); datasource.setJdbcUrl(jdbcUrl); datasource.setDriverClass(DriverClass); return datasource; &#125; @Profile(&quot;dev&quot;) @Bean(&quot;devDatasource&quot;) public ComboPooledDataSource datasource1() throws Exception&#123; ComboPooledDataSource datasource = new ComboPooledDataSource(); datasource.setUser(user); datasource.setPassword(pwd); datasource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/ssm&quot;); datasource.setDriverClass(DriverClass); return datasource; &#125;&#125; 1234567891011121314151617@Test public void test7()&#123; //创建一个application AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(); //设置环境 app.getEnvironment().setActiveProfiles(&quot;dev&quot;); //注册配置类 app.register(MainConfigProfile.class); //启动刷新容器 app.refresh(); String[] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; &#125; 注：app.getEnvironment().setActiveProfiles(“dev”，”test”);可以同时写多个 12mainConfigProfiledevDatasource 此时可以看出 app.getEnvironment().setActiveProfiles(“dev”); 这里只添加了一个环境，所以得到在dev环境下的bean，其余的均不会装配到bean容器中 此种情况下，也会自动装入到bean容器 12345678910@Profile(&quot;default&quot;) @Bean(&quot;devDatasource&quot;) public ComboPooledDataSource datasource1() throws Exception&#123; ComboPooledDataSource datasource = new ComboPooledDataSource(); datasource.setUser(user); datasource.setPassword(pwd); datasource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/ssm&quot;); datasource.setDriverClass(DriverClass); return datasource; &#125; AOP： 在程序运行期间，能够动态的将某段代码切入到指定的位置进行编程 1.导入aop模块：aspects 2.业务逻辑类 3.日志切面类： 前置通知：@Before 后置通知: @After 异常通知：@AfterReturning 返回通知：@AfterThrowing 环绕通知：@Around 4.将切面类和业务逻辑加入容器里 5.告诉spring那个类是切面类 切面类加一个注解@Aspect：告诉spring当前类是一个切面类 6.给配置类家@EnableAspectJAutoProxy 开启基于注解模式动态代理 //切面类 123456789101112131415161718192021222324252627282930313233@Aspectpublic class LogAspects &#123; //抽取公共的接入点 //本类的引用：pointCut() //外部类的引用：coom.MrChengs.aop.LogAspects.pointCut() @Pointcut(&quot;execution(public int coom.MrChengs.aop.MathCAL.*(..))&quot;) public void pointCut()&#123;&#125;; //目标方法之前切入；切入点表达式（指定在那个方面切入） //JoinPoint这个参数一定要出现在参数表的第一位，否则会报错 @Before(&quot;pointCut()&quot;) public void loginStart(JoinPoint joinpoint)&#123; //拿到执行的数据 Object [] args = joinpoint.getArgs(); System.out.println(&quot;开始计算:&quot;+joinpoint.getSignature().getName()+&quot;--&quot;+Arrays.asList(args)); &#125; //无论正常还是异常结束 @After(&quot;pointCut()&quot;) public void loginEnd()&#123; System.out.println(&quot;结束计算&quot;); &#125; @AfterReturning(value=&quot;pointCut()&quot;,returning=&quot;res&quot;) public void logReturn(int res )&#123; System.out.println(&quot;结果L:&quot; + res); &#125; @AfterThrowing(value =&quot;pointCut()&quot;,throwing=&quot;exc&quot;) public void loginException(Exception exc)&#123; System.out.println(&quot;Exception:&quot; + exc); &#125;&#125; //业务类 123456public class MathCAL &#123; public int div(int i,int j)&#123; System.out.println(&quot;正在计算.....&quot;); return (i / j); &#125;&#125; 123456789101112131415@EnableAspectJAutoProxy@Configurationpublic class MainAopConfig &#123; //业务逻辑类 @Bean public MathCAL mathCal()&#123; return new MathCAL(); &#125; //切面类 @Bean public LogAspects logAspect()&#123; return new LogAspects(); &#125; &#125; 12345678@Test public void test()&#123; AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(MainAopConfig.class); MathCAL math = app.getBean(MathCAL.class); math.div(2, 0); &#125; 12345&gt; 开始计算:div--[2, 0]&gt; 正在计算.....&gt; 结束计算&gt; Exception:java.lang.ArithmeticException: / by zero&gt; AOP原理： @EnableAspectJAutoProxy 1234567@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123;...&#125;class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123;...&#125; 利用AspectJAutoProxyRegistrar自定义为容器注入bean 原文链接","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring:生命周期，属性赋值，自动装配","slug":"spring-characteristics","date":"2020-01-28T10:24:43.000Z","updated":"2022-09-17T14:13:56.176Z","comments":true,"path":"spring/spring-characteristics/","link":"","permalink":"https://www.cicoding.cn/spring/spring-characteristics/","excerpt":"","text":"1.Bean的生命周期 创建—初始化—销毁 容器管理bean的生命周期： 我们可以自定义初始化和销毁的方法 构造器： 1.单实例：在容器创建好之后创建实例 2.多实例：在每次获取的时候创建对象 初始化： 对象创建好，并赋值好，进行初始化 销毁： 单实例：容器关闭的时候 多实例：容器不会管理这个bean，在容器关闭的时候不会调用销毁的方法 指定初始化和销毁的方法：通过@Bean的注解 相当于：init-method,destroy-method 123456789101112public class Chirld &#123; public Chirld() &#123; System.out.println(&quot;创建Child实例....&quot;); &#125; public void init()&#123; System.out.println(&quot;初始化方法.....&quot;); &#125; public void destroy()&#123; System.out.println(&quot;销毁方法....&quot;); &#125;&#125; 1234567@Configurationpublic class TheLifeOfInitAnfDestroy &#123; @Bean(initMethod=&quot;init&quot;,destroyMethod=&quot;destroy&quot;) public Chirld car()&#123; return new Chirld(); &#125;&#125; 12345678@Testpublic void test4()&#123; AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(TheLifeOfInitAnfDestroy.class); System.out.println(&quot;容器创建完成&quot;); //关闭 app.close();&#125; 123456创建Child实例....初始化方法.....容器创建完成十一月 16, 2018 12:19:32 上午 org.springframework.context.annotation.AnnotationConfigApplicationContext doClose信息: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@512ddf17: startup date [Fri Nov 16 00:19:32 CST 2018]; root of context hierarchy销毁方法.... 在容器关闭的时候进行销毁 接口方法 通过Bean实现InitializingBean自定义初始化逻辑 ​ DisposableBean自定义销毁容器 123456public interface InitializingBean &#123; void afterPropertiesSet() throws Exception;&#125;public interface DisposableBean &#123; void destroy() throws Exception;&#125; 1234567891011121314@Componentpublic class Chirld2 implements InitializingBean,DisposableBean &#123; public Chirld2() &#123; System.out.println(&quot;创建Child2实例....&quot;); &#125; public void afterPropertiesSet() throws Exception &#123; System.out.println(&quot;init.....&quot;); &#125; public void destroy() throws Exception &#123; System.out.println(&quot;destroy....&quot;); &#125;&#125; 12345@Configuration@ComponentScan(&quot;coom.MrChengs.bean&quot;)public class TheLifeOfInitAnfDestroy &#123;&#125; 12345678@Test public void test4()&#123; AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(TheLifeOfInitAnfDestroy.class); System.out.println(&quot;容器创建完成&quot;); //关闭 app.close(); &#125; 123456创建Child2实例....init.....容器创建完成十一月 16, 2018 12:35:43 上午 org.springframework.context.annotation.AnnotationConfigApplicationContext doClose信息: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@512ddf17: startup date [Fri Nov 16 00:35:43 CST 2018]; root of context hierarchydestroy.... 可以使用JSR250 @PostConStruct：在bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy：在容器销毁bean之前通知我们进行清理 //代码….. 4.BeanPostProcessor接口：bean的后置处理器 在bean初始化之后进行一些处理工作 postProcessBeforeInitialization：在初始化之前工作 postProcessAfterInitialization： 在初始化之后工作 12345678910111213@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor&#123; //bean:刚刚创建的实例 //beanName：bean的名字 public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;post init.....&quot;); return bean; &#125; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;aftet init ....&quot;); return bean; &#125;&#125; 1234@Configuration@ComponentScan(&quot;coom.MrChengs.bean&quot;)public class TheLifeOfInitAnfDestroy &#123;&#125; 1234567@Testpublic void test4()&#123; AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(TheLifeOfInitAnfDestroy.class); System.out.println(&quot;容器创建完成&quot;); //关闭 app.close();&#125; 1234567891011121314post init.....aftet init ....post init.....aftet init ....post init.....aftet init ....创建Child2实例....post init.....init.....aftet init ....容器创建完成十一月 16, 2018 8:25:25 上午 org.springframework.context.annotation.AnnotationConfigApplicationContext doClose信息: Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@512ddf17: startup date [Fri Nov 16 08:25:24 CST 2018]; root of context hierarchydestroy.... 底层对BeanPostProcessor的使用： bean赋值，注入其他组建，@Autowire,生命周期注解功能。。。。。 2.属性赋值： @Value(“”) 1.基本数值 2.可以写Spel ： #{} 3.可以写 ${ } ，取出配置文件中的只 person.properties 1person.school=MrChengs 12345678910public class Person &#123; @Value(&quot;MrChengs&quot;) private String name; @Value(&quot;#&#123;20-12&#125;&quot;) private int age; @Value(&quot;$&#123;person.school&#125;&quot;) private String school;...&#125; 12345678@Configuration//引入资源@PropertySource(value=&#123;&quot;classpath:/person.properties&quot;&#125;)public class ValueConfig &#123; @Bean public Person person()&#123; return new Person(); &#125;&#125; 123456789101112@Test public void test5()&#123; AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(ValueConfig.class); String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; Person person = app.getBean(Person.class); System.out.println(person); &#125; valueConfigpersonPerson [name=MrChengs, age=8, school=MrChengs] @PropertySource(value={“classpath:/person.properties”})用于加载配置文件 123456789101112public @interface PropertySource &#123; String name() default &quot;&quot;; String[] value(); boolean ignoreResourceNotFound() default false; String encoding() default &quot;&quot;; Class&lt;? extends PropertySourceFactory&gt; factory() default PropertySourceFactory.class;&#125; 自动装配： 利用依赖注入（DI）完成对IOC容器中各个组件的依赖关系。 前提自动注入的需要提前在容器中 @Autowired 默认优先按照类型进行容器组件中查找 当容器中有多个相同类型的组件，再将属性的名作为组件的id去容器中查找 12345applicationContext.getBean(&quot;customerDao&quot;)... @Autowired private CustomerDao customerDao;默认按照方法名去id中查找 @Qualifier 指定需要装配的组件id 123@Qualifier(&quot;customerDao&quot;) @Autowired private CustomerDao customerDao2; 默认一定将属性赋值好 如果没有的情况下组件默认是null 不是必须的，此时容器中没有所需要装配的bean也不会报错 123@Qualifier(&quot;customerDao&quot;)@Autowired(required=false)private CustomerDao customerDao2; @Primary:让spring进行装配的时候，默认使用首选的bean 123456789 @Autowired(required=false) private CustomerDao customerDao; @Primary @Bean(&quot;customerDao2&quot;) public CustomerDao customer()&#123; ...&#125; 123@Repositorypublic class CustomerDao &#123;&#125; 123456789@Servicepublic class CustomerService &#123; @Autowired private CustomerDao customerDao; public void print()&#123; System.out.println(&quot;----&gt;&quot;+customerDao); &#125;&#125; 123456789@Configuration@ComponentScan(&#123;&quot;coom.MrChengs.config.service&quot;,&quot;coom.MrChengs.config.dao&quot;&#125;)public class AutowiredConfig &#123; @Bean(&quot;customerDao2&quot;) public CustomerDao customer()&#123; return new CustomerDao(&quot;customer2&quot;); &#125; &#125; 123456789101112@Testpublic void test6()&#123; AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(coom.MrChengs.config.AutowiredConfig.class); String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; CustomerService cus = app.getBean(CustomerService.class); cus.print(); //System.out.println(cus);&#125; 123456789autowiredConfigcustomerService此时容器中有两个相同类型的beancustomerDaocustomerDao2此时注入的类型是：----&gt;CustomerDao [name=null] spring还支持@Resource和@Inject java规范注解 @Resource 可以实现和@Autowire一样的功能 实现，默认是按照组件的名称进行装配 12@Resourceprivate CustomerDao customerDao; 可以修改器默认装配的名称 12@Resource(name=&quot;customerDao2&quot;)private CustomerDao customerDao; 不可以支持@Primary功能和request=false的功能 @Inject 需要导入下面的依赖 123456&lt;!-- https://mvnrepository.com/artifact/javax.inject/javax.inject --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.inject&lt;/groupId&gt; &lt;artifactId&gt;javax.inject&lt;/artifactId&gt; &lt;version&gt;1&lt;/version&gt;&lt;/dependency&gt; 12@Injectprivate CustomerDao customerDao; 其实先功能和@Autowire功能一样 其本身没有属性，没有require=false这个属性 支持@Primary @Autowire 12345@Target(&#123;ElementType.CONSTRUCTOR, ElementType.METHOD, ElementType.PARAMETER, ElementType.FIELD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Autowired &#123; 可以标注的位置有构造器，方法，属性 方法上 1234@Componentpublic class Person &#123;...&#125; 123456789@Componentpublic class Students &#123;... @Autowired public void setPerson(Person person) &#123; this.person = person; &#125;..&#125; 1234567AnnotationConfigApplicationContext app = new AnnotationConfigApplicationContext(coom.MrChengs.config.AutowiredConfig.class); Students s = app.getBean(Students.class); System.out.println(s); Person p = app.getBean(Person.class); System.out.println(p); Students [person=Person [name=MrChengs, age=8, school=${person.school}], name=null]Person [name=MrChengs, age=8, school=${person.school}] 构造器： 1234567@Autowiredpublic Students(Person person, String name) &#123; super(); this.person = person; this.name = name; System.out.println(&quot;Students.....&quot;);&#125; 1.标注在方法位置上，@Bean+方法参数，参数从容器中获取 2.标注在构造器上：如果组件只有一个构造函数，可以省略 3.放在参数位置 原文链接","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring注解：@Lazy，@Conditional，@import，FactoryBean接口","slug":"spring-component","date":"2020-01-28T08:43:43.000Z","updated":"2022-09-17T14:13:56.176Z","comments":true,"path":"spring/spring-component/","link":"","permalink":"https://www.cicoding.cn/spring/spring-component/","excerpt":"","text":"1.@Lazy懒加载 懒加载：针对单实例的 单实例bean，默认在容器启动的时候创建对象 懒加载就是：容器启动的时候不创建对象，在第一次获取bean的时候创建对象，并且初始化、 Config2.class 12345678@Configurationpublic class Config2 &#123; @Bean(&quot;per&quot;) public Person person()&#123; System.out.println(&quot;person对象创建完成&quot;); return new Person(&quot;MrChengs&quot;,20); &#125;&#125; 测试 123456@Testpublic void test2()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanDefinitionNames(); System.out.println(&quot;容器创建完成...&quot;);&#125; 此时并没有去获取Person对象！ 此时容器创建之后就会实例化对象 12person对象创建完成容器创建完成... 使用懒加载： 123456789@Configurationpublic class Config2 &#123; @Lazy @Bean(&quot;per&quot;) public Person person()&#123; System.out.println(&quot;person对象创建完成&quot;); return new Person(&quot;MrChengs&quot;,20); &#125;&#125; 测试： 容器创建完成… 2..@Conditional 按照一定的条件判断，满足条件给容器注册 可以在类上也可以在方法上 放置在类上，满足 条件，配置的所有的bean都会生效 假设在windows和Linux操作系统获取自动的注册信息 1234567891011121314151617181920212223@Configurationpublic class Config2 &#123; @Lazy @Bean(&quot;per&quot;) public Person person()&#123; System.out.println(&quot;person对象创建完成&quot;); return new Person(&quot;MrChengs&quot;,20); &#125; //按照一定的条件判断，满足条件给容器注册 @Conditional(&#123;LinuxCondition.class&#125;) @Bean(&quot;person1&quot;) public Person person1()&#123; return new Person(&quot;Mr&quot;,12); &#125; @Conditional(&#123;WindowsCondition.class&#125;) @Bean(&quot;person2&quot;) public Person person2()&#123; return new Person(&quot;Mx&quot;,20); &#125;&#125; 123456789101112131415161718192021public class LinuxCondition implements Condition&#123; //ConditionContext:判条件能使用的上下文 //AnnotatedTypeMetadata：注释信息 public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; //能获取到IOC容器使用的beanfactory ConfigurableListableBeanFactory c = context.getBeanFactory(); //获取加载器 ClassLoader classLoader = context.getClassLoader(); //获取当前的环境信息 //Environment environment = (Environment) context.getEnvironment(); //获取bean定义注册的类 BeanDefinitionRegistry resistroy = context.getRegistry(); //获取当前的操作系统 String name = context.getEnvironment().getProperty(&quot;os.name&quot;); if(name.contains(&quot;Linux&quot;))&#123; return true; &#125; return false; &#125;&#125; 123456789101112131415161718192021public class WindowsCondition implements Condition&#123; //ConditionContext:判条件能使用的上下文 //AnnotatedTypeMetadata：注释信息 public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; //能获取到IOC容器使用的beanfactory ConfigurableListableBeanFactory c = context.getBeanFactory(); //获取加载器 ClassLoader classLoader = context.getClassLoader(); //获取当前的环境信息 //Environment environment = (Environment) context.getEnvironment(); //获取bean定义注册的类 BeanDefinitionRegistry resistroy = context.getRegistry(); String name = context.getEnvironment().getProperty(&quot;os.name&quot;); if(name.contains(&quot;Win&quot;))&#123; return true; &#125; return false; &#125;&#125; 123456789@Testpublic void test3()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanNamesForType(Person.class); for(String name : names)&#123; System.out.println(name); &#125; System.out.println(&quot;容器创建完成...&quot;);&#125; perperson2容器创建完成… 3.@import 快速的给容器中导入一个组建 默认创建的是bean是组建的全类名 12345@Configuration@Import(Person.class)public class Config2 &#123;&#125; 123456789@Testpublic void test3()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanNamesForType(Person.class); for(String name : names)&#123; System.out.println(name); &#125; System.out.println(&quot;容器创建完成...&quot;);&#125; coom.MrChengs.bean.Person容器创建完成… 源码： 1234567public @interface Import &#123; /** * &#123;@link Configuration&#125;, &#123;@link ImportSelector&#125;, &#123;@link ImportBeanDefinitionRegistrar&#125; * or regular component classes to import. */ Class&lt;?&gt;[] value();&#125; 可以同时传入多个 1@Import(&#123;Person.class，xxxxx&#125;) 直接注入到容器中 ImportSelector 是一个接口 123456789public class MyImportSelector implements ImportSelector&#123; //返回值就是需要导入到容器中的全类名 //AnnotationMetadata ： 就是获取标注@Import（）注解类的所有信息 public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[]&#123;&quot;coom.MrChengs.bean.Person&quot;&#125;; &#125;&#125; 1234@Configuration@Import(&#123;MyImportSelector.class&#125;)public class Config2 &#123;&#125; 123456789@Test public void test3()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; System.out.println(&quot;容器创建完成...&quot;); &#125; config2coom.MrChengs.bean.Person容器创建完成… ImportBeanDefinitionRegistrar接口 1234567891011121314151617public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123; //AnnotationMetadata:当前类的注解信息 //BeanDefinitionRegistry：注册类 public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //coom.MrChengs.bean.Person //判断当前类是否有下面的这个bean boolean a = registry.containsBeanDefinition(&quot;coom.MrChengs.bean.Person&quot;); //如果没有我们进行注册 if(!a)&#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(Person.class); //指定bean的名字 //注册一个bean registry.registerBeanDefinition(&quot;peson&quot;, beanDefinition ); &#125; &#125;&#125; 1234@Configuration@Import(&#123;MyImportBeanDefinitionRegistrar.class&#125;)public class Config2 &#123;&#125; 123456789@Test public void test3()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; System.out.println(&quot;容器创建完成...&quot;); &#125; config2peson容器创建完成… 4.FactoryBean接口 1234567891011121314151617181920public class PersonFactoryBean implements FactoryBean&lt;Person&gt;&#123; //返回一个person对象，这个对象会添加到容器中 public Person getObject() throws Exception &#123; // TODO Auto-generated method stub return new Person(); &#125; //返回类型 public Class&lt;?&gt; getObjectType() &#123; // TODO Auto-generated method stub return Person.class; &#125; //是单例吗？ public boolean isSingleton() &#123; // TODO Auto-generated method stub return false; &#125;&#125; 12345678@Configurationpublic class Config2 &#123; @Bean public PersonFactoryBean personFactoryBean()&#123; return new PersonFactoryBean(); &#125;&#125; 1234567891011@Testpublic void test3()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; Object name = app.getBean(&quot;personFactoryBean&quot;).getClass(); System.out.println(name); System.out.println(&quot;容器创建完成...&quot;);&#125; 1234config2personFactoryBeanclass coom.MrChengs.bean.Person -&gt; Object name = app.getBean(&quot;personFactoryBean&quot;).getClass();容器创建完成... 得到的是Person对象 默认得到的是getObject的对象 给id前面加一个&amp; 符号得到的是对象本身 Object name = app.getBean(“&amp;personFactoryBean”).getClass(); class coom.MrChengs.bean.PersonFactoryBean 原文链接","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"注解：@ComponentScan 注解","slug":"spring-componentscan","date":"2020-01-28T08:43:43.000Z","updated":"2022-09-17T14:13:56.176Z","comments":true,"path":"spring/spring-componentscan/","link":"","permalink":"https://www.cicoding.cn/spring/spring-componentscan/","excerpt":"","text":"在平时的开发，我们会配置 @Controller 、 @Service 、 @Repository 、@Component 注解来声明该类为 Spring IoC容器的组件。 在 xml 中会配置扫描包，那么使用 JavaConfig 的方式，同样可以配置扫描包。 DAO 的注解类 123456@Repositorypublic class BusinessDAO &#123; public void update() &#123; System.out.println(\"调用了 dao 层的 update 方法....\"); &#125;&#125; Service 的注解类 1234567891011@Servicepublic class BusinessService &#123; @Autowired private BusinessDAO dao; public void service() &#123; System.out.println(\"调用了 service 层的 service() 方法 .....\"); dao.update(); &#125;&#125; Controller 的注解类 123456789101112@Controllerpublic class BusinessController &#123; @Autowired private BusinessService service; public void request() &#123; System.out.println(\" 调用了 Controller 的 request() 方法...\"); service.service(); &#125; &#125; 以上三个类是我们平时开发时经常使用的方式，在不同的类上打不同的注解，然后让 Spring 的包扫描自动去扫描这些类。 Java Config 配置类 1234@Configuration@ComponentScan(\"me.sjl.*\")public class ScanConfig &#123;&#125; 结果 @ComponentScan 的排除规则FilterType.ANNOTATION 按注解类型排除123456@Configuration@ComponentScan(basePackages = \"me.sjl.*\", excludeFilters = &#123; @Filter(type = FilterType.ANNOTATION, classes = Controller.class)&#125;)public class ScanConfig &#123;&#125; excludeFilters 属性表示排除规则， 可以写多个 @Filter 来排除， 上面的代码表示 排除 Controller 注解的类 测试结果 除了排除，还可以指定只包含的类注解 JavaConfig 配置 123456@Configuration@ComponentScan(basePackages = \"me.sjl.*\", useDefaultFilters = false, includeFilters = &#123; @Filter(type = FilterType.ANNOTATION, classes = Controller.class)&#125;)public class ScanConfig &#123;&#125; useDefaultFilters = false 表示禁用默认的过滤规则 FilterType.ASSIGNABLE_TYPE 类型FilterType.ASPECTJ AspectJ表达式FilterType.REGEX 正则表示达FilterType.CUSTOM 自定义规则自定义过滤规则是需要实现 TypeFilter 接口 自定义扫描规则， 类名中带有 Service 的类，被 Spring IoC 容器扫描 1234567public class MyCustomerFilter implements TypeFilter &#123; public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; String className = metadataReader.getClassMetadata().getClassName(); return className.contains(\"Service\"); &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring注解：@Configuration，@Bean，@ComponentScan(），@Scope","slug":"spring-configuration-bean-componentscan-scope","date":"2020-01-28T08:15:43.000Z","updated":"2022-09-17T14:13:56.177Z","comments":true,"path":"spring/spring-configuration-bean-componentscan-scope/","link":"","permalink":"https://www.cicoding.cn/spring/spring-configuration-bean-componentscan-scope/","excerpt":"","text":"传统的Spring做法是使用.xml文件来对bean进行注入或者是配置aop、事物，这么做有两个缺点：1、如果所有的内容都配置在.xml文件中，那么.xml文件将会十分庞大；如果按需求分开.xml文件，那么.xml文件又会非常多。总之这将导致配置文件的可读性与可维护性变得很低。2、在开发中在.java文件和.xml文件之间不断切换，是一件麻烦的事，同时这种思维上的不连贯也会降低开发的效率。为了解决这两个问题，Spring引入了注解，通过”@XXX”的方式，让注解与Java Bean紧密结合，既大大减少了配置文件的体积，又增加了Java Bean的可读性与内聚性。 所有的注解都是在一个工程中进行演示、后面不懂得可以参考前面的随笔！ 开始注解的代码编程： 1.工程准备 Person.class 12345public class Person &#123; private String name; private int age;...&#125; 配置类： Config.class 12345678910111213//配置类 === 配置文件xxx.xml//@Configuration是告诉Spring这是一个配置类@Configurationpublic class Config &#123; //给容器注册一个bean，相当于配置文件的 &lt;bean&gt;&lt;/bean&gt; //类型默认是返回的类型 //id默认是方法名 @Bean(\"per\") public Person person()&#123; return new Person(\"MrChengs\",20); &#125;&#125; 测试： 123ApplicationContext app = new AnnotationConfigApplicationContext(Config.class);Person p =app.getBean(Person.class);System.out.println(p); Person [name=MrChengs, age=20] @Configuration 告诉sprin该类是一个配置类 所谓的配置类相当于我们所写的xxx.xml配置文件 @Bean 给容器中注入一个Bean，相当于进行实例化一个bean 属性： 默认value可以不写 @ComponentScan（） 等同于：&lt;context:component-scan base-package=””&gt; 新建四个类，分别使用：@Repository，@Service，@Controller三个注解 123456789@Repositorypublic class CustomerDao &#123;&#125;@Servicepublic class CustomerService &#123;&#125;@Controllerpublic class CustomerConteoller &#123;&#125; 在Config.class类中 12345678910@Configuration@ComponentScan(value=\"coom.MrChengs.config\",excludeFilters=&#123; @Filter(type=FilterType.ANNOTATION,classes=&#123;Repository.class&#125;)&#125;)public class Config &#123; @Bean(\"per\") public Person person()&#123; return new Person(\"MrChengs\",20); &#125;&#125; 1@ComponentScan： value ：指定需要扫描的包 excludeFilters ：指定扫描的适合排除那些包 Filter[] excludeFilters() default {}; FilterType type() default FilterType.ANNOTATION; ​ Class&lt;?&gt;[] classes() default {}; includeFilters: 指定扫描的时候只包含那些包 在使用的时候需要添加：useDefaultFilters=false属性 其余属性和excludeFilters类似 123456789@Testpublic void test()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config.class); //获取bean的name String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125;&#125; 12345&gt; config&gt; customerConteoller&gt; customerService&gt; per&gt; 关于@Filter的使用： 1234561.type=FilterType.ANNOTATION： 是根据注解的规则2.type=FilterType.ASSIGNABLE_TYPE：按照给定的类型 @Filter(type=FilterType.ASSIGNABLE_TYPE,classes=CustomerService.class3.type=FilterType.ASPECTJ:使用aspectj表达式4.type=FilterType.REGEX：使用正则表达式5.type=FilterTyoe.CUSTOM:自定义规则 使用5进行测试： 123@ComponentScan(value=&quot;coom.MrChengs.config&quot;,includeFilters=&#123; @Filter(type=FilterType.CUSTOM,classes=&#123;MyTypeFilter.class&#125;), &#125;,useDefaultFilters=false) 123456789101112131415161718public class MyTypeFilter implements TypeFilter&#123; //MetadataReader:读取到当前正在扫描的包信息 //MetadataReaderFactory：可以获取到其他类的任何信息 public boolean match(MetadataReader arg0, MetadataReaderFactory arg1) throws IOException &#123; //获取当前类的注解信息 AnnotationMetadata annotationMetadata =arg0.getAnnotationMetadata(); //获取当前正在扫描类的信息 ClassMetadata classMetadata = arg0.getClassMetadata(); //获取当前类的资源（路径，url...) Resource resource = arg0.getResource(); //获取类的全类名 //扫描到的类 String className = classMetadata.getClassName(); System.out.println(&quot;---&gt;&quot; + className); return false; &#125;&#125; 在测试打印的时候 这些都是className中打印出来的 扫描到的类 1234---&gt;coom.MrChengs.config.conteoller.CustomerConteoller---&gt;coom.MrChengs.config.dao.CustomerDao---&gt;coom.MrChengs.config.MyTypeFilter---&gt;coom.MrChengs.config.service.CustomerService 当return true的时候 当然我们可以进行系统的判断进行放行 12345configcustomerConteollercustomerDaomyTypeFiltercustomerService 可以把所有的@ComponentScan都写在里面 123@ComponentScans(value=&#123;@ComponentScan(value=\"coom.MrChengs.config\",excludeFilters=&#123; @Filter(type=FilterType.ANNOTATION,classes=&#123;Repository.class&#125;)&#125;)&#125;) 4.@Scope 调整作用域 Config2.java 12345678@Configurationpublic class Config2 &#123; @Bean(&quot;per&quot;) public Person person()&#123; return new Person(&quot;MrChengs&quot;,20); &#125;&#125; 123456789101112@Testpublic void test2()&#123; ApplicationContext app = new AnnotationConfigApplicationContext(Config2.class); String [] names = app.getBeanDefinitionNames(); for(String name : names)&#123; System.out.println(name); &#125; Person p = (Person) app.getBean(&quot;per&quot;); Person p1 = (Person) app.getBean(&quot;per&quot;); System.out.println(p == p1);&#125; 123config2pertrue 说明默认是单实例的，只实例化一个bean @Scope 1234* @see ConfigurableBeanFactory#SCOPE_PROTOTYPE * @see ConfigurableBeanFactory#SCOPE_SINGLETON* @see org.springframework.web.context.WebApplicationContext#SCOPE_REQUEST* @see org.springframework.web.context.WebApplicationContext#SCOPE_SESSION //prototype 多实例的 在IOC容器创建之后获取对象才开始创建，获取一次创建一次 //singleton 单例的 IOC容器启动的时候就会调用对象放到IOC容器中，多次获取也是只获取同一个 //request 同一次请求 //session 同一个session 123456789101112@Configurationpublic class Config2 &#123; //prototype 多实例的 //singleton 单例的 //request //session @Scope(value=&quot;prototype&quot;) @Bean(&quot;per&quot;) public Person person()&#123; return new Person(&quot;MrChengs&quot;,20); &#125;&#125; 123config2perfalse 多实例情况下，获取一次则创建一个实例 原文链接","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring @Configuration和@Component区别","slug":"difference-between-configuration-and-component","date":"2020-01-28T01:15:43.000Z","updated":"2022-09-17T14:13:56.173Z","comments":true,"path":"spring/difference-between-configuration-and-component/","link":"","permalink":"https://www.cicoding.cn/spring/difference-between-configuration-and-component/","excerpt":"","text":"Spring @Configuration 和 @Component 区别一句话概括就是 @Configuration 中所有带 @Bean 注解的方法都会被动态代理，因此调用该方法返回的都是同一个实例。 下面看看实现的细节。 1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Configuration &#123; String value() default \"\";&#125; 从定义来看， @Configuration 注解本质上还是 @Component，因此 context:component-scan/ 或者 @ComponentScan 都能处理@Configuration 注解的类。 @Configuration 标记的类必须符合下面的要求： 配置类必须以类的形式提供（不能是工厂方法返回的实例），允许通过生成子类在运行时增强（cglib 动态代理）。 配置类不能是 final 类（没法动态代理）。 配置注解通常为了通过 @Bean 注解生成 Spring 容器管理的类， 配置类必须是非本地的（即不能在方法中声明，不能是 private）。 任何嵌套配置类都必须声明为static。 @Bean 方法可能不会反过来创建进一步的配置类（也就是返回的 bean 如果带有 @Configuration，也不会被特殊处理，只会作为普通的 bean）。 加载过程Spring 容器在启动时，会加载默认的一些 PostPRocessor，其中就有 ConfigurationClassPostProcessor，这个后置处理程序专门处理带有 @Configuration 注解的类，这个程序会在 bean 定义加载完成后，在 bean 初始化前进行处理。主要处理的过程就是使用 cglib 动态代理增强类，而且是对其中带有 @Bean 注解的方法进行处理。 在 ConfigurationClassPostProcessor 中的 postProcessBeanFactory 方法中调用了下面的方法： 123456789101112131415161718192021222324252627282930313233343536373839/** * Post-processes a BeanFactory in search of Configuration class BeanDefinitions; * any candidates are then enhanced by a &#123;@link ConfigurationClassEnhancer&#125;. * Candidate status is determined by BeanDefinition attribute metadata. * @see ConfigurationClassEnhancer */public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) &#123; Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = new LinkedHashMap&lt;String, AbstractBeanDefinition&gt;(); for (String beanName : beanFactory.getBeanDefinitionNames()) &#123; BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName); if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) &#123; //省略部分代码 configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef); &#125; &#125; if (configBeanDefs.isEmpty()) &#123; // nothing to enhance -&gt; return immediately return; &#125; ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer(); for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123; AbstractBeanDefinition beanDef = entry.getValue(); // If a @Configuration class gets proxied, always proxy the target class beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE); try &#123; // Set enhanced subclass of the user-specified bean class Class&lt;?&gt; configClass = beanDef.resolveBeanClass(this.beanClassLoader); Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader); if (configClass != enhancedClass) &#123; //省略部分代码 beanDef.setBeanClass(enhancedClass); &#125; &#125; catch (Throwable ex) &#123; throw new IllegalStateException( \"Cannot load configuration class: \" + beanDef.getBeanClassName(), ex); &#125; &#125;&#125; 在方法的第一次循环中，查找到所有带有 @Configuration 注解的 bean 定义，然后在第二个 for 循环中，通过下面的方法对类进行增强： 1Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader); 然后使用增强后的类替换了原有的 beanClass： 1beanDef.setBeanClass(enhancedClass); 所以到此时，所有带有 @Configuration 注解的 bean 都已经变成了增强的类。 下面关注上面的 enhance 增强方法，多跟一步就能看到下面的方法： 1234567891011121314/** * Creates a new CGLIB &#123;@link Enhancer&#125; instance. */private Enhancer newEnhancer(Class&lt;?&gt; superclass, ClassLoader classLoader) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(superclass); enhancer.setInterfaces(new Class&lt;?&gt;[] &#123;EnhancedConfiguration.class&#125;); enhancer.setUseFactory(false); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); enhancer.setStrategy(new BeanFactoryAwareGeneratorStrategy(classLoader)); enhancer.setCallbackFilter(CALLBACK_FILTER); enhancer.setCallbackTypes(CALLBACK_FILTER.getCallbackTypes()); return enhancer;&#125; 通过 cglib 代理的类在调用方法时，会通过 CallbackFilter 调用，这里的 CALLBACK_FILTER 如下： 123456789// The callbacks to use. Note that these callbacks must be stateless.private static final Callback[] CALLBACKS = new Callback[] &#123; new BeanMethodInterceptor(), new BeanFactoryAwareMethodInterceptor(), NoOp.INSTANCE&#125;;private static final ConditionalCallbackFilter CALLBACK_FILTER = new ConditionalCallbackFilter(CALLBACKS); 其中 BeanMethodInterceptor 匹配方法如下： 123456789@Overridepublic boolean isMatch(Method candidateMethod) &#123; return BeanAnnotationHelper.isBeanAnnotated(candidateMethod);&#125;//BeanAnnotationHelperpublic static boolean isBeanAnnotated(Method method) &#123; return AnnotatedElementUtils.hasAnnotation(method, Bean.class);&#125; 也就是当方法有 @Bean 注解的时候，就会执行这个回调方法。 另一个 BeanFactoryAwareMethodInterceptor 匹配的方法如下： 1234567@Overridepublic boolean isMatch(Method candidateMethod) &#123; return (candidateMethod.getName().equals(\"setBeanFactory\") &amp;&amp; candidateMethod.getParameterTypes().length == 1 &amp;&amp; BeanFactory.class == candidateMethod.getParameterTypes()[0] &amp;&amp; BeanFactoryAware.class.isAssignableFrom(candidateMethod.getDeclaringClass()));&#125; 当前类还需要实现 BeanFactoryAware 接口，上面的 isMatch 就是匹配的这个接口的方法。 @Bean 注解方法执行策略先给一个简单的示例代码： 1234567891011121314@Configurationpublic class MyBeanConfig &#123; @Bean public Country country()&#123; return new Country(); &#125; @Bean public UserInfo userInfo()&#123; return new UserInfo(country()); &#125;&#125; 相信大多数人第一次看到上面 userInfo() 中调用 country() 时，会认为这里的 Country 和上面 @Bean 方法返回的 Country 可能不是同一个对象，因此可能会通过下面的方式来替代这种方式： @Autowiredprivate Country country; 实际上不需要这么做（后面会给出需要这样做的场景），直接调用 country() 方法返回的是同一个实例。下面看调用 country() 和 userInfo() 方法时的逻辑。 现在我们已经知道 @Configuration 注解的类是如何被处理的了，现在关注上面的 BeanMethodInterceptor，看看带有 @Bean 注解的方法执行的逻辑。下面分解来看 intercept 方法。 123456789101112131415161718192021222324252627282930313233343536373839//首先通过反射从增强的 Configuration 注解类中获取 beanFactoryConfigurableBeanFactory beanFactory = getBeanFactory(enhancedConfigInstance);//然后通过方法获取 beanName，默认为方法名，可以通过 @Bean 注解指定String beanName = BeanAnnotationHelper.determineBeanNameFor(beanMethod);//确定这个 bean 是否指定了代理的范围//默认下面 if 条件 false 不会执行Scope scope = AnnotatedElementUtils.findMergedAnnotation(beanMethod, Scope.class);if (scope != null &amp;&amp; scope.proxyMode() != ScopedProxyMode.NO) &#123; String scopedBeanName = ScopedProxyCreator.getTargetBeanName(beanName); if (beanFactory.isCurrentlyInCreation(scopedBeanName)) &#123; beanName = scopedBeanName; &#125;&#125;//中间跳过一段 Factorybean 相关代码//判断当前执行的方法是否为正在执行的 @Bean 方法//因为存在在 userInfo() 方法中调用 country() 方法//如果 country() 也有 @Bean 注解，那么这个返回值就是 false.if (isCurrentlyInvokedFactoryMethod(beanMethod)) &#123; // 判断返回值类型，如果是 BeanFactoryPostProcessor 就写警告日志 if (logger.isWarnEnabled() &amp;&amp; BeanFactoryPostProcessor.class.isAssignableFrom(beanMethod.getReturnType())) &#123; logger.warn(String.format( \"@Bean method %s.%s is non-static and returns an object \" + \"assignable to Spring's BeanFactoryPostProcessor interface. This will \" + \"result in a failure to process annotations such as @Autowired, \" + \"@Resource and @PostConstruct within the method's declaring \" + \"@Configuration class. Add the 'static' modifier to this method to avoid \" + \"these container lifecycle issues; see @Bean javadoc for complete details.\", beanMethod.getDeclaringClass().getSimpleName(), beanMethod.getName())); &#125; //直接调用原方法创建 bean return cglibMethodProxy.invokeSuper(enhancedConfigInstance, beanMethodArgs);&#125;//如果不满足上面 if，也就是在 userInfo() 中调用的 country() 方法return obtainBeanInstanceFromFactory(beanMethod, beanMethodArgs, beanFactory, beanName); 关于 isCurrentlyInvokedFactoryMethod 方法 可以参考 SimpleInstantiationStrategy 中的 instantiate 方法，这里先设置的调用方法： currentlyInvokedFactoryMethod.set(factoryMethod); return factoryMethod.invoke(factoryBean, args); 而通过方法内部直接调用 country() 方法时，不走上面的逻辑，直接进的代理方法，也就是当前的 intercept方法，因此当前的工厂方法和执行的方法就不相同了。 obtainBeanInstanceFromFactory 方法比较简单，就是通过 beanFactory.getBean 获取 Country，如果已经创建了就会直接返回，如果没有执行过，就会通过 invokeSuper 首次执行。 因此我们在 @Configuration 注解定义的 bean 方法中可以直接调用方法，不需要 @Autowired 注入后使用。@Component 注意 @Component 注解并没有通过 cglib 来代理@Bean 方法的调用，因此像下面这样配置时，就是两个不同的 country。 1234567891011121314@Componentpublic class MyBeanConfig &#123; @Bean public Country country()&#123; return new Country(); &#125; @Bean public UserInfo userInfo()&#123; return new UserInfo(country()); &#125;&#125; 这种方式可以保证使用的同一个 Country 实例。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"SpringCloud Stream整合RocketMQ实现消息发送与接收","slug":"springcloud-stream-integrates-rocketmq","date":"2020-01-27T13:44:44.000Z","updated":"2022-09-17T14:13:56.161Z","comments":true,"path":"micro-service/springcloud-stream-integrates-rocketmq/","link":"","permalink":"https://www.cicoding.cn/micro-service/springcloud-stream-integrates-rocketmq/","excerpt":"","text":"RocketMQ 介绍RocketMQ 是一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。同时，广泛应用于多个领域，包括异步通信解耦、企业解决方案、金融支付、电信、电子商务、快递物流、广告营销、社交、即时通信、移动应用、手游、视频、物联网、车联网等。 具有以下特点： 能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 亿级消息堆积能力 RocketMQ 基本使用 下载 RocketMQ 下载 RocketMQ最新的二进制文件，并解压 解压后的目录结构如下： 12345678apache-rocketmq├── LICENSE├── NOTICE├── README.md├── benchmark├── bin├── conf└── lib 启动 NameServer 12nohup sh bin/mqnamesrv &amp;tail -f ~/logs/rocketmqlogs/namesrv.log 启动 Broker 12nohup sh bin/mqbroker -n localhost:9876 &amp;tail -f ~/logs/rocketmqlogs/broker.log 发送、接收消息 发送消息： 1sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 发送成功后显示：SendResult [sendStatus=SEND_OK, msgId= … 接收消息： 1sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 接收成功后显示：ConsumeMessageThread_%d Receive New Messages: [MessageExt… 关闭 Server 12sh bin/mqshutdown brokersh bin/mqshutdown namesrv Spring Cloud Stream 介绍Spring Cloud Stream 是一个用于构建基于消息的微服务应用框架。它基于 SpringBoot 来创建具有生产级别的单机 Spring 应用，并且使用 Spring Integration 与 Broker 进行连接。 Spring Cloud Stream 提供了消息中间件配置的统一抽象，推出了 publish-subscribe、consumer groups、partition 这些统一的概念。 Spring Cloud Stream 内部有两个概念：Binder 和 Binding。 Binder: 跟外部消息中间件集成的组件，用来创建 Binding，各消息中间件都有自己的 Binder 实现。 比如 Kafka 的实现 KafkaMessageChannelBinder，RabbitMQ 的实现 RabbitMessageChannelBinder 以及 RocketMQ 的实现 RocketMQMessageChannelBinder。 Binding: 包括 Input Binding 和 Output Binding。 Binding 在消息中间件与应用程序提供的 Provider 和 Consumer 之间提供了一个桥梁，实现了开发者只需使用应用程序的 Provider 或 Consumer 生产或消费数据即可，屏蔽了开发者与底层消息中间件的接触。 Figure 1. Spring Cloud Stream 使用 Spring Cloud Stream 完成一段简单的消息发送和消息接收代码： 123456789101112MessageChannel messageChannel = new DirectChannel();// 消息订阅((SubscribableChannel) messageChannel).subscribe(new MessageHandler() &#123; @Override public void handleMessage(Message&lt;?&gt; message) throws MessagingException &#123; System.out.println(&quot;receive msg: &quot; + message.getPayload()); &#125;&#125;);// 消息发送messageChannel.send(MessageBuilder.withPayload(&quot;simple msg&quot;).build()); 这段代码所有的消息类都是 spring-messaging 模块里提供的。屏蔽具体消息中间件的底层实现，如果想用更换消息中间件，在配置文件里配置相关消息中间件信息以及修改 binder 依赖即可。 Spring Cloud Stream 底层基于这段代码去做了各种抽象。 如何使用 Spring Cloud Alibaba RocketMQ Binder如果要在您的项目中引入 RocketMQ Binder，需要引入如下 maven 依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 或者可以使用 Spring Cloud Stream RocketMQ Starter： 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; Spring Cloud Alibaba RocketMQ Binder 实现RocketMQ Binder 的实现依赖于 RocketMQ-Spring 框架。 RocketMQ-Spring 框架是 RocketMQ 与 Spring Boot 的整合，RocketMQ Spring 主要提供了 3 个特性： 使用 RocketMQTemplate 用来统一发送消息，包括同步、异步发送消息和事务消息 @RocketMQTransactionListener 注解用来处理事务消息的监听和回查 @RocketMQMessageListener 注解用来消费消息 RocketMQ Binder 的核心类 RocketMQMessageChannelBinder 实现了 Spring Cloud Stream 规范，内部构建会 RocketMQInboundChannelAdapter 和 RocketMQMessageHandler。 RocketMQMessageHandler 会基于 Binding 配置构造 RocketMQTemplate，RocketMQTemplate 内部会把 spring-messaging 模块内 org.springframework.messaging.Message 消息类转换成 RocketMQ 的消息类 org.apache.rocketmq.common.message.Message，然后发送出去。 RocketMQInboundChannelAdapter 也会基于 Binding 配置构造 RocketMQListenerBindingContainer，RocketMQListenerBindingContainer 内部会启动 RocketMQ Consumer 接收消息。 Note 在使用 RocketMQ Binder 的同时也可以配置 rocketmq.** 用于触发 RocketMQ Spring 相关的 AutoConfiguration 目前 Binder 支持在 Header 中设置相关的 key 来进行 RocketMQ Message 消息的特性设置。 比如 TAGS、DELAY、TRANSACTIONAL_ARG、KEYS、WAIT_STORE_MSG_OK、FLAG 表示 RocketMQ 消息对应的标签， 123456MessageBuilder builder = MessageBuilder.withPayload(msg) .setHeader(RocketMQHeaders.TAGS, &quot;binder&quot;) .setHeader(RocketMQHeaders.KEYS, &quot;my-key&quot;) .setHeader(&quot;DELAY&quot;, &quot;1&quot;);Message message = builder.build();output().send(message); MessageSource 支持目前 RocketMQ 已经支持 MessageSource，可以进行消息的拉取，例子如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445@SpringBootApplication@EnableBinding(MQApplication.PolledProcessor.class)public class MQApplication &#123; private final Logger logger = LoggerFactory.getLogger(MQApplication.class); public static void main(String[] args) &#123; SpringApplication.run(MQApplication.class, args); &#125; @Bean public ApplicationRunner runner(PollableMessageSource source, MessageChannel dest) &#123; return args -&gt; &#123; while (true) &#123; boolean result = source.poll(m -&gt; &#123; String payload = (String) m.getPayload(); logger.info(&quot;Received: &quot; + payload); dest.send(MessageBuilder.withPayload(payload.toUpperCase()) .copyHeaders(m.getHeaders()) .build()); &#125;, new ParameterizedTypeReference&lt;String&gt;() &#123; &#125;); if (result) &#123; logger.info(&quot;Processed a message&quot;); &#125; else &#123; logger.info(&quot;Nothing to do&quot;); &#125; Thread.sleep(5_000); &#125; &#125;; &#125; public static interface PolledProcessor &#123; @Input PollableMessageSource source(); @Output MessageChannel dest(); &#125;&#125; 配置选项RocketMQ Binder Properties spring.cloud.stream.rocketmq.binder.name-server RocketMQ NameServer 地址(老版本使用 namesrv-addr 配置项)。Default: 127.0.0.1:9876. spring.cloud.stream.rocketmq.binder.access-key 阿里云账号 AccessKey。Default: null. spring.cloud.stream.rocketmq.binder.secret-key 阿里云账号 SecretKey。Default: null. spring.cloud.stream.rocketmq.binder.enable-msg-trace 是否为 Producer 和 Consumer 开启消息轨迹功能Default: true. spring.cloud.stream.rocketmq.binder.customized-trace-topic 消息轨迹开启后存储的 topic 名称。Default: RMQ_SYS_TRACE_TOPIC. RocketMQ Consumer Properties下面的这些配置是以 spring.cloud.stream.rocketmq.bindings..consumer. 为前缀的 RocketMQ Consumer 相关的配置。 enable 是否启用 Consumer。默认值: true. tags Consumer 基于 TAGS 订阅，多个 tag 以 || 分割。默认值: empty. sql Consumer 基于 SQL 订阅。默认值: empty. broadcasting Consumer 是否是广播消费模式。如果想让所有的订阅者都能接收到消息，可以使用广播模式。默认值: false. orderly Consumer 是否同步消费消息模式。默认值: false. delayLevelWhenNextConsume 异步消费消息模式下消费失败重试策略：-1,不重复，直接放入死信队列0,broker 控制重试策略&gt;0,client 控制重试策略默认值: 0. suspendCurrentQueueTimeMillis 同步消费消息模式下消费失败后再次消费的时间间隔。默认值: 1000. RocketMQ Provider Properties下面的这些配置是以 spring.cloud.stream.rocketmq.bindings..producer. 为前缀的 RocketMQ Producer 相关的配置。 enable 是否启用 Producer。默认值: true. group Producer group name。默认值: empty. maxMessageSize 消息发送的最大字节数。默认值: 8249344. transactional 是否发送事务消息。默认值: false. sync 是否使用同步得方式发送消息。默认值: false. vipChannelEnabled 是否在 Vip Channel 上发送消息。默认值: true. sendMessageTimeout 发送消息的超时时间(毫秒)。默认值: 3000. compressMessageBodyThreshold 消息体压缩阀值(当消息体超过 4k 的时候会被压缩)。默认值: 4096. retryTimesWhenSendFailed 在同步发送消息的模式下，消息发送失败的重试次数。默认值: 2. retryTimesWhenSendAsyncFailed 在异步发送消息的模式下，消息发送失败的重试次数。默认值: 2. retryNextServer 消息发送失败的情况下是否重试其它的 broker。默认值: false. 官方文档https://cloud.spring.io/spring-cloud-static/spring-cloud-stream/2.2.0.RELEASE/spring-cloud-stream.html Spring Cloud Stream编写生产者加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 加注解 1@EnableBinding(Source.class) 加配置 12345678910spring: cloud: stream: rocketmq: binder: name-server: 127.0.0.1:9876 bindings: output: # 指定topic destination: stream-test-topic 创建消息 12345678@GetMapping(\"test-stream\")public String testStream()&#123; this.source.output().send( MessageBuilder.withPayload(\"消息！！\").build() ); return \"success\";&#125; Spring Cloud Stream编写消费者加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 加注解 1@EnableBinding(&#123;Sink.class&#125;) 加配置 1234567891011spring: cloud: stream: rocketmq: binder: name-server: 127.0.0.1:9876 bindings: input: destination: stream-test-topic # rocketmq一定要设置group（随便写） 其他的mq可留空 group: binding-group 消费消息 1234567891011121314151617181920212223package cn.cicoding.usercenter.rocketmq;import lombok.extern.slf4j.Slf4j;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.stereotype.Service;/** * @author zhaokejin * @description * @date 2019/11/15 */@Service@Slf4jpublic class TestStreamConsumer &#123; @StreamListener(Sink.INPUT) public void receive(String messageBody)&#123; log.info(&quot;通过stream收到消息，messageBody = &#123;&#125;&quot;, messageBody); &#125;&#125; 启动测试！可以看到控制台收到的消息 12342019-12-28 11:54:08.988 INFO 14568 --- [MessageThread_1] c.c.m.consumer.TestStreamConsumer : 通过stream收到消息，messageBody = RocketMQ消息！！2019-12-28 11:54:11.814 INFO 14568 --- [MessageThread_1] c.c.m.consumer.TestStreamConsumer : 通过stream收到消息，messageBody = RocketMQ消息！！2019-12-28 11:54:12.435 INFO 14568 --- [MessageThread_1] c.c.m.consumer.TestStreamConsumer : 通过stream收到消息，messageBody = RocketMQ消息！！2019-12-28 11:54:12.612 INFO 14568 --- [MessageThread_1] c.c.m.consumer.TestStreamConsumer : 通过stream收到消息，messageBody = RocketMQ消息！！","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"},{"name":"SpringCloud Stream","slug":"SpringCloud-Stream","permalink":"https://www.cicoding.cn/tags/SpringCloud-Stream/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"Spring Cloud Sleuth与Zipkin配合使用","slug":"microservice11","date":"2020-01-27T13:04:05.000Z","updated":"2022-09-17T14:13:56.160Z","comments":false,"path":"micro-service/microservice11/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice11/","excerpt":"","text":"Spring Cloud Sleuth入门经过前文讲述，我们的微服务架构日趋完善，已可使用Spring Cloud构建一个非常健壮的系统！ 但假设，你的项目一旦出现问题，如何才能快速定位出来呢？一般项目上要求我们快速定位两种问题： 调用发生失败，快速定位出是哪个环节出了问题。是微服务问题，还是网络？ 调用慢，如何快速找到性能瓶颈？ 这正是调用链监控要做的事情。Spring Cloud提供Sleuth来实现调用链监控。 简介Spring Cloud Sleuth为Spring Cloud提供了分布式跟踪的解决方案，它大量借用了Google Dapper、Twitter Zipkin和Apache HTrace的设计。 TIPS Spring Cloud Sleuth的GitHub：https://github.com/spring-cloud/spring-cloud-sleuth Dapper论文：https://research.google.com/pubs/pub36356.html 基本概念(1) Span（跨度）: 基本工作单元。span用一个64位的id唯一标识。除ID外，span还包含其他数据，例如描述、时间戳事件、键值对的注解（标签），span ID、span父ID等。 span被启动和停止时，记录了时间信息。初始化span被称为“root span”，该span的id和trace的id相等。 (2) Trace（跟踪）: 一组共享“root span”的span组成的树状结构称为trace。trace也用一个64位的ID唯一标识，trace中的所有span都共享该trace的ID。 (3) Annotation（标注）: annotation用来记录事件的存在，其中，核心annotation用来定义请求的开始和结束。 1234(1) cs（Client Sent 客户端发送）：客户端发起一个请求，该annotation描述了span的开始。(2) sr（Server Received 服务器端接收）：服务器端获得请求并准备处理它。如果用sr减去cs时间戳，就能得到网络延迟。(3) ss（Server Sent 服务器端发送）：该annotation表明完成请求处理（当响应发回客户端时）。如果用ss减去sr时间戳，就能得到服务器端处理请求所需的时间。(4) cr（Client Received 客户端接收）：span结束的标识。客户端成功接收到服务器端的响应。如果cr减去cs时间戳，就能得到从客户端发送请求到服务器响应的所需的时间。 快速入门 加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; 写配置： 1234logging: level: root: INFO org.springframework.cloud.sleuth: DEBUG 其中，配不是必选的，这里加上日志，只是为了看到更多Sleuth相关的日志。 是不是非常简单！ 测试 启动 microservice-provider-user-sleuth 访问 http://localhost:8000/users/1 ，可看到类似如下的日志： 12345672019-03-13 23:32:46.913 INFO [microservice-provider-user,,,] 14759 --- [nio-8000-exec-1] o.apache.tomcat.util.http.parser.Cookie : A cookie header was received [1551574921,1551708812,1552142696] that contained an invalid cookie. That cookie will be ignored.Note: further occurrences of this error will be logged at DEBUG level.Hibernate: select user0_.id as id1_0_0_, user0_.age as age2_0_0_, user0_.balance as balance3_0_0_, user0_.name as name4_0_0_, user0_.username as username5_0_0_ from user user0_ where user0_.id=?2019-03-13 23:32:46.975 TRACE [microservice-provider-user,e22f74e62c06104b,e22f74e62c06104b,false] 14759 --- [nio-8000-exec-1] o.h.type.descriptor.sql.BasicBinder : binding parameter [1] as [BIGINT] - [1]2019-03-13 23:32:46.981 TRACE [microservice-provider-user,e22f74e62c06104b,e22f74e62c06104b,false] 14759 --- [nio-8000-exec-1] o.h.type.descriptor.sql.BasicExtractor : extracted value ([age2_0_0_] : [INTEGER]) - [20]2019-03-13 23:32:46.982 TRACE [microservice-provider-user,e22f74e62c06104b,e22f74e62c06104b,false] 14759 --- [nio-8000-exec-1] o.h.type.descriptor.sql.BasicExtractor : extracted value ([balance3_0_0_] : [NUMERIC]) - [100.00]2019-03-13 23:32:46.982 TRACE [microservice-provider-user,e22f74e62c06104b,e22f74e62c06104b,false] 14759 --- [nio-8000-exec-1] o.h.type.descriptor.sql.BasicExtractor : extracted value ([name4_0_0_] : [VARCHAR]) - [张三]2019-03-13 23:32:46.982 TRACE [microservice-provider-user,e22f74e62c06104b,e22f74e62c06104b,false] 14759 --- [nio-8000-exec-1] o.h.type.descriptor.sql.BasicExtractor : extracted value ([username5_0_0_] : [VARCHAR]) - [account1] 从日志可以发现，此时日志多出来类似 [microservice-provider-user,e22f74e62c06104b,e22f74e62c06104b,false] 的内容。 一个良好的监控，应该有一个人类亲和的界面，这个界面就是Zipkin。 Zipin简介Zipkin是Twitter开源的分布式跟踪系统，基于Dapper的论文设计而来。它的主要功能是收集系统的时序数据，从而追踪微服务架构的系统延时等问题。Zipkin还提供了一个非常友好的界面，帮助我们分析追踪数据。 TIPS Zipkin官方网站：http://zipkin.io/ Zipkin Server搭建 使用https://search.maven.org/remote_content?g=io.zipkin.java&amp;a=zipkin-server&amp;v=LATEST&amp;c=exec 下载最新版本的Zipkin Server，例如zipkin-server-2.11.3-exec.jar 启动Zipkin Server 1java -jar zipkin-server-2.11.7-exec.jar 访问http://localhost:9411 即可看到Zipkin Server的首页。 Zipkin UIZipkin UI首页： 简单讲解图中各个查询条件的含义： ① Service Name表示服务名称，也就是各个微服务spring.application.name的值。 ② 第二列表示span的名称，“all”表示所有span，也可选择指定span。 ③ Lookback用于执行想要查看的之间段。 ④ Duration表示持续时间，即span从创建到关闭所经历的时间。 ⑤ Limit表示查询几条数据。类似于MySQL数据库中的limit关键词。 ⑥ Annotations Query，用于自定义查询条件。 微服务整合Zipkin在 Spring Cloud Sleuth入门 的基础上： 加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 加配置 1234567spring: zipkin: base-url: http://localhost:9411 sleuth: sampler: # 采样率，模式0.1，也就是10%，为了便于观察效果，改为1.0，也就是100%。生产环境建议保持默认。 probability: 1.0 测试 启动微服务，访问http://localhost:8000/users/1 观察http://localhost:9411 ，可看到类似如下界面： 点击上图中标注的3，可看到类似如下的界面： 如图，已经展示了该次请求的耗时。如果你有多个应用，Zipkin将会展示每个应用消耗了多少时间，蓝色表示请求正常，红色表示请求失败。 配套代码microservice-provider-sleuth-zipkin","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud Sleuth","slug":"Spring-Cloud-Sleuth","permalink":"https://www.cicoding.cn/tags/Spring-Cloud-Sleuth/"},{"name":"Zipkin","slug":"Zipkin","permalink":"https://www.cicoding.cn/tags/Zipkin/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"SpringCloud组件之Zuul","slug":"microservice10","date":"2020-01-27T13:03:05.000Z","updated":"2022-09-17T14:13:56.159Z","comments":false,"path":"micro-service/microservice10/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice10/","excerpt":"","text":"Zuul是Netflix开源的微服务网关，可以和Eureka、Ribbon、Hystrix等组件配合使用，Spring Cloud对Zuul进行了整合与增强，Zuul默认使用的HTTP客户端是Apache HTTPClient，也可以使用RestClient或okhttp3.OkHttpClient。 Zuul的主要功能是路由转发和过滤器。路由功能是微服务的一部分，比如／demo/test转发到到demo服务。zuul默认和Ribbon结合实现了负载均衡的功能 为什么要使用网关不同的微服务一般会有不同的网络地址，而外部客户端（例如手机APP）可能需要调用多个服务的接口才能完成一个业务需求。例如一个电影购票的手机APP，可能会调用多个微服务的接口，才能完成一次购票的业务流程，如下图所示。 如果让客户端直接与各个微服务通信，会有以下的问题： 客户端会多次请求不同的微服务，增加了客户端的复杂性。 存在跨域请求，在一定场景下处理相对复杂。 认证复杂，每个服务都需要独立认证。 难以重构，随着项目的迭代，可能需要重新划分微服务。例如，可能将多个服务合并成一个或者将一个服务拆分成多个。如果客户端直接与微服务通信，那么重构将会很难实施。 某些微服务可能使用了防火墙/浏览器不友好的协议，直接访问会有一定的困难。 以上问题可借助微服务网关解决。微服务网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过微服务网关。使用微服务网关后，架构如下所示。 此时，微服务网关封装了应用程序的内部结构，客户端只须跟网关交互，而无须直接调用特定微服务的接口。这样，开发就可以得到简化。不仅如此，使用微服务网关还有以下优点： 易于监控。可在微服务网关收集监控数据并将其推送到外部系统进行分析。 易于认证。可在微服务网关上进行认证，然后再将请求转发到后端的微服务，而无须在每个微服务中进行认证。 减少了客户端与各个微服务之间的交互次数。 Zuul简介Zuul是Netflix开源的微服务网关，它可以和Eureka、Ribbon、Hystrix等组件配合使用。Zuul的核心是一系列的过滤器，这些过滤器帮助我们完成以下功能： 身份认证与安全：识别每个资源的验证要求，并拒绝那些与要求不符的请求； 审查与监控：在边缘位置追踪有意义的数据和统计结果，从而为我们带来精确的生产视图； 动态路由：动态地将请求路由到不同的后端集群； 压力测试：逐渐增加指向集群的流量，以了解性能； 负载分配：为每一种负载类型分配对应容量，并弃用超出限定值的请求； 静态响应处理：在边缘位置直接建立部分响应，从而避免其转发到内部集群； 多区域弹性：跨越AWS Region进行请求路由，旨在实现ELB（Elastic Load Balancing）使用的多样化；以及让系统的边缘更贴近系统的使用者。 注1：以上介绍来自Zuul官方文档，但其实开源版本的Zuul以上功能一个都没有——开源的Zuul只是几个Jar包而已，以上能力指的应该是Netflix官方自用的Zuul的能力。 注2：Netflix自用的Zuul能力是比较强大的，可使用Groovy编写过滤器，并且可动态加载/卸载、修改规则，而且使用Cassandra作为数据库，然而开源版本这些一个都没有。 注3：Spring Cloud中，Zuul绝大部分功能都是Spring Cloud团队为Zuul开发的。 注4：所以Zuul 2.x的开源进度延后一年，Spring Cloud团队开发了自己的Spring Cloud Gateway，并宣布Spring Cloud不打算支持Zuul 2.x，你还觉得意外吗？ 注5：看到这里，很多人可能没有动力学习Zuul了，个人认为还是可以了解一下的，后面讲到Spring Cloud Gateway时，你会发现很多设计理念是相通的。 Spring Cloud对Zuul进行了整合与增强。目前，Zuul使用的默认HTTP客户端是Apache HTTP Client，也可以使用RestClient或者okhttp3.OkHttpClient 。 如果想要使用RestClient，可以设置ribbon.restclient.enabled=true ；想要使用okhttp3.OkHttpClient ，可以设置ribbon.okhttp.enabled=true 。 TIPS Zuul的GitHub：https://github.com/Netflix/zuul 入门下面通过一个简单的例子帮助大家快速入门Zuul。 编码 加依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 加注解：@EnableZuulProxy 写配置： 123456789server: port: 8040spring: application: name: microservice-gateway-zuuleureka: client: service-url: defaultZone: http://localhost:8761/eureka/ 由代码可知，我们编写了一个Zuul，并将其注册到了Eureka上。 测试准备工作启动多个应用，Eureka Server上展示如下： 反向代理测试 访问http://127.0.0.1:8040/microservice-provider-user/users/1 ，会发现请求被转发到了microservice-provider-user 服务的/users/1 端点； 访问http://127.0.0.1:8040/microservice-consumer-movie/movies/users/1 ，发现请求被转发到了microservice-consumer-movie 服务的/movies/users/1 端点； 负载均衡测试多次访问访问http://127.0.0.1:8040/microservice-provider-user/users/1 ，会发现两个microservice-provider-user 都会打印类似如下的日志： 12Hibernate: select user0_.id as id1_0_0_, user0_.age as age2_0_0_, user0_.balance as balance3_0_0_, user0_.name as name4_0_0_, user0_.username as username5_0_0_ from user user0_ where user0_.id=?... 断路器测试在application.yml 中添加如下配置后，并重启Zuul： 12345678management: endpoints: web: exposure: include: &apos;*&apos; endpoint: health: show-details: always 此时，此时访问http://localhost:8040/actuator/health ，可看到类似如下结果： 1234&#123; ... &quot;hystrix&quot;:&#123;&quot;status&quot;:&quot;UP&quot;&#125;&#125; 并且，当Zuul转发API后，访问http://localhost:8040/actuator/hystrix.stream 可看到类似如下的信息： 1data: &#123;&quot;type&quot;:&quot;HystrixCommand&quot;,&quot;name&quot;:&quot;microservice-provider-user&quot;,.....&#125; 说明Zuul整合了Hystrix。 配套代码microservice-gateway-zuul","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Zuul","slug":"Zuul","permalink":"https://www.cicoding.cn/tags/Zuul/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"熔断器 - Turbine","slug":"microservice09","date":"2020-01-17T02:45:05.000Z","updated":"2022-09-17T14:13:56.159Z","comments":false,"path":"micro-service/microservice09/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice09/","excerpt":"","text":"Turbine在复杂的分布式系统中，相同服务的节点经常需要部署上百甚至上千个，很多时候，运维人员希望能够把相同服务的节点状态以一个整体集群的形式展现出来，这样可以更好的把握整个系统的状态。 为此，Netflix提供了一个开源项目（Turbine）来提供把多个hystrix.stream的内容聚合为一个数据源供Dashboard展示。 和Hystrix Dashboard一样，Turbine也可以下载war包部署到Web容器，本文不做赘述。下面讨论Spring Cloud是怎么使用Turbine的。 代码示例新建Maven项目，并在pom.xml中添加如下内容： 1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;microservice-hystrix-turbine&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;cn.cicoding.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-microservice-study&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-turbine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类：TurbineApplication.java 1234567891011/** * 通过@EnableTurbine接口，激活对Turbine的支持。 * @author eacdy */@SpringBootApplication@EnableTurbinepublic class TurbineApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(TurbineApplication.class).web(true).run(args); &#125;&#125; 配置文件：application.yml 12345678910111213141516171819spring: application.name: microservice-hystrix-turbineserver: port: 8031security.basic.enabled: falseturbine: aggregator: clusterConfig: default # 指定聚合哪些集群，多个使用&quot;,&quot;分割，默认为default。可使用http://.../turbine.stream?cluster=&#123;clusterConfig之一&#125;访问 appConfig: microservice-consumer-movie-feign-with-hystrix-stream,microservice-consumer-movie-ribbon-with-hystrix ### 配置Eureka中的serviceId列表，表明监控哪些服务 clusterNameExpression: new String(&quot;default&quot;) # 1. clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称 # 2. 当clusterNameExpression: default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default # 3. 当clusterNameExpression: metadata[&apos;cluster&apos;]时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC，则需要配置，同时turbine.aggregator.clusterConfig: ABCeureka: client: serviceUrl: defaultZone: http://discovery:8761/eureka/### 参考：http://blog.csdn.net/liaokailin/article/details/51344281### 参考：http://blog.csdn.net/zhuchuangang/article/details/51289593 这样一个Turbine微服务就编写完成了。 Turbine测试 启动项目：microservice-discovery-eureka 启动项目：microservice-provider 启动项目：microservice-consumer-ribbon-with-hystrix 启动项目：microservice-consumer-movie-feign-hystrix-stream 启动项目：microservice-hystrix-dashboard 启动项目：microservice-hystrix-turbine（即本例） 访问：http://localhost:8020/fegin/user/1 ，调用feign接口 访问：http://localhost:8010/ribbon/user/1 /1，调用ribbon接口 访问：http://localhost:8031/turbine.stream ，可查看到和Hystrix监控类似的内容： 1data: &#123;&quot;rollingCountFallbackSuccess&quot;:0,&quot;rollingCountFallbackFailure&quot;:0,&quot;propertyValue_circuitBreakerRequestVolumeThreshold&quot;:20,&quot;p 并且会不断刷新以获取实时的监控数据。同样的，我们可以将这些文本内容放入到Dashboard中展示。 访问Hystrix Dashboard：http://localhost:8030/hystrix.stream ，并将http://localhost:8031/turbine.stream 输入到其上的输入框，并随意指定一个Title，如下图： 将会查看到如下的图表，有图可见，我们把两个项目的API都监控了： TIPS 项目microservice-consumer-movie-ribbon-with-hystrix 和 microservice-consumer-movie-feign-with-hystrix-stream 需要配置不同的主机名，并将preferIpAddress设为false或者不设置，否则将会造成在单个主机上测试，Turbine只显示一个图表的情况。项目的代码已经修改好并注释了，这边友情提示一下。 配置项：turbine.clusterNameExpression 与 turbine.aggregator.clusterConfig的关系： turbine.clusterNameExpression取值 turbine.aggregator.clusterConfig 取值 默认（appName） 配置想要聚合的项目，此时使用turbine.stream?cluster=项目名称大写访问监控数据 new String(“default”) 或者”‘default’” 不配置，或者配置default，因为默认就是default metadata[‘cluster’]；同时待监控的项目配置了类似：eureka.instance.metadata-map.cluster: ABC 也设成ABC，需要和待监控的项目配置的eureka.instance.metadata-map.cluster一致。 具体可以关注org.springframework.cloud.netflix.turbine.CommonsInstanceDiscovery和org.springframework.cloud.netflix.turbine.EurekaInstanceDiscovery两个类。特别关注一下org.springframework.cloud.netflix.turbine.EurekaInstanceDiscovery.marshall(InstanceInfo)方法。 参考文档 http://blog.csdn.net/liaokailin/article/details/51344281 http://stackoverflow.com/questions/31468227/whats-for-the-spring-cloud-turbine-clusternameexpression-config-mean","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Turbine","slug":"Turbine","permalink":"https://www.cicoding.cn/tags/Turbine/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"熔断器-Hystrix Dashboard","slug":"microservice08","date":"2020-01-17T01:49:05.000Z","updated":"2022-09-17T14:13:56.158Z","comments":false,"path":"micro-service/microservice08/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice08/","excerpt":"","text":"Hystrix监控Ribbon除了隔离依赖服务的调用以外，Hystrix还提供了近实时的监控，Hystrix会实时、累加地记录所有关于HystrixCommand的执行信息，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。 上文提到的microservice-consumer-ribbon-with-hystrix项目已经具备对Hystrix监控的能力，下面我们进入测试。 Hystrix提供了监控Hystrix Command的能力，本节来详细探讨。 监控端点与数据应用整合Hystrix，同时应用包含spring-boot-starter-actuator 依赖，就会存在一个/actuator/hystrix.stream 端点，用来监控Hystrix Command。当被@HystrixCommand 注解了的方法被调用时，就会产生监控信息，并暴露到该端点中。当然，该端点默认是不会暴露的，需使用如下配置将其暴露。 123456management: endpoints: web: exposure: include: &apos;hystrix.stream&apos; include: &apos;*&apos; 此时，访问/actuator/hystrix.stream 可返回如下结果： 1&#123;&quot;type&quot;:&quot;HystrixCommand&quot;,&quot;name&quot;:&quot;findById&quot;,&quot;group&quot;:&quot;MovieController&quot;,&quot;currentTime&quot;:1547905939151,&quot;isCircuitBreakerOpen&quot;:false,&quot;errorPercentage&quot;:0,&quot;errorCount&quot;:0,&quot;requestCount&quot;:0,&quot;rollingCountBadRequests&quot;:0,&quot;rollingCountCollapsedRequests&quot;:0,&quot;rollingCountEmit&quot;:0,&quot;rollingCountExceptionsThrown&quot;:0,&quot;rollingCountFailure&quot;:0,&quot;rollingCountFallbackEmit&quot;:0,&quot;rollingCountFallbackFailure&quot;:0,&quot;rollingCountFallbackMissing&quot;:0,&quot;rollingCountFallbackRejection&quot;:0,&quot;rollingCountFallbackSuccess&quot;:0,&quot;rollingCountResponsesFromCache&quot;:0,&quot;rollingCountSemaphoreRejected&quot;:0,&quot;rollingCountShortCircuited&quot;:0,&quot;rollingCountSuccess&quot;:0,&quot;rollingCountThreadPoolRejected&quot;:0,&quot;rollingCountTimeout&quot;:0,&quot;currentConcurrentExecutionCount&quot;:0,&quot;rollingMaxConcurrentExecutionCount&quot;:0,&quot;latencyExecute_mean&quot;:0,&quot;latencyExecute&quot;:&#123;&quot;0&quot;:0,&quot;25&quot;:0,&quot;50&quot;:0,&quot;75&quot;:0,&quot;90&quot;:0,&quot;95&quot;:0,&quot;99&quot;:0,&quot;99.5&quot;:0,&quot;100&quot;:0&#125;,&quot;latencyTotal_mean&quot;:0,&quot;latencyTotal&quot;:&#123;&quot;0&quot;:0,&quot;25&quot;:0,&quot;50&quot;:0,&quot;75&quot;:0,&quot;90&quot;:0,&quot;95&quot;:0,&quot;99&quot;:0,&quot;99.5&quot;:0,&quot;100&quot;:0&#125;,&quot;propertyValue_circuitBreakerRequestVolumeThreshold&quot;:20,&quot;propertyValue_circuitBreakerSleepWindowInMilliseconds&quot;:5000,&quot;propertyValue_circuitBreakerErrorThresholdPercentage&quot;:50,&quot;propertyValue_circuitBreakerForceOpen&quot;:false,&quot;propertyValue_circuitBreakerForceClosed&quot;:false,&quot;propertyValue_circuitBreakerEnabled&quot;:true,&quot;propertyValue_executionIsolationStrategy&quot;:&quot;THREAD&quot;,&quot;propertyValue_executionIsolationThreadTimeoutInMilliseconds&quot;:1000,&quot;propertyValue_executionTimeoutInMilliseconds&quot;:1000,&quot;propertyValue_executionIsolationThreadInterruptOnTimeout&quot;:true,&quot;propertyValue_executionIsolationThreadPoolKeyOverride&quot;:null,&quot;propertyValue_executionIsolationSemaphoreMaxConcurrentRequests&quot;:10,&quot;propertyValue_fallbackIsolationSemaphoreMaxConcurrentRequests&quot;:10,&quot;propertyValue_metricsRollingStatisticalWindowInMilliseconds&quot;:10000,&quot;propertyValue_requestCacheEnabled&quot;:true,&quot;propertyValue_requestLogEnabled&quot;:true,&quot;reportingHosts&quot;:1,&quot;threadPool&quot;:&quot;MovieController&quot;&#125; 测试步骤 启动：microservice-discovery-eureka 启动：microservice-provider 启动：microservice-consumer-ribbon-with-hystrix 访问：http://localhost:8010/ribbon/user/1 ，注意：该步骤不能省略，因为如果应用的所有接口都未被调用，将只会看到一个ping 访问：http://localhost:8010/actuator/hystrix.stream，可以看到类似如下输出： 1data: &#123;&quot;type&quot;:&quot;HystrixCommand&quot;,&quot;name&quot;:&quot;findById&quot;,&quot;group&quot;:&quot;RibbonHystrixService&quot;,&quot;currentTime&quot;:1472658867784,&quot;isCircuitBreakerOpen&quot;:false,&quot;errorPercentage&quot;:0,&quot;errorCount&quot;:0,&quot;requestCount&quot;:0,&quot;rollingCountBadRequests&quot;:0....&#125; 并且会不断刷新以获取实时的监控数据。但是纯文字的输出可读性实在是太差，运维人员很难一眼看出系统当前的运行状态。那么是不是有可视化的工具呢？ 监控对于Feign前面讲过Feign默认已经整合了Hystrix，但这个整合其实是“不完整”，因为它默认不带有监控端点，如果你在使用Feign的同时，也想使用监控端点，需按照如下步骤操作： 加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 在启动类上添加注解@EnableCircuitBreaker 在application.yml 中添加如下配置： 12345management: endpoints: web: exposure: include: &apos;hystrix.stream&apos; 测试：http://127.0.0.1:8020/actuator/hystrix.stream 代码示例：microservice-consumer-movie-feign-hystrix-stream Hystrix DashboardHystrix Dashboard可以可视化查看实时监控数据。我们可以下载hystrix-dashboard的war包部署到诸如Tomcat之类的容器中，本文不做赘述。另外Spring Cloud也提供了Hystrix Dashboard的整合，下面我们看看Spring Cloud是怎么玩转Hystrix Dashboard的。 新建一个maven项目，在pom.xml中添加如下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;microservice-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;microservice-hystrix-dashboard&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 编写启动类：HystrixDashboardApplication.java 1234567891011121314/** * 测试步骤: * 1. 访问http://localhost:8030/hystrix.stream 可以查看Dashboard * 2. 在上面的输入框填入: http://想监控的服务:端口/hystrix.stream进行测试 * 注意：首先要先调用一下想监控的服务的API，否则将会显示一个空的图表. * @author example */@SpringBootApplication@EnableHystrixDashboardpublic class HystrixDashboardApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(HystrixDashboardApplication.class).web(true).run(args); &#125;&#125; 配置文件：application.yml 12345spring: application: name: hystrix-dashboardserver: port: 8030 启动后，访问http://localhost:8030/hystrix.stream 将会看到如下界面： 启动microservice-consumer-movie-feign-hystrix-stream 启动microservice-hystrix-dashboard 此时，我们在输入框中输入http://localhost:8020/actuator/hystrix.stream ，并随意设置一个Title后，点击Monitor Stream按钮，会出现如下界面： 此时我们会看到findById这个API的各种指标。Hystrix Dashboard Wiki上详细说明了图上每个指标的含义，如下图： 此时，我们可以尝试将microservice-provider停止，然后重复访问多次http://localhost:8020/fegin/user/1 （20次以上），会发现断路器状态会变为开启。 大功告成！鼓掌！","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Hystrix Dashboard","slug":"Hystrix-Dashboard","permalink":"https://www.cicoding.cn/tags/Hystrix-Dashboard/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"熔断器-Feign使用Hystrix","slug":"microservice07","date":"2020-01-17T01:48:05.000Z","updated":"2022-09-17T14:13:56.158Z","comments":false,"path":"micro-service/microservice07/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice07/","excerpt":"","text":"Feign默认已经整合了Hystrix，本节详细探讨Feign使用Hystrix的具体细节。 服务降级 加配置，默认Feign是不启用Hystrix的，需要添加如下配置启用Hystrix，这样所有的Feign Client都会受到Hystrix保护！ 123feign: hystrix: enabled: true 提供Fallback： 123456789101112@FeignClient(name = &quot;microservice-provider-user&quot;, fallback = UserFeignClientFallback.class)public interface UserFeignClient &#123; @GetMapping(&quot;/users/&#123;id&#125;&quot;) User findById(@PathVariable(&quot;id&quot;) Long id);&#125;@Componentclass UserFeignClientFallback implements UserFeignClient &#123; @Override public User findById(Long id) &#123; return new User(id, &quot;默认用户&quot;, &quot;aaaaaa&quot;, &quot;13899988898&quot;); &#125;&#125; 测试 启动microservice-discovery-eureka 启动microservice-provider 启动microservice-consumer-feign-with-hystrix 访问http://localhost:8010/feign/user/1 ，能正常返回结果 关闭microservice-provider ，再次访问http://localhost:8010/feign/user/1 ，可返回类似如下结果，说明当服务提供者时，服务消费者进入了回退方法。 123456&#123; &quot;userId&quot;: 1, &quot;userName&quot;: &quot;默认用户&quot;, &quot;password&quot;: &quot;aaaaaa&quot;, &quot;phone&quot;: &quot;13908888888&quot;&#125; 访问http://localhost:8010/actuator/health ，可获得类似如下结果： 1234567891011&#123; &quot;status&quot;: &quot;UP&quot;, &quot;details&quot;: &#123; &quot;diskSpace&quot;: ..., &quot;refreshScope&quot;: ..., &quot;discoveryComposite&quot;: ..., &quot;hystrix&quot;: &#123; &quot;status&quot;: &quot;UP&quot; &#125; &#125;&#125; 由结果不难发现，此时断路器并未打开！这是为什么呢？ 原因是：此时只请求了一次，没有达到Hystrix的阈值——Hystrix设计来保护高并发应用的，它要求10秒（可用hystrix.command.default.metrics.rollingStats.timeInMilliseconds 自定义）以内API错误次数超过20次（用circuitBreaker.requestVolumeThreshold 自定义），此时才可能触发断路器。 持续不断地访问http://localhost:8010/feign/user/1 多次（至少20次） 再次访问http://localhost:8010/actuator/health ，可获得类似如下结果： 12345678910&#123; &quot;hystrix&quot;: &#123; &quot;status&quot;: &quot;CIRCUIT_OPEN&quot;, &quot;details&quot;: &#123; &quot;openCircuitBreakers&quot;: [ &quot;microservice-provider::UserFeignClient#findById(Integer)&quot; ] &#125; &#125;&#125; 由结果可知，此时断路器已经打开，并且列出了是哪个API的断路器被打开了。 获得造成fallback的原因12345678910111213141516171819@FeignClient(name = &quot;microservice-provider&quot;, fallbackFactory = UserFeignClientFallbackFactory.class)public interface UserFeignClient &#123; @GetMapping(&quot;/user/&#123;id&#125;&quot;) User findById(@PathVariable(&quot;id&quot;) Long id);&#125;@Component@Slf4jclass UserFeignClientFallbackFactory implements FallbackFactory&lt;UserFeignClient&gt; &#123; @Override public UserFeignClient create(Throwable throwable) &#123; return new UserFeignClient() &#123; @Override public User findById(Long id) &#123; log.error(&quot;进入回退逻辑&quot;, throwable); return new User(id, &quot;默认用户&quot;, &quot;aaaaaa&quot;, &quot;13899988898&quot;); &#125; &#125;; &#125;&#125; Feign启用/禁用Hystrix全局启用1feign.hystrix.enabled: true 全局禁用1feign.hystrix.enabled: false 或直接省略不写。 局部启用利用Feign配置的自定义，为指定Feign Client指定如下配置类即可 1234567public class FeignDisableHystrixConfiguration &#123; @Bean @Scope(&quot;prototype&quot;) public HystrixFeign.Builder feignBuilder() &#123; return HystrixFeign.builder(); &#125;&#125; 局部禁用1234567public class FeignDisableHystrixConfiguration &#123; @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder() &#123; return Feign.builder(); &#125;&#125; 代码示例服务降级： microservice-consumer-feign-with-hystrix 获得造成fallback的原因： microservice-consumer-feign-hystrix-fallback-factory","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/tags/Feign/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://www.cicoding.cn/tags/Hystrix/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"熔断器-Ribbon使用Hystrix","slug":"microservice06","date":"2020-01-17T01:45:05.000Z","updated":"2022-09-17T14:13:56.158Z","comments":false,"path":"micro-service/microservice06/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice06/","excerpt":"","text":"本节详细讲解使用Hystrix的通用方式。 简介Hystrix是由Netflix开源的一个延迟和容错库，用于隔离访问远程系统、服务或者第三方库，防止级联失败，从而提升系统的可用性与容错性。Hystrix主要通过以下几点实现延迟和容错。 包裹请求 使用HystrixCommand（或HystrixObservableCommand）包裹对依赖的调用逻辑，每个命令在独立线程中执行。这使用到了设计模式中的“命令模式”。 跳闸机制 当某服务的错误率超过一定阈值时，Hystrix可以自动或者手动跳闸，停止请求该服务一段时间。 资源隔离 Hystrix为每个依赖都维护了一个小型的线程池（或者信号量）。如果该线程池已满，发往该依赖的请求就被立即拒绝，而不是排队等候，从而加速失败判定。 监控 Hystrix可以近乎实时地监控运行指标和配置的变化，例如成功、失败、超时、以及被拒绝的请求等。 回退机制 当请求失败、超时、被拒绝，或当断路器打开时，执行回退逻辑。回退逻辑可由开发人员自行提供，例如返回一个缺省值。 自我修复 断路器打开一段时间后，会自动进入“半开”状态。断路器打开、关闭、半开的逻辑转换，前面我们已经详细探讨过了，不再赘述。 通用方式使用Hystrix服务降级 加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 加注解：在启动类上添加@EnableCircuitBreaker 注解。 使用： 123456789101112131415161718192021@RequestMapping(&quot;/ribbon&quot;)@RestController@Slf4jpublic class RibbonController &#123; @Autowired private RestTemplate restTemplate; @HystrixCommand(fallbackMethod = &quot;findByIdFallback&quot;) @GetMapping(&quot;/user/&#123;id&#125;&quot;) public User findById(@PathVariable Integer id) &#123; // 这里用到了RestTemplate的占位符能力 User user = this.restTemplate.getForObject(&quot;http://microservice-provider/user/&#123;id&#125;&quot;, User.class, id); // ...电影微服务的业务... return user; &#125; public User findByIdFallback(Integer id, Throwable throwable) &#123; log.error(&quot;进入回退方法&quot;, throwable); return new User(id, &quot;默认用户&quot;, &quot;aaaaaa&quot;, &quot;13906123017&quot;); &#125;&#125; 由代码可知，只需使用@HystrixCommand 注解，就可保护该API。这里的”保护“，其实带有三层含义——”超时机制“、”仓壁模式“、”断路器“！如果您不了解这些是什么，或者想要探寻其中原理，可详见：微服务容错 PS 本例使用了fallbackMethod 属性，指定了一个降级方法，如不指定，Hystrix会有一个默认的降级方案，那就是抛异常。 如何知道断路器打开还是关闭呢？还记得健康检查吗？只需访问应用的/actuator/health 端点，即可查看！断路器的状态——当然，你必须添加如下配置： 1234management: endpoint: health: show-details: always 1234management: endpoint: health: show-details: always 测试 启动microservice-discovery-eureka 启动microservice-provider 启动microservice-consumer-ribbon-with-hystrix 访问http://localhost:8010/ribbon/user/1 ，能正常返回结果 关闭microservice-provider ，再次访问http://localhost:8010/ribbon/user/1 ，可返回类似如下结果，说明当服务提供者时，服务消费者进入了回退方法。 123456&#123; &quot;userId&quot;: 1, &quot;userName&quot;: &quot;默认用户&quot;, &quot;password&quot;: &quot;aaaaaa&quot;, &quot;phone&quot;: &quot;13908888888&quot;&#125; 访问http://localhost:8010/actuator/health ，可获得类似如下结果： 1234567891011&#123; &quot;status&quot;: &quot;UP&quot;, &quot;details&quot;: &#123; &quot;diskSpace&quot;: ..., &quot;refreshScope&quot;: ..., &quot;discoveryComposite&quot;: ..., &quot;hystrix&quot;: &#123; &quot;status&quot;: &quot;UP&quot; &#125; &#125;&#125; 由结果不难发现，此时断路器并未打开！这是为什么呢？ 原因是：此时只请求了一次，没有达到Hystrix的阈值——Hystrix设计来保护高并发应用的，它要求10秒（可用hystrix.command.default.metrics.rollingStats.timeInMilliseconds 自定义）以内API错误次数超过20次（用circuitBreaker.requestVolumeThreshold 自定义），此时才可能触发断路器。 持续不断地访问http://localhost:8010/ribbon/user/1 多次（至少20次） 再次访问http://localhost:8010/actuator/health ，可获得类似如下结果： 1234567891011121314&#123; &quot;status&quot;: &quot;UP&quot;, &quot;details&quot;: &#123; &quot;diskSpace&quot;: ..., &quot;refreshScope&quot;: ..., &quot;discoveryComposite&quot;: ..., &quot;hystrix&quot;: &#123; &quot;status&quot;: &quot;CIRCUIT_OPEN&quot;, &quot;details&quot;: &#123; &quot;openCircuitBreakers&quot;: [&quot;MovieController::findById&quot;] &#125; &#125; &#125;&#125; 由结果可知，此时断路器已经打开，并且列出了是哪个API的断路器被打开了。 获得造成fallback的原因在实际项目中，很可能需要获得造成fallback的原因，此时可将代码修改为如下： 12345678910111213141516@HystrixCommand(fallbackMethod = &quot;findByIdFallback&quot;)@GetMapping(&quot;/user/&#123;id&#125;&quot;)public User findById(@PathVariable Long id) &#123; // 这里用到了RestTemplate的占位符能力 User user = this.restTemplate.getForObject( &quot;http://microservice-provider/user/&#123;id&#125;&quot;, User.class, id ); // ...电影微服务的业务... return user;&#125;public User findByIdFallback(Long id, Throwable throwable) &#123; log.error(&quot;进入回退方法&quot;, throwable); return new User(id, &quot;默认用户&quot;, &quot;aaaaaa&quot;, &quot;13906412317&quot;);&#125; 配套代码microservice-consumer-ribbon-with-hystrix","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Ribbon","slug":"Ribbon","permalink":"https://www.cicoding.cn/tags/Ribbon/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://www.cicoding.cn/tags/Hystrix/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"聊聊@Controller和@RestController的区别？","slug":"spring-controller-restcontroller","date":"2020-01-10T06:25:43.000Z","updated":"2022-09-17T14:13:56.177Z","comments":true,"path":"spring/spring-controller-restcontroller/","link":"","permalink":"https://www.cicoding.cn/spring/spring-controller-restcontroller/","excerpt":"","text":"知识点：@RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用。 1) 如果只是使用@RestController注解Controller，则Controller中的方法无法返回jsp页面，或者html，配置的视图解析器 InternalResourceViewResolver不起作用，返回的内容就是Return 里的内容。 2) 如果需要返回到指定页面，则需要用 @Controller配合视图解析器InternalResourceViewResolver才行。如果需要返回JSON，XML或自定义mediaType内容到页面，则需要在对应的方法上加上@ResponseBody注解。 例如： 使用@Controller 注解，在对应的方法上，视图解析器可以解析return 的jsp,html页面，并且跳转到相应页面 若返回json等内容到页面，则需要加@ResponseBody注解 123456789101112131415161718@CrossOrigin@Controllerpublic class FileUploadController &#123;//跳转到上传文件的页面@RequestMapping(value=\"/gouploadimg\", method = RequestMethod.GET)public String goUploadImg() &#123; //跳转到 templates 目录下的 uploadimg.html return \"uploadimg\";&#125;//处理文件上传@RequestMapping(value=\"/testuploadimg\", method = RequestMethod.POST)public @ResponseBody String uploadImg(@RequestParam(\"file\") MultipartFile file, HttpServletRequest request) &#123; System.out.println(\"调用文件上传方法\"); String contentType = file.getContentType(); String fileName = file.getOriginalFilename(); @RestController注解，相当于@Controller+@ResponseBody两个注解的结合，返回json数据不需要在方法前面加@ResponseBody注解了，但使用@RestController这个注解，就不能返回jsp,html页面，视图解析器无法解析jsp,html页面 123@CrossOrigin@RestController /* @Controller + @ResponseBody*/public class HospitalController &#123; 12345678910111213//注入Service服务对象@Autowiredprivate HospitalService hospitalService;/** * 查询所有医院信息（未分页） */@RequestMapping(value = \"findAllHospital\",method = RequestMethod.GET)public List&lt;Hospital&gt; findAllHospital()&#123; List&lt;Hospital&gt; hospitalList= hospitalService.findAllHospital(); return hospitalList;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"Java-b2-spring注解","slug":"Java-b2-spring注解","permalink":"https://www.cicoding.cn/tags/Java-b2-spring注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"SpringBoot2.1.X整合MongoDB（支持事务）","slug":"springboot-and-mongotemplate-transactional","date":"2020-01-04T09:19:43.000Z","updated":"2022-09-17T14:13:56.181Z","comments":true,"path":"springboot/springboot-and-mongotemplate-transactional/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-and-mongotemplate-transactional/","excerpt":"","text":"简述本周主要的工作任务是，将mongDB集成到Springboot中，并且要用注解事务（@Transactional），本文记录下集成过程。 前期依赖准备 要支持多文档事务，mongo版本必须为4.0以上 开启replica-set（多文档事务必须要在replica-set的基础上才能开启，MongoDB官网上有描述），具体怎么开启可参考此文： windows下配置replica-set 查看mongodb的数据库是否能正确连接 此处推荐mongodb数据的可视化工具：adminMongo，或者用官方的mongoCompass。 ​ 加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 加配置1spring.data.mongodb.uri=mongodb://10.254.193.30:27017/test?maxPoolSize=512 事务开启创建配置类，开启事务 12345678910111213141516package com.example.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.mongodb.MongoDbFactory;import org.springframework.data.mongodb.MongoTransactionManager;@Configurationpublic class TransactionConfig &#123; @Bean MongoTransactionManager transactionManager(MongoDbFactory factory)&#123; return new MongoTransactionManager(factory); &#125;&#125; 然后方法注解 @Transactional(rollbackFor = Throwable.class) 12345@Transactional(rollbackFor = Throwable.class)public void saveTest(Mongo test) &#123; mongoTemplate.save(test); int i = 1/0;&#125; 在启动类上加上事务注解@EnableTransactionManagement。 注：以上为MongoTemplate方式，MongoTemplate和MongoRepository方式都与Spring整合SpringDataMongoDB相同","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.cicoding.cn/categories/MongoDB/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.cicoding.cn/tags/Spring-Boot/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.cicoding.cn/tags/MongoDB/"},{"name":"MongoTemplate","slug":"MongoTemplate","permalink":"https://www.cicoding.cn/tags/MongoTemplate/"},{"name":"Transaction","slug":"Transaction","permalink":"https://www.cicoding.cn/tags/Transaction/"}],"keywords":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.cicoding.cn/categories/MongoDB/"}]},{"title":"SpringCloud Feign","slug":"microservice05","date":"2020-01-04T08:45:05.000Z","updated":"2022-09-17T14:13:56.157Z","comments":false,"path":"micro-service/microservice05/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice05/","excerpt":"","text":"在前面的文章中可以发现当我们通过RestTemplate调用其它服务的API时，所需要的参数须在请求的URL中进行拼接，如果参数少的话或许我们还可以忍受，一旦有多个参数的话，这时拼接请求字符串就会效率低下，并且显得好傻。 那么有没有更好的解决方案呢？答案是确定的有，Netflix已经为我们提供了一个框架：Feign。 Feign是一个声明式的Web Service客户端，它的目的就是让Web Service调用更加简单。Feign提供了HTTP请求的模板，通过编写简单的接口和插入注解，就可以定义好HTTP请求的参数、格式、地址等信息。 而Feign则会完全代理HTTP请求，我们只需要像调用方法一样调用它就可以完成服务请求及相关处理。Feign整合了Ribbon和Hystrix(关于Hystrix我们后面再讲)，可以让我们不再需要显式地使用这两个组件。 总起来说，Feign具有如下特性： 可插拔的注解支持，包括Feign注解和JAX-RS注解; 支持可插拔的HTTP编码器和解码器; 支持Hystrix和它的Fallback; 支持Ribbon的负载均衡; 支持HTTP请求和响应的压缩。 这看起来有点像我们springmvc模式的Controller层的RequestMapping映射。这种模式是我们非常喜欢的。Feign是用@FeignClient来映射服务的。 经过前文讲解，我们已使用Eureka实现服务发现；使用Ribbon实现了负载均衡这种听起来很高端的东西。我们的架构已经初具雏形，但依然存在很多问题，下面不妨来分析下前文的代码—— 1234567891011@GetMapping(\"/user/&#123;id&#125;\")public User findById(@PathVariable Long id) &#123; // 这里用到了RestTemplate的占位符能力 User user = this.restTemplate.getForObject( \"http://microservice-provider-user/users/&#123;id&#125;\", User.class, id ); // ...电影微服务的业务... return user;&#125; 这里，this.restTemplate.getForObject(&quot;http://microservice-provider/user/{id}&quot;…这行代码是比较糟糕的，存在诸多问题—— 如果系统业务非常复杂，而你是一个新人，当你看到这行代码，恐怕很难一眼看出其用途是什么！此时，你很可能需要寻求老同事的帮助（往往是这行代码的作者，可万一离职了呢？），或者查阅该目标地址对应的文档（文档常常还和代码不匹配），才能清晰了解这行代码背后的含义！否则，你只能陷入蛋疼的境地！ 这个例子构造的URL非常简单，但如果你需要构造类似如下这么丑陋的URL时：https://www.baidu.com/s?wd=asf&amp;rsv_spt=1&amp;rsv_iqid=0xa25bbeba000047fd&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=3&amp;rsv_sug1=2&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;inputT=328&amp;rsv_sug4=328，恐怕就有心无力了！尽管RestTemplate支持使用占位符，从而让我们避免字符串拼接的尴尬境地，但构造这么复杂的URL依然是很麻烦的。更可怕的是，互联网时代需求变化非常之快，你的参数可能会从10个变成12个、15个，再后来又精简成13个……维护这个URL真的是想想都累……总而言之，复杂URL的构造会让你处于一种不性福的状态！ 如何解决以上问题？用Feign！TIPS Feign本质上来说是个山寨，其设计思想基本都来源于Retrofit（使用方式更是如出一辙）。 Retrofit的GitHub：https://github.com/square/retrofit ，如果你知道Square公司，那么你很厉害！是的，Retrofit也是开源OKHttp的那家公司开源的——所以，笔者喜欢将Square公司称为‘’HTTP客户端小王子”，但其实人家是做移动支付的。 Spring Cloud对Retrofit也有支持：https://github.com/spring-cloud-incubator/spring-cloud-square ，目前正在孵化中，有兴趣的可以去体验一下。学会Feign后，Retrofit上手也就是5分钟的事情。 简介Feign是Netflix开发的声明式、模板化的HTTP客户端，其灵感来自Retrofit、JAXRS-2.0以及WebSocket。Feign可帮助我们更加便捷、优雅地调用HTTP API。在Spring Cloud中，使用Feign非常简单——只需创建接口，并在接口上添加注解即可。Feign支持多种注解，例如Feign自带的注解或者JAX-RS注解等。Spring Cloud对Feign进行了增强，使其支持Spring MVC注解，另外还整合了Ribbon和Eureka，从而使得Feign的使用更加方便。TIPSFeign的GitHub：https://github.com/OpenFeign/feign Quick Start下面来将前面的例子用Feign改写，让其达到与Ribbon + RestTemplate相同的效果。 复制项目microservice-consumer，将ArtifactId修改为microservice-consumer-feign ； 加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 加注解：启动类上添加@EnableFeignClients ； 编写Feign Client： 12345@FeignClient(name = \"microservice-provider\")public interface UserFeignClient &#123; @GetMapping(\"/user/&#123;id&#125;\") User findById(@PathVariable(\"id\") Long id);&#125; 这样一个Feign Client就写完啦！其中，@FeignClient 注解中的microservice-provider是想要请求服务的名称，这是用来创建Ribbon Client的（Feign整合了Ribbon）。在本例中，由于使用了Eureka，所以Ribbon会把microservice-provider 解析成Eureka Server中的服务。除此之外，还可使用url属性指定请求的URL（URL可以是完整的URL或主机名），例如@FeignClient(name = &quot;abcde&quot;, url = &quot;http://localhost:8000/&quot;) 。此时，name可以是任意值，但不可省略，否则应用将无法启动！ Controller： 12345678910@RequestMapping(\"/fegin\")@RestControllerpublic class MovieController &#123; @Autowired private UserFeignClient userFeignClient; @GetMapping(\"/user/&#123;id&#125;\") public User findById(@PathVariable Long id) &#123; return this.userFeignClient.findById(id); &#125;&#125; 只需使用@Autowire注解，即可注入上面编写的Feign Client。 RestTemplate与Feign对比相信通过本文的例子，聪明的你对如何使用Feign已经了然于心了。文章的最后，对比一下RestTemplate + Ribbon与Feign。 角度 RestTemplate + Ribbon Feign（自带Ribbon） 可读性、可维护性 欠佳（无法从URL直观了解这个远程调用是干什么的） 极佳（能在接口上写注释，方法名称也是可读的，能一眼看出这个远程调用是干什么的） 开发体验 欠佳（拼凑URL不性福） 极佳（写出漂亮的代码，女朋友更爱你了） 风格一致性 欠佳（本地API调用和RestTemplate调用的代码风格截然不同） 极佳（完全一致，不点开Feign的接口，根本不会察觉这是一个远程调用而非本地API调用） 性能 较好 中等（性能是RestTemplate的50%左右；如果为Feign配置连接池，性能可提升15%左右） 灵活性 极佳 中等（内置功能能满足大多数项目的需求） 那么如何选择呢？相信这才是大家最关注的问题！ 一般来说，建议使用Feign，并杜绝使用RestTmplate。为什么用Feign相信不必啰嗦；可为什么要杜绝RestTemplate，那是因为在一个项目里，保持统一的编码风格乃至体验，是非常重要的。我个人的架构原则是尽量减少开发人员的选择，如果A能解决问题，就杜绝使用B——最佳实践永远只有一个！并且，共存带来的往往不是相得益彰，反而是歧义、错乱以及额外的学习成本、理解成本（笔者当年参与过一个同时使用Struts1 + Struts2 + Servlet的项目，可以想象一下学习成本有多高；笔者还参与一个一个使用Jackson + FastJson + json-lib + Gson的项目，可想而知操作JSON的代码有多混乱……，并抨击别人使用他不熟悉的JSON操作库，后来被笔者统一成Jackson后，大家都安心干活了）！ 有人可能会对Feign的性能存在顾虑，Feign的性能虽然不那么优秀，但大部分场景下都是OK的——项目的性能瓶颈一般都不出在HTTP客户端上，而在于自身业务的处理！ 求同存异——上文虽说要杜绝RestTemplate，但事无绝对，你得根据具体情况具体分析——对于某些变态需求，在使用Feign很难实现或无法实现时，可考虑使用RestTemplate + Feign共存的方式……Spring Cloud官方也承认，无论Fegin怎么改进，其灵活性也无法比得上RestTemplate！但是，这么做之前请务必慎重，记住，共存带来的往往不是相得益彰，反而是歧义、错乱以及额外的学习成本、理解成本。 代码示例microservice-discovery-eurekamicroservice-providermicroservice-consumer-feign","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/tags/Feign/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"SpringCloud Ribbon","slug":"microservice04","date":"2020-01-04T08:25:05.000Z","updated":"2022-09-17T14:13:56.157Z","comments":false,"path":"micro-service/microservice04/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice04/","excerpt":"","text":"在之前几篇 Spring Cloud 的 5 分钟指南里我们已经依次介绍了多个 Spring Cloud 的核心组件，其中涵盖了微服务架构中必须的基础功能，例如服务发现，熔断，中心化配置。今天介绍的主角同样是由 Netflix 出品的 Ribbon，官方给 Ribbon 的定义是一个用于远程调用的库，而它更为人熟知的作用是可以进行客户端的 Load Balance。 Load Balance 对于任何一个分布式系统都是必要的基础功能，从实现角度而言，可以分为客户端 LB 和服务器端 LB。在日常工作中大家接触最多的应该是基于服务器的 LB 解决方案，例如通过 nginx 的反向代理，或是商用的 F5。但是今天的例子中会演示如何使用 Ribbon 搭建一个具有 LB 的客户端应用。让我们开始吧。 一般来说，提到负载均衡，大家一般很容易想到浏览器 -&gt; NGINX -&gt; 反向代理多个Tomcat这样的架构图——业界管这种负载均衡模式叫“服务器端负载均衡”，因为此种模式下，负载均衡算法是NGINX提供的，而NGINX部署在服务器端。本节所讲的Ribbon则是一个客户端侧负载均衡组件——通俗地说，就是集成在客户端（服务消费者一侧），并提供负载均衡算法的一个组件。 Ribbon简介Ribbon是Netflix发布的负载均衡器，它可以帮我们控制HTTP和TCP客户端的行为。只需为Ribbon配置服务提供者地址列表，Ribbon就可基于负载均衡算法计算出要请求的目标服务地址。Ribbon默认为我们提供了很多的负载均衡算法，例如轮询、随机、响应时间加权等——当然，为Ribbon自定义负载均衡算法也非常容易，只需实现IRule 接口即可。TIPSRibbon的GitHub：https://github.com/Netflix/ribbon 引入Ribbon在Spring Cloud中，当Ribbon与Eureka配合使用时，Ribbon可自动从Eureka Server获取服务提供者地址列表，并基于负载均衡算法，选择其中一个服务提供者实例。下图展示了Ribbon与Eureka配合使用时的大致架构。 Ribbon入门代码示例 复制项目microservice-consumer ，将ArtifactId修改为microservice-consumer-ribbon 。 加依赖：由于spring-cloud-starter-netflix-eureka-client 已经包含spring-cloud-starter-netfilx-ribbon ，故而无需额外添加依赖。 写代码： 12345@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; 如代码所示，只需在RestTemplate 上添加LoadBalanced 注解，即可让RestTemplate整合Ribbon！ 调用： 123456789101112131415@RequestMapping(\"/ribbon\")@RestControllerpublic class RibbonController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"/user/&#123;id&#125;\") public User findById(@PathVariable Long id) &#123; // 这里用到了RestTemplate的占位符能力 User user = this.restTemplate.getForObject(\"http://microservice-provider/user/&#123;id&#125;\", User.class, id);// User user = this.restTemplate.getForObject(\"http://microservice-provider-user/users/&#123;id&#125;\", User.class, id);// User user = this.restTemplate.getForObject(\"http://10.254.193.129:8180/user/&#123;id&#125;\", User.class, id); return user; &#125;&#125; 由代码可知，我们将请求的目标服务改成了http://microservice-provider/user/{id}，也就是http://{目标服务名称}/{目标服务端点} 的形式，Ribbon会自动在实际调用时，将目标服务名替换为该服务的IP和端口。 测试 依次启动microservice-discovery-eureka 、microservice-provider 两个实例、microservice-consumer-ribbon 访问http://localhost:8010/ribbon/user/1 多次，会发现两个user服务实例都会打印日志。 WARNING事实上，这里的目标服务名称，在Ribbon里叫虚拟主机名 ，主机名是不能包含_ 等特殊字符的——这意味着，一般不建议配置spring.application.name = xxx_xxx ，如果你的应用名称一定（谁这么变态？？）带有下划线这种字符，那么请额外配置eureka.instance.virtual-host-name = 一个合法的主机名 ，否则Ribbon将会提示虚拟主机名不合法的异常（在早期的版本则是报空指针）！这点请大家务必注意。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Ribbon","slug":"Ribbon","permalink":"https://www.cicoding.cn/tags/Ribbon/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"Java并发编程：CountDownLatch、CyclicBarrier和 Semaphore","slug":"CountDownLatch-CyclicBarrier-Semaphorepy","date":"2019-12-28T00:15:43.000Z","updated":"2022-09-17T14:13:56.150Z","comments":true,"path":"java/CountDownLatch-CyclicBarrier-Semaphorepy/","link":"","permalink":"https://www.cicoding.cn/java/CountDownLatch-CyclicBarrier-Semaphorepy/","excerpt":"","text":"在java 1.5中，提供了一些非常有用的辅助类来帮助我们进行并发编程，比如CountDownLatch，CyclicBarrier和Semaphore，今天我们就来学习一下这三个辅助类的用法。 以下是本文目录大纲： 一.CountDownLatch用法 二.CyclicBarrier用法 三.Semaphore用法 一.CountDownLatch用法CountDownLatch类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。 CountDownLatch类只提供了一个构造器： 1public CountDownLatch(int count) &#123; &#125;; //参数count为计数值 然后下面这3个方法是CountDownLatch类中最重要的方法： 123public void await() throws InterruptedException &#123; &#125;; //调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public void countDown() &#123; &#125;; //将count值减1 下面看一个例子大家就清楚CountDownLatch的用法了： 123456789101112131415161718192021222324252627282930313233343536373839public class Test &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread()&#123; public void run() &#123; try &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在执行\"); Thread.sleep(3000); System.out.println(\"子线程\"+Thread.currentThread().getName()+\"执行完毕\"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; try &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在执行\"); Thread.sleep(3000); System.out.println(\"子线程\"+Thread.currentThread().getName()+\"执行完毕\"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); try &#123; System.out.println(\"等待2个子线程执行完毕...\"); latch.await(); System.out.println(\"2个子线程已经执行完毕\"); System.out.println(\"继续执行主线程\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果： 线程Thread-0正在执行 线程Thread-1正在执行 等待2个子线程执行完毕... 线程Thread-0执行完毕 线程Thread-1执行完毕 2个子线程已经执行完毕 继续执行主线程二.CyclicBarrier用法字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。我们暂且把这个状态就叫做barrier，当调用await()方法之后，线程就处于barrier了。 CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器： 12345public CyclicBarrier(int parties, Runnable barrierAction) &#123;&#125; public CyclicBarrier(int parties) &#123;&#125; 参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。 然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本： 12public int await() throws InterruptedException, BrokenBarrierException &#123; &#125;;public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException &#123; &#125;; 第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务； 第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。 下面举几个例子就明白了： 假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情，此时就可以利用CyclicBarrier了： 1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) new Writer(barrier).start(); &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果 线程Thread-0正在写入数据... 线程Thread-3正在写入数据... 线程Thread-2正在写入数据... 线程Thread-1正在写入数据... 线程Thread-2写入数据完毕，等待其他线程写入完毕 线程Thread-0写入数据完毕，等待其他线程写入完毕 线程Thread-3写入数据完毕，等待其他线程写入完毕 线程Thread-1写入数据完毕，等待其他线程写入完毕 所有线程写入完毕，继续处理其他任务... 所有线程写入完毕，继续处理其他任务... 所有线程写入完毕，继续处理其他任务... 所有线程写入完毕，继续处理其他任务...从上面输出结果可以看出，每个写入线程执行完写数据操作之后，就在等待其他线程写入操作完毕。 当所有线程线程写入操作完毕之后，所有线程就继续进行后续的操作了。 如果说想在所有线程写入操作完之后，进行额外的其他操作可以为CyclicBarrier提供Runnable参数： 1234567891011121314151617181920212223242526272829303132333435public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N,new Runnable() &#123; @Override public void run() &#123; System.out.println(\"当前线程\"+Thread.currentThread().getName()); &#125; &#125;); for(int i=0;i&lt;N;i++) new Writer(barrier).start(); &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 运行结果： 线程Thread-0正在写入数据... 线程Thread-1正在写入数据... 线程Thread-2正在写入数据... 线程Thread-3正在写入数据... 线程Thread-0写入数据完毕，等待其他线程写入完毕 线程Thread-1写入数据完毕，等待其他线程写入完毕 线程Thread-2写入数据完毕，等待其他线程写入完毕 线程Thread-3写入数据完毕，等待其他线程写入完毕 当前线程Thread-3 所有线程写入完毕，继续处理其他任务... 所有线程写入完毕，继续处理其他任务... 所有线程写入完毕，继续处理其他任务... 所有线程写入完毕，继续处理其他任务... 从结果可以看出，当四个线程都到达barrier状态后，会从四个线程中选择一个线程去执行Runnable。下面看一下为await指定时间的效果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) &#123; if(i&lt;N-1) new Writer(barrier).start(); else &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Writer(barrier).start(); &#125; &#125; &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); try &#123; cyclicBarrier.await(2000, TimeUnit.MILLISECONDS); &#125; catch (TimeoutException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 线程Thread-0正在写入数据... 线程Thread-2正在写入数据... 线程Thread-1正在写入数据... 线程Thread-2写入数据完毕，等待其他线程写入完毕 线程Thread-0写入数据完毕，等待其他线程写入完毕 线程Thread-1写入数据完毕，等待其他线程写入完毕 线程Thread-3正在写入数据... java.util.concurrent.TimeoutException Thread-1所有线程写入完毕，继续处理其他任务... Thread-0所有线程写入完毕，继续处理其他任务... at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58) java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58) java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58) Thread-2所有线程写入完毕，继续处理其他任务... java.util.concurrent.BrokenBarrierException 线程Thread-3写入数据完毕，等待其他线程写入完毕 at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58) Thread-3所有线程写入完毕，继续处理其他任务...上面的代码在main方法的for循环中，故意让最后一个线程启动延迟，因为在前面三个线程都达到barrier之后，等待了指定的时间发现第四个线程还没有达到barrier，就抛出异常并继续执行后面的任务。 另外CyclicBarrier是可以重用的，看下面这个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) &#123; new Writer(barrier).start(); &#125; try &#123; Thread.sleep(25000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"CyclicBarrier重用\"); for(int i=0;i&lt;N;i++) &#123; new Writer(barrier).start(); &#125; &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 线程Thread-0正在写入数据... 线程Thread-1正在写入数据... 线程Thread-3正在写入数据... 线程Thread-2正在写入数据... 线程Thread-1写入数据完毕，等待其他线程写入完毕 线程Thread-3写入数据完毕，等待其他线程写入完毕 线程Thread-2写入数据完毕，等待其他线程写入完毕 线程Thread-0写入数据完毕，等待其他线程写入完毕 Thread-0所有线程写入完毕，继续处理其他任务... Thread-3所有线程写入完毕，继续处理其他任务... Thread-1所有线程写入完毕，继续处理其他任务... Thread-2所有线程写入完毕，继续处理其他任务... CyclicBarrier重用 线程Thread-4正在写入数据... 线程Thread-5正在写入数据... 线程Thread-6正在写入数据... 线程Thread-7正在写入数据... 线程Thread-7写入数据完毕，等待其他线程写入完毕 线程Thread-5写入数据完毕，等待其他线程写入完毕 线程Thread-6写入数据完毕，等待其他线程写入完毕 线程Thread-4写入数据完毕，等待其他线程写入完毕 Thread-4所有线程写入完毕，继续处理其他任务... Thread-5所有线程写入完毕，继续处理其他任务... Thread-6所有线程写入完毕，继续处理其他任务... Thread-7所有线程写入完毕，继续处理其他任务...从执行结果可以看出，在初次的4个线程越过barrier状态后，又可以用来进行新一轮的使用。而CountDownLatch无法进行重复使用。 三.Semaphore用法Semaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。Semaphore类位于java.util.concurrent包下，它提供了2个构造器： 123456public Semaphore(int permits) &#123; //参数permits表示许可数目，即同时可以允许多少线程进行访问 sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; //这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可 sync = (fair)? new FairSync(permits) : new NonfairSync(permits);&#125; 下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法： 1234public void acquire() throws InterruptedException &#123; &#125; //获取一个许可public void acquire(int permits) throws InterruptedException &#123; &#125; //获取permits个许可public void release() &#123; &#125; //释放一个许可public void release(int permits) &#123; &#125; //释放permits个许可 acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。 release()用来释放许可。注意，在释放许可之前，必须先获获得许可。 这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法： 1234public boolean tryAcquire() &#123; &#125;; //尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(int permits) &#123; &#125;; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false 另外还可以通过availablePermits()方法得到可用的许可数目。 下面通过一个例子来看一下Semaphore的具体使用： 假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现： 123456789101112131415161718192021222324252627282930public class Test &#123; public static void main(String[] args) &#123; int N = 8; //工人数 Semaphore semaphore = new Semaphore(5); //机器数目 for(int i=0;i&lt;N;i++) new Worker(i,semaphore).start(); &#125; static class Worker extends Thread&#123; private int num; private Semaphore semaphore; public Worker(int num,Semaphore semaphore)&#123; this.num = num; this.semaphore = semaphore; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println(\"工人\"+this.num+\"占用一个机器在生产...\"); Thread.sleep(2000); System.out.println(\"工人\"+this.num+\"释放出机器\"); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 执行结果： 工人0占用一个机器在生产... 工人1占用一个机器在生产... 工人2占用一个机器在生产... 工人4占用一个机器在生产... 工人5占用一个机器在生产... 工人0释放出机器 工人2释放出机器 工人3占用一个机器在生产... 工人7占用一个机器在生产... 工人4释放出机器 工人5释放出机器 工人1释放出机器 工人6占用一个机器在生产... 工人3释放出机器 工人7释放出机器 工人6释放出机器下面对上面说的三个辅助类进行一个总结： 1）CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 2）Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。 参考资料： 《Java编程思想》 http://www.itzhai.com/the-introduction-and-use-of-a-countdownlatch.html http://leaver.me/archives/3220.html http://developer.51cto.com/art/201403/432095.htm http://blog.csdn.net/yanhandle/article/details/9016329 https://blog.csdn.net/CrankZ/article/details/83781380 http://blog.csdn.net/cutesource/article/details/5780740 http://www.cnblogs.com/whgw/archive/2011/09/29/2195555.html","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/tags/Java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://www.cicoding.cn/tags/并发编程/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://www.cicoding.cn/categories/Java/"}]},{"title":"微服务服务提供者在Eureka中注册","slug":"microservice03","date":"2019-12-25T09:23:52.000Z","updated":"2022-09-17T14:13:56.157Z","comments":false,"path":"micro-service/microservice03/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice03/","excerpt":"","text":"服务提供者被其他微服务调用的微服务 首先我们用首先打开http://start.spring.io，如下图所示， 创建报名，项目名 microservice-provider 最后点击下方的“Generate Project”按钮， 将会生成 zip包。 microservice-provider.zip 然后解压，导入idea中。 然后开始编写代码 编写服务提供者创建一个Maven项目，依赖如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;microservice-provider&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;microservice-provider&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- springboot admin jar --&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--排除默认的tomcat-jdbc--&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--&lt;dependency&gt;--&gt; &lt;!--&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;--&gt; &lt;!--&lt;/dependency&gt;--&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 其中，spring-boot-starter-web提供了Spring MVC的支持；spring-boot-starter-data-jpa提供了Spring lombok则是一款开发利器，可以帮助你简化掉N多冗余代码。WARNING Lombok之前，必须为你的IDE安装Lombok插件！可参考：http://www.cnblogs.com/shindo/p/7550790.html TIPS Lombok快速上手：https://blog.csdn.net/motui/article/details/79012846 Lombok官方网站：https://projectlombok.org/ 创建实体类：1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.example.model;public class UserDomain &#123; private Integer userId; private String userName; private String password; private String phone; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125;&#125; 创建DAO：123456789101112131415161718192021package com.example.dao;import com.example.model.UserDomain;import org.apache.ibatis.annotations.Mapper;import org.apache.ibatis.annotations.Param;import java.util.List;@Mapperpublic interface UserDao &#123; int insert(UserDomain record); void deleteUserById(@Param(\"userId\") Integer userId); void updateUser(UserDomain userDomain); List&lt;UserDomain&gt; selectUsers(); UserDomain findById(Integer id);&#125; 创建mapper的xml映射文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.example.dao.UserDao\" &gt; &lt;sql id=\"BASE_TABLE\"&gt; t_user &lt;/sql&gt; &lt;sql id=\"BASE_COLUMN\"&gt; userId,userName,password,phone &lt;/sql&gt; &lt;insert id=\"insert\" parameterType=\"com.example.model.UserDomain\"&gt; INSERT INTO &lt;include refid=\"BASE_TABLE\"/&gt; &lt;trim prefix=\"(\" suffix=\")\" suffixOverrides=\",\"&gt; userName,password, &lt;if test=\"phone != null\"&gt; phone, &lt;/if&gt; &lt;/trim&gt; &lt;trim prefix=\"VALUES(\" suffix=\")\" suffixOverrides=\",\"&gt; #&#123;userName, jdbcType=VARCHAR&#125;,#&#123;password, jdbcType=VARCHAR&#125;, &lt;if test=\"phone != null\"&gt; #&#123;phone, jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;/trim&gt; &lt;/insert&gt; &lt;delete id=\"deleteUserById\"&gt; DELETE FROM &lt;include refid=\"BASE_TABLE\"/&gt; WHERE userId = #&#123;userId, jdbcType=INTEGER&#125; &lt;/delete&gt; &lt;!-- 更新用户信息，为空的字段不进行置空 --&gt; &lt;update id=\"updateUser\" parameterType=\"com.example.model.UserDomain\"&gt; UPDATE &lt;include refid=\"BASE_TABLE\"/&gt; &lt;set&gt; &lt;if test=\"userName != null\"&gt; userName = #&#123;userName, jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"password != null\"&gt; password = #&#123;password, jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;if test=\"phone != null\"&gt; phone = #&#123;phone, jdbcType=VARCHAR&#125;, &lt;/if&gt; &lt;/set&gt; &lt;where&gt; userId = #&#123;userId, jdbcType=INTEGER&#125; &lt;/where&gt; &lt;/update&gt; &lt;select id=\"selectUsers\" resultType=\"com.example.model.UserDomain\"&gt; SELECT &lt;include refid=\"BASE_COLUMN\"/&gt; FROM &lt;include refid=\"BASE_TABLE\"/&gt; &lt;/select&gt; &lt;select id=\"findById\" resultType=\"com.example.model.UserDomain\"&gt; SELECT &lt;include refid=\"BASE_COLUMN\"/&gt; FROM &lt;include refid=\"BASE_TABLE\"/&gt; where userId = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 创建controller1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.example.controller;import com.example.model.UserDomain;import com.example.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.*;@RestController@RequestMapping(\"/user\")public class UserController &#123; @Autowired private UserService userService; @PostMapping(\"\") public ResponseEntity addUser(@RequestParam(value = \"userName\", required = true) String userName, @RequestParam(value = \"password\", required = true) String password, @RequestParam(value = \"phone\", required = false) String phone)&#123; UserDomain userDomain = new UserDomain(); userDomain.setUserName(userName); userDomain.setPassword(password); userDomain.setPhone(phone); userService.insert(userDomain); return ResponseEntity.ok(\"添加成功\"); &#125; @DeleteMapping(\"\") public ResponseEntity deleteUser(@RequestParam(value = \"userId\", required = true) Integer userId)&#123; userService.deleteUserById(userId); return ResponseEntity.ok(\"删除成功\"); &#125; @PutMapping(\"\") public ResponseEntity updateUser(@RequestParam(value = \"userId\", required = true) Integer userId, @RequestParam(value = \"userName\", required = false) String userName, @RequestParam(value = \"password\", required = false) String password, @RequestParam(value = \"phone\", required = false) String phone )&#123; UserDomain userDomain = new UserDomain(); userDomain.setUserId(userId); userDomain.setUserName(userName); userDomain.setPassword(password); userDomain.setPhone(phone); userService.updateUser(userDomain); return ResponseEntity.ok(\"更新成功\"); &#125; @GetMapping(\"\") public ResponseEntity getUsers()&#123; return ResponseEntity.ok(userService.selectUsers()); &#125; @GetMapping(\"/&#123;id&#125;\") public UserDomain findById(@PathVariable Integer id) &#123; return this.userService.findById(id); &#125;&#125; 其中， @GetMapping，是Spring 4.3提供的新注解。它是一个组合注解，等价于@RequestMapping(method = RequestMethod.GET)，用于简化开发。同理还有@PostMapping、@PutMapping、@DeleteMapping、@PatchMapping等。 编写启动类1234567891011121314package com.example;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@EnableEurekaClient@SpringBootApplicationpublic class ProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderApplication.class, args); &#125;&#125; @SpringBootApplication是一个组合注解，它整合了@Configuration、@EnableAutoConfiguration和@ComponentScan注解，并开启了Spring Boot程序的组件扫描和自动配置功能。在开发Spring Boot程序的过程中，常常会组合使用@Configuration、@EnableAutoConfiguration和@ComponentScan等注解，所以Spring Boot提供了@SpringBootApplication，来简化开发。 编写配置文件application.yml ：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849eureka: client: service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:8888/eureka/ instance: hostname: localhostlogging: level: com: example: debug root: info web: tracemanagement: endpoint: health: show-details: always endpoints: web: exposure: include: '*'mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.example.modelserver: port: 8080spring: application: name: microservice-provider boot: admin: client: url: http://localhost:8788 datasource: auto-commit: true default-auto-commit: true driver-class-name: com.mysql.cj.jdbc.Driver initial-size: 5 max-idle: 10 max-wait: 10000 maximum-pool-size: 100 min-idle: 5 minEvictableIdleTimeMillis: 300000 password: root test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800 url: jdbc:mysql://localhost:3309/mytest?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=UTC&amp;autoReconnect=true username: root validation-query: SELECT 1 传统Web应用开发中，常使用properties格式文件作为配置文件。Spring Boot以及Spring Cloud支持使用properties或者yml格式的文件作为配置文件。yml文件格式是YAML（Yet Another Markup Language）编写的文件格式，YAML和properties格式的文件可互相转换，例如本节中的application.yml，就等价于如下的properties文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758server.port=8080eureka.instance.hostname=localhost#### 数据库连接池属性spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver#spring.datasource.url=jdbc:mysql://10.254.193.154:3306/mytest?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;allowPublicKeyRetrieval=truespring.datasource.url=jdbc:mysql://localhost:3309/mytest?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=UTC&amp;autoReconnect=truespring.datasource.username=rootspring.datasource.password=root#自动提spring.datasource.default-auto-commit=true#指定updates是否自动提交spring.datasource.auto-commit=truespring.datasource.maximum-pool-size=100spring.datasource.max-idle=10spring.datasource.max-wait=10000spring.datasource.min-idle=5spring.datasource.initial-size=5spring.datasource.validation-query=SELECT 1spring.datasource.test-on-borrow=falsespring.datasource.test-while-idle=true# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.time-between-eviction-runs-millis=18800# 配置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.minEvictableIdleTimeMillis=300000# mybatis对应的映射文件路径mybatis.mapper-locations=classpath:mapper/*.xml# mybatis对应的实体类mybatis.type-aliases-package=com.example.model#logging.config = classpath:logback.xmllogging.level.root=infologging.level.com.example= debug# 指定注册到eureka server上的服务名称spring.application.name=microservice-providerspring.boot.admin.client.url=http://localhost:8788# 开放所有监控端点management.endpoints.web.exposure.include=*# 是否展示健康检查详情management.endpoint.health.show-details = always# 指定eureka server通信地址，注意/eureka/小尾巴不能少#eureka.client.service-url.defaultZone=http://10.254.193.30:9001/eureka/,http://10.254.193.31:9002/eureka/,http://10.254.193.32:9003/eureka/eureka.client.service-url.defaultZone=http://$&#123;eureka.instance.hostname&#125;:8888/eureka/# 是否注册IP到eureka server，如不指定或设为false，那就会注册主机名到eureka server#eureka.instance.prefer-ip-address=true#eureka.instance.ip-address=10.254.193.120#eureka.instance.prefer-ip-address=false#eureka.instance.hostname=10.254.193.129logging.level.web=trace 从中不难看出，YAML比properties结构清晰；可读性、可维护性也更强，并且语法非常简洁。因此，本书使用YAML格式作为配置文件。但，yml有严格的缩进，并且key与value之间使用: 分隔，冒号后的空格不能少，请大家注意。 测试启动eureka，然后启动我们的microservices-provider,在eureka中可以看到注册上去了 至此，我们完成了服务提供者注册到eureka！","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Eureka","slug":"Eureka","permalink":"https://www.cicoding.cn/tags/Eureka/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"SpringBoot2.x整合FastDFS","slug":"springboot-fastdfs","date":"2019-12-17T01:59:21.000Z","updated":"2022-09-17T14:13:56.182Z","comments":true,"path":"springboot/springboot-fastdfs/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-fastdfs/","excerpt":"","text":"本篇博客学习SpringBoot 2.1.11.RELEASE整合FastDFS。 FastDFS作用FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件上传、文件下载等，解决了大容量存储和负载均衡的问题。 安装连接： CentOS 7 安裝FastDFS V6.0.3 我们开始吧 新建一个springboot项目 pom文件加入fastdfs-client-java包 12345&lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 注意：fastdfs-client-java包mvn库中没有编译包，需要自己下载编译到自己的mvn本地库中，官方地址：https://github.com/happyfish100/fastdfs-client-java fdfs_client.conf在resources文件夹下新建fdfs_client.conf,编写如下： 1234567connect_timeout = 2network_timeout = 30charset = UTF-8http.tracker_http_port = 6666http.anti_steal_token = nohttp.secret_key = FastDFS1234567890tracker_server = 192.168.31.100:22122 文件工具类编写fastdfs初始化连接配置工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167import org.apache.commons.io.IOUtils;import org.apache.commons.lang3.StringUtils;import org.csource.common.MyException;import org.csource.common.NameValuePair;import org.csource.fastdfs.*;import org.springframework.stereotype.Service;import java.io.*;@Servicepublic class FastDFSService &#123; FastDFSService() throws IOException, MyException &#123; ClientGlobal.init(\"fdfs_client.conf\"); &#125; public String upload(byte[] bs, String stringbe) &#123; TrackerServer trackerServer = null; StorageServer storageServer = null; String fileIds = null; try &#123; trackerServer = init(); StorageClient1 storageClient = new StorageClient1(trackerServer, storageServer); fileIds = storageClient.upload_file1(bs, getFileExt(stringbe), null); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (MyException e) &#123; e.printStackTrace(); &#125; finally &#123; close(storageServer, trackerServer); &#125; return fileIds; &#125; public byte[] download(String groupName) &#123; TrackerServer trackerServer = null; StorageServer storageServer = null; byte[] b = null; try &#123; trackerServer = init(); StorageClient1 storageClient1 = new StorageClient1(trackerServer, storageServer); b = storageClient1.download_file1(groupName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; close(storageServer, trackerServer); &#125; return b; &#125; public FileInfo getFileInfo(String groupName) &#123; TrackerServer trackerServer = null; StorageServer storageServer = null; FileInfo fi = null; try &#123; trackerServer = init(); StorageClient1 storageClient1 = new StorageClient1(trackerServer, storageServer); fi = storageClient1.get_file_info1(groupName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; close(storageServer, trackerServer); &#125; return fi; &#125; public NameValuePair[] getFileMate(String groupName) &#123; TrackerServer trackerServer = null; StorageServer storageServer = null; NameValuePair nvps[] = null; try &#123; trackerServer = init(); StorageClient1 storageClient1 = new StorageClient1(trackerServer, storageServer); nvps = storageClient1.get_metadata1(groupName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; close(storageServer, trackerServer); &#125; return nvps; &#125; public int delete(String groupName) &#123; TrackerServer trackerServer = null; StorageServer storageServer = null; int i = 0; try &#123; trackerServer = init(); StorageClient1 storageClient1 = new StorageClient1(trackerServer, storageServer); i = storageClient1.delete_file1(groupName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; close(storageServer, trackerServer); &#125; return i; &#125; public byte[] File2byte(File file) &#123; byte[] buffer = null; try &#123; FileInputStream fis = new FileInputStream(file); ByteArrayOutputStream bos = new ByteArrayOutputStream(); byte[] b = new byte[1024]; int n; while ((n = fis.read(b)) != -1) &#123; bos.write(b, 0, n); &#125; fis.close(); bos.close(); buffer = bos.toByteArray(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return buffer; &#125; private TrackerServer init() &#123; TrackerServer trackerServer = null; try &#123; TrackerClient tracker = new TrackerClient(); trackerServer = tracker.getConnection(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return trackerServer; &#125; private void close(StorageServer storageServer, TrackerServer trackerServer) &#123; try &#123; if (storageServer != null) &#123; storageServer.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; if (trackerServer != null) &#123; trackerServer.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private String getFileExt(String fileName) &#123; if (StringUtils.isBlank(fileName) || !fileName.contains(\".\")) &#123; return \"\"; &#125; else &#123; return fileName.substring(fileName.lastIndexOf(\".\") + 1); // 不带最后的点 &#125; &#125; public String getFileName(String fileName) &#123; if (StringUtils.isBlank(fileName) || !fileName.contains(\"/\")) &#123; return \"\"; &#125; else &#123; return fileName.substring(fileName.lastIndexOf(\"/\") + 1); // 不带最后的点 &#125; &#125;&#125; 演示案例编写测试类 12345678910111213141516171819202122232425262728293031323334import cn.cicoding.service.FastDFSService;import org.apache.commons.io.IOUtils;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import java.io.File;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootFastdfsApplicationTests &#123; @Autowired private FastDFSService fastDFSService; @Test public void contextLoads() throws IOException &#123; String local_filename = \"C:\\\\Users\\\\Public\\\\Pictures\\\\Sample Pictures\\\\123.jpg\"; File f=new File(local_filename); String groupName= fastDFSService.upload(fastDFSService.File2byte(f),f.getName()); System.out.println(groupName); IOUtils.write(fastDFSService.download(groupName), new FileOutputStream(\"D:/app/fastdfs/\"+fastDFSService.getFileName(groupName))); System.out.println(fastDFSService.getFileInfo(groupName)); System.out.println(fastDFSService.getFileMate(groupName)); System.out.println(fastDFSService.delete(groupName)==0 ? \"删除成功\" : \"删除失败\"); &#125;&#125; 运行测试类得到结果： 1234group1/M00/00/00/wKgfZF3vl6WAJDW5AAvWFlS1kOw230.jpg123.jpg删除成功 源码可以加群获取！","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"https://www.cicoding.cn/tags/FastDFS/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"CentOS 7 安裝FastDFS V6.0.3","slug":"install-fastDFS-v6.0.3","date":"2019-12-12T00:55:24.000Z","updated":"2022-09-17T14:13:56.150Z","comments":true,"path":"install/install-fastDFS-v6.0.3/","link":"","permalink":"https://www.cicoding.cn/install/install-fastDFS-v6.0.3/","excerpt":"","text":"什么是FastDFS？FastDFS是一个开源的分布式文件系统，她对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。 FastDFS是一个应用级分布式文件存储服务，其采用中心型结构（类似GFS、HDFS、TFS等），主要用于大中型网站存储资源文件。FastDFS具有轻量级，支持高并发放访问，负载均衡，可扩展等优点。而FastDFS最大的亮点就是对小文件的存储性能较好，这主要来自于其文件名策略。 1.小文件存储性能优化小文件的性能瓶颈主要来自于对元数据服务器（如FastDFS中的TrackerServer或TFS中的NameServer）的访问，因为当文件本身大小很小时，元数据存储所占空间与文件内容存储所占空间的比例就变得较大，访问元数据所消耗资源与访问文件内容所消耗资源的比例也变得较大。因此，通常对小文件存储的优化方法主要有两大类思路：一是减少访问元数据的次数，比如Cache预取；二是减少元数据所占的存储空间，比如FastDFS使用的文件名策略。 2. FastDFS文件名策略FastDFS中的文件名是在向StorageServer存储文件时由系统指定的，文件名中包含了VolumeID和FileID。也就是说，当客户要读取某个文件时，通过在客户端对文件名进行解析，就可以知道该文件存储在哪个Volume上和它在StorageServer中的FileID。但是此时用户还不能读取文件，因为他不知道Volume内各个StorageServer的ip地址，也不知道应该从Volume内的哪个StorageServer中读取。所以用户需手持欲访问的文件的VolumeID向TrackerServer询问，TrackerServe会均衡当前各StorageServer的IO负载状况，返回一个最佳的StorageServer的ip地址。最后用户与该StorageServer连接，出示欲访问文件的FileID，StorageServer上会维持一个FileID对应偏移量的表，从而得到欲访问文件的偏移量。 可见，FastDFS的文件名策略将文件存储位置信息隐含在文件名中，从而减少了元数据量，达到了优化小文件存储性能的作用。 FastDFS服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。 上传交互过程编辑 client询问tracker上传到的storage，不需要附加参数； tracker返回一台可用的storage； client直接和storage通讯完成文件上传。 FastDFS file download 下载交互过程编辑 client询问tracker下载文件的storage，参数为文件标识（卷名和文件名）； tracker返回一台可用的storage； client直接和storage通讯完成文件下载。 需要说明的是，client为使用FastDFS服务的调用方，client也应该是一台服务器，它对tracker和storage的调用均为服务器间的调用。 存储节点存储文件，完成文件管理的所有功能：存储、同步和提供存取接口，FastDFS同时对文件的meta data进行管理。所谓文件的meta data就是文件的相关属性，以键值对（key value pair）方式表示，如：width=1024，其中的key为width，value为1024。文件meta data是文件属性列表，可以包含多个键值对。 FastDFS系统结构如下图所示： 准备好四个文件 下载地址： https://github.com/happyfish100 CentOS 7 FastDFS搭建安装libfastcommon上传到服务器,解压: 1[root@localhost home]# unzip libfastcommon-master.zip 进入libfastcommon-1.0.36目录: 123456789101112[root@localhost home]# cd libfastcommon-master/[root@localhost libfastcommon-master]# lltotal 32drwxr-xr-x. 2 root root 114 Dec 6 11:49 doc-rw-r--r--. 1 root root 10179 Dec 6 11:49 HISTORY-rw-r--r--. 1 root root 674 Dec 6 11:49 INSTALL-rw-r--r--. 1 root root 1607 Dec 6 11:49 libfastcommon.spec-rwxr-xr-x. 1 root root 3253 Dec 6 11:49 make.shdrwxr-xr-x. 2 root root 191 Dec 6 11:49 php-fastcommon-rw-r--r--. 1 root root 2776 Dec 6 11:49 READMEdrwxr-xr-x. 3 root root 4096 Dec 6 11:49 src[root@localhost libfastcommon-master]# 用yum安装gcc: Yum命令相当好用，是RedHad和CentOS从指定服务器下载RPM包并自动安装。我个人比较喜欢。 1[root@localhost libfastcommon-master]# yum -y install gcc-c++ Complete! 执行完成了！ 这个时候分别执行./make.sh和./make.sh install，正常情况是可以成功的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879[root@localhost libfastcommon-master]# ./make.shcc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o hash.o hash.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o chain.o chain.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o shared_func.o shared_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o ini_file_reader.o ini_file_reader.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o logger.o logger.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o sockopt.o sockopt.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o base64.o base64.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o sched_thread.o sched_thread.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o http_func.o http_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o md5.o md5.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o pthread_func.o pthread_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o local_ip_func.o local_ip_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o avl_tree.o avl_tree.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o ioevent.o ioevent.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o ioevent_loop.o ioevent_loop.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_task_queue.o fast_task_queue.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_timer.o fast_timer.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o process_ctrl.o process_ctrl.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_mblock.o fast_mblock.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o connection_pool.o connection_pool.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_mpool.o fast_mpool.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_allocator.o fast_allocator.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_buffer.o fast_buffer.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o multi_skiplist.o multi_skiplist.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o flat_skiplist.o flat_skiplist.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o system_info.o system_info.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o fast_blocked_queue.o fast_blocked_queue.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o id_generator.o id_generator.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o char_converter.o char_converter.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o char_convert_loader.o char_convert_loader.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o common_blocked_queue.o common_blocked_queue.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o multi_socket_client.o multi_socket_client.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o skiplist_set.o skiplist_set.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -o json_parser.o json_parser.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o hash.lo hash.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o chain.lo chain.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o shared_func.lo shared_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o ini_file_reader.lo ini_file_reader.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o logger.lo logger.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o sockopt.lo sockopt.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o base64.lo base64.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o sched_thread.lo sched_thread.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o http_func.lo http_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o md5.lo md5.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o pthread_func.lo pthread_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o local_ip_func.lo local_ip_func.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o avl_tree.lo avl_tree.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o ioevent.lo ioevent.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o ioevent_loop.lo ioevent_loop.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_task_queue.lo fast_task_queue.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_timer.lo fast_timer.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o process_ctrl.lo process_ctrl.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_mblock.lo fast_mblock.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o connection_pool.lo connection_pool.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_mpool.lo fast_mpool.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_allocator.lo fast_allocator.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_buffer.lo fast_buffer.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o multi_skiplist.lo multi_skiplist.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o flat_skiplist.lo flat_skiplist.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o system_info.lo system_info.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o fast_blocked_queue.lo fast_blocked_queue.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o id_generator.lo id_generator.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o char_converter.lo char_converter.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o char_convert_loader.lo char_convert_loader.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o common_blocked_queue.lo common_blocked_queue.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o multi_socket_client.lo multi_socket_client.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o skiplist_set.lo skiplist_set.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -c -fPIC -o json_parser.lo json_parser.c cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O3 -o libfastcommon.so -shared hash.lo chain.lo shared_func.lo ini_file_reader.lo logger.lo sockopt.lo base64.lo sched_thread.lo http_func.lo md5.lo pthread_func.lo local_ip_func.lo avl_tree.lo ioevent.lo ioevent_loop.lo fast_task_queue.lo fast_timer.lo process_ctrl.lo fast_mblock.lo connection_pool.lo fast_mpool.lo fast_allocator.lo fast_buffer.lo multi_skiplist.lo flat_skiplist.lo system_info.lo fast_blocked_queue.lo id_generator.lo char_converter.lo char_convert_loader.lo common_blocked_queue.lo multi_socket_client.lo skiplist_set.lo json_parser.lo -lm -ldl -lpthreadar rcs libfastcommon.a hash.o chain.o shared_func.o ini_file_reader.o logger.o sockopt.o base64.o sched_thread.o http_func.o md5.o pthread_func.o local_ip_func.o avl_tree.o ioevent.o ioevent_loop.o fast_task_queue.o fast_timer.o process_ctrl.o fast_mblock.o connection_pool.o fast_mpool.o fast_allocator.o fast_buffer.o multi_skiplist.o flat_skiplist.o system_info.o fast_blocked_queue.o id_generator.o char_converter.o char_convert_loader.o common_blocked_queue.o multi_socket_client.o skiplist_set.o json_parser.o[root@localhost libfastcommon-master]# ./make.sh installmkdir -p /usr/lib64mkdir -p /usr/libmkdir -p /usr/include/fastcommoninstall -m 755 libfastcommon.so /usr/lib64install -m 644 common_define.h hash.h chain.h logger.h base64.h shared_func.h pthread_func.h ini_file_reader.h _os_define.h sockopt.h sched_thread.h http_func.h md5.h local_ip_func.h avl_tree.h ioevent.h ioevent_loop.h fast_task_queue.h fast_timer.h process_ctrl.h fast_mblock.h connection_pool.h fast_mpool.h fast_allocator.h fast_buffer.h skiplist.h multi_skiplist.h flat_skiplist.h skiplist_common.h system_info.h fast_blocked_queue.h php7_ext_wrapper.h id_generator.h char_converter.h char_convert_loader.h common_blocked_queue.h multi_socket_client.h skiplist_set.h fc_list.h json_parser.h /usr/include/fastcommonif [ ! -e /usr/lib/libfastcommon.so ]; then ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so; fi[root@localhost libfastcommon-master]# libfastcommon默认会被安装到/usr/lib64/libfastcommon.so但是FastDFS的主程序却在/usr/local/lib目录下 这个时候我们就要建立一个软链接了，实际上也相当于windows上的快捷方式。 ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 123456[root@localhost libfastcommon-master]# ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so[root@localhost libfastcommon-master]# ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.soln: failed to create symbolic link ‘/usr/lib/libfastcommon.so’: File exists[root@localhost libfastcommon-master]# ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so[root@localhost libfastcommon-master]# ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so[root@localhost libfastcommon-master]# 安装FastDFS解压FastDFS安装包 1[root@localhost home]# unzip fastdfs-master.zip 解压后看到： 123456789[root@localhost home]# lltotal 2144drwx------. 2 dev1 dev1 62 Apr 11 2018 dev1drwxr-xr-x. 12 root root 4096 Dec 8 10:17 fastdfs-master-rw-r--r--. 1 root root 905173 Dec 10 20:24 fastdfs-master.zip-rw-r--r--. 1 root root 22492 Dec 10 20:24 fastdfs-nginx-module-master.zipdrwxr-xr-x. 5 root root 153 Dec 10 20:37 libfastcommon-master-rw-r--r--. 1 root root 218881 Dec 10 20:24 libfastcommon-master.zip-rw-r--r--. 1 root root 1037527 Dec 10 20:24 nginx-1.17.6.tar.gz 进到刚解压的目录 123[root@localhost home]# cd fastdfs-master/[root@localhost fastdfs-master]# ./make.sh[root@localhost fastdfs-master]# ./make.sh install 如果没有报错那么就成功了。安装log中会提示FastDFS安装到了/etc/fdfs目录下。 成功后查看安装目录： 12345678[root@localhost fastdfs-master]# cd /etc/fdfs/[root@localhost fdfs]# lltotal 28-rw-r--r--. 1 root root 1909 Dec 10 20:40 client.conf.sample-rw-r--r--. 1 root root 10246 Dec 10 20:40 storage.conf.sample-rw-r--r--. 1 root root 620 Dec 10 20:40 storage_ids.conf.sample-rw-r--r--. 1 root root 8128 Dec 10 20:40 tracker.conf.sample[root@localhost fdfs]# 我们需要把这三个示例文件复制一份，去掉.sample。 12345678910111213[root@localhost fdfs]# cp client.conf.sample client.conf[root@localhost fdfs]# cp storage.conf.sample storage.conf[root@localhost fdfs]# cp tracker.conf.sample tracker.conf[root@localhost fdfs]# lltotal 52-rw-r--r--. 1 root root 1909 Dec 10 20:40 client.conf-rw-r--r--. 1 root root 1909 Dec 10 20:40 client.conf.sample-rw-r--r--. 1 root root 10246 Dec 10 20:40 storage.conf-rw-r--r--. 1 root root 10246 Dec 10 20:40 storage.conf.sample-rw-r--r--. 1 root root 620 Dec 10 20:40 storage_ids.conf.sample-rw-r--r--. 1 root root 8128 Dec 10 20:40 tracker.conf-rw-r--r--. 1 root root 8128 Dec 10 20:40 tracker.conf.sample[root@localhost fdfs]# FastDFS安装结束。 安装tracker创建tracker工作目录这个目录可以自定义，用来保存tracker的data和log 根据个人习惯，我创建了下面的目录： 123456789[root@localhost ~]# mkdir /data[root@localhost ~]# cd /data/[root@localhost data]# mkdir fastdfs[root@localhost data]# cd fastdfs/[root@localhost fastdfs]# mkdir fastdfs_tracker[root@localhost fastdfs]# cd fastdfs_tracker/[root@localhost fastdfs_tracker]# pwd/data/fastdfs/fastdfs_tracker[root@localhost fastdfs_tracker]# 配置tracker123[root@localhost fastdfs-5.11]# cd /etc/fdfs/[root@localhost fastdfs-5.11]# vim tracker.conf[root@localhost fastdfs-5.11]# 最小化的CentOS7是没有安装vim的，可以把vim tracker.conf命令改成vi tracker.conf，也可以去下载一个vim yum -y install vim 打开后重点关注下面4个配置： 1234disabled = falseport=22122base_path=/data/fastdfs/fastdfs_trackerhttp.server_port=6666 # 默认8080 9901 启动tracker保存配置后启动tracker，命令如下： 1service fdfs_trackerd start 如果不能启动，或提示用systemctl可改用命令： 1systemctl start fdfs_trackerd 成功后应该可以看到： 1234[root@localhost fdfs]# service fdfs_trackerd startReloading systemd: [ OK ]Starting fdfs_trackerd (via systemctl): [ OK ][root@localhost fdfs]# 进行刚刚创建的tracker目录，发现目录中多了data和log两个目录 123456[root@localhost fdfs]# cd /data/fastdfs/fastdfs_tracker/[root@localhost fastdfs_tracker]# lltotal 0drwxr-xr-x. 2 root root 83 Dec 10 20:45 datadrwxr-xr-x. 2 root root 26 Dec 10 20:44 logs[root@localhost fastdfs_tracker]# 最后我们需要给tracker加入开机启动 123[root@localhost fastdfs_tracker]# ll /etc/rc.d/rc.local-rw-r--r--. 1 root root 473 Feb 20 2019 /etc/rc.d/rc.local[root@localhost fastdfs_tracker]# 发现并没有执行权限，需要加一下： 12[root@localhost fastdfs_tracker]# chmod +x /etc/rc.d/rc.local[root@localhost fastdfs_tracker]# 加完后应该是这样的： 123[root@localhost fastdfs_tracker]# ll /etc/rc.d/rc.local -rwxr-xr-x. 1 root root 473 Feb 20 2019 /etc/rc.d/rc.local[root@localhost fastdfs_tracker]# 修改rc.local 123456789101112131415[root@localhost fastdfs_tracker]# vim /etc/rc.d/rc.local#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure# that this script will be executed during boot.touch /var/lock/subsys/localservice fdfs_trackerd start 查看一下tracker的端口监听情况 123[root@localhost fastdfs_tracker]# netstat -unltp|grep fdfstcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 20553/fdfs_trackerd [root@localhost fastdfs_tracker]# 端口22122成功监听。 安装storagestorage的安装与tracker很类似。 为storage配置工作目录与tracker不现的是，由于storage还需要一个目录用来存储数据，所以我另外多建了一个fasdfs_storage_data 下面是我的目录结构： 123456789[root@localhost fastdfs]# cd /data/fastdfs[root@localhost fastdfs]# mkdir fastdfs_storage[root@localhost fastdfs]# mkdir fastdfs_storage_data[root@localhost fastdfs]# lltotal 0drwxr-xr-x. 2 root root 6 Dec 10 20:43 fastdfs_storagedrwxr-xr-x. 2 root root 6 Dec 10 20:43 fastdfs_storage_datadrwxr-xr-x. 4 root root 30 Dec 10 20:42 fastdfs_tracker[root@localhost fastdfs]# 修改storage配置文件修改storage.conf 12345678910111213[root@localhost fastdfs]# vim /etc/fdfs/storage.confdisabled=false group_name=group1 #组名，根据实际情况修改 port=23000 #设置storage的端口号，默认是23000，同一个组的storage端口号必须一致 base_path=/data/fastdfs/fastdfs_storage #设置storage数据文件和日志目录 store_path_count=1 #存储路径个数，需要和store_path个数匹配 》》》》》store_path0=/data/fastdfs/fastdfs_storage_data #实际文件存储路径 》》》》》base_path0=/data/fastdfs/fastdfs_storage_data #实际文件存储路径 tracker_server=192.168.31.100:22122 #我CentOS7的ip地址 http.server_port=8888 #设置 http 端口号[root@localhost fastdfs]# 修改保存后创建软引用 12[root@localhost fastdfs]# ln -s /usr/bin/fdfs_storaged /usr/local/bin[root@localhost fastdfs]# 启动storage1service fdfs_storaged start 如果不能启动，或提示用systemctl可改用命令： systemctl start fdfs_storaged 成功后应该可以看到： 123[root@localhost fastdfs]# service fdfs_storaged startStarting fdfs_storaged (via systemctl): [ OK ][root@localhost fastdfs]# 同样的，设置开机启动： 修改rc.local 123456789101112131415#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure# that this script will be executed during boot.touch /var/lock/subsys/localservice fdfs_trackerd startservice fdfs_storaged start 查看一下服务是否启动 1234[root@localhost fastdfs]# netstat -unltp | grep fdfstcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 20553/fdfs_trackerd tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 20817/fdfs_storaged [root@localhost fastdfs]# 校验整合到这里，fastdfs的东西都已安装完成，最后我们还要确定一下，storage是否注册到了tracker中去。 查看命令： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[root@localhost fastdfs]# /usr/bin/fdfs_monitor /etc/fdfs/storage.conf[2019-12-10 21:04:31] DEBUG - base_path=/data/fastdfs/fastdfs_storage, connect_timeout=5, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=1, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0server_count=1, server_index=0tracker server is 192.168.31.100:22122group count: 1Group 1:group name = group1disk total space = 51175 MBdisk free space = 48527 MBtrunk free space = 0 MBstorage server count = 1active server count = 1storage server port = 23000storage HTTP port = 8888store path count = 1subdir count per path = 256current write server index = 0current trunk file id = 0 Storage 1: id = 10.254.193.118 ip_addr = 10.254.193.118 (anantes-651-1-49-net.w2-0.abo.wanadoo.fr) ACTIVE http domain = version = 6.04 join time = 2019-12-10 21:01:47 up time = 2019-12-10 21:01:47 total storage = 51175 MB free storage = 48527 MB upload priority = 10 store_path_count = 1 subdir_count_per_path = 256 storage_port = 23000 storage_http_port = 8888 current_write_path = 0 source storage id = if_trunk_server = 0 connection.alloc_count = 256 connection.current_count = 0 connection.max_count = 0 total_upload_count = 0 success_upload_count = 0 total_append_count = 0 success_append_count = 0 total_modify_count = 0 success_modify_count = 0 total_truncate_count = 0 success_truncate_count = 0 total_set_meta_count = 0 success_set_meta_count = 0 total_delete_count = 0 success_delete_count = 0 total_download_count = 0 success_download_count = 0 total_get_meta_count = 0 success_get_meta_count = 0 total_create_link_count = 0 success_create_link_count = 0 total_delete_link_count = 0 success_delete_link_count = 0 total_upload_bytes = 0 success_upload_bytes = 0 total_append_bytes = 0 success_append_bytes = 0 total_modify_bytes = 0 success_modify_bytes = 0 stotal_download_bytes = 0 success_download_bytes = 0 total_sync_in_bytes = 0 success_sync_in_bytes = 0 total_sync_out_bytes = 0 success_sync_out_bytes = 0 total_file_open_count = 0 success_file_open_count = 0 total_file_read_count = 0 success_file_read_count = 0 total_file_write_count = 0 success_file_write_count = 0 last_heart_beat_time = 2019-12-10 21:04:20 last_source_update = 1970-01-01 08:00:00 last_sync_update = 1970-01-01 08:00:00 last_synced_timestamp = 1970-01-01 08:00:00 [root@localhost fastdfs]# 测试前面已对FastDFS的安装和配置，做了比较详细的讲解。FastDFS的基础模块都搭好了，现在开始测试下载。 配置客户端同样的，需要修改客户端的配置文件： 1234[root@localhost fastdfs]# vim /etc/fdfs/client.confbase_path = /data/fastdfs/fastdfs_trackertracker_server = 192.168.31.100:22122http.tracker_server_port = 6666 # 默认端口80 通过ftp上传图片到CentOS: 在我的windows上，我随便拖了一张图片上去。 1234567891011[root@localhost fastdfs]# cd /home/[root@localhost home]# lltotal 1148-rw-r--r--. 1 root root 18832 Oct 12 12:58 123.pngdrwx------. 2 dev1 dev1 62 Apr 11 2018 dev1drwxr-xr-x. 12 root root 4096 Dec 8 10:17 fastdfs-5.11-rw-r--r--. 1 root root 905173 Dec 10 11:38 fastdfs-5.11.zip-rw-r--r--. 1 root root 22492 Dec 10 11:38 fastdfs-nginx-module-master.zipdrwxr-xr-x. 5 root root 153 Dec 10 19:48 libfastcommon-1.0.36-rw-r--r--. 1 root root 218881 Dec 10 11:36 libfastcommon-1.0.36.zip[root@localhost home]# 模拟上传确定图片位置后，我们输入上传图片命令： 123[root@localhost home]# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /home/123.jpg group1/M00/00/00/wKgfZF3vl6WAJDW5AAvWFlS1kOw230.jpg[root@localhost home]# 成功后会返回图片的路径： [root@localhost~]# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /home/123.png group1/M00/00/00/wKgfZF3vl6WAJDW5AAvWFlS1kOw230.jpg 组名：group1 磁盘：M00 目录：00/00 文件名称：wKgfZF3vl6WAJDW5AAvWFlS1kOw230.png 我们上传的图片会被上传到我们创建的storage_data目录下，让我们去看看： 1234567891011121314151617181920[root@localhost fastdfs_storage_data]# cd /data/fastdfs/fastdfs_storage_data/data/[root@localhost data]# ls00 06 0C 12 18 1E 24 2A 30 36 3C 42 48 4E 54 5A 60 66 6C 72 78 7E 84 8A 90 96 9C A2 A8 AE B4 BA C0 C6 CC D2 D8 DE E4 EA F0 F6 FC01 07 0D 13 19 1F 25 2B 31 37 3D 43 49 4F 55 5B 61 67 6D 73 79 7F 85 8B 91 97 9D A3 A9 AF B5 BB C1 C7 CD D3 D9 DF E5 EB F1 F7 FD02 08 0E 14 1A 20 26 2C 32 38 3E 44 4A 50 56 5C 62 68 6E 74 7A 80 86 8C 92 98 9E A4 AA B0 B6 BC C2 C8 CE D4 DA E0 E6 EC F2 F8 FE03 09 0F 15 1B 21 27 2D 33 39 3F 45 4B 51 57 5D 63 69 6F 75 7B 81 87 8D 93 99 9F A5 AB B1 B7 BD C3 C9 CF D5 DB E1 E7 ED F3 F9 FF04 0A 10 16 1C 22 28 2E 34 3A 40 46 4C 52 58 5E 64 6A 70 76 7C 82 88 8E 94 9A A0 A6 AC B2 B8 BE C4 CA D0 D6 DC E2 E8 EE F4 FA05 0B 11 17 1D 23 29 2F 35 3B 41 47 4D 53 59 5F 65 6B 71 77 7D 83 89 8F 95 9B A1 A7 AD B3 B9 BF C5 CB D1 D7 DD E3 E9 EF F5 FB[root@localhost data]# cd 00/[root@localhost 00]# ls00 06 0C 12 18 1E 24 2A 30 36 3C 42 48 4E 54 5A 60 66 6C 72 78 7E 84 8A 90 96 9C A2 A8 AE B4 BA C0 C6 CC D2 D8 DE E4 EA F0 F6 FC01 07 0D 13 19 1F 25 2B 31 37 3D 43 49 4F 55 5B 61 67 6D 73 79 7F 85 8B 91 97 9D A3 A9 AF B5 BB C1 C7 CD D3 D9 DF E5 EB F1 F7 FD02 08 0E 14 1A 20 26 2C 32 38 3E 44 4A 50 56 5C 62 68 6E 74 7A 80 86 8C 92 98 9E A4 AA B0 B6 BC C2 C8 CE D4 DA E0 E6 EC F2 F8 FE03 09 0F 15 1B 21 27 2D 33 39 3F 45 4B 51 57 5D 63 69 6F 75 7B 81 87 8D 93 99 9F A5 AB B1 B7 BD C3 C9 CF D5 DB E1 E7 ED F3 F9 FF04 0A 10 16 1C 22 28 2E 34 3A 40 46 4C 52 58 5E 64 6A 70 76 7C 82 88 8E 94 9A A0 A6 AC B2 B8 BE C4 CA D0 D6 DC E2 E8 EE F4 FA05 0B 11 17 1D 23 29 2F 35 3B 41 47 4D 53 59 5F 65 6B 71 77 7D 83 89 8F 95 9B A1 A7 AD B3 B9 BF C5 CB D1 D7 DD E3 E9 EF F5 FB[root@localhost 00]# cd 00[root@localhost 00]# lswKgfZF3vl6WAJDW5AAvWFlS1kOw230.png[root@localhost 00]# 果然通过刚刚返回的路径，我们成功找到了图片。 我们仔细看一下，实际文件存储路径下有创建好的多级目录。data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件，新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。 HTTP访问文件我们去浏览器用http请求访问一下刚刚的图片： 这里写图片描述 我们发现，http不能直接访问到图片。这是为什么呢。 我去官网看了一原码，在HISTORY中发现，原来早在4.05的时候，就remove embed HTTP support Version 4.05 2012-12-30 * client/fdfs_upload_file.c can specify storage ip port and store path index * add connection pool * client load storage ids config * common/ini_file_reader.c does NOT call chdir * keep the mtime of file same * use g_current_time instead of call time function * remove embed HTTP support HTTP请求不能访问文件的原因我们在使用FastDFS部署一个分布式文件系统的时候，通过FastDFS的客户端API来进行文件的上传、下载、删除等操作。同时通过FastDFS的HTTP服务器来提供HTTP服务。但是FastDFS的HTTP服务较为简单，无法提供负载均衡等高性能的服务，所以FastDFS的开发者——淘宝的架构师余庆同学，为我们提供了Nginx上使用的FastDFS模块（也可以叫FastDFS的Nginx模块）。 FastDFS通过Tracker服务器,将文件放在Storage服务器存储,但是同组之间的服务器需要复制文件,有延迟的问题.假设Tracker服务器将文件上传到了192.168.128.131,文件ID已经返回客户端,这时,后台会将这个文件复制到192.168.128.131,如果复制没有完成,客户端就用这个ID在192.168.128.131取文件,肯定会出现错误。这个fastdfs-nginx-module可以重定向连接到源服务器取文件,避免客户端由于复制延迟的问题,出现错误。 正是这样，FastDFS需要结合nginx，所以取消原来对HTTP的直接支持。 FastDFS的nginx模块安装安装nginx准备将nginx-1.17.6.tar.gz上传至linux 12345678910111213[root@localhost 00]# cd /home/[root@lml74xunyuanfuwuqi home]# ll总用量 2164-rw-r--r-- 1 root root 18832 10月 12 12:58 123.pngdrwx------ 2 dceq dceq 62 11月 15 18:14 dceqdrwxr-xr-x 12 root root 4096 12月 8 10:17 fastdfs-master-rw-r--r-- 1 root root 905173 12月 10 11:38 fastdfs-master.zip-rw-r--r-- 1 root root 22492 12月 10 11:38 fastdfs-nginx-module-master.zipdrwxr-xr-x 5 root root 153 12月 11 15:07 libfastcommon-master-rw-r--r-- 1 root root 218881 12月 10 11:36 libfastcommon-master.zip-rw-r--r-- 1 root root 1037527 12月 10 13:38 nginx-1.17.6.tar.gzdrwxr-xr-x 3 root root 21 12月 11 09:03 work[root@localhost home]# 在安装nginx之前要安装nginx所需的依赖lib: 123[root@localhost home]# yum -y install pcre pcre-devel [root@localhost home]# yum -y install zlib zlib-devel[root@localhost home]# yum -y install openssl openssl-devel 安装nginx并添加fastdfs-nginx-module解压nginx,和fastdfs-nginx-module: 12[root@localhost home]# tar -zxvf nginx-1.17.6.tar.gz [root@localhost home]# unzip fastdfs-nginx-module-master.zip 解压后进入nginx目录编译安装nginx,并添加fastdfs-nginx-module： 1234[root@lml74xunyuanfuwuqi home]# cd nginx-1.17.6[root@localhost nginx-1.17.6]# ./configure --prefix=/usr/local/nginx --add-module=/home/fastdfs-nginx-module-master/src#解压后fastdfs-nginx-module所在的位置 如果配置不报错的话，就开始编译： 12[root@localhost nginx-1.17.6]# make[root@localhost nginx-1.17.6]# make install 如果报错的话，很可能是版本的原因，在我的第二篇博文中提供了我测试成功不报错的版本下载。 nginx的默认目录是/usr/local/nginx，安装成功后查看： 12345678910[root@localhost nginx-1.17.6]# cd /usr/local/nginx/[root@localhost nginx]# lltotal 4drwxr-xr-x. 2 root root 4096 Dec 10 21:06 confdrwxr-xr-x. 2 root root 40 Dec 10 21:06 htmldrwxr-xr-x. 2 root root 6 Dec 10 21:06 logsdrwxr-xr-x. 2 root root 19 Dec 10 21:06 sbin[root@lml74xunyuanfuwuqi nginx]# cd conf/[root@localhost nginx]# [root@lml74xunyuanfuwuqi conf]# vi nginx.conf 配置storage nginx修改nginx.conf: 修改监听端口 listen 9999， 新增location 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144[root@localhost nginx]# cd conf/[root@localhost conf]# lltotal 68-rw-r--r--. 1 root root 1077 Dec 10 21:06 fastcgi.conf-rw-r--r--. 1 root root 1077 Dec 10 21:06 fastcgi.conf.default-rw-r--r--. 1 root root 1007 Dec 10 21:06 fastcgi_params-rw-r--r--. 1 root root 1007 Dec 10 21:06 fastcgi_params.default-rw-r--r--. 1 root root 2837 Dec 10 21:06 koi-utf-rw-r--r--. 1 root root 2223 Dec 10 21:06 koi-win-rw-r--r--. 1 root root 5231 Dec 10 21:06 mime.types-rw-r--r--. 1 root root 5231 Dec 10 21:06 mime.types.default-rw-r--r--. 1 root root 2656 Dec 10 21:06 nginx.conf-rw-r--r--. 1 root root 2656 Dec 10 21:06 nginx.conf.default-rw-r--r--. 1 root root 636 Dec 10 21:06 scgi_params-rw-r--r--. 1 root root 636 Dec 10 21:06 scgi_params.default-rw-r--r--. 1 root root 664 Dec 10 21:06 uwsgi_params-rw-r--r--. 1 root root 664 Dec 10 21:06 uwsgi_params.default-rw-r--r--. 1 root root 3610 Dec 10 21:06 win-utf[root@localhost conf]# vi nginx.conf#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 9999; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; location ~/group1/M00 &#123; root /data/fastdfs/fastdfs_storage_data/data; ngx_fastdfs_module; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125;[root@localhost conf]# [root@localhost conf]# 然后进入FastDFS安装时的解压过的目录，将http.conf和mime.types拷贝到/etc/fdfs目录下： 1234567891011121314[root@localhost conf]# cd /home/fastdfs-master/conf/[root@localhost conf]# lltotal 88-rw-r--r--. 1 root root 23981 Dec 8 10:17 anti-steal.jpg-rw-r--r--. 1 root root 1909 Dec 8 10:17 client.conf-rw-r--r--. 1 root root 965 Dec 8 10:17 http.conf-rw-r--r--. 1 root root 31172 Dec 8 10:17 mime.types-rw-r--r--. 1 root root 10246 Dec 8 10:17 storage.conf-rw-r--r--. 1 root root 620 Dec 8 10:17 storage_ids.conf-rw-r--r--. 1 root root 8128 Dec 8 10:17 tracker.conf[root@localhost conf]# [root@localhost conf]# cp http.conf /etc/fdfs/[root@localhost conf]# cp mime.types /etc/fdfs/[root@localhost conf]# 另外还需要把fastdfs-nginx-module安装目录中src目录下的mod_fastdfs.conf也拷贝到/etc/fdfs目录下： 12[root@localhost conf]# cp /home/fastdfs-nginx-module-master/src/mod_fastdfs.conf /etc/fdfs/[root@localhost conf]# 对刚刚拷贝的mod_fastdfs.conf文件进行修改： 1234567891011121314151617181920212223242526272829303132[root@localhost conf]# vim /etc/fdfs/mod_fastdfs.conf! base_path=/data/fastdfs/fastdfs_storage #保存日志目录! tracker_server=192.168.31.100:22122 #tracker服务器的IP地址以及端口号! storage_server_port=23000 #storage服务器的端口号! url_have_group_name = true #文件 url 中是否有 group 名! store_path0=/data/fastdfs/fastdfs_storage_data #存储路径group_count = 3 #设置组的个数，事实上这次只使用了group1在文件的最后，设置group[group1]group_name=group1storage_server_port=23000store_path_count=1store_path0=/data/fastdfs/fastdfs_storage_datastore_path1=/data/fastdfs/fastdfs_storage_data# group settings for group #2# # since v1.14# # when support multi-group, uncomment following section as neccessary[group2]group_name=group2storage_server_port=23000store_path_count=1store_path0=/data/fastdfs/fastdfs_storage_data[group3]group_name=group3storage_server_port=23000store_path_count=1store_path0=/data/fastdfs/fastdfs_storage_data[root@localhost conf]# 创建M00至storage存储目录的符号连接： 12[root@localhost conf]# ln -s /data/fastdfs/fastdfs_storage_data/data/ /data/fastdfs/fastdfs_storage_data/data/M00[root@localhost conf]# 启动nginx: 123[root@localhost conf]# /usr/local/nginx/sbin/nginx ngx_http_fastdfs_set pid=31687[root@localhost conf]# 成功启动： 123[root@localhost conf]# /usr/local/nginx/sbin/nginx ngx_http_fastdfs_set pid=31687[root@localhost conf]# 恭喜你，storage的nginx已配置成功。接下来，我们还要继续配置tracker的nginx。 配置tracker nginx再解压一个nginx： 我在我自己的工作下再建了一个nginx2，把原来的nginx-1.12.0.tar.gz又解压了一份到里面 12345[root@localhost home]# mkdir nginx2[root@localhost home]# tar -zxvf nginx-1.17.6.tar.gz -C nginx2/[root@localhost home]# cd nginx2/nginx-1.17.6/[root@localhost nginx-1.17.6]# ./configure --prefix=/usr/local/nginx2 --add-module=/home/fastdfs-nginx-module-master/src[root@localhost nginx-1.17.6]# make &amp;&amp; make install 接下来，一样的还是修改nginx.conf，端口号可以不改，用80的。需将upstream指向tracker的nginx地址。 123456789101112131415161718192021222324252627282930[root@localhost nginx-1.17.6]# vim /usr/local/nginx2/conf/nginx.conf upstream fdfs_group1 &#123; server 127.0.0.1:9999; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /group1/M00 &#123; proxy_pass http://fdfs_group1; &#125; #location / &#123; # root html; # index index.html index.htm; #&#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; 启动nginx2: 1[root@localhost nginx-1.17.6]# /usr/local/nginx2/sbin/nginx 可以成功访问。 防火墙端口设置成功了，为什么还要讲这个呢。因为有些同学到这里，还是不到访问，很可能是防火墙没有开启相应的端口。防火墙这个东西我建议大家还是不要关闭，虽然麻烦了一点。 查看已开启的端口： 123[root@localhost nginx-1.13.8]# firewall-cmd --zone=public --list-ports20880/tcp 80/tcp 2181/tcp 23000/tcp 22122/tcp 9999/tcp[root@localhost nginx-1.13.8]# 在我的CentOS上这些端口都是开放的。storage:20880tracker:23000这两个端口要开启，到时候下一篇讲fastdfs-client-javas可能会造成无法连接。9999和80端口是提供给nginx访问的。开放端口号命令：–permanent表示永久生效，不加的话，重启后不生效 1firewall-cmd --zone=public --add-port=23000/tcp --permanent #开户端口号 CentOS7 防火墙相关命令： 123systemctl enable firewalld.service #开启防火墙systemctl stop firewalld.service #关闭防火墙(开机会仍会启动)systemctl disable firewalld.service #禁用防火墙(开机后不再启动) HTTP测试现在我们再去访问一下，原来我们上传过的文件： 这个时候已经能成功访问。","categories":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}],"tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"https://www.cicoding.cn/tags/FastDFS/"}],"keywords":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}]},{"title":"对Redis的理解，Redis是什么，Redis和Memcache谁快？","slug":"redis-and-memcache","date":"2019-12-02T00:15:43.000Z","updated":"2022-09-17T14:13:56.170Z","comments":false,"path":"redis/redis-and-memcache/","link":"","permalink":"https://www.cicoding.cn/redis/redis-and-memcache/","excerpt":"","text":"​ 前段时间微博发生了一起大的系统故障，结果说是因为Redis集群的问题，很多技术的朋友都比较关心，其中的原因不会超出James Hamilton 在On Designing and Deploying Internet-Scale Service 概括的那几个范围，James 第一条经验“Design for failure ”是所有互联网架构成功的一个关键。互联网系统的工程理论其实非常简单，James paper 中内容几乎称不上理论，而是多条实践经验分享，每个公司对这些经验的理解及执行力决定了架构成败。 题外话说完，最近又研究了 Redis 。去年曾做过一个MemcacheDB, Tokyo Tyrant, Redis performance test ，到目前为止，这个benchmark 结果依然有效。这1年我们经历了很多眼花缭乱的key / value 存储产品的诱惑，从Cassandra的淡出(Twitter 暂停在主业务使用)到Hbase 的兴起(Facebook新的邮箱业务选用HBase)，当再回头再去看Redis，发现这个只有1万多行源代码的程序充满了神奇及大量未经挖掘的特性。Redis性能惊人，国内前十大网站的子产品估计用1台Redis就可以满足存储及Cache的需求。除了性能印象之外，业界其实普遍对Redis的认识存在一定误区。本文提出一些观点供大家探讨。 一、 Redis是什么？这个问题的结果影响了我们怎么用 Redis 。如果你认为 Redis 是一个key value store , 那可能会用它来代替 MySQL ；如果认为它是一个可以持久化的cache , 可能只是它保存一些频繁访问的临时数据。 Redis 是REmote DIctionary Server 的缩写，在 Redis 在官方网站的的副标题是A persistent key-value database with built-in net interface written in ANSI-C for Posix systems ，这个定义偏向key value store 。还有一些看法则认为 Redis 是一个memory database ，因为它的高性能都是基于内存操作的基础。另外一些人则认为 Redis 是一个data structure server ，因为Redis支持复杂的数据特性，比如List, Set等。对Redis的作用的不同解读决定了你对Redis的使用方式。 互联网数据目前基本使用两种方式来存储，关系数据库或者key value。但是这些互联网业务本身并不属于这两种数据类型，比如用户在社会化平台中的关系，它是一个list，如果要用关系数据库存储就需要转换成一种多行记录的形式，这种形式存在很多冗余数据，每一行需要存储一些重复信息。如果用key value存储则修改和删除比较麻烦，需要将全部数据读出再写入。Redis在内存中设计了各种数据类型，让业务能够高速原子的访问这些数据结构，并且不需要关心持久存储的问题，从架构上解决了前面两种存储需要走一些弯路的问题。 二、Redis不可能比Memcache快？很多开发者都认为 Redis 不可能比 Memcached 快， Memcached 完全基于内存，而Redis 具有持久化保存特性，即使是异步的，Redis 也不可能比Memcached 快。但是测试结果基本是Redis占绝对优势。一直在思考这个原因，目前想到的原因有这几方面。 Libevent 和Memcached 不同，Redis并没有选择Libevent 。Libevent 为了迎合通用性造成代码庞大(目前Redis代码还不到libevent的1/3)及牺牲了在特定平台的不少性能。Redis用libevent 中两个文件修改实现了自己的epoll event loop 。业界不少开发者也建议Redis使用另外一个libevent高性能替代libev，但是作者还是坚持Redis应该小巧并去依赖的思路。一个印象深刻的细节是编译Redis之前并不需要执行./configure 。 CAS 问题。CAS 是Memcached 中比较方便的一种防止竞争修改资源的方法。CAS 实现需要为每个cache key设置一个隐藏的cas token ，cas 相当value 版本号，每次set 会token 需要递增，因此带来CPU和内存的双重开销，虽然这些开销很小，但是到单机10G+ cache以及QPS 上万之后这些开销就会给双方相对带来一些细微性能差别。 三、单台Redis的存放数据必须比物理内存小 Redis 的数据全部放在内存带来了高速的性能，但是也带来一些不合理之处。比如一个中型网站有100万注册用户，如果这些资料要用Redis来存储，内存的容量必须能够容纳这100万用户。但是业务实际情况是100万用户只有5万活跃用户，1周来访问过1次的也只有15万用户，因此全部100万用户的数据都放在内存有不合理之处，RAM需要为冷数据买单。 这跟操作系统非常相似，操作系统所有应用访问的数据都在内存，但是如果物理内存容纳不下新的数据，操作系统会智能将部分长期没有访问的数据交换到磁盘，为新的应用留出空间。现代操作系统给应用提供的并不是物理内存，而是虚拟内存(Virtual Memory )的概念。 基于相同的考虑，Redis 2.0 也增加了VM特性。让Redis 数据容量突破了物理内存的限制。并实现了数据冷热分离。 四、Redis的VM实现是重复造轮子Redis 的VM依照之前的epoll实现思路依旧是自己实现。但是在前面操作系统的介绍提到OS也可以自动帮程序实现冷热数据分离，Redis只需要OS申请一块大内存，OS会自动将热数据放入物理内存，冷数据交换到硬盘，另外一个知名的“理解了现代操作系统(3)”的Varnish就是这样实现，也取得了非常成功的效果。 作者antirez在解释为什么要自己实现VM中提到几个原因。主要OS的VM换入换出是基于Page 概念，比如OS VM1 个Page 是4K, 4K中只要还有一个元素即使只有1个字节被访问，这个页也不会被SWAP, 换入也同样道理，读到一个字节可能会换入4K无用的内存。而Redis自己实现则可以达到控制换入的粒度。另外访问操作系统SWAP内存区域时block进程，也是导致Redis要自己实现VM原因之一。 五、用get / set方式使用Redis作为一个key / value 存在，很多开发者自然的使用set/get 方式来使用 Redis ，实际上这并不是最优化的使用方法。尤其在未启用VM 情况下，Redis 全部数据需要放入内存，节约内存尤其重要。 假如一个key-value单元需要最小占用512字节，即使只存一个字节也占了512字节。这时候就有一个设计模式，可以把key复用，几个key-value放入一个key中，value再作为一个set存入，这样同样512字节就会存放10-100倍的容量。 这就是为了节约内存，建议使用hashset而不是set/get的方式来使用Redis。 六、使用aof代替snapshotRedis 有两种存储方式，默认是snapshot 方式，实现方法是定时将内存的快照(snapshot )持久化到硬盘，这种方法缺点是持久化之后如果出现crash则会丢失一段数据。因此在完美主义者的推动下作者增加了aof 方式。aof 即append only mode ，在写入内存数据的同时将操作命令保存到日志文件，在一个并发更改上万的系统中，命令日志是一个非常庞大的数据，管理维护成本非常高，恢复重建时间会非常长，这样导致失去aof 高可用性本意。另外更重要的是Redis 是一个内存数据结构模型，所有的优势都是建立在对内存复杂数据结构高效的原子操作上，这样就看出aof 是一个非常不协调的部分。 其实aof 目的主要是数据可靠性及高可用性，在 Redis 中有另外一种方法来达到目的：Replication 。由于 Redis 的高性能，复制基本没有延迟。这样达到了防止单点故障及实现了高可用。 转自：https://www.sojson.com/blog/243.html","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/tags/Redis/"},{"name":"Memcache","slug":"Memcache","permalink":"https://www.cicoding.cn/tags/Memcache/"}],"keywords":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/categories/Redis/"}]},{"title":"使用MongoDB的Spring Boot和MongoTemplate教程","slug":"springboot-and-mongotemplate-tutorials","date":"2019-11-26T00:19:43.000Z","updated":"2022-09-17T14:13:56.181Z","comments":true,"path":"springboot/springboot-and-mongotemplate-tutorials/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-and-mongotemplate-tutorials/","excerpt":"","text":"​ 在本教程中，我们将构建一个Spring Boot应用程序，该应用程序演示如何使用MongoTemplate API访问MongoDB数据库中的数据。 ​ 对于MongoDB，我们将使用mLab，它提供了MongoDB数据库即服务平台，因此您甚至不必在计算机上安装MongoDB数据库。 配置​ 为了快速设置我们的项目，我们将使用一个称为Spring Initializr的工具。使用此工具，我们可以快速提供所需的依赖项列表并下载引导程序： 使用Spring Initializr创建新的Spring Boot项目时，仅选择两个依赖项： Web (Spring Boot Starter Web) MongoDB (MongoDB Starter) Maven Dependencies 当下载使用Spring Initializr生成的项目并打开其pom.xml文件时，您应该看到添加了以下依赖项： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 项目结构 在继续进行并开始处理该项目的代码之前，让我们介绍一下完成所有代码添加到项目后将拥有的项目结构： 该代码以多个程序包进行组织，因此遵循关注点分离的原则，并且代码保持模块化。 创建数据库​ 对于MongoDB，我们将使用mLab。您可以使用mLab创建一个免费帐户，并在云中使用MongoDB，而无需在计算机上下载和安装它。 登录到mLab后，您将看到一个类似的仪表板： 要创建一个新的MongoDB数据库，请单击创建新按钮： 输入所有详细信息后，我们可以确认： 完成此操作后，我们将看到一个连接字符串，如下图所示： 在开始使用此数据库之前，我们还需要创建一个用户。让我们在上图所示的“用户”标签上执行此操作： 现在，我们已经准备好继续写些Java代码，因为我们的mLab数据库已经完全准备就绪。 应用配置 使用Spring Boot，仅使用MongoDB连接String的单个必需属性即可轻松配置我们的应用程序： 12345# application propertiesserver.port=8090# MongoDB propertiesspring.data.mongodb.uri=mongodb://cicoding.cn:password@ds915721.mlab.com:29670/cicoding_db 我们只是提供了一个MongoDB连接字符串，该字符串将由Spring Boot读取，并且将使用内部API建立连接。 建立模型 我们将创建一个简单的Person实体，其中包含一些字段，我们将使用它们来演示简单的MongoDB查询： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.cicoding.mongotemplatedemo.model;import org.springframework.data.annotation.Id;import org.springframework.data.mongodb.core.mapping.Document;import java.util.Calendar;import java.util.Date;import java.util.List;import java.util.Locale;import static java.util.Calendar.DATE;import static java.util.Calendar.MONTH;import static java.util.Calendar.YEAR;@Document(collection = \"person\")public class Person &#123; @Id private String personId; private String name; private long age; private List&lt;String&gt; favoriteBooks; private Date dateOfBirth; public Person() &#123; &#125; public Person(String name, List&lt;String&gt; childrenName, Date dateOfBirth) &#123; this.name = name; this.favoriteBooks = childrenName; this.dateOfBirth = dateOfBirth; this.age = getDiffYears(dateOfBirth, new Date()); &#125; // standard getters and setters private int getDiffYears(Date first, Date last) &#123; Calendar a = getCalendar(first); Calendar b = getCalendar(last); int diff = b.get(YEAR) - a.get(YEAR); if (a.get(MONTH) &gt; b.get(MONTH) || (a.get(MONTH) == b.get(MONTH) &amp;&amp; a.get(DATE) &gt; b.get(DATE))) &#123; diff--; &#125; return diff; &#125; private Calendar getCalendar(Date date) &#123; Calendar cal = Calendar.getInstance(Locale.US); cal.setTime(date); return cal; &#125; @Override public String toString() &#123; return String.format(\"Person&#123;personId='%s', name='%s', age=%d, dateOfBirth=%s&#125;\\n\", personId, name, age, dateOfBirth); &#125;&#125; 除了简单的字段外，我们还添加了一些帮助程序功能，可以在保存用户的出生日期时计算该用户的年龄。这使我们不必计算用户的年龄。 定义数据访问层接口 让我们定义一个数据层接口，该接口将通知我们在应用程序中将演示多少操作。这是界面： 1234567891011121314public interface PersonDAL &#123; Person savePerson(Person person); List&lt;Person&gt; getAllPerson(); List&lt;Person&gt; getAllPersonPaginated( int pageNumber, int pageSize); Person findOneByName(String name); List&lt;Person&gt; findByName(String name); List&lt;Person&gt; findByBirthDateAfter(Date date); List&lt;Person&gt; findByAgeRange(int lowerBound, int upperBound); List&lt;Person&gt; findByFavoriteBooks(String favoriteBook); void updateMultiplePersonAge(); Person updateOnePerson(Person person); void deletePerson(Person person);&#125; 这些是相当多的操作。真正的乐趣是当我们执行这些操作时，接下来将要做的事情。 实施数据访问层 我们将使用MongoTemplate bean，它是由Spring Boot使用上面在application.properties中定义的属性初始化的。让我们看看如何定义所需的bean： 123456789101112@Repositorypublic class PersonDALImpl implements PersonDAL &#123; private final MongoTemplate mongoTemplate; @Autowired public PersonDALImpl(MongoTemplate mongoTemplate) &#123; this.mongoTemplate = mongoTemplate; &#125; ...&#125; 我们将开始使用简单的方法来理解查询，首先是要保存并从数据库中获取所有人员： 12345678910@Overridepublic Person savePerson(Person person) &#123; mongoTemplate.save(person); return person;&#125;@Overridepublic List&lt;Person&gt; getAllPerson() &#123; return mongoTemplate.findAll(Person.class);&#125; MongoTemplate为我们提供了一些抽象方法，通过这些方法我们可以将对象保存到数据库中，也可以从数据库中获取所有数据。 使用分页查询 上述从数据库中获取所有人的方法的问题在于，数据库中可能有数千个对象。 我们应该始终在查询中实现分页，以便可以确保仅从数据库中提取有限的数据： 12345678@Overridepublic List&lt;Person&gt; getAllPersonPaginated(int pageNumber, int pageSize) &#123; Query query = new Query(); query.skip(pageNumber * pageSize); query.limit(pageSize); return mongoTemplate.find(query, Person.class);&#125; 这样，一次将仅从数据库中获取pageSize个对象。 通过精确值获取对象 我们也可以通过匹配数据库中的精确值来提取对象： 123456789101112131415@Overridepublic Person findOneByName(String name) &#123; Query query = new Query(); query.addCriteria(Criteria.where(&quot;name&quot;).is(name)); return mongoTemplate.findOne(query, Person.class);&#125;@Overridepublic List&lt;Person&gt; findByName(String name) &#123; Query query = new Query(); query.addCriteria(Criteria.where(&quot;name&quot;).is(name)); return mongoTemplate.find(query, Person.class);&#125; 我们展示了两种方法。第一种方法是从数据库中获取单个对象，而第二种方法是从数据库中获取具有匹配条件的所有对象。 按范围和数据列表查找 我们还可以找到具有指定范围内的字段值的对象。或具有特定日期之后的日期数据的对象。让我们看看如何做到这一点，以及如何构造相同的查询： 1234567891011121314151617181920212223@Overridepublic List&lt;Person&gt; findByBirthDateAfter(Date date) &#123; Query query = new Query(); query.addCriteria(Criteria.where(&quot;dateOfBirth&quot;).gt(date)); return mongoTemplate.find(query, Person.class);&#125;@Overridepublic List&lt;Person&gt; findByAgeRange(int lowerBound, int upperBound) &#123; Query query = new Query(); query.addCriteria(Criteria.where(&quot;age&quot;).gt(lowerBound) .andOperator(Criteria.where(&quot;age&quot;).lt(upperBound))); return mongoTemplate.find(query, Person.class);&#125;@Overridepublic List&lt;Person&gt; findByFavoriteBooks(String favoriteBook) &#123; Query query = new Query(); query.addCriteria(Criteria.where(&quot;favoriteBooks&quot;).in(favoriteBook)); return mongoTemplate.find(query, Person.class);&#125; 更新对象 我们可以使用Update查询更新MongoDB中的数据。我们可以找到一个对象，然后自己更新提供的字段： 12345678910111213@Overridepublic void updateMultiplePersonAge() &#123; Query query = new Query(); Update update = new Update().inc(&quot;age&quot;, 1); mongoTemplate.findAndModify(query, update, Person.class);;&#125;@Overridepublic Person updateOnePerson(Person person) &#123; mongoTemplate.save(person); return person;&#125; 在第一个查询中，由于没有向查询添加任何条件，因此我们收到了所有对象。接下来，我们提供了一个Update子句，其中所有用户的年龄都增加了一个。 删除对象 删除对象也与单个方法调用有关： 1234@Overridepublic void deletePerson(Person person) &#123; mongoTemplate.remove(person);&#125; 我们也可以简单地传递Query对象以及要删除的人的ID。 制作命令行运行器 我们将在适当的位置使用命令行运行程序来运行我们的应用程序，该命令行运行程序将提供我们在上面的数据访问层实现中定义的一些功能。这是命令行运行器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.cicoding.mongotemplatedemo;import com.cicoding.mongotemplatedemo.dal.PersonDAL;import com.cicoding.mongotemplatedemo.model.Person;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.CommandLineRunner;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import java.util.Arrays;import java.util.Date;@SpringBootApplicationpublic class MongoTemplateApp implements CommandLineRunner &#123; private static final Logger LOG = LoggerFactory.getLogger(&quot;cicoding&quot;); private final PersonDAL personDAL; @Autowired public MongoTemplateApp(PersonDAL personDAL) &#123; this.personDAL = personDAL; &#125; public static void main(String[] args) &#123; SpringApplication.run(MongoTemplateApp.class, args); &#125; @Override public void run(String... args) &#123; personDAL.savePerson(new Person( &quot;Shubham&quot;, Arrays.asList(&quot;Harry potter&quot;, &quot;Waking Up&quot;), new Date(769372200000L))); personDAL.savePerson(new Person( &quot;Sergey&quot;, Arrays.asList(&quot;Startup Guides&quot;, &quot;Java&quot;), new Date(664309800000L))); personDAL.savePerson(new Person( &quot;David&quot;, Arrays.asList(&quot;Harry potter&quot;, &quot;Success&quot;), new Date(695845800000L))); personDAL.savePerson(new Person( &quot;Ivan&quot;, Arrays.asList(&quot;Secrets of Butene&quot;, &quot;Meeting Success&quot;), new Date(569615400000L))); personDAL.savePerson(new Person( &quot;Sergey&quot;, Arrays.asList(&quot;Harry potter&quot;, &quot;Startup Guides&quot;), new Date(348777000000L))); LOG.info(&quot;Getting all data from MongoDB: \\n&#123;&#125;&quot;, personDAL.getAllPerson()); LOG.info(&quot;Getting paginated data from MongoDB: \\n&#123;&#125;&quot;, personDAL.getAllPersonPaginated(0, 2)); LOG.info(&quot;Getting person By name &apos;Sergey&apos;: &#123;&#125;&quot;, personDAL.findByName(&quot;Sergey&quot;)); LOG.info(&quot;Getting all person By name &apos;Sergey&apos;: &#123;&#125;&quot;, personDAL.findOneByName(&quot;Sergey&quot;)); LOG.info(&quot;Getting people between age 22 &amp; 26: &#123;&#125;&quot;, personDAL.findByAgeRange(22, 26)); &#125;&#125; 我们可以使用一个简单的命令来运行我们的应用程序： mvn spring-boot:run 运行应用程序后，我们将能够在终端中看到一个简单的输出： 结论 如果我们将MongoTemplate与简单的Spring Data JPA进行比较，它看起来可能很复杂，但是它也使我们对如何构造查询有更多的控制。 Spring Data JPA过多地提取了有关构造什么查询，将哪些条件传递给查询等的详细信息。 使用MongoTemplate，我们可以对查询组成进行更细粒度的控制，Spring Boot为我们提供了易于开发的应用程序。","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.cicoding.cn/categories/MongoDB/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.cicoding.cn/tags/Spring-Boot/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.cicoding.cn/tags/MongoDB/"},{"name":"MongoTemplate","slug":"MongoTemplate","permalink":"https://www.cicoding.cn/tags/MongoTemplate/"}],"keywords":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.cicoding.cn/categories/MongoDB/"}]},{"title":"Redis的消息订阅/发布 Utils工具类","slug":"redis-pub-push-utils","date":"2019-11-12T12:15:43.000Z","updated":"2022-09-17T14:13:56.170Z","comments":false,"path":"redis/redis-pub-push-utils/","link":"","permalink":"https://www.cicoding.cn/redis/redis-pub-push-utils/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package cn.cicoding.utils;import org.json.JSONException;import org.json.JSONObject;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;import redis.clients.jedis.JedisPubSub;import redis.clients.jedis.Protocol;import redis.clients.jedis.exceptions.JedisConnectionException;class MQClient &#123; public static final int MSG_REALTIME = 1; public static final int MSG_CACHED = 2; public static final int MSG_SERIALIZABLE = 3; public static final String NOTIFY_CHANNEL = \"ClientNotify\"; private JedisPool pool; private boolean exit; private JedisPubSub pubsub; public MQClient(String ip, int port, JedisPubSub pubsub) &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxWaitMillis(10 * 1000); config.setMaxIdle(1000); config.setTestOnBorrow(true); pool = new JedisPool(config, ip, port, Protocol.DEFAULT_TIMEOUT, null); exit = false; this.pubsub = pubsub; &#125; public boolean publish(String channels, String message, String content) &#123; JSONObject obj = new JSONObject(); boolean ret = false; Jedis jedis = null; try &#123; jedis = pool.getResource(); if (message != null) &#123; obj.put(\"message\", message); &#125; try &#123; JSONObject objCon = new JSONObject(content); obj.put(\"content\", objCon); &#125; catch (JSONException e) &#123; obj.put(\"content\", content); &#125; String[] tmp = channels.split(\";\"); for (String channel : tmp) &#123; try &#123; if (jedis.publish(channel, obj.toString()) &gt; 0) &#123; ret = true; &#125; &#125; catch (Exception e) &#123; break; &#125; &#125; &#125; catch (JSONException e) &#123; &#125; finally &#123; if (jedis != null)&#123; jedis.close(); &#125; &#125; return ret; &#125; public boolean clientNotify(String clients, String message, String content, int type) &#123; if (type == MSG_REALTIME) &#123; return publish(clients, message, content); &#125; boolean ret = false; try &#123; JSONObject obj = new JSONObject(); obj.put(\"clients\", clients); obj.put(\"type\", type); if (message != null) &#123; obj.put(\"message\", message); &#125; try &#123; JSONObject objCon = new JSONObject(content); obj.put(\"content\", objCon); &#125; catch (JSONException e) &#123; obj.put(\"content\", content); &#125; if (pool.getResource().publish(NOTIFY_CHANNEL, obj.toString()) &gt; 0) &#123; ret = true; &#125; &#125; catch (JSONException e) &#123; &#125; return ret; &#125; public boolean setValue(String key, String value) &#123; try &#123; String response = pool.getResource().set(key, value); if (response != null &amp;&amp; response.equals(\"OK\")) &#123; return true; &#125; &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); &#125; return false; &#125; public String getValue(String key) &#123; return pool.getResource().get(key); &#125; public void subscribe(String... channels) &#123; while (!exit) &#123; try &#123; pool.getResource().subscribe(pubsub, channels); &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); System.out.println(\"try reconnect\"); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; &#125; &#125; &#125;&#125; Test测试函数： 123456789101112131415161718package cn.cicoding.utils;import redis.clients.jedis.JedisPubSub;public class Test extends JedisPubSub &#123; @Override public void onMessage(String channel, String message) &#123; System.out.println(channel + \":\" + message); &#125; public static void main(String[] args) &#123; MQClient client = new MQClient(\"127.0.0.1\", 6379, new Test()); client.setValue(\"abc\", \"java setted\"); System.out.println(client.getValue(\"abc\")); System.out.println(client.clientNotify(\"nodeSubscriber\", \"message from java\", \"&#123;\\\"debug\\\":0&#125;\", MQClient.MSG_REALTIME)); client.subscribe(\"testInitiativePerception\"); &#125;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/tags/Redis/"},{"name":"消息订阅","slug":"消息订阅","permalink":"https://www.cicoding.cn/tags/消息订阅/"},{"name":"发布","slug":"发布","permalink":"https://www.cicoding.cn/tags/发布/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"聊聊@Repository、@Component、@Controller、@Service有什么区别","slug":"whats-the-difference-between-component-repository-service-controller-annotations-in","date":"2019-11-12T00:15:43.000Z","updated":"2022-09-17T14:13:56.178Z","comments":true,"path":"spring/whats-the-difference-between-component-repository-service-controller-annotations-in/","link":"","permalink":"https://www.cicoding.cn/spring/whats-the-difference-between-component-repository-service-controller-annotations-in/","excerpt":"","text":"​ 继《聊聊Spring家族中的那几百个注解》之后，我们来谈谈@Repository、@Component、@Controller、@Service有什么区别与使用： Spring的官方文档中的一段描述： ​ 在Spring2.0之前的版本中，@Repository注解可以标记在任何的类上，用来表明该类是用来执行与数据库相关的操作（即dao对象），并支持自动处理数据库操作产生的异常 ​ 在Spring2.5版本中，引入了更多的Spring类注解：@Component,@Service,@Controller。@Component是一个通用的Spring容器管理的单例bean组件。而@Repository, @Service, @Controller就是针对不同的使用场景所采取的特定功能化的注解组件。 ​ 因此，当你的一个类被@Component所注解，那么就意味着同样可以用@Repository, @Service, @Controller来替代它，同时这些注解会具备有更多的功能，而且功能各异。 ​ 最后，如果你不知道要在项目的业务层采用@Service还是@Component注解。那么，@Service是一个更好的选择。 ​ 就如上文所说的，@Repository早已被支持了在你的持久层作为一个标记可以去自动处理数据库操作产生的异常（译者注：因为原生的java操作数据库所产生的异常只定义了几种，但是产生数据库异常的原因却有很多种，这样对于数据库操作的报错排查造成了一定的影响；而Spring拓展了原生的持久层异常，针对不同的产生原因有了更多的异常进行描述。所以，在注解了@Repository的类上如果数据库操作中抛出了异常，就能对其进行处理，转而抛出的是翻译后的spring专属数据库异常，方便我们对异常进行排查处理）。 注解 含义 @Component 最普通的组件，可以被注入到spring容器进行管理 @Repository 作用于持久层 @Service 作用于业务逻辑层 @Controller 作用于表现层（spring-mvc的注解） 为了让 Spring 能够扫描类路径中的类并识别出 @Repository 注解，需要在 XML 配置文件中启用Bean 的自动扫描功能，这可以通过context:component-scan/实现。如下所示： 1` // 首先使用 @Repository 将 DAO 类声明为 Bean package bookstore.dao; @Repository public class UserDaoImpl implements UserDao&#123; …… &#125; // 其次，在 XML 配置文件中启动 Spring 的自动扫描功能 …… …… ` ​ 这几个注解几乎可以说是一样的：因为被这些注解修饰的类就会被Spring扫描到并注入到Spring的bean容器中。 这里，有两个注解是不能被其他注解所互换的： @Controller 注解的bean会被spring-mvc框架所使用。 @Repository 会被作为持久层操作（数据库）的bean来使用 如果想使用自定义的组件注解，那么只要在你定义的新注解中加上@Component即可： 123@Component @Scope(&quot;prototype&quot;)public @interface ScheduleJob &#123;...&#125; ​ 这样，所有被@ScheduleJob注解的类就都可以注入到spring容器来进行管理。我们所需要做的，就是写一些新的代码来处理这个自定义注解（译者注：可以用反射的方法），进而执行我们想要执行的工作。@Scope参数了解继续往下读。 如果你想提供一个自定义的作用域解析策略而不使用基于注解的方法，只需实现 ScopeMetadataResolver接口，确认包含一个默认的没有参数的构造方法。然后在配置扫描器时提供全限定类名： 1&lt;context:component-scan base-package=&quot;a.b&quot; scope-resolver=&quot;footmark.SimpleScopeResolver&quot; /&gt; @Component就是跟&lt;bean&gt;一样，可以托管到Spring容器进行管理。 @Service, @Controller , @Repository = {@Component + 一些特定的功能}。这个就意味着这些注解在部分功能上是一样的。 当然，下面三个注解被用于为我们的应用进行分层： @Controller注解类进行前端请求的处理，转发，重定向。包括调用Service层的方法 @Service注解类处理业务逻辑 @Repository注解类作为DAO对象（数据访问对象，Data Access Objects），这些类可以直接对数据库进行操作 有这些分层操作的话，代码之间就实现了松耦合，代码之间的调用也清晰明朗，便于项目的管理；假想一下，如果只用@Controller注解，那么所有的请求转发，业务处理，数据库操作代码都糅合在一个地方，那这样的代码该有多难拓展和维护。 总结 @Component, @Service, @Controller, @Repository是spring注解，注解后可以被spring框架所扫描并注入到spring容器来进行管理 @Component是通用注解，其他三个注解是这个注解的拓展，并且具有了特定的功能，他是一个泛化的概念，仅仅表示一个组件 (Bean) ，可以作用在任何层次。 @Repository注解在持久层中，具有将数据库操作抛出的原生异常翻译转化为spring的持久层异常的功能。 @Controller层是spring-mvc的注解，具有将请求进行转发，重定向的功能。 @Service层是业务逻辑层注解，这个注解只是标注该类处于业务逻辑层。 用这些注解对应用进行分层之后，就能将请求处理，义务逻辑处理，数据库操作处理分离出来，为代码解耦，也方便了以后项目的维护和开发。 Scope的prototype与singleton区别12&lt;bean class=\"com.****.boss.domain.utils.CacheManager\" scope=\"singleton\" init-method=\"init\" destroy-method=\"destory\"&gt;&lt;/bean&gt; 123&lt;bean id=\"messageProcessService\" class=\"com.****.boss.domain.common.service.MessageProcessService\" scope=\"prototype\"&gt; &lt;property name=\"orderHandleConfigService\" ref=\"orderHandleConfigService\" /&gt;&lt;/bean&gt; 1、singleton作用域 当一个bean的作用域设置为singleton, 那么Spring IOC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。换言之，当把一个bean定义设置为singleton作用域时，Spring IOC容器只会创建该bean定义的唯一实例。这个单一实例会被存储到单例缓存（singleton cache）中，并且所有针对该bean的后续请求和引用都将返回被缓存的对象实例，这里要注意的是singleton作用域和GOF设计模式中的单例是完全不同的，单例设计模式表示一个ClassLoader中只有一个class存在，而这里的singleton则表示一个容器对应一个bean，也就是说当一个bean被标识为singleton时候，spring的IOC容器中只会存在一个该bean。 2、prototype prototype作用域部署的bean，每一次请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）都会产生一个新的bean实例，相当与一个new的操作，对于prototype作用域的bean，有一点非常重要，那就是Spring不能对一个prototype bean的整个生命周期负责，容器在初始化、配置、装饰或者是装配完一个prototype实例后，将它交给客户端，随后就对该prototype实例不闻不问了。不管何种作用域，容器都会调用所有对象的初始化生命周期回调方法，而对prototype而言，任何配置好的析构生命周期回调方法都将不会被调用。清除prototype作用域的对象并释放任何prototype bean所持有的昂贵资源，都是客户端代码的职责。（让Spring容器释放被singleton作用域bean占用资源的一种可行方式是，通过使用bean的后置处理器，该处理器持有要被清除的bean的引用。） scope=”prototype”没写的问题,项目中对一个表的增删该操作是用一个action，这个 actionadd,update,delete,save这些方法， 添加和修改是共用一个页面，当页面得到id时代表进行的修改操作，反之是添加操作。因为在配置spring的bean是忘了写scope=”prototype” 所以每次添加时都显示最后一次访问过的记录,scope=”prototype” 会在该类型的对象被请求 时创建一个新的action对象。如果没有配置scope=prototype则添加的时候不会新建一个action，他任然会保留上次访问的过记录的信息 webwork的Action不是线程安全的，要求在多线程环境下必须是一个线程对应一个独立的实例，不能使用singleton。所以，我们在Spring配置Webwork Action Bean时，需要加上属性scope=prototype”或singleton=”false”。 singleton模式指的是对某个对象的完全共享，包括代码空间和数据空间，说白了，如果一个类是singleton的，假如这个类有成员变量，那么这个成员变量的值是各个线程共享的（有点类似于static的样子了），当线程A往给变量赋了一个值以后，线程B就能读出这个值。因此，对于前台Action，肯定不能使用singleton的模式，必须是一个线程请求对应一个独立的实例。推而广之，只要是带数据成员变量的类，为了防止多个线程混用数据，就不能使用singleton。对于我们用到的Service、Dao，之所以用了singleton，就是因为他们没有用到数据成员变量，如果谁的Service需要数据成员变量，请设置singleton=false。 有状态的bean都使用Prototype作用域，而对无状态的bean则应该使用singleton作用域。 简单的说： singleton 只有一个实例，也即是单例模式。 prototype访问一次创建一个实例，相当于new。 应用场合： 需要回收重要资源(数据库连接等)的事宜配置为singleton，如果配置为prototype需要应用确保资源正常回收。 有状态的Bean配置成singleton会引发未知问题，可以考虑配置为prototype。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"注解","slug":"注解","permalink":"https://www.cicoding.cn/tags/注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"Spring Boot自定义Banner","slug":"springboot-banner","date":"2019-11-01T01:09:15.000Z","updated":"2022-09-17T14:13:56.182Z","comments":true,"path":"springboot/springboot-banner/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-banner/","excerpt":"","text":"TIPS 本文基于Spring Boot 2.1.9，理论支持Spring Boot所有版本。 相信玩过Spring Boot的童鞋一定在启动日志中见过类似如下的内容。本文详细探讨如何定制这部分内容，让内容更加趣味性。 12345671. ____ _ __ _ _2 /\\\\ / ___&apos;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\3( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\4 \\\\/ ___)| |_)| | | | | || (_| | ) ) ) )5 &apos; |____| .__|_| |_|_| |_\\__, | / / / /6 =========|_|==============|___/=/_/_/_/7 :: Spring Boot :: (v2.1.9.RELEASE) 如何自定义自定义Banner非常简单，只需在 classpath （ src/main/resources ）下创建创建名为 banner.txt 的文件即可。 Banner生成工具自己画Banner是很麻烦的，下面提供几款工具，将图片转换成ASCII字符，快速生成Banner。 工具地址 作用 http://patorjk.com/software/taag 写文字，选择字体，将字转成ASCII http://picascii.com/ 上传图片，将图片转ASCII 其他 使用搜索引擎，搜索”图片转ASCII”即可 等等 http://patorjk.com/software/taaghttp://www.network-science.de/ascii/http://www.degraeve.com/img2txt.php 下面是笔者准备好的Banner： 1234567891011121314151617181920 _ooOoo_ o8888888o 88&quot; . &quot;88 (| ^_^ |) O\\ = /O ____/`---&apos;\\____ .&apos; \\\\| |// `. / \\\\||| : |||// \\ / _||||| -:- |||||- \\ | | \\\\\\ - /// | | | \\_| &apos;&apos;\\---/&apos;&apos; | | \\ .-\\__ `-` ___/-. / ___`. .&apos; /--.--\\ `. . ___ .&quot;&quot; &apos;&lt; `.___\\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. | | : `- \\`.;`\\ _ /`;.`/ - ` : | |========`-.____`-.___\\_____/___.-`____.-&apos;======== \\ \\ `-. \\_ __\\ /__ _/ .-` / / `=---=&apos;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 佛祖保佑 永不宕机 永无Bug 占位符与描述信息banner.txt 支持占位符，占位符可用于描述项目，同时也可定制Banner显示的具体细节。 允许使用的占位符如下表所示： Variable Description ${application.version} 应用版本，从MANIFEST.MF 读取Implementation-Version 的值并显示。例如Implementation-Version: 1.0 ，则打印 1.0 ${application.formatted-version} 将应用版本用括号括起来，并添加前缀v。例如：Implementation-Version: 1.0 ，则打印 (v1.0) ${spring-boot.version} 打印Spring Boot版本，例如 2.1.4.RELEASE ${spring-boot.formatted-version} 将Spring Boot版本用括号括起来，并添加前缀v。例如： (v2.1.4.RELEASE) ${Ansi.NAME} (or ${AnsiColor.NAME}, ${AnsiBackground.NAME}, ${AnsiStyle.NAME}) 指定ANSI转义码，详见 org.springframework.boot.ansi.AnsiPropertySource ${application.title} 应用标题，从 MANIFEST.MF 读取 Implementation-Title 的值并打印。例如 Implementation-Title: itmuch-app ，则打印 itmuch-app 。 测试创建 banner.txt ，内容如下： 1234$&#123;AnsiBackground.BRIGHT_YELLOW&#125;$&#123;AnsiColor.BLUE&#125;$&#123;AnsiStyle.BOLD&#125;应用版本：$&#123;application.version&#125;Spring Boot版本：$&#123;spring-boot.version&#125;应用标题：$&#123;application.title&#125; 图片支持Spring Boot同样支持使用图片作为Banner，只需将图片放到项目的classpath （src/main/resources ）目录下，命名为banner ，格式支持png 、jpg 、gif 。 禁用Banner添加如下配置： 123spring: main: banner-mode: &quot;off&quot; 或在启动类上添加类似如下代码： 12345public static void main(String[] args) &#123; SpringApplication app = new SpringApplication(MySpringConfiguration.class); app.setBannerMode(Banner.Mode.OFF); app.run(args);&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"},{"name":"Banner","slug":"Banner","permalink":"https://www.cicoding.cn/tags/Banner/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"详解通过 Nexus3.x 搭建 Maven 私服","slug":"nexus3.x-maven","date":"2019-10-29T08:29:15.000Z","updated":"2023-06-20T06:34:39.687Z","comments":false,"path":"maven/nexus3.x-maven/","link":"","permalink":"https://www.cicoding.cn/maven/nexus3.x-maven/","excerpt":"","text":"概述如果团队使用 java 进行开发，开发人员通常通过共享 jar 包的方式进行项目间公共代码的维护，这些 jar 包的维护就需要一个 maven 私服来进行管理，一方面，这样既能够保证代码的安全性，又能快速上传、管理 jar 包 Nexus 是“开箱即用”的系统，不需要数据库，它使用文件系统加 Lucene 来组织数据，支持 WebDAV 与 LDAP 安全身份认证 Nexus 还提供了强大的仓库管理功能，构件搜索功能，它还提供了一套 REST 客户端，占用内存较少，极大地简化了本地内部仓库的维护和外部仓库的访问 总之，本地内部仓库在本地构建nexus私服的好处有： 加速构建、稳定 节省带宽、节省中央maven仓库的带宽 控制和审计 能够部署第三方构件 可以建立本地内部仓库、可以建立公共仓库 这些优点使得Nexus日趋成为最流行的Maven仓库管理器 本文，我们就来详细介绍一下如何通过 nexus 搭建 maven 私服 详解通过 Nexus3.x 搭建 Maven 私服 Nexus2 还是 Nexus3Nexus3.x 相较 2.x 版本有很大的改变 从底层重构，从而提高性能，增强扩展能力，并改善用户体验 升级界面，增加更多的浏览，搜索和管理功能 提供安装包，使部署更简单（安装完自动添加成服务，省去手动添加的麻烦） 增加 Docker，NuGet，npm，Bower的支持 提供新的管理接口，从而能自动管理任务 所以本文使用 nexus3 作为介绍，但是事实上，nexus3 的安装启动与 nexus2 非常类似 nexus3 要求必须先安装并配置好 jdk8 以上的版本 安装 Nexus3.x获取安装包首先执行 wget 命令获取安装包 12# 获取 Nexus3.6.0wget http://sonatype-download.global.ssl.fastly.net/nexus/3/nexus-3.6.0-02-unix.tar.gz 安装 Nexus执行下面命令安装 12345sudo mkdir -P /usr/local/nexussudo tar -zxvf nexus-3.6.0-02-unix.tar.gz -C /usr/local/nexussudo mv /usr/local/nexus/nexus-3.6.0-02 /usr/local/nexus/nexuscd /etc/init.dsudo ln -s /usr/local/nexus/nexus/bin/nexus . 现在我们就可以通过 service 命令来启动、停止或查看 nexus 的运行状态了 启动 Nexus在启动 nexus 之前，要知道操作系统默认一个程序最大的能打开的文件数只有 4096，对于一个管理所有 jar 包的 Nexus 来说，这通常来说是不够的，我们需要将这个限制调大 打开 /etc/security/limits.conf 文件，添加如下配置： 1nexus - nofile 65536 现在执行 1sudo service nexus start 即可启动 nexus，默认端口是 8081，因此用浏览器打开 http://localhost:8081 就可以看到 nexus 内置的 REST 页面了 创建用户点击页面上的 log in 按钮，输入默认用户名（admin）和默认密码（admin123）登录 可以点击上面的“设置”图标，在“设置”里可以添加用户、角色，对接LDAP等的设置 这里我们填写信息创建用户 Grant 可以选择用户权限： nx-admin – 管理员权限 nx-anonymous – 无差别用户权限，无法看到设置图标并且无法进入设置页面 创建仓库接下来我们就可以创建仓库了 这里我们有三种 maven 仓库可选 他们的区别是： proxy – 远程仓库的代理，当用户向这个仓库请求一个 artifact，他会先在本地查找，如果找不到的话，就会从远程仓库下载，然后返回给用户 hosted – 宿主仓库，用户可以 deploy 到 hosted 中，也可以手工上传构件到 hosted 里，在 central repository 是获取不到的，就需要手工上传到hosted里 group – 仓库组，在 maven 里没有这个概念，是 nexus 特有的。目的是将上述多个仓库聚合，对用户暴露统一的地址 这里我们创建两个 hosted 仓库 他们分别用来管理正式版 jar 包和 SNAPSHOT 包，区别在于是否允许重复上传 配置 settings.xml123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt;&lt;/settings&gt; 配置 pom.xml我们创建一个项目，然后配置 pom.xml 最重要的是 distributionManagement 节点的配置，引用我们在 settings.xml 中配置的 nexus 私服 id 配置中的 url 通过下图按钮处点击获取即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.techlog&lt;/groupId&gt; &lt;artifactId&gt;fortest&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;fortest Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project&apos;s website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Release Repository&lt;/name&gt; &lt;url&gt;http://localhost:8081/repository/java/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;url&gt;http://localhost:8081/repository/java-snapshot/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;fortest&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;!-- 打jar包插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.properties&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包源码插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;configuration&gt; &lt;attach&gt;true&lt;/attach&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.20.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 打包上传接下来我们执行 mvn deploy -e 就可以实现打包上传了 通过页面，我们可以看到已经上传成功 转载： https://techlog.cn/article/list/10183220","categories":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/tags/Maven/"},{"name":"Nexus3.x","slug":"Nexus3-x","permalink":"https://www.cicoding.cn/tags/Nexus3-x/"}],"keywords":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}]},{"title":"Docker部署Spring Boot项目","slug":"12-docker-lession-index","date":"2019-10-26T02:20:27.000Z","updated":"2022-09-17T14:13:56.147Z","comments":false,"path":"docker/12-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/12-docker-lession-index/","excerpt":"","text":"一、构建一个简单的Spring Boot项目1. 启动类12345678910111213141516@SpringBootApplicationpublic class MicroservicesDockerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MicroservicesDockerApplication.class, args); &#125; @RestController public class HelloSimonController&#123; @RequestMapping(&quot;/hello&quot;) public String hello()&#123; return &quot;hello world!&quot;; &#125; &#125;&#125; 2. pom依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;microservices-docker&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;microservices-docker&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 启动这个demo，浏览器访问http://localhost:8080/hello,返回 “hello world!”，接口正常。 二、添加Docker支持添加Docker构建插件 1234567891011121314151617&lt;!-- Docker maven plugin --&gt;&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;simon/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 简要说明插件配置： imageName:用于指定镜像名称，其中simon是仓库名称，${project.artifactId}是镜像名称，${project.version}是标签名称； resources.resource.directory:用于指定需要复制的文件，${project.build.directory}表示target目录； resources.resource.include:用于指定需要复制的文件。${project.build.finalName}.jar指的是打包后的jar 在目录src/main/docker下创建 Dockerfile 文件，Dockerfile 文件用来说明如何来构建镜像 1234FROM openjdk:8-jdk-alpineVOLUME /tmp(可忽略)ADD demo-0.0.1-SNAPSHOT.jar app.jarENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] FROM：表示使用 Jdk8 环境 为基础镜像，如果镜像不是本地的会从 DockerHub 进行下载 VOLUME：VOLUME 指向了一个/tmp的目录，由于 Spring Boot 使用内置的Tomcat容器，Tomcat 默认使用/tmp作为工作目录。这个命令的效果是：在宿主机的/var/lib/docker目录下创建一个临时文件并把它链接到容器中的/tmp目录 ADD：拷贝文件并且重命名 ENTRYPOINT：为了缩短 Tomcat 的启动时间，添加java.security.egd的系统属性指向/dev/urandom作为 ENTRYPOINT 三、打包部署项目我们需要把demo这个项目上传到linux上进行打包部署。linux上需要安装jdk和maven（不讲述安装过程），还需要安装Docker环境，可以参考之前的文章Centos7 安装Docker。 构建镜像进入demo项目的根目录，执行下面的命令 1mvn package docker:build 查看是否构建成功1docker images 1234[root@localhost ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEsimon/microservices-docker 0.0.1-SNAPSHOT a8aa192bf68c 12 hours ago 660MBjava latest d23bdf5b1b1b 2 years ago 643MB simon/microservices-docker就是构建的镜像 运行镜像1docker run -p 8080:8080 -t simon/microservices-docker:0.0.1-SNAPSHOT 查看正在运行的镜像1docker ps 12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf216e60cb5ec simon/microservices-docker:0.0.1-SNAPSHOT &quot;java -Djava.securit…&quot; 7 minutes ago Up 7 minutes 0.0.0.0:8080-&gt;8080/tcp zen_leakey 访问项目浏览器访问http://IP地址:8080/hello,返回hello world！，部署成功。 停止实例1docker stop zen_leakey 哦了！","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://www.cicoding.cn/tags/Spring-Boot/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"在Docker中安装Redis以及主从环境搭建","slug":"11-docker-lession-index","date":"2019-10-23T02:20:27.000Z","updated":"2022-09-17T14:13:56.147Z","comments":false,"path":"docker/11-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/11-docker-lession-index/","excerpt":"","text":"单实例redis安装下载redis镜像1docker pull redis 启动redis容器1docker run -d --name redis -p 6379:6379 redis 使用客户端RedisDesktopManager连接redis 官方下载地址 https://redisdesktop.com/download 我本地是win7系统，因此下载的是windows环境的软件安装包。 打开软件，数据相关IP以及端口号，连接redis服务，如下图： 由于我是在我的阿里云服务器上安装的redis，IP就是外网IP地址，端口号就是redis默认的端口号6379。 因为当前并未给redis设置密码验证，因此无需输入密码。 输入完成后，点击左下角的测试连接按钮。出现“success”字样的弹出框，就说明已经成功连接了远程服务器上的redis服务。 认真思考一下，上面的启动redis服务有什么缺点？如果对于docker数据挂载有了解的朋友，或许很容器想到，上面启动redis服务的方式，存在“数据存储”的问题。 当然也有其他的相关待优化的问题，比如redis配置文件可以映射到宿主机上某目录下，方便维护管理，等等。 上面的默认情况下，redis中存储的数据，是由Docker容器管理的，我们可以通过命令查看一下数据存储的地方： 1docker inspect e8 其中的“e8”指的是redis容器的ID 如下图所示（由于信息内容很多，我们只截取我们需要看的内容）： 其中黄色圈起来的地方，就是redis数据存储的目录映射。“Source”指的是宿主机下的目录，“Destination”指的是容器中的目录。 虽然最终的数据依然是存储在宿主机上的，但是默认是由Docker容器管理的，如果我们想自己管理维护redis中的数据，就需要早启动redis容器的时候，在run命令中指定目录映射。 redis数据挂载首先我们先停止上面启动的redis容器 在宿主机上创建redis相关的数据以及配置文件的存储目录 我们需要在宿主机上创建用于存储、管理redis相关数据以及配置文件的目录。 这里我就在 /opt 目录下新建一个 “docker_redis” 目录，然后在“docker_redis”目录下新建 “data”和“conf”这两个目录，最终结构如下： 复制一份redis.conf文件到宿主机的 /opt/docker_redis/conf/ 目录下 有些时候，在容器中找不到对应的文件在哪里，我们可以自己手动下载一个对应版本的redis的软件包，将里面的redis.conf复制一份到宿主机的目录中即可。 因为当前的redis容器中的redis版本是4.0.9（可以通过docker inspect 命令查看容器详细信息），因此我下载的软件包也是redis-4.0.9，尽量保持一致。 上传成功后，在对应目录下就有了一个redis.conf文件： 为了方便，这里我就上传一个redis.conf文件在附件里，如果有需要，可自行下载使用（redis版本是4.0.9）。 📎redis-conf.zip 修改redis.conf配置文件 既然我们将redis的配置文件映射到了宿主机上进行维护管理，我们就需要按照自己的需求，来进行相应的修改配置文件。 让redis支持持久化： 将文件中的 “appendonly”的值配置成“yes”。（文件内容很多，自己慢慢寻找） 开启redis访问密码： 将文件中的 “requirepass”的值配置成你自定义的密码即可。 支持客户端访问容器中的redis服务 注意点：要想让其他客户端（非宿主机的应用）可以访问到容器中的redis服务，需要配置redis.conf中的“bind”参数，值为redis容器的IP。 查看正在运行中的redis的容器IP；如果没有正在运行的redis容器的话，你可以先启动一个redis容器： 1234docker run --name redis -p 6379:6379 \\-v /opt/docker_redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \\-v /opt/docker_redis/data:/data \\-d redis redis-server /usr/local/etc/redis/redis.conf 查看redis容器的ip，可以通过下面命令查看： 1docker inspect 09|grep -i add 其中的“09”指的是redis容器的ID 回车运行，如下图所示： 可以明显看到，当前redis容器的IP地址是 172.18.0.3 因此，你可以将此IP地址配置到宿主机下面的 /opt/docker_redis/conf/redis.conf 文件中的bind参数。 修改完成bind参数之后，停止当前redis容器（docker stop命令）。 提醒：如果没有将redis.conf文件中的bind设置成redis容器的IP的话，客户端（比如 RedisDesktopManager）是无法连接redis服务的。 重启redis容器，实现配置文件映射以及数据挂载 这里是重启redis容器，因为上面我们已经运行了一个redis容器了。如果重新运行一个的话，显得有点浪费资源。 如果你忘记了之前停止的redis容器的ID的话，我们可以通过命令 docker ps -a 查看已经停止的容器以及正在运行中的容器列表。 在上面我们已经知道，redis容器ID的前两位字符是“09”，因此可以直接重启这个redis容器： 1docker start 09 如果你的主机上没有正在运行的redis容器，也可以通过上面给出的命令运行一个新的容器： 1234docker run --name redis -p 6379:6379 \\-v /opt/docker_redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \\-v /opt/docker_redis/data:/data \\-d redis redis-server /usr/local/etc/redis/redis.conf 到此，就实现了redis的配置文件以及持久化数据挂载了宿主机上，方便后期的维护管理。 测试连接redis服务 通过命令行测试连接redis服务 12&gt; docker exec -it 09 redis-cli -p 6379 -h 172.18.0.3&gt; 其中的“09”指的是redis容器的ID，“redis-cli”是redis的客户端连接工具。 回车即可连接到redis服务，同时我们也可以在里面验证一个密码是否有效，如下图所示： 可以看到，当执行“keys *”命令的时候，redis会提示你认证失败，原因是因为我们在redis.conf文件中设置了密码，所以，只有正确输入密码，才能执行命令并返回结果。 【注意项】：因为我们在redis.conf文件中配置了bind参数为容器的IP，所以我们在命令行连接redis的时候，需要指定 “-h 172.18.0.3” ，这样才能正常连接访问redis服务，不然无法连接的。 通过客户端软件连接redis服务 在本地电脑上，通过RedisDesktopManager软件来测试连接，这一种连接还是很简单的。 其中的IP地址，指的是我的阿里云服务器的外网IP。 这次我们就需要输入密码才能访问redis服务。 redis主从环境安装redis主从环境的搭建，有多种方式。平常最常用的方式就是，通过修改redis.conf文件，在文件中添加“slaveof”的参数配置。 对于以上的搭建方式，这里我就不多做讲解了，有兴趣的可以自行网上查阅资料学习。 虽然通过手动编辑redis.conf文件加入“slaveof”参数实现主从环境的搭建，但是大家有没有感受到，这种方式感觉很繁琐，不方便~如果从节点有很多呢，难道都要手动去修改吗？如果真是这样的话，就违背了docker的初衷。 鉴于上面的方式，既然是在docker上运行服务，那我们就要使用docker提供给我们的工具，来实现主从、甚至集群环境的多容器启动，强大的工具就是——docker compose。 因此，对于redis的主从环境搭建，我们就通过docker-compose这个docker编排工具来实现。 对于docker-compose不了解的，可以网上查阅资料学习一下，其实也不是很难理解，无非就是将我们平时使用的 run 命令通过在yml文件中描述出来，然后通过docker-compose命令运行这个文件来启动多个容器服务。 系统中需要安装docker-compose的软件包，这个我在之前的章节有讲解过，可以查看： https://yuque.com/zhoubang/docker/docker-zookeeper-install#rl0bfu 创建 docker-compose 文件在宿主机的 /opt/docker_redis/ 目录下新建 “redis_MS”目录，然后在 “redis_MS”目录下新建“docker-compose.yml”文件，然后在该文件中编写以下内容： 12345678910111213141516version: &apos;2&apos;services: redis-master: image: redis container_name: redis-master ports: - &quot;7010:6379&quot; redis-slave: image: redis container_name: redis-slave ports: - &quot;7011:6379&quot; command: redis-server --slaveof redis-master 6379 links: - redis-master:redis-master 上面的配置，简单来说，其实就是启动了2个容器，容器名称分别是 redis-master、redis-slave。 以上配置中，每个容器都有image、ports、container_name（可选参数）这3个参数项，其实如果你了解 run 命令的话，很容器知道其中每个参数的含义。无非就是把 run 命令通过yml文件的形式编写出来罢了。做一下对比来消化理解，就比较容器了。 当然，docker compoer 还有很多高级的命令，有兴趣的可自行网上查阅资料学习。 启动 docker-compose在 “docker-compose.yml”文件所在的目录下（/opt/docker_redis/redis_MS/）执行以下启动命令： 1docker-compose up -d 运行效果如下图： 你会看到日志打印出了我们在yml文件中定义的2个容器名称。 查看容器是否启动成功 以下2种查看方式都是可以的。 通过 docker ps 命令查看运行中的容器列表 通过 docker-compose ps 命令查看运行中的 可以看到，其中的“State”列的值都是“Up”状态，说明容器处于正常运行。 验证redis主从是否有效这里我们就直接使用客户端软件 RedisDesktopManager 来测试，比较直观一些。 首先还是打开此客户端软件，然后分别连接我们上面启动的2个redis服务，端口分别是7010和7011. 其中，7010这个端口对应的redis是一个master角色（主节点），而7011对应的redis是一个slave角色（从节点），因为，从上面的yml文件中就看的出来，7011的配置项中通过“links”来指向了7010的容器。 如下图所示： 在master节点下面新增一个数据（直接在软件上手动新增一条数据）： 我们已经在master节点下面新增了一条测试数据，然后我们手动刷新一下下面的slave节点，看看db0下面是否会出现和master的db0下面相同的数据，刷新后如下图： 可以看到，数据已经自动同步到slave节点上了。redis主从可以说已经搭建好了。^_^ 还有一个问题需要验证一下：既然是主从，说明master是可读写的，而slave只能是只读的，不能写操作。 在“redis-slave-7011”这个从节点下面手动新增一个K-V数据，看看是否能成功写数据，最终效果如下： 通过上图可以看到，控制台信息打印出“You can’t write against a read only slave.”，意思也就是，你不能在只读模式的节点下面进行写操作。这也就验证了我们的从节点是只读的。 同时，slave、master节点下面，也没有任何的数据变化。 删除“redis-slave-7011”节点下面的test测试数据，看看是否能删除成功，经过试验，最终结果依然是： You can’t write against a read only slave. 这与上面出现的提示一样，说明slave节点是只读的。 删除“redis-master-7010”节点下面的test测试数据，看看从节点（redis-slave-7011）下面是否同步删除，经过试验，最终结果是： “redis-slave-7011”这个 从节点 下面的相同数据也同步被删除掉了。 通过上面的3个验证方式，印证了我们上面说的，master是可读写的，slave是只读的，不可写。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/tags/Redis/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"SpringBoot2.2.0 Release版本发行特性","slug":"springboot2.2.0-release-notes","date":"2019-10-21T00:23:15.000Z","updated":"2022-09-17T14:13:56.184Z","comments":false,"path":"springboot/springboot2.2.0-release-notes/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot2.2.0-release-notes/","excerpt":"","text":"Spring Boot 2.2 Release Notes ApplicationContextRunner简单的bean注册 RestTemplateBuilder 要求定制 从配置注释处理器中排除 groovy.lang.MetaClass 类型 响应式Elasticsearch自动配置 Banners ASCII标语文件现在可以使用来使用ANSI 256颜色转义码 空闲JDBC连接指标 Kubernetes检测 ConditionalOnCloudPlatform 现在可以检测应用程序是否在Kubernetes上运行 RSocket支持 Java 13支持 Spring Boot 2.2增加了对Java 13的支持。还支持Java 8和11 ······ 更多特性 依赖升级Spring Boot 2.2移至几个Spring项目的新版本： Reactor Dysprosium Spring AMQP 2.2 Spring Batch 4.2 Spring Data Moore Spring Framework 5.2 Spring HATEOAS 1.0 Spring Integration 5.2 Spring Kafka 2.3 Spring Security 5.2 Spring Session Corn 第三方版本的更新： Artemis 2.9 Elasticsearch 6.7 Flyway 6.0 Git Commit ID Plugin 3.0 Hazelcast 3.12 HSQLDB 2.5 Jackson 2.10 Jedis 3.1 Jersey 2.29 Kafka 2.3 Lettuce 5.2 Micrometer 1.3 Mockito 3.1 Solr 8.0 Spring Boot 2.2中的弃用 该logging.name属性已重命名为logging.file.name。 该logging.path属性已重命名为logging.file.path。 server.connection-timeout不建议使用该属性，而应使用服务器特定的属性，因为它们的行为并不完全相同。 agentMaven插件的属性已重命名为agents。 WebTestClientBuilderCustomizer已移至org.springframework.boot.test.web.reactive.server。 ······ 参考文档： Spring Boot 2.2 Release Notes","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"在Docker中安装Zookeeper以及集群环境搭建","slug":"10-docker-lession-index","date":"2019-10-20T02:20:27.000Z","updated":"2022-09-17T14:13:56.147Z","comments":false,"path":"docker/10-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/10-docker-lession-index/","excerpt":"","text":"前言 如果你对于zookeeper不懂的话，不建议来看此文章的内容。你可以自行网上查阅zookeeper资料学习。 在学习一门技术的时候，首先要了解这技术是干什么用的、基本的概念以及简单的上手使用。 搭建zookeeper单节点环境获取zookeeper镜像 只要是想使用镜像，第一步都是先获取镜像 1docker pull zookeeper 查看下载的zookeeper镜像1docker images 如下图所示： 运行zookeeper镜像1docker run -d --name zookeeper -p 2181:2181 zookeeper 这里的2181是zookeeper的默认端口号。当然，你在启动镜像的时候，可以不用指定port的映射，解决的办法就是可以通过docker提供的link机制来实现容器的访问。 查看运行中的zookeeper容器1docker ps 如下图所示： 连接zookeeper服务在Linux命令行中执行以下命令： 1docker exec -it ea zkCli.sh 其中的“ea”是zookeeper容器ID的前两位字符。 回车如下图（一般需要按两下回车键，才能看到最下面的“CONNECTED”的字样）： 出现上面的信息，说明zookeeper正常启动 另一种连接zookeeper服务的方式 或许有的朋友可能对上面的命令“docker exec -it ea zkCli.sh”中的 zkCli.sh 不太明白。这个 zkCli.sh 是哪里来的？ 你也可以通过另外一种命令来进入zookeeper容器： 1docker exec -it ea /bin/bash 唯一不同的地方，就是最后面的命令内容。 执行该命令之后，进入的是zookeeper容器的文件系统的根目录。 我们可以查看一下容器的文件系统根目录下面有什么东西，在容器内执行命令： 12&gt; cd /&gt; 回车之后，再执行命令： 12&gt; ls&gt; 如下图所示： 可以明显的看到，有一个zookeeper的文件夹，也就是我们在容器中安装的zookeeper所在的目录。 然后，除了黄色区域的内容，再仔细看一下其他的目录，是不是发现了什么？不错，和我们平时看到的Linux系统根目录下面的内容是一样的。其实Docker容器就是一个简洁型的Linux文件系统。 找到我们的zookeeper目录之后，执行下面命令： 12&gt; cd ./zookeeper-3.4.12/bin/&gt; 可以看到目录下面有一些脚本： 如果我们要连接zookeeper服务的话，需要使用 zkCli.sh 脚本来连接。 使用zkCli.sh连接zookeeper 在上面所在的目录下，执行以下命令： 12&gt; ./zkCli.sh -server 127.0.0.1:2181&gt; 出现下图所示信息，说明成功连接了zookeeper服务： 查看当前zookeeper的模式 和上面一样，需要在 /zookeeper-3.4.12/bin/ 目录下，执行以下命令查看zookeeper服务的模式： 12&gt; ./zkServer.sh status&gt; 如下图所示： 可以看到，当前zookeeper服务是单节点的，并非集群环境。 搭建zookeeper集群环境 实际企业生产环境，往往都是搭建的集群环境，避免单实例情况下的异常导致服务不可用。 这是我以前写的在原生的centos系统上搭建的zookeeper集群环境的文档，有兴趣可以看看 https://pan.baidu.com/s/1hrMaRpq 这里我们就搭建3个zookeeper节点吧。3个节点已经算是最小单元的集群环境了。 为了编写简单，zookeeper 名称我们使用“ZK”来表示。 因为一个一个地启动 ZK 太麻烦了, 所以为了方便起见, 我们直接使用 docker-compose 来启动 ZK 集群。 Docker-Compose —— Docker编排工具 简介 Docker Compose是一个用来定义和运行复杂应用的Docker工具。一个使用Docker容器的应用，通常由多个容器组成。使用Docker Compose不再需要使用shell脚本来启动容器。 Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 Docker-Compose是一个部署多个容器的简单但是非常必要的工具. 两种最新的安装Docker-Compose的方式 从github上下载docker-compose二进制文件安装 pip安装 官方文档 https://docs.docker.com/compose/install/ 这里我就使用 pip 的方式安装。 安装Docker-Compose之前，请先安装 python-pip 安装 python-pip 首先检查Linux有没有安装python-pip包，终端执行 pip -V 1pip -V 如果出现 -bash: pip: command not found 的提示，说明没有安装python-pip，需要安装一下python-pip包。 参考文章 https://www.cnblogs.com/YatHo/p/7815400.html 以下是我的阿里云服务器上的执行情况： 可以看到已经自带了pip包。 对安装好的pip进行升级 因为系统自带的软件包，很有可能不是最新版本，所以我们最好先更新到最新版本。 1pip install --upgrade pip 运行结果如下： 已经升级到最新的 10.0.1 版本了。 安装Docker-Compose在Linux命令行中执行命令： 1pip install docker-compose 查看安装的docker-compose版本 1docker-compose -version 如下图所示表示安装成功： 创建 docker-compose 文件这里我就在 /opt 目录下新建了一个 zookeeper 目录（你也可以自定义存储目录），如下图： 在当前目录（/opt/zookeeper/）创建一个名为 docker-compose.yml 的文件, 其内容如下: 123456789101112131415161718192021222324252627282930version: &apos;2&apos;services:zoo1: image: zookeeper restart: always container_name: zoo1 ports: - &quot;2181:2181&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888zoo2: image: zookeeper restart: always container_name: zoo2 ports: - &quot;2182:2181&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888zoo3: image: zookeeper restart: always container_name: zoo3 ports: - &quot;2183:2181&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 这个配置文件会告诉 Docker 分别运行三个 zookeeper 镜像, 并分别将本地的 2181, 2182, 2183 端口绑定到对应的容器的2181端口上（每个zookeeper容器的默认端口都是2181，这句话意思也就是说，将宿主机的2181、2182、2183这3个端口号，分别映射到3个zookeeper容器的2181端口）。ZOO_MY_ID 和 ZOO_SERVERS 是搭建 ZK 集群需要设置的两个环境变量，其中 ZOO_MY_ID 表示 ZK 服务的 id，它是1-255 之间的整数，必须在集群中唯一；ZOO_SERVERS 是ZK 集群的主机列表。 运行 docker-compose接着我们在 docker-compose.yml 所在的目录（/opt/zookeeper/ ）下运行： 1COMPOSE_PROJECT_NAME=zk_cluster docker-compose up 即可启动 ZK 集群了。 注意：这种方式非后台运行，当执行 Ctrl + C 组合键的时候，所有的ZK容器都会停止运行。 以后台方式运行docker-compose1COMPOSE_PROJECT_NAME=zk_cluster docker-compose up -d 很简单，只要在最后面加上“-d”即可。 运行效果如下图： 可以看到，是以后台方式运行的ZK容器集群。 查看启动的ZK集群执行上述命令成功后，接着新开启一个终端，然后在新终端界面中，首先进入 /opt/zookeeper/ 目录，在该目录下运行以下命令可以查看启动的 ZK 容器： 1COMPOSE_PROJECT_NAME=zk_cluster docker-compose ps 如下图： 你也可以通过 docker ps 命令查看启动的ZK容器列表，如下图： 很明显的看到，启动了3个ZK容器，每个容器对应着宿主机的不同的端口号。 测试连接ZK集群 查看ZK集群的信息，有多种方法。这里我们就使用最普通的进入容器内部来查看ZK节点的信息以及它的模式。 通过上面的图，可以看到3个ZK容器的ID信息。 这里我们先进入zoo1这个容器，查看ZK的信息，执行以下命令： 1docker exec -it 49 zkServer.sh status 其中“49”指的是zoo1容器的ID。 运行结果如下图： 可以看到，Mode的值为“follower”，指的是从节点，并非主节点。 以此类推，查看 zoo2 这个ZK容器的信息： 当前ZK容器节点为主节点 查看 zoo3 这个ZK容器的信息： 当前ZK容器节点为从节点 经过以上的查看，可以清晰的看到，其中一个ZK容器是一个主节点leader，另外2个都是从节点follower。 到此，在Docker中搭建zookeeper的集群环境已经讲解完了。 当然，其中的知识点还是很多的，文章只是一个入门级，对于更深层次的技术探索，各位可以自行网上学习的。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://www.cicoding.cn/tags/Zookeeper/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"SpringBoot那些好用的连接池HikariCP","slug":"springboot-HikariCP","date":"2019-10-16T09:50:15.000Z","updated":"2022-09-17T14:13:56.181Z","comments":false,"path":"springboot/springboot-HikariCP/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-HikariCP/","excerpt":"","text":"HikariCP来自于日语，翻译过来是光的意思，由此可见，连接池非常的快。 HikariCP是什么HikariCP是数据库连接池,而且是号称史上最快的,而且目前来看确实是这样的,SpringBoot2.0也已经采用HikariCP作为默认连接池配置. HikariCP GitHub网址 HikariCP为什么这么快 字节码级别优化(很多方法通过JavaAssist生成) 代码量非常小，很多方法都没有写，是通过JavaAssist编译的时候是动态生成的。 大量小改进 用FastStatementList代替ArrayList 无锁集合ConcurrentBag（借鉴了.NET中的ConcurrentBag，在java中实现了自己的ConcurrentBag，对于高并发方面有些优化） 代理类的优化 (比如，用invokestatic代替了invokevirtual) [invokestatic通过调用getProxyPreparedStatement静态方法生成了18个操作 invokevirtual通过ProxyFactory.getProxyPreparedStatement生成15个操作，由此可见。 在Spring Boot中的配置Spring Boot 2.x 默认使用HikariCP 配置spring.datasource.hikari.* 配置 Spring Boot 1.x 默认使用Tomcat连接池，需要移除tomcat-jdbc依赖 spring.datasource.type=com.zaxxer.hikari.HikariDataSource HikariCP数据源配置源码： 1234567891011121314151617181920212223/** * Hikari DataSource configuration. */@Configuration@ConditionalOnClass(HikariDataSource.class)@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = \"spring.datasource.type\", havingValue = \"com.zaxxer.hikari.HikariDataSource\", matchIfMissing = true)static class Hikari &#123; @Bean @ConfigurationProperties(prefix = \"spring.datasource.hikari\") public HikariDataSource dataSource(DataSourceProperties properties) &#123; HikariDataSource dataSource = createDataSource(properties, HikariDataSource.class); if (StringUtils.hasText(properties.getName())) &#123; dataSource.setPoolName(properties.getName()); &#125; return dataSource; &#125;&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"},{"name":"HikariCP","slug":"HikariCP","permalink":"https://www.cicoding.cn/tags/HikariCP/"}],"keywords":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/categories/SpringBoot/"}]},{"title":"在Docker中安装Nginx","slug":"09-docker-lession-index","date":"2019-10-16T02:20:27.000Z","updated":"2022-09-17T14:13:56.146Z","comments":false,"path":"docker/09-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/09-docker-lession-index/","excerpt":"","text":"前言 由于nginx是一个反向代理服务器，涉及到一些配置。如果你对nginx一点都不懂的话，那么，你在学习下面的内容的时候，可能就会不太懂，因为我们是要在docker中操作nginx，同时需要编辑一些配置文件。 适合对于nginx有一定了解的朋友参考使用。 下载nginx镜像1docker pull nginx 查看下载的nginx镜像1docker images 如下图： 启动nginx镜像容器1docker run -d -p 80:80 --name nginx nginx nginx是一个代理，端口默认是80 访问服务器 当前nginx是安装在我的阿里云服务器上的，所以，我们可以访问一下阿里云服务器。 我的阿里云服务器域名是 http://www.cicoding.com 在浏览器中输入域名 http://www.cicoding.com ，回车看一下效果： 出现上面的页面，说明nginx已经正常启动了。 将nginx的配置文件、日志目录映射到宿主机 在测试环境、生产环境的话，都是需要编辑一些nginx的配置的，最常见的修改就是nginx.conf文件。 将nginx的配置文件、日志目录等，映射到宿主机上进行管理维护，是很方便的，也是推荐的做法。 在宿主机中创建nginx相关目录 首先在宿主机中创建一个用于存放nginx相关文件的目录，这里我就在 /opt 目录下新建了一个 docker_nginx 的目录文件。 然后在 docker_nginx 目录下新建 conf 、log 、www 这三个目录，目录含义是： conf：存放nginx的相关配置文件，比如 nginx.conf log：存放nginx的日志文件 www：存放相关静态资源文件 最终的目录结构如下： 复制一份nginx.conf文件到宿主机对应的目录下： 1docker cp nginx:/etc/nginx/nginx.conf /opt/docker_nginx/conf/nginx.conf 这条命令的作用，就是复制nginx的docker容器中的 /etc/nginx/nginx.conf 文件到宿主机下的 /opt/docker_nginx/conf/ 目录下。这样可以直接进行默认的配置文件的编辑。 看一下默认的nginx.conf配置文件的内容： 编辑 nginx 的配置文件： 我们暂时就修改其中的 access_log 、error_log 、root 这些基本配置。 从上图可以看到，配置文件最下面，有这样一段配置： 12&gt; include /etc/nginx/conf.d/*.conf;&gt; 意思也就是引入了其他配置文件。 既然我们要在宿主机上管理nginx的配置文件，所以对于上面的include引入的文件，我们也要复制一份到对应的宿主机上。 我们进入nginx容器，去查看一下这个路径下面有哪些文件： 进入nginx容器 12&gt; docker exec -it e4 /bin/bash&gt; 其中的 e4 指的是容器ID的前2位字符串。 查看 /etc/nginx/conf.d/ 目录 可以看到，里面有一个default.conf配置文件 查看 default.conf配置文件 其中用黄色圈起来的部分，是我们要修改的内容（上面说过了，目前就先简单修改基本的配置，只是方便大家看到一下效果，至于其他的配置，可自行按照这样的步骤自行编辑）。 复制一份default.conf文件到宿主机对应的目录下 12&gt; docker cp nginx:/etc/nginx/conf.d/default.conf /opt/docker_nginx/conf/default.conf&gt; 查看一下目前宿主机下面的nginx配置文件情况 同样的，我们也需要把nginx的默认首页文件，复制到宿主机下面 12&gt; docker cp nginx:/usr/share/nginx/html/index.html /opt/docker_nginx/www/&gt; 编辑宿主机上的nginx相关配置文件 首先修改 nginx.conf 配置文件，修改后结果是： 其中error_log的配置，就是我们前面在宿主机下面创建的nginx的log目录。 注意需要修改最下面的include配置，指定宿主机下面的default.conf配置文件（default/conf与nginx.conf在相同目录下，所以直接写名称即可，无需指定具体目录路径） 编辑default.conf文件 12&gt; vim /opt/docker_nginx/conf/default.conf&gt; 修改文件中的 access_log 以及 root 配置，效果如下 同样，access_log 以及 root 的配置，就是我们前面在宿主机下面创建的nginx的相关目录。 重启nginx容器 先停止之前启动的nginx容器 1docker stop e4 重启nginx容器 这次重启nginx容器的话，就不能使用一开始那种简单的run命令了，需要添加一些参数，具体命令如下： 12345docker run -p 80:80 --name nginx-new \\ -v /opt/docker_nginx/www:/usr/share/nginx/html \\ -v /opt/docker_nginx/log:/var/log/nginx \\ -v /opt/docker_nginx/conf/nginx.conf:/etc/nginx/conf \\ -d nginx 这里的 -v 参数的含义是，将宿主机上的目录挂载到容器中的对应目录。 “：”冒号前面是宿主机的目录，后面是容器中的目录。 有些朋友可能会不搞不明白冒号后面的容器路径是怎么来的，这里解释一下，其实很简单，就是指的是nginx的默认的日志路径、配置文件路径。 你在nginx容器中去查看一下nginx.conf以及default.conf配置文件的内容，就可以看到log和配置文件的默认存储路径了。文章上面也有截图出来nginx.conf以及default.conf的默认配置截图，可自行翻阅到上面查看。 查看启动的nginx容器 修改nginx默认首页内容 先看一下默认首页的样子： 我们把这个首页内容全部删除掉，加入我们自己的内容！ 编辑宿主机下面的 /opt/docker_nginx/www/index.html 文件： 12&gt; vim /opt/docker_nginx/www/index.html&gt; 修改之后如下： 重新访问服务器域名，查看最终效果 如果页面出现中文乱码的问题，可以在 index.html 好 标签里面加入： 12&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&gt; 最终index.html文件内容如下： 12345678910111213141516171819&gt; &lt;!DOCTYPE html&gt;&gt; &lt;html&gt;&gt; &lt;head&gt;&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&gt; &lt;title&gt;Welcome to nginx!&lt;/title&gt;&gt; &lt;style&gt;&gt; body &#123;&gt; width: 35em;&gt; margin: 0 auto;&gt; font-family: Tahoma, Verdana, Arial, sans-serif;&gt; &#125;&gt; &lt;/style&gt;&gt; &lt;/head&gt;&gt; &lt;body&gt;&gt; &lt;h1&gt;欢迎访问!&lt;/h1&gt;&gt; &lt;p&gt;当前nginx服务来源于Docker容器&lt;/p&gt;&gt; &lt;/body&gt;&gt; &lt;/html&gt;&gt;","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.cicoding.cn/tags/Nginx/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"服务发现 - Eureka","slug":"microservice02","date":"2019-10-16T00:23:52.000Z","updated":"2022-09-17T14:13:56.156Z","comments":false,"path":"micro-service/microservice02/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice02/","excerpt":"","text":"Eureka简介Eureka是Netflix开源的服务发现组件，本身是一个基于REST的服务，包含Server和Client两部分，Spring Cloud将它集成在子项目Spring Cloud Netflix中。 关于服务发现在微服务架构中，服务发现（Service Discovery）是关键原则之一。手动配置每个客户端或某种形式的约定是很难做的，并且很脆弱。Spring Cloud提供了多种服务发现的实现方式，例如：Eureka、Consul、Zookeeper。 Spring Cloud支持得最好的是Eureka，其次是Consul，最次是Zookeeper。 代码示例 创建一个Maven工程（microservice-discovery-eureka），并在pom.xml中加入如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.cicoding&lt;/groupId&gt; &lt;artifactId&gt;microservice-discovery-eureka&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 添加spring-boot的maven插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 编写Spring Boot启动程序：通过@EnableEurekaServer申明一个注册中心： 12345678910111213package cn.cicoding;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 在默认情况下，Eureka会将自己也作为客户端尝试注册，所以在单机模式下，我们需要禁止该行为，只需要在application.yml中如下配置： 12345678910server: port: 8761eureka: client: # 是否要注册到其他Eureka Server实例 register-with-eureka: false # 是否要从其他Eureka Server实例获取数据 fetch-registry: false service-url: defaultZone: http://localhost:8761/eureka/ 启动工程后，访问：http://discovery:8761/ ，如下图。我们会发现此时还没有服务注册到Eureka上面。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"},{"name":"Eureka","slug":"Eureka","permalink":"https://www.cicoding.cn/tags/Eureka/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"在Docker中安装Mysql","slug":"08-docker-lession-index","date":"2019-10-15T02:20:27.000Z","updated":"2022-09-17T14:13:56.146Z","comments":false,"path":"docker/08-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/08-docker-lession-index/","excerpt":"","text":"前言 此篇幅内容较多，讲解的很详细，也有很多知识点。能耐心认真的读完，就很不错了~ 如果你觉得此文章不错的话，或者是根据此文档进行安装mysql的话，抽空在文档最下方留个言吧让我看到你的支持 Docker 中国官方镜像加速 如果觉得国外下载速度太慢，可以配置一个“Docker 中国官方镜像加速”，来提高镜像下载的速度。 详情配置请查看 http://www.docker-cn.com/registry-mirror 一般情况下，都会永久性的配置镜像加速，在Linux中修改 /etc/docker/daemon.json 文件，填入以下内容： 1234&gt; &#123;&gt; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&gt; &#125;&gt; 如果daemon.json不存在的话，需要自己创建一下。 文件修改保存成功之后，记得重启一下Docker服务，以便让这个镜像加速生效。 重启Docker服务 我们在【在centos系统中安装Docker】一节中讲过Docker随着服务器重启自动启动的内容，正好可以通过命令service docker restart来实现Docker服务的重启。 具体详情请查看 https://yuque.com/zhoubang/docker/rqspmt#cuygcr 然后我们在Linux中执行命令： 12&gt; service docker restart&gt; 出现下图所示结果，表明Docker服务已经重新启动了！这样就可以永久性的使用Docker加速服务了。 如果不做特别的配置的话，之前处于运行状态的容器，随着Docker服务的重启也会停止运行。 下载mysql镜像1docker pull mysql 如果配置了镜像加速，那么在下载mysql镜像或者其他比较大的文件的时候，会发现下载速度变得非常快！ 启动mysql容器1docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name=mysql mysql 其中 -e 的作用是用于设置环境变量，mysql默认用户名为root，则MYSQL_ROOT_PASSWORD即为root设置密码，即123456 查看运行的mysql容器1docker ps 如下图： mysql容器已经正常启动了！ 进入mysql容器 既然mysql服务启动了，如果我们想对mysql进行操作（比如进入命令行操作、客户端连接等操作），该怎么办？ 通过 docker exec 命令进入mysql容器： 1docker exec -it c9 /bin/bash 其中的“c9”指的当前mysql容器ID的前面部分值（在上图就可以看出来mysql容器的ID是 c94faeed480a）。 回车运行效果如下图： 其实这个时候，命令行控制台可以输入mysql相关的命令了。 连接mysql数据库1mysql -u root -p123456 如下图： 这个就是我们非常熟悉的mysql命令行界面了！ 我们可以在这里创建数据库、表等操作。再次印证了Docker的强大和方便！ 查看当前所有的数据库在mysql命令行中执行命令： 1show databases; 如下图所示： 完全就是和平常使用mysql一样。 创建数据库、表、新增测试数据 创建数据库 1create database docker_test; 效果如下图： 这里我就创建了一个数据库docker_test 选择数据库 首先需要选择具体的数据库，执行命令选择刚刚创建的数据库： 12&gt; use docker_test&gt; 创建表： 12&gt; create table test(name varchar(20),age int(11));&gt; 创建了test表，有2个字段：name、age 添加测试数据： 12&gt; insert into test values(&quot;Kitty&quot;,26),(&quot;Tom&quot;,18),(&quot;Jack&quot;,36);&gt; 这里就简单添加3条测试数据。 我们查询一下数据是否存在于数据库中： 12&gt; select * from test;&gt; 一切OK！ 客户端连接mysql数据库 既然mysql成功启动并运行，除了能在命令行中操作mysql数据库之外，肯定也是必须要能在客户端上连接和操作数据库才行。 下面我就在我本地电脑上通过数据库客户端软件连接一下这个mysql数据库， 看看能不能正常连接和操作。 我使用的是DataGrip客户端软件，如果你们需要的话，可以下载使用 https://pan.baidu.com/s/1NkzEG_rjwFBylUSMxfIUzw 如果版本低的话，可以到官方下载最新版本 https://www.jetbrains.com/datagrip/ 打开本地DataGrip客户端，新建连接mysql数据库 输入正确的mysql相关信息，连接数据库： 输入完成之后，可以点击下方的 Test Connection 按钮，来测试连接是否正常。 查看创建的**数据库和表：** 到此，mysql的相关服务已经正常访问和操作了。这和我们传统的使用mysql没有什么不同。 客户端中操作表数据 我们通过DataGrip客户端，在test表中手动再添加一条数据，然后我们在docker中看看是否能查看到新增的数据： 【注意】：我这里添加了一条带有中文的数据。 进入mysql容器中查询表数据 呀！是不是发现问题了~ 没错，中文乱码！怎么解决呢？ mysql容器中解决表数据中文乱码查看mysql容器的ID： 进入mysql的docker容器： 1docker exec -it c9 /bin/bash 编辑mysql配置文件： 1vim /etc/mysql/my.cnf 如果提示 vim: command not found 的错误信息，需要安装相关依赖包，执行下面两个命令即可： 12&gt; apt-get update&gt; 12&gt; apt-get install vim&gt; 在my.cnf文件中加入以下配置： 123456[mysqld]character-set-server=utf8 [client]default-character-set=utf8 [mysql]default-character-set=utf8 最终修改结果为： 重新进入mysql容器，查询表数据，显示结果为： 可以看到，已经正常显示中文了！ 停止并重启mysql容器，再次查看效果 客户端DataGrip重新连接mysql： 客户端连接正常！ 进入mysql容器，查看表数据： mysql容器重启之后，查询数据正常显示中文！一切没什么问题了~ 通过commit命令提交新的镜像 根据在mysql容器中所做的更改，创建新的mysql镜像。 回想一下，我们在mysql容器中做了什么更改？ 创建数据库、表、新增数据、修改my.cnf配置文件，就是这些吧~ 使用commit命令**提交新镜像** 通过在Linux命令行中执行命令，提交新的镜像： 1docker commit c9 mysql-new 其中，“c9”就是指的容器ID，新的镜像名称为“mysql-new”。 如下图： 查看所有镜像列表： 是不是发现了我们创建的新的镜像mysql-new了。 启动新创建的mysql镜像 由于上面我们已经运行了一个mysql的容器了，端口是3306，所以我们新运行一个mysql容器的时候，端口号就不能是3306了，这里我指定为3307，且容器的别名是mysql-new，方便区分查看。 进入新创建的mysql容器 查看mysql数据库信息 查看my.cnf配置文件内容 从上面2张图中，可以明显的看到，我们之前创建的数据库docker_test、表test，都没有了！但是修改的my.cnf配置文件的内容还是保留着的。 why？？？ 为什么会这样呢？ 官方文档在commit命令的介绍中，有这样一段话： The commit operation will not include any data contained in volumes mounted inside the container. 意思是commit操作并不会包含容器内挂载数据卷中的数据。 如果对于“数据卷”不了解的话，确实看不懂是什么意思。 数据卷与数据卷容器 生产环境中使用Docker的过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，这必然涉及容器的数据管理操作。 容器中管理数据主要有两种方式： 数据卷（Data Volumes）：数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器。 数据卷容器（Data Volume Containers）：数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷，供其他容器挂载使用的。 根据官方文档对于commit的介绍中，可以猜测到为何之前创建的数据库、表都不见了，原因是因为mysql容器的挂载数据卷引起的。 我们可以通过命令查看到别名是“mysql”的容器挂载数据卷的目录。 看一下我们的“mysql”容器的ID信息，方便查看。 通过命令docker inspect查看mysql这个容器的数据卷挂载信息： 1docker inspect c9 执行命令之后，由于显示的内容比较多，这里我们就贴一下重要的信息： 通过图中可以看到，mysql容器将容器内的/var/lib/mysql路径作为volume挂载。真正的数据库相关数据文件所在的目录就是“Source”对应的目录，即：/var/lib/docker/volumes/1b0b17f6a4f78d357a187116d75991db8ee784213e67cc9b9988c8ef647fe563/_data 我们可以进入mysql容器查看/var/lib/mysql目录下的内容： 发现的确是mysql数据库的数据文件（红色区域）。 这时候，我们切换到Linux命令行，进入到mysql容器的数据挂载目录，看看该目录下有什么内容： /var/lib/docker/volumes/1b0b17f6a4f78d357a187116d75991db8ee784213e67cc9b9988c8ef647fe563/_data 如下图所示： 咦~ 是不是发现了什么！把黄色区域的内容与上图中红色区域内容进行对比，是不是内容一模一样！ 这也就印证了，当初我们在mysql容器中创建的数据库、表等，真正的数据库文件存放的位置就是在宿主机下面，而不是存放在容器中。 到此，我们终于知道了为何mysql-new容器中的数据库、表都不见了，原来数据库文件是存放在宿主机上的。 那该如何解决这个问题呢？怎样才能让mysql-new容器启动之后可以正常加载我们之前创建的数据库、表等数据呢？这就引入了下面的正题 —— 数据挂载。 数据挂载docker的数据挂载分为三种，volume、bind mount和tmpfs，关于三种的具体说明，有兴趣了解的可以看一下官网的文档 https://docs.docker.com/storage/ 参考文档 《基于docker部署mysql的数据持久化问题》 https://www.jianshu.com/p/530d00f97cbf 上面的文章里面，把问题描述的非常详细清楚。我这里就不多做说明了。 使用 -v 实现数据挂载（数据卷）如果我们想在 run 一个新的mysql容器的时候，可以正常访问我们之前在mysql容器中创建的数据库、表数据，则在docker run命令启动容器的时候，就需要指定挂载目录。 注意：要想让新的mysql容器能正常挂载名称是“mysql”容器，前提是需要先停止名称是“mysql”的容器，不然的话，即使run命令配置正确，容器启动的时候会一直报错： 上图就是因为没有事先停止mysql容器导致的。 下面开始具体操作： 先停止mysql容器 重新启动一个新的mysql容器，命令如下： 1docker run -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql-v -v /var/lib/docker/volumes/1b0b17f6a4f78d357a187116d75991db8ee784213e67cc9b9988c8ef647fe563/_data:/var/lib/mysql mysql 最重要的一个参数 -v ：挂载数据卷。-v 后面的值中间有“：”号，前半部分指的是宿主机的目录（也就是我们上面的mysql容器的数据库存储的目录），后半部分指的是容器的目录。 实现的效果就是说：新启动的容器，挂载宿主机的目录，实现数据共享。 运行结果： 登录新的mysql-v容器，查看数据库信息直接看下图的命令操作吧： 看到效果了吧！在这个mysql-v的新容器里面，已经可以看到我们一开始在“mysql”容器中创建的数据库和表了。 也就实现了容器之间的数据共享。 核心的实现就是在run命令里面加入了 -v 参数。如果不太明白-v的含义的，可以自行网上查询资料了解学习，加深印象。 上面我们解决了容器挂载数据卷的问题，但是细心的朋友，可能还有一个疑问：为什么修改了my.cnf配置文件、以及运行mysql镜像时指定的MYSQL_ROOT_PASSWORD=123456，却依然可以在新容器mysql-new中使用呢，为什么这俩样数据不会消失呢？ 官方文档对于commit命令还有这样一段描述： It can be useful to commit a container’s file changes or settings into a new image. 谷歌翻译过来的意思就是：将容器的文件更改或设置提交到新映像可能很有用。 还记得我们当初运行第一个mysql容器的时候，docker run 命令是怎样的，这里贴一下当时启动容器的命令： 1docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name=mysql mysql 其中，里面使用到了 -e 参数，设置了root用户的密码为123456。 所以，结合官方文档对commit的介绍（It can be useful to commit a container’s file changes or settings into a new image. ），就可以知道，通过 -e 设置的信息，在使用commit提交新镜像的时候，这些设置被容器保留了下来，commit命令使用这些设置构建了新的镜像，在新容器里面使用的是相同的设置。 这也印证了，我们在mysql-new容器中登录数据库的时候，登录密码写的是123456。因为在第一次启动mysql服务的时候，用户root密码是通过 -e 指定的，所以在commit提交新的镜像的时候，是被一同提交到了新镜像mysql-new中。 数据卷容器 通过数据卷容器也可以实现多个容器间的数据共享。 如果要授权一个容器访问另一个容器的数据卷，我们可以使用-volumes-from参数来执行docker run。 （这里就不多做说明了，有兴趣的可以网上自行查阅资料研究）","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"https://www.cicoding.cn/tags/Mysql/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"HttpClient工具类","slug":"httpclient-utils","date":"2019-10-11T09:32:16.000Z","updated":"2022-09-17T14:13:56.148Z","comments":false,"path":"http/httpclient-utils/","link":"","permalink":"https://www.cicoding.cn/http/httpclient-utils/","excerpt":"","text":"HttpClientUtils123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874import java.io.BufferedReader;import java.io.DataOutputStream;import java.io.EOFException;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.io.UnsupportedEncodingException;import java.net.HttpURLConnection;import java.net.URI;import java.net.URL;import java.net.URLConnection;import java.security.KeyManagementException;import java.security.NoSuchAlgorithmException;import java.security.cert.CertificateException;import java.security.cert.X509Certificate;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.Set; import javax.net.ssl.SSLContext;import javax.net.ssl.SSLException;import javax.net.ssl.SSLSession;import javax.net.ssl.SSLSocket;import javax.net.ssl.TrustManager;import javax.net.ssl.X509TrustManager; import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.http.Consts;import org.apache.http.HttpEntity;import org.apache.http.HttpResponse;import org.apache.http.HttpStatus;import org.apache.http.NameValuePair;import org.apache.http.ParseException;import org.apache.http.client.ClientProtocolException;import org.apache.http.client.HttpClient;import org.apache.http.client.config.RequestConfig;import org.apache.http.client.entity.UrlEncodedFormEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.client.methods.HttpPost;import org.apache.http.client.methods.RequestBuilder;import org.apache.http.client.utils.URIBuilder;import org.apache.http.client.utils.URLEncodedUtils;import org.apache.http.conn.scheme.Scheme;import org.apache.http.conn.ssl.SSLSocketFactory;import org.apache.http.conn.ssl.X509HostnameVerifier;import org.apache.http.entity.ByteArrayEntity;import org.apache.http.entity.ContentType;import org.apache.http.entity.StringEntity;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.DefaultHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.message.BasicHeader;import org.apache.http.message.BasicNameValuePair;import org.apache.http.params.BasicHttpParams;import org.apache.http.params.HttpConnectionParams;import org.apache.http.params.HttpParams;import org.apache.http.protocol.HTTP;import org.apache.http.util.ByteArrayBuffer;import org.apache.http.util.EntityUtils; /** * 封装了一些采用HttpClient发送HTTP请求的方法 * * @see 本工具所采用的是最新的HttpComponents-Client-4.2.1 */public class HttpClientUtils &#123; private static Log logger = LogFactory.getLog(HttpClientUtils.class); /** * 设置请求头和参数 post提交 * * @param urlStr * 地址 * @param headMap * 请求头 * @param paramMap * 内容参数 * @return */ public static String connectPost(String urlStr, Map&lt;String, String&gt; headMap, Map&lt;String, String&gt; paramMap) &#123; logger.info(\"========设置请求头和参数并以 post提交=======\"); URL url; String sCurrentLine = \"\"; String sTotalString = \"\"; DataOutputStream out = null; try &#123; url = new URL(urlStr); logger.info(\"请求地址:\" + urlStr); URLConnection URLconnection = url.openConnection(); HttpURLConnection httpConnection = (HttpURLConnection) URLconnection; // httpConnection.setRequestProperty(\"Content-type\", \"application/json\"); httpConnection.setRequestProperty(\"Accept-Charset\", \"utf-8\"); httpConnection.setRequestProperty(\"contentType\", \"utf-8\"); if (headMap != null &amp;&amp; !headMap.isEmpty()) &#123; for (String key : headMap.keySet()) &#123; logger.info(\"头部信息key:\" + key + \"===值: \" + headMap.get(key)); httpConnection.setRequestProperty(key, headMap.get(key)); &#125; &#125; httpConnection.setRequestMethod(\"POST\"); httpConnection.setDoOutput(true); httpConnection.setDoInput(true); StringBuffer params = new StringBuffer(); // 表单参数与get形式一样 if (paramMap != null &amp;&amp; !paramMap.isEmpty()) &#123; for (String key : paramMap.keySet()) &#123; if (params.length() &gt; 1) &#123; params.append(\"&amp;\"); &#125; params.append(key).append(\"=\").append(paramMap.get(key).trim()); &#125; logger.info(\"请求参数: \" + params.toString()); &#125; //System.out.println(\"params = \" + params.toString()); out = new DataOutputStream(httpConnection.getOutputStream()); // 发送请求参数 if (params!=null) &#123; out.writeBytes(params.toString()); &#125; // flush输出流的缓冲 out.flush(); // int responseCode = httpConnection.getResponseCode(); // if (responseCode == HttpURLConnection.HTTP_OK) &#123; InputStream urlStream = httpConnection.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(urlStream)); while ((sCurrentLine = bufferedReader.readLine()) != null) &#123; sTotalString += sCurrentLine; &#125; // //System.out.println(sTotalString); // 假设该url页面输出为\"OK\" // &#125;else&#123; // System.err.println(\"FIAL\"); // &#125; &#125; catch (Exception e) &#123; logger.info(\"请求错误: \" + e.getMessage()); logger.error(\"系统错误:\",e); &#125; finally &#123; &#125; logger.info(\"响应信息: \" + sTotalString); return sTotalString; &#125; public static void test() throws Exception&#123; String url = \"http://******/api/hdfs/proxy/create?username=******&amp;password=*****&amp;uri=/test/test-xx.txt\"; byte[] bytes = \"1\".getBytes(); HttpClient client = HttpClients.createDefault(); RequestBuilder requestBuilder = RequestBuilder.post(); requestBuilder.setEntity(new ByteArrayEntity(bytes)); requestBuilder.setUri(url); HttpResponse response = client.execute(requestBuilder.build()); HttpEntity entity = response.getEntity(); //获得响应流 InputStream is = entity.getContent(); //读取流中内容 ByteArrayBuffer buffer = new ByteArrayBuffer(4096); byte[] tmp = new byte[4096]; int count; try &#123; while ((count = is.read(tmp)) != -1) &#123; buffer.append(tmp, 0, count); &#125; &#125; catch (EOFException e) &#123; logger.error(\"系统错误:\",e); &#125; //System.out.println(new String(buffer.toByteArray())); &#125; /** * Http Get方法 * * @param url * @param param * @return */ public static String doGet(String url, Map&lt;String, String&gt; param) &#123; // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); String resultString = \"\"; CloseableHttpResponse response = null; try &#123; // 创建uri URIBuilder builder = new URIBuilder(url); if (param != null) &#123; for (String key : param.keySet()) &#123; builder.addParameter(key, param.get(key)); &#125; &#125; URI uri = builder.build(); // 创建http GET请求 HttpGet httpGet = new HttpGet(uri); // 执行请求 response = httpclient.execute(httpGet); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) &#123; resultString = EntityUtils.toString(response.getEntity(), \"UTF-8\"); &#125; &#125; catch (Exception e) &#123; logger.error(\"系统错误:\",e); &#125; finally &#123; try &#123; if (response != null) &#123; response.close(); &#125; httpclient.close(); &#125; catch (IOException e) &#123; logger.error(\"系统错误:\",e); &#125; &#125; return resultString; &#125; /** * Http Get方法 * * @param url * @param param * @return */ public static String doGet(String url,Map&lt;String, String&gt; headMap,Map&lt;String, String&gt; param) &#123; // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); String resultString = \"\"; CloseableHttpResponse response = null; try &#123; // 创建uri URIBuilder builder = new URIBuilder(url); if (param != null) &#123; for (String key : param.keySet()) &#123; builder.addParameter(key, param.get(key)); &#125; &#125; URI uri = builder.build(); // 创建http GET请求 HttpGet httpGet = new HttpGet(uri); if (headMap != null &amp;&amp; !headMap.isEmpty()) &#123; for (String key : headMap.keySet()) &#123; logger.info(\"头部信息key:\" + key + \"===值: \" + headMap.get(key)); httpGet.addHeader(key, headMap.get(key)); &#125; &#125; // 执行请求 response = httpclient.execute(httpGet); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) &#123; resultString = EntityUtils.toString(response.getEntity(), \"UTF-8\"); &#125; &#125; catch (Exception e) &#123; logger.error(\"系统错误:\",e); &#125; finally &#123; try &#123; if (response != null) &#123; response.close(); &#125; httpclient.close(); &#125; catch (IOException e) &#123; logger.error(\"系统错误:\",e); &#125; &#125; return resultString; &#125; public static String doGet(String url) &#123; return doGet(url, null); &#125; /** * httpclient post方法 * * @param url * @param param * @return */ public static String doPost(String url,Map&lt;String, String&gt; headers,Map&lt;String, String&gt; param) &#123; // 创建Httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); CloseableHttpResponse response = null; String resultString = \"\"; try &#123; // 创建Http Post请求 HttpPost httpPost = new HttpPost(url); if(headers != null) &#123; for (String key : headers.keySet()) &#123; httpPost.setHeader(key, headers.get(key)); &#125; &#125; // 创建参数列表 if (param != null) &#123; List&lt;NameValuePair&gt; paramList = new ArrayList&lt;&gt;(); for (String key : param.keySet()) &#123; paramList.add(new BasicNameValuePair(key, param.get(key))); &#125; // 模拟表单 UrlEncodedFormEntity entity = new UrlEncodedFormEntity(paramList, \"utf-8\"); httpPost.setEntity(entity); &#125; // 执行http请求 response = httpClient.execute(httpPost); resultString = EntityUtils.toString(response.getEntity(), \"utf-8\"); &#125; catch (Exception e) &#123; logger.error(\"系统错误:\",e); &#125; finally &#123; try &#123; if (response!=null) &#123; response.close(); &#125; &#125; catch (IOException e) &#123; logger.error(\"系统错误:\",e); &#125; &#125; return resultString; &#125; public static String doPost(String url) &#123; return doPost(url,null,null); &#125; /** * 请求的参数类型为json * * @param url * @param json * @return &#123;username:\"\",pass:\"\"&#125; */ public static String doPostJson(String url, String json) &#123; logger.info(\"=====请求地址:\"+url); // 创建Httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); CloseableHttpResponse response = null; String resultString = \"\"; try &#123; // 创建Http Post请求 HttpPost httpPost = new HttpPost(url); // 创建请求内容 logger.info(\"=====请求参数:\"+json); StringEntity entity = new StringEntity(json, ContentType.APPLICATION_JSON); httpPost.setEntity(entity); // 执行http请求 response = httpClient.execute(httpPost); logger.info(\"=====响应参数:\"+response); resultString = EntityUtils.toString(response.getEntity(), \"utf-8\"); &#125; catch (Exception e) &#123; logger.error(\"系统错误:\",e); &#125; finally &#123; try &#123; if (response!=null) &#123; response.close(); &#125; &#125; catch (IOException e) &#123; logger.error(\"系统错误:\",e); &#125; &#125; return resultString; &#125; /** * 发送HTTP_GET请求 * * @see 该方法会自动关闭连接,释放资源 * @param requestURL * 请求地址(含参数) * @param decodeCharset * 解码字符集,解析响应数据时用之,其为null时默认采用UTF-8解码 * @return 远程主机响应正文 */ public static String sendGetRequest(String reqURL, String decodeCharset) &#123; long responseLength = 0; // 响应长度 String responseContent = null; // 响应内容 HttpClient httpClient = new DefaultHttpClient(); // 创建默认的httpClient实例 HttpGet httpGet = new HttpGet(reqURL); // 创建org.apache.http.client.methods.HttpGet try &#123; HttpResponse response = httpClient.execute(httpGet); // 执行GET请求 HttpEntity entity = response.getEntity(); // 获取响应实体 if (null != entity) &#123; responseLength = entity.getContentLength(); responseContent = EntityUtils.toString(entity, decodeCharset == null ? \"UTF-8\" : decodeCharset); EntityUtils.consume(entity); // Consume response content &#125; //System.out.println(\"请求地址: \" + httpGet.getURI()); //System.out.println(\"响应状态: \" + response.getStatusLine()); //System.out.println(\"响应长度: \" + responseLength); //System.out.println(\"响应内容: \" + responseContent); &#125; catch (ClientProtocolException e) &#123; logger.debug(\"该异常通常是协议错误导致,比如构造HttpGet对象时传入的协议不对(将'http'写成'htp')或者服务器端返回的内容不符合HTTP协议要求等,堆栈信息如下\", e); &#125; catch (ParseException e) &#123; logger.debug(e.getMessage(), e); &#125; catch (IOException e) &#123; logger.debug(\"该异常通常是网络原因引起的,如HTTP服务器未启动等,堆栈信息如下\", e); &#125; finally &#123; httpClient.getConnectionManager().shutdown(); // 关闭连接,释放资源 &#125; return responseContent; &#125; /** * 发送HTTP_POST请求 * * @see 该方法为&lt;code&gt;sendPostRequest(String,String,boolean,String,String)&lt;/code&gt;的简化方法 * @see 该方法在对请求数据的编码和响应数据的解码时,所采用的字符集均为UTF-8 * @see 当&lt;code&gt;isEncoder=true&lt;/code&gt;时,其会自动对&lt;code&gt;sendData&lt;/code&gt;中的[中文][|][ * ]等特殊字符进行&lt;code&gt;URLEncoder.encode(string,\"UTF-8\")&lt;/code&gt; * @param isEncoder * 用于指明请求数据是否需要UTF-8编码,true为需要 */ public static String sendPostRequest(String reqURL, String sendData, boolean isEncoder) &#123; return sendPostRequest(reqURL, sendData, isEncoder, null, null); &#125; /** * 发送HTTP_POST请求 * * @see 该方法会自动关闭连接,释放资源 * @see 当&lt;code&gt;isEncoder=true&lt;/code&gt;时,其会自动对&lt;code&gt;sendData&lt;/code&gt;中的[中文][|][ * ]等特殊字符进行&lt;code&gt;URLEncoder.encode(string,encodeCharset)&lt;/code&gt; * @param reqURL * 请求地址 * @param sendData * 请求参数,若有多个参数则应拼接成param11=value11&amp;22=value22&amp;33=value33的形式后,传入该参数中 * @param isEncoder * 请求数据是否需要encodeCharset编码,true为需要 * @param encodeCharset * 编码字符集,编码请求数据时用之,其为null时默认采用UTF-8解码 * @param decodeCharset * 解码字符集,解析响应数据时用之,其为null时默认采用UTF-8解码 * @return 远程主机响应正文 */ public static String sendPostRequest(String reqURL, String sendData, boolean isEncoder, String encodeCharset, String decodeCharset) &#123; String responseContent = null; HttpClient httpClient = new DefaultHttpClient(); HttpPost httpPost = new HttpPost(reqURL); // httpPost.setHeader(HTTP.CONTENT_TYPE, \"application/x-www-form-urlencoded; // charset=UTF-8\"); httpPost.setHeader(HTTP.CONTENT_TYPE, \"application/x-www-form-urlencoded\"); try &#123; if (isEncoder) &#123; List&lt;NameValuePair&gt; formParams = new ArrayList&lt;NameValuePair&gt;(); for (String str : sendData.split(\"&amp;\")) &#123; formParams.add(new BasicNameValuePair(str.substring(0, str.indexOf(\"=\")), str.substring(str.indexOf(\"=\") + 1))); &#125; httpPost.setEntity(new StringEntity( URLEncodedUtils.format(formParams, encodeCharset == null ? \"UTF-8\" : encodeCharset))); &#125; else &#123; httpPost.setEntity(new StringEntity(sendData)); &#125; HttpResponse response = httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); if (null != entity) &#123; responseContent = EntityUtils.toString(entity, decodeCharset == null ? \"UTF-8\" : decodeCharset); EntityUtils.consume(entity); &#125; &#125; catch (Exception e) &#123; logger.debug(\"与[\" + reqURL + \"]通信过程中发生异常,堆栈信息如下\", e); &#125; finally &#123; httpClient.getConnectionManager().shutdown(); &#125; return responseContent; &#125; /** * 发送HTTP_POST请求 * * @see 该方法会自动关闭连接,释放资源 * @see 该方法会自动对&lt;code&gt;params&lt;/code&gt;中的[中文][|][ * ]等特殊字符进行&lt;code&gt;URLEncoder.encode(string,encodeCharset)&lt;/code&gt; * @param reqURL * 请求地址 * @param params * 请求参数 * @param encodeCharset * 编码字符集,编码请求数据时用之,其为null时默认采用UTF-8解码 * @param decodeCharset * 解码字符集,解析响应数据时用之,其为null时默认采用UTF-8解码 * @return 远程主机响应正文 */ public static String sendPostRequest(String reqURL, Map&lt;String, String&gt; params, String encodeCharset, String decodeCharset) &#123; String responseContent = null; HttpClient httpClient = new DefaultHttpClient(); HttpPost httpPost = new HttpPost(reqURL); List&lt;NameValuePair&gt; formParams = new ArrayList&lt;NameValuePair&gt;(); // 创建参数队列 for (Map.Entry&lt;String, String&gt; entry : params.entrySet()) &#123; formParams.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); &#125; try &#123; httpPost.setEntity(new UrlEncodedFormEntity(formParams, encodeCharset == null ? \"UTF-8\" : encodeCharset)); HttpResponse response = httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); if (null != entity) &#123; responseContent = EntityUtils.toString(entity, decodeCharset == null ? \"UTF-8\" : decodeCharset); EntityUtils.consume(entity); &#125; &#125; catch (Exception e) &#123; logger.debug(\"与[\" + reqURL + \"]通信过程中发生异常,堆栈信息如下\", e); &#125; finally &#123; httpClient.getConnectionManager().shutdown(); &#125; return responseContent; &#125; /** * 发送HTTPS_POST请求 * * @see 该方法为&lt;code&gt;sendPostSSLRequest(String,Map&lt;String,String&gt;,String,String)&lt;/code&gt;方法的简化方法 * @see 该方法在对请求数据的编码和响应数据的解码时,所采用的字符集均为UTF-8 * @see 该方法会自动对&lt;code&gt;params&lt;/code&gt;中的[中文][|][ * ]等特殊字符进行&lt;code&gt;URLEncoder.encode(string,\"UTF-8\")&lt;/code&gt; */ public static String sendPostSSLRequest(String reqURL, Map&lt;String, String&gt; params) &#123; return sendPostSSLRequest(reqURL, params, null, null); &#125; /** * 发送HTTPS_POST请求 * * @see 该方法会自动关闭连接,释放资源 * @see 该方法会自动对&lt;code&gt;params&lt;/code&gt;中的[中文][|][ * ]等特殊字符进行&lt;code&gt;URLEncoder.encode(string,encodeCharset)&lt;/code&gt; * @param reqURL * 请求地址 * @param params * 请求参数 * @param encodeCharset * 编码字符集,编码请求数据时用之,其为null时默认采用UTF-8解码 * @param decodeCharset * 解码字符集,解析响应数据时用之,其为null时默认采用UTF-8解码 * @return 远程主机响应正文 */ public static String sendPostSSLRequest(String reqURL, Map&lt;String, String&gt; params, String encodeCharset, String decodeCharset) &#123; String responseContent = \"\"; HttpClient httpClient = new DefaultHttpClient(); X509TrustManager xtm = new X509TrustManager() &#123; public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125; &#125;; try &#123; SSLContext ctx = SSLContext.getInstance(\"TLS\"); ctx.init(null, new TrustManager[] &#123; xtm &#125;, null); SSLSocketFactory socketFactory = new SSLSocketFactory(ctx); httpClient.getConnectionManager().getSchemeRegistry().register(new Scheme(\"https\", 443, socketFactory)); HttpPost httpPost = new HttpPost(reqURL); List&lt;NameValuePair&gt; formParams = new ArrayList&lt;NameValuePair&gt;(); for (Map.Entry&lt;String, String&gt; entry : params.entrySet()) &#123; formParams.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); &#125; httpPost.setEntity(new UrlEncodedFormEntity(formParams, encodeCharset == null ? \"UTF-8\" : encodeCharset)); HttpResponse response = httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); if (null != entity) &#123; responseContent = EntityUtils.toString(entity, decodeCharset == null ? \"UTF-8\" : decodeCharset); EntityUtils.consume(entity); &#125; &#125; catch (Exception e) &#123; logger.debug(\"与[\" + reqURL + \"]通信过程中发生异常,堆栈信息为\", e); &#125; finally &#123; httpClient.getConnectionManager().shutdown(); &#125; return responseContent; &#125; /** * 发送HTTP_POST请求 * * @see 若发送的&lt;code&gt;params&lt;/code&gt;中含有中文,记得按照双方约定的字符集将中文&lt;code&gt;URLEncoder.encode(string,encodeCharset)&lt;/code&gt; * @see 本方法默认的连接超时时间为30秒,默认的读取超时时间为30秒 * @param reqURL * 请求地址 * @param params * 发送到远程主机的正文数据,其数据类型为&lt;code&gt;java.util.Map&lt;String, String&gt;&lt;/code&gt; * @return 远程主机响应正文`HTTP状态码,如&lt;code&gt;\"SUCCESS`200\"&lt;/code&gt;&lt;br&gt; * 若通信过程中发生异常则返回\"Failed`HTTP状态码\",如&lt;code&gt;\"Failed`500\"&lt;/code&gt; */ public static String sendPostRequestByJava(String reqURL, Map&lt;String, String&gt; params) &#123; StringBuilder sendData = new StringBuilder(); for (Map.Entry&lt;String, String&gt; entry : params.entrySet()) &#123; sendData.append(entry.getKey()).append(\"=\").append(entry.getValue()).append(\"&amp;\"); &#125; if (sendData.length() &gt; 0) &#123; sendData.setLength(sendData.length() - 1); // 删除最后一个&amp;符号 &#125; return sendPostRequestByJava(reqURL, sendData.toString()); &#125; /** * 发送HTTP_POST请求 * * @see 若发送的&lt;code&gt;sendData&lt;/code&gt;中含有中文,记得按照双方约定的字符集将中文&lt;code&gt;URLEncoder.encode(string,encodeCharset)&lt;/code&gt; * @see 本方法默认的连接超时时间为30秒,默认的读取超时时间为30秒 * @param reqURL * 请求地址 * @param sendData * 发送到远程主机的正文数据 * @return 远程主机响应正文`HTTP状态码,如&lt;code&gt;\"SUCCESS`200\"&lt;/code&gt;&lt;br&gt; * 若通信过程中发生异常则返回\"Failed`HTTP状态码\",如&lt;code&gt;\"Failed`500\"&lt;/code&gt; */ public static String sendPostRequestByJava(String reqURL, String sendData) &#123; HttpURLConnection httpURLConnection = null; OutputStream out = null; // 写 InputStream in = null; // 读 int httpStatusCode = 0; // 远程主机响应的HTTP状态码 try &#123; URL sendUrl = new URL(reqURL); httpURLConnection = (HttpURLConnection) sendUrl.openConnection(); httpURLConnection.setRequestMethod(\"POST\"); httpURLConnection.setDoOutput(true); // 指示应用程序要将数据写入URL连接,其值默认为false httpURLConnection.setUseCaches(false); httpURLConnection.setConnectTimeout(30000); // 30秒连接超时 httpURLConnection.setReadTimeout(30000); // 30秒读取超时 out = httpURLConnection.getOutputStream(); out.write(sendData.toString().getBytes()); // 清空缓冲区,发送数据 out.flush(); // 获取HTTP状态码 httpStatusCode = httpURLConnection.getResponseCode(); in = httpURLConnection.getInputStream(); byte[] byteDatas = new byte[in.available()]; in.read(byteDatas); return new String(byteDatas) + \"`\" + httpStatusCode; &#125; catch (Exception e) &#123; logger.debug(e.getMessage()); return \"Failed`\" + httpStatusCode; &#125; finally &#123; if (out != null) &#123; try &#123; out.close(); &#125; catch (Exception e) &#123; logger.debug(\"关闭输出流时发生异常,堆栈信息如下\", e); &#125; &#125; if (in != null) &#123; try &#123; in.close(); &#125; catch (Exception e) &#123; logger.debug(\"关闭输入流时发生异常,堆栈信息如下\", e); &#125; &#125; if (httpURLConnection != null) &#123; httpURLConnection.disconnect(); httpURLConnection = null; &#125; &#125; &#125; /** * https posp请求，可以绕过证书校验 * * @param url * @param params * @return */ public static final String sendHttpsRequestByPost(String url, Map&lt;String, String&gt; params) &#123; String responseContent = null; HttpClient httpClient = new DefaultHttpClient(); // 创建TrustManager X509TrustManager xtm = new X509TrustManager() &#123; public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; &#125; public X509Certificate[] getAcceptedIssuers() &#123; return null; &#125; &#125;; // 这个好像是HOST验证 X509HostnameVerifier hostnameVerifier = new X509HostnameVerifier() &#123; public boolean verify(String arg0, SSLSession arg1) &#123; return true; &#125; public void verify(String arg0, SSLSocket arg1) throws IOException &#123; &#125; public void verify(String arg0, String[] arg1, String[] arg2) throws SSLException &#123; &#125; public void verify(String arg0, X509Certificate arg1) throws SSLException &#123; &#125; &#125;; try &#123; // TLS1.0与SSL3.0基本上没有太大的差别，可粗略理解为TLS是SSL的继承者，但它们使用的是相同的SSLContext SSLContext ctx = SSLContext.getInstance(\"TLS\"); // 使用TrustManager来初始化该上下文，TrustManager只是被SSL的Socket所使用 ctx.init(null, new TrustManager[] &#123; xtm &#125;, null); // 创建SSLSocketFactory SSLSocketFactory socketFactory = new SSLSocketFactory(ctx); socketFactory.setHostnameVerifier(hostnameVerifier); // 通过SchemeRegistry将SSLSocketFactory注册到我们的HttpClient上 httpClient.getConnectionManager().getSchemeRegistry().register(new Scheme(\"https\", socketFactory, 443)); HttpPost httpPost = new HttpPost(url); List&lt;NameValuePair&gt; formParams = new ArrayList&lt;NameValuePair&gt;(); // 构建POST请求的表单参数 for (Map.Entry&lt;String, String&gt; entry : params.entrySet()) &#123; formParams.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); &#125; httpPost.setEntity(new UrlEncodedFormEntity(formParams, \"UTF-8\")); HttpResponse response = httpClient.execute(httpPost); HttpEntity entity = response.getEntity(); // 获取响应实体 if (entity != null) &#123; responseContent = EntityUtils.toString(entity, \"UTF-8\"); &#125; &#125; catch (KeyManagementException e) &#123; logger.error(\"系统错误:\",e); &#125; catch (NoSuchAlgorithmException e) &#123; logger.error(\"系统错误:\",e); &#125; catch (UnsupportedEncodingException e) &#123; logger.error(\"系统错误:\",e); &#125; catch (ClientProtocolException e) &#123; logger.error(\"系统错误:\",e); &#125; catch (ParseException e) &#123; logger.error(\"系统错误:\",e); &#125; catch (IOException e) &#123; logger.error(\"系统错误:\",e); &#125; finally &#123; // 关闭连接,释放资源 httpClient.getConnectionManager().shutdown(); &#125; return responseContent; &#125; /** * 发送HTTP_POST请求,json格式数据 * * @param url * @param body * @return * @throws Exception */ public static String sendPostByJson(String url, String body) throws Exception &#123; CloseableHttpClient httpclient = HttpClients.custom().build(); HttpPost post = null; String resData = null; CloseableHttpResponse result = null; try &#123; post = new HttpPost(url); HttpEntity entity2 = new StringEntity(body, Consts.UTF_8); post.setConfig(RequestConfig.custom().setConnectTimeout(30000).setSocketTimeout(30000).build()); post.setHeader(\"Content-Type\", \"application/json\"); post.setHeader(\"Access-Token\", \"sund2f3bf3e7ecea902bcdb7027e9139a02\"); post.setEntity(entity2); result = httpclient.execute(post); if (HttpStatus.SC_OK == result.getStatusLine().getStatusCode()) &#123; resData = EntityUtils.toString(result.getEntity()); &#125; &#125; finally &#123; if (result != null) &#123; result.close(); &#125; if (post != null) &#123; post.releaseConnection(); &#125; httpclient.close(); &#125; return resData; &#125; /** * HttpPost发送header,Content(json格式) * * @param url * @param json * @param headers * @return */ public static String post(String url, Map&lt;String, String&gt; headers, Map&lt;String, String&gt; jsonMap) &#123; HttpClient client = new DefaultHttpClient(); HttpPost post = new HttpPost(url); logger.info(\"请求地址:\" + url); // post.setHeader(\"Content-Type\", \"application/x-www-form-urlencoded\"); logger.info(\"请求头信息:\" + headers); if (headers != null) &#123; Set&lt;String&gt; keys = headers.keySet(); for (Map.Entry&lt;String, String&gt; entrdy : headers.entrySet()) &#123; post.addHeader(entrdy.getKey(), entrdy.getValue()); //System.out.println(\"headers:\" + entrdy.getKey() + \",值\" + entrdy.getValue()); &#125; &#125; String charset = null; try &#123; StringEntity s = new StringEntity(jsonMap.toString(), \"utf-8\"); logger.info(\"请求json参数:\" + jsonMap); // s.setContentEncoding(new BasicHeader(HTTP.CONTENT_TYPE, \"application/json\")); // s.setContentType(\"application/json\"); // s.setContentType(new BasicHeader(HTTP.CONTENT_TYPE, \"application/json\")); post.setEntity(s); logger.info(\"请求实体数据:\" + post); // HttpResponse res = client.execute(post); HttpResponse httpResponse = client.execute(post); InputStream inStream = httpResponse.getEntity().getContent(); BufferedReader reader = new BufferedReader(new InputStreamReader(inStream, \"utf-8\")); StringBuilder strber = new StringBuilder(); String line = null; while ((line = reader.readLine()) != null) strber.append(line + \"\\n\"); inStream.close(); logger.info(\"MobilpriseActivity:\" + strber); if (httpResponse.getStatusLine().getStatusCode() == HttpStatus.SC_OK) &#123; HttpEntity entity = httpResponse.getEntity(); charset = EntityUtils.getContentCharSet(entity); &#125; &#125; catch (Exception e) &#123; logger.info(\"报错咯:\" + e.getMessage()); throw new RuntimeException(e); &#125; logger.info(\"响应参数:\" + charset); return charset; &#125; public static void main(String[] args) &#123; try &#123; Map&lt;String,String&gt; headmap = new HashMap&lt;String,String&gt;(); headmap.put(\"Access-Token\", \"sund2f3bf3e7ecea902bcdb7027e9139a02\"); Map&lt;String,String&gt; paramap = new HashMap&lt;String,String&gt;(); paramap.put(\"customerDeptId\", \"38\"); paramap.put(\"postCode\", \"qqqq\"); System.out.println(doPost(\"http://10.39.137.100/api/needs/getInfoByCondition\",headmap,paramap)); //System.out.println(sendPostByJson(\"http://10.39.137.100/api/needs/getInfoByCondition\",\"&#123;\\\"customerDeptId\\\":38,\\\"postCode\\\":\\\"qqqq\\\"&#125;\")); &#125; catch (Exception e) &#123; logger.error(\"系统错误:\",e); &#125; &#125; &#125; 请求示例:1234567891011// 设置请求参数Map&lt;String, String&gt; param = new HashMap&lt;String, String&gt;();param.put(\"test\", \"test\");// 设置请求头信息Map&lt;String, String&gt; headMap =new HashMap&lt;String, String&gt;();headMap.put(\"Authorization\", token);headMap.put(\"Content-type\", \"application/json\");// 判断token获取的user信息String tkJson = HttpClientUtils.connectPost(ssoGetUserURL, headMap, param);JSONObject resultJson = JSONObject.fromObject(tkJson);String employeeNo=json.getString(\"EmployeeNo\"); 相关依赖包123456789101112&lt;!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;version&gt;4.4.12&lt;/version&gt;&lt;/dependency&gt; 原文链接：https://blog.csdn.net/lchq1995/article/details/88293047","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://www.cicoding.cn/categories/HTTP/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://www.cicoding.cn/tags/HTTP/"},{"name":"httpclient","slug":"httpclient","permalink":"https://www.cicoding.cn/tags/httpclient/"}],"keywords":[{"name":"HTTP","slug":"HTTP","permalink":"https://www.cicoding.cn/categories/HTTP/"}]},{"title":"SpringBoot2.1.6集成spring session redis实现session共享","slug":"springboot-redis-springsession","date":"2019-10-11T05:15:15.000Z","updated":"2022-09-17T14:13:56.183Z","comments":false,"path":"springboot/springboot-redis-springsession/","link":"","permalink":"https://www.cicoding.cn/springboot/springboot-redis-springsession/","excerpt":"","text":"使用 Redis 实现 Session 共享1 什么是 Session由于 HTTP 协议是无状态的协议，因而服务端需要记录用户的状态时，就需要用某种机制来识具体的用户。Session 是另一种记录客户状态的机制，不同的是 Cookie 保存在客户端浏览器中，而 Session 保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是 Session。客户端浏览器再次访问时只需要从该 Session 中查找该客户的状态就可以了。 2 为什么需要同步session ？ 当用户量比较大时候一个tomcat可能无法处理更多的请求，超过单个tomcat的承受能力，可能会出现用户等待，严重的导致tomcat宕机。 这时候我们后端可能会采用多个tomcat去处理请求，分派请求，不同请求让多个tomcat分担处理。 登录的时候可能采用的是tomca1，下单的时候可能采用的是tomcat2 等等等。 若没有session共享同步，可能在tomcat1登录了，下一次请求被分派到tomcat2上，这时候用户就需要重新登录。 在实际工作中我们建议使用外部的缓存设备来共享 Session，避免单个节点挂掉而影响服务，使用外部缓存 Session 后，我们的共享数据都会放到外部缓存容器中，服务本身就会变成无状态的服务，可以随意的根据流量的大小增加或者减少负载的设备。 目前主流的分布式 Session 管理有两种方案。 1 Session 复制部分 Web 服务器能够支持 Session 复制功能，如 Tomcat。用户可以通过修改 Web 服务器的配置文件，让 Web 服务器进行 Session 复制，保持每一个服务器节点的 Session 数据都能达到一致。 这种方案的实现依赖于 Web 服务器，需要 Web 服务器有 Session 复制功能。当 Web 应用中 Session 数量较多的时候，每个服务器节点都需要有一部分内存用来存放 Session，将会占用大量内存资源。同时大量的 Session 对象通过网络传输进行复制，不但占用了网络资源，还会因为复制同步出现延迟，导致程序运行错误。 在微服务架构中，往往需要 N 个服务端来共同支持服务，不建议采用这种方案。 这种session 管理方式，可以参考此篇文章：传送门 2 Session 集中存储在单独的服务器或服务器集群上使用缓存技术，如 Redis 存储 Session 数据，集中管理所有的 Session，所有的 Web 服务器都从这个存储介质中存取对应的 Session，实现 Session 共享。将 Session 信息从应用中剥离出来后，其实就达到了服务的无状态化，这样就方便在业务极速发展时水平扩充。 Spring SessionSpring Session 提供了一套创建和管理 Servlet HttpSession 的方案。Spring Session 提供了集群 Session（Clustered Sessions）功能，默认采用外置的 Redis 来存储 Session 数据，以此来解决 Session 共享的问题。 Spring Session 为企业级 Java 应用的 Session 管理带来了革新，使得以下的功能更加容易实现： API 和用于管理用户会话的实现； HttpSession，允许以应用程序容器（即 Tomcat）中性的方式替换 HttpSession；将 Session 所保存的状态卸载到特定的外部 Session 存储中，如 Redis 或 Apache Geode中，它们能够以独立于应用服务器的方式提供高质量的集群； 支持每个浏览器上使用多个Session，从而能够很容易地构建更加丰富的终端用户体验； 控制 Session ID如何在客户端和服务器之间进行交换，这样的话就能很容易地编写 Restful API，因为它可以从 HTTP 头信息中获取 SessionID，而不必再依赖于 cookie； 当用户使用 WebSocket 发送请求的时候，能够保持 HttpSession 处于活跃状态。需要说明的很重要的一点就是，Spring Session 的核心项目并不依赖于 Spring 框架，因此，我们甚至能够将其应用于不使用Spring 框架的项目中。 3 项目准备3.1 pom文件添加依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis-reactive&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 3.2 配置文件添加redis 链接12345678910spring.redis.database=0spring.redis.host=127.0.0.1spring.redis.port=6379spring.redis.password=spring.redis.jedis.pool.max-idle=8spring.redis.jedis.pool.max-wait=-1spring.redis.jedis.pool.min-idle=0spring.redis.timeout=5000server.port=8081 3.3添加redis session配置123456789package com.crecgec.cas.frontend.config;import org.springframework.context.annotation.Configuration;import org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSession;@Configuration @EnableRedisHttpSessionpublic class RedisSessionConfig &#123; &#125; 3.4 获取sessionid Controller123456789101112131415161718192021222324252627282930package com.crecgec.cas.frontend.controller; import java.util.HashMap;import java.util.Map; import javax.servlet.http.HttpSession; import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController; @RestControllerpublic class SessionController &#123; @RequestMapping(value = &quot;/setsession&quot;) public Object setSession(@RequestParam(required=false) String value, HttpSession session) &#123; session.setAttribute(&quot;value&quot;, value); return session.getId(); &#125; @RequestMapping(value = &quot;/getsession&quot;) public Object getSession(HttpSession session) &#123; Object value = session.getAttribute(&quot;value&quot;); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;sessionId&quot;, session.getId()); map.put(&quot;value&quot;, value); return map; &#125; &#125; 3.5 测试访问http://localhost:8080/setsession 启动8081 http://localhost:8081/getsession 参考文献：springboot2.1入门系列四 Spring Session实现session共享Redis共享Session原理及示例SpringBoot 使用 Redis 实现 Session 共享","categories":[{"name":"SpringSession","slug":"SpringSession","permalink":"https://www.cicoding.cn/categories/SpringSession/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cicoding.cn/tags/SpringBoot/"},{"name":"session共享","slug":"session共享","permalink":"https://www.cicoding.cn/tags/session共享/"},{"name":"SpringSession","slug":"SpringSession","permalink":"https://www.cicoding.cn/tags/SpringSession/"}],"keywords":[{"name":"SpringSession","slug":"SpringSession","permalink":"https://www.cicoding.cn/categories/SpringSession/"}]},{"title":"在Docker中安装Tomcat","slug":"07-docker-lession-index","date":"2019-10-04T02:20:27.000Z","updated":"2022-09-17T14:13:56.145Z","comments":false,"path":"docker/07-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/07-docker-lession-index/","excerpt":"","text":"Docker 中国官方镜像加速 http://www.docker-cn.com/registry-mirror 前言 Tomcat镜像中已经包含jdk环境依赖，所以我们可以不用去启动java容器，直接运行tomcat容器就可以正常访问tomcat服务的，当然，你启动了java容器，也不会有什么影响，因为容器之间是隔离的。 查询Tomcat镜像列表1docker search tomcat 运行结果如下图： 一般情况下，都会选择下载stars数量最多的那个镜像，排在第一位的，一般都是官方提供的镜像。 下载Tomcat镜像执行命令下载tomcat镜像： 1docker pull tomcat 运行Tomcat镜像1docker run -p 8081:8080 tomcat 运行效果如下图： 访问tomcat： 当前docker服务运行在我的阿里云服务器上的，公网IP是39.106.18.21，所以打开浏览器输入：39.106.18.21:8081 效果如下： 是不是很简单，一个tomcat就这样启动完成了！不得不说docker的强大！ 有没有觉得上面的启动方式存在什么问题？如果在命令行界面中按下 Ctrl+C快捷键，会有什么效果？ 没错，当前的tomcat容器会停止运行，服务无法访问！ 有什么办法可以让tomcat容器一直运行呢？ 解决办法其实很简单，答案就再在 docker run 命令里面设置一个 -d 的参数即可，如下： 看到没有，和上面的启动tomcat的效果不同，控制台并未输出tomcat启动的日志信息，这时候我们打开浏览器，重新访问一下： 00.00.00.00:8081 效果如下： 通过上面两次docker run 启动tomcat的效果对比，我想大家也应该看得出区别了。所以，如果想让应用在后台一直运行的话，通过在 docker run 命令中使用“-d”参数来让容器处于后台运行。 查看运行中的Tomcat容器通过下面命令，来查看当前服务器上运行的docker容器列表： 1docker ps 如下图所示： 从图中可以看到tomcat容器的一些信息，在最后一列的“NAMES”显示的tomcat名称是“quirky_mayer”，这是因为你在docker run的时候，没有指定“–name”别名，docker会给你自动生成一个别名，一般情况下，我们还是建议使用–name来设置别名以及版本，方便实际使用容易区分。 然后tomcat容器的“PORTS”这一列，可以看到8081 &gt; 8080 的信息，我们知道tomcat是运行在容器里面的，而tomcat默认的端口是8080，也就是说tomcat所在容器的对外端口是8080，我们如果想通过浏览器等访问到tomcat，就需要指定一个宿主机的端口与这个tomcat容器端口进行映射，也就是8081这个宿主机的端口。我们实际在浏览器访问的时候，就是通过8081来访问的，不能使用8080访问。端口号的话你也可以自定义的。 停止Tomcat容器 我们在jdk的文章中已经提及到停止容器的命令。 首先我们还是要查看一下目前正在运行状态的tomcat容器的信息（ID或者别名）： 1docker ps 如下图： 我们可以看到tomcat容器的ID以及别名的信息，这里我就直接使用ID进行容器的操作了。 通过docker stop实现容器停止关闭：1docker stop 22 运行结果如图： 回车之后，控制台输出“22”，表示已经成功停止了容器ID以“22”开头的tomcat容器。 这时候在去查看一下当前处于运行状态的容器列表： 可以看到，tomcat容器已经被关闭了。 或许你会有疑问 【问题】： 之前启动了tomcat容器，最后又把它关闭了，那我如果想再运行这个tomcat服务，怎么办？难道是要重新执行docker run这个命令来运行一个tomcat容器吗？ 【解答】： 我们要知道docker run这个命令的作用，其实是运行一个全新的容器。你执行一次docker run命令，就会生成一个新的容器，通过一个图来看一下具体情况： 从图中可以看到，出现了很多tomcat的容器，而且“STATUS”状态为“Exited”。什么意思呢？因为我在操作的过程中，总共执行了5次docker run命令（这里忽略docker rm删除的容器），启动了5个全新的容器，每个容器之间是隔离的。同时，我又对每个tomcat容器执行了docker stop关闭命令，所以状态都是“Exited”。 所以，你每次启动的容器，docker都会给你保留下来，并不是说你执行了docker stop命令，容器就会被删除掉，答案是不会删除掉，只是标记一下容器的STATUS为Exited状态，处于未运行状态。 所以，如果想重新运行关闭状态下的容器，请使用docker start命令，比如我这里随便启动一个tomcat容器： 12&gt; docker start 22&gt; 这时候通过docker ps查看处于运行状态的容器列表： 说明tomcat容器已经启动成功了！ 我们再通过docker ps -a查看所有的容器列表（包括未运行的容器），主要看一下tomcat容器的数量是否和上面的5个一致，并未重新运行一个全新的容器： 可以看到，tomcat容器的数量并未发生变化，其中的一个tomcat容器处于运行状态，剩余4个都是Exited停止状态。 【问题】： 如果上图中代表当前服务器上的容器情况，如果这时候我执行以下命令，你觉得会出现什么问题？ 12&gt; docker run -d -p 8082:8080 --name quirky_mayer tomcat&gt; 命令的含义应该都明白吧。启动一个新的tomcat容器，映射的宿主机端口号是8082（因为之前已经启动了一个8081的容器，宿主机的端口号不能冲突），给该tomcat容器起了一个别名“quirky_mayer”，注意观察一下上图的tomcat容器的别名信息哦~ 【解答】 运行结果如下图： 其实错误信息很明显了，就是容器的别名“quirky_mayer”已经存在了，别的tomcat容器的别名也存在一个是“quirky_mayer”的。 这个别名校验是否重复，是针对所有容器而言的，并非是只判断运行状态的容器，那些Exited状态的容器也会进行校验。 因此，我们在使用–name指定别名的时候，不要出现重复。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://www.cicoding.cn/tags/Tomcat/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"在Docker中安装JDK","slug":"06-docker-lession-index","date":"2019-10-02T02:20:27.000Z","updated":"2022-09-17T14:13:56.145Z","comments":false,"path":"docker/06-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/06-docker-lession-index/","excerpt":"","text":"所有的环境安装，都是在centos系统中操作的，并非本地windows系统。 Docker 中国官方镜像加速 http://www.docker-cn.com/registry-mirror 获取JAVA镜像： 在终端客户端命令行输入以下命令，获取JAVA镜像。 12&gt; docker pull java&gt; 默认是从Docker Hub官方的仓库中下载镜像的。如果没有指定对应的版本，默认会获取版本为latest的镜像。 注意： latest是针对于镜像所在的仓库里面的软件最新版本。并非是软件本身的最新发布版本。 回车执行，一开始会进行下载对应的依赖库，稍作等待： 出现下面的信息，说明镜像下载完成： 查看下载的镜像命令行中执行命令，查看刚刚下载的JAVA镜像： 1docker images 如下图所示： 启动容器命令行中执行命令，启动JAVA镜像容器： 1docker run -d -it --name java java 如下图所示，说明成功启动了容器： 其中，–name后面的“java”是为容器指定了一个别名，而最后的那个“java”指的是下载镜像时的名称。 命令以及参数的含义： run：启动一个镜像容器 -d：指定容器运行于后台 -it：-i 和 -t 的缩写； -i：以交互模式运行容器，通常与 -t 同时使用 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 –name：指定容器名字，后续可以通过名字进行容器管理 具体更多的参数含义，可自行网上学习。 查看运行的容器首先我们在命令行中执行命令，查看处于运行状态的容器： 1docker ps 因为在上面的操作步骤中，我们运行了java镜像，所以你会看到有一个名称为java的容器正在运行，如下图： 通过输出的信息可以看到，当前容器的ID是“9179eb86b007”，容器别名是java（最后一列的值）。 登录容器【询问】：如果想查看容器中安装的jdk版本，该怎么做呢？ 如果直接在命令行输入java -version会报错的，如下图： 原因是因为：jdk是安装在容器里面的，需要进入容器，才能查看。意思就是说，jdk环境是在容器里面的，并非是宿主机。 进入容器内部 使用attach进入容器 1docker attach 91 其中的 “91” 指的是什么呢？ 上面有提到过，我们启动的java镜像的容器ID是“9179eb86b007”，所以， docker attach 命令后面，你可以指定容器ID来进入具体的容器。可以指定91、9179、9179e等任意长度的值，都代表了当前的java容器。 回车，效果如下图： 如果回车后没有反应，可以再次按下回车就可以进入容器的命令行模式了。 除了使用容器ID进入容器之外，也可以使用容器的别名进入容器： 1docker attach java 上面这种是通过容器的别名进入容器内部的。 使用exec命令进入容器 【方式一】：通过容器别名进入容器： 12&gt; docker exec -it java /bin/bash&gt; 【方式二】：通过容器ID进入容器： 12&gt; docker exec -it 91 /bin/bash&gt; 回车之后，就会看到命令行发生了一些变化： 仔细看第二行的开头，@符号后面的“9179eb86b007”就是我们的java容器的ID吧，这也就说明，我们已经进入了容器内部了，可以对容器进行操作了。 进入容器后，输入 java -version 查看JDK版本信息1java -version 无论是通过attach还是exec进入的容器，我们都可以在命令行中输入命令“java -version”来查看JDK版本信息。 下面我们就分别使用这2个命令进入容器，来看看效果，如下图所示： attach命令进入容器，查看JDK版本信息 exec命令进入容器，查看JDK版本信息 登陆Docker容器的方式 上面已经简单的介绍了attach、exec命令的使用，下面讲解一下这两个命令之间的区别。 对于运行在后台的Docker容器，我们运维人员时常是有登陆进去的需求。登陆Docker容器的方式： 使用ssh登陆容器 这种方法需要在容器中启动sshd，存在开销和攻击面增大的问题。同时也违反了Docker所倡导的一个容器一个进程的原则。 使用自带命令docker attach登陆容器 docker attach存在的问题是：当多个窗口同时attach到同一个容器时，所有的窗口都会同步的显示，假如其中的一个窗口发生阻塞时，其它的窗口也会阻塞，docker attach命令可以说是最不方便的进入后台docker容器的方法 使用自带命令docker exec登陆容器 docker exec和docker attach是Docker的原生方法，大多数情况下就使用这两种命令登陆容器。docker exec命令是在docker1.3之后出现的，比docker attach命令更加方便 分别使用attach与exec进入容器，查看它们的区别1、Docker attach必须是登陆到一个已经运行的容器里。需要注意的是如果从这个容器中exit退出的话，就会导致容器停止！！这是极其不方便的！ 见下图所示结果： 你会发现通过attach进入容器的话，当使用exit退出容器的时候，对应的容器也停止运行了，所以在生产环境中很少使用。 2、docker exec登陆容器，注意有两个参数：-t和-i，这两个参数很重要！ 对于 -t 、-i 的具体作用，可以参考 https://www.cnblogs.com/kevingrace/p/6656095.html 使用docker exec -it 进入容器和我们平常操作console界面类似。而且不像attach方式退出，导致整个容器退出，exec在生产环境中用的比较多。exec 比使用ssh 、nsenter、nsinit方式更方便，生产中常用的方式。 在使用docker exec登陆容器或执行容器中的命令时，最好都带上-t和-i参数。 退出Docker容器 如果是通过 attach 进入的容器，在退出容器的时候，如果不想让容器停止运行的话，就不能使用exit命令或者Ctrl+D快捷键的形式退出，而是使用 Ctrl + P + Q 组合键退出容器。 如果是通过 exec 命令进入的容器，在退出容器的时候，就可以使用exit或者Ctrl+D快捷键退出容器，同时容器不会停止运行，这也是exec与attach的最大区别。当然，你也可以使用Ctrl + P + Q 组合键退出容器，容器一样不会停止运行。 所以，通过上面的比较，也就印证了exec在实际使用过程中用的最多的，也是建议使用的一种方式。尤其是生产环境下，强烈建议使用exec的方式。 停止容器通过 docker stop (容器ID | 容器别名) 的命令，可以停止正在运行状态的容器： 1docker stop java 上面是通过容器别名来停止容器的，你也可以使用容器ID。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"JDK","slug":"JDK","permalink":"https://www.cicoding.cn/tags/JDK/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ--最佳实践","slug":"rocketmq-best-practice","date":"2019-10-02T01:46:00.000Z","updated":"2022-06-14T02:52:49.506Z","comments":false,"path":"rocketmq/rocketmq-best-practice/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-best-practice/","excerpt":"","text":"1. 最佳实践 1.1 生产者1.1.1 发送消息注意事项1 Tags的使用一个应用尽可能用一个Topic，而消息子类型则可以用tags来标识。tags可以由应用自由设置，只有生产者在发送消息设置了tags，消费方在订阅消息时才可以利用tags通过broker做消息过滤：message.setTags(“TagA”)。 2 Keys的使用每个消息在业务层面的唯一标识码要设置到keys字段，方便将来定位消息丢失问题。服务器会为每个消息创建索引（哈希索引），应用可以通过topic、key来查询这条消息内容，以及消息被谁消费。由于是哈希索引，请务必保证key尽可能唯一，这样可以避免潜在的哈希冲突。 123// 订单Id String orderId = \"20034568923546\"; message.setKeys(orderId); 3 日志的打印消息发送成功或者失败要打印消息日志，务必要打印SendResult和key字段。send消息方法只要不抛异常，就代表发送成功。发送成功会有多个状态，在sendResult里定义。以下对每个状态进行说明： SEND_OK 消息发送成功。要注意的是消息发送成功也不意味着它是可靠的。要确保不会丢失任何消息，还应启用同步Master服务器或同步刷盘，即SYNC_MASTER或SYNC_FLUSH。 FLUSH_DISK_TIMEOUT 消息发送成功但是服务器刷盘超时。此时消息已经进入服务器队列（内存），只有服务器宕机，消息才会丢失。消息存储配置参数中可以设置刷盘方式和同步刷盘时间长度，如果Broker服务器设置了刷盘方式为同步刷盘，即FlushDiskType=SYNC_FLUSH（默认为异步刷盘方式），当Broker服务器未在同步刷盘时间内（默认为5s）完成刷盘，则将返回该状态——刷盘超时。 FLUSH_SLAVE_TIMEOUT 消息发送成功，但是服务器同步到Slave时超时。此时消息已经进入服务器队列，只有服务器宕机，消息才会丢失。如果Broker服务器的角色是同步Master，即SYNC_MASTER（默认是异步Master即ASYNC_MASTER），并且从Broker服务器未在同步刷盘时间（默认为5秒）内完成与主服务器的同步，则将返回该状态——数据同步到Slave服务器超时。 SLAVE_NOT_AVAILABLE 消息发送成功，但是此时Slave不可用。如果Broker服务器的角色是同步Master，即SYNC_MASTER（默认是异步Master服务器即ASYNC_MASTER），但没有配置slave Broker服务器，则将返回该状态——无Slave服务器可用。 1.1.2 消息发送失败处理方式Producer的send方法本身支持内部重试，重试逻辑如下： 至多重试2次（同步发送为2次，异步发送为0次）。 如果发送失败，则轮转到下一个Broker。这个方法的总耗时时间不超过sendMsgTimeout设置的值，默认10s。 如果本身向broker发送消息产生超时异常，就不会再重试。 以上策略也是在一定程度上保证了消息可以发送成功。如果业务对消息可靠性要求比较高，建议应用增加相应的重试逻辑：比如调用send同步方法发送失败时，则尝试将消息存储到db，然后由后台线程定时重试，确保消息一定到达Broker。 上述db重试方式为什么没有集成到MQ客户端内部做，而是要求应用自己去完成，主要基于以下几点考虑：首先，MQ的客户端设计为无状态模式，方便任意的水平扩展，且对机器资源的消耗仅仅是cpu、内存、网络。其次，如果MQ客户端内部集成一个KV存储模块，那么数据只有同步落盘才能较可靠，而同步落盘本身性能开销较大，所以通常会采用异步落盘，又由于应用关闭过程不受MQ运维人员控制，可能经常会发生 kill -9 这样暴力方式关闭，造成数据没有及时落盘而丢失。第三，Producer所在机器的可靠性较低，一般为虚拟机，不适合存储重要数据。综上，建议重试过程交由应用来控制。 1.1.3 选择oneway形式发送通常消息的发送是这样一个过程： 客户端发送请求到服务器 服务器处理请求 服务器向客户端返回应答 所以，一次消息发送的耗时时间是上述三个步骤的总和，而某些场景要求耗时非常短，但是对可靠性要求并不高，例如日志收集类应用，此类应用可以采用oneway形式调用，oneway形式只发送请求不等待应答，而发送请求在客户端实现层面仅仅是一个操作系统系统调用的开销，即将数据写入客户端的socket缓冲区，此过程耗时通常在微秒级。 1.2 消费者1.2.1 消费过程幂等RocketMQ无法避免消息重复（Exactly-Once），所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理。可以借助关系数据库进行去重。首先需要确定消息的唯一键，可以是msgId，也可以是消息内容中的唯一标识字段，例如订单Id等。在消费之前判断唯一键是否在关系数据库中存在。如果不存在则插入，并消费，否则跳过。（实际过程要考虑原子性问题，判断是否存在可以尝试插入，如果报主键冲突，则插入失败，直接跳过） msgId一定是全局唯一标识符，但是实际使用中，可能会存在相同的消息有两个不同msgId的情况（消费者主动重发、因客户端重投机制导致的重复等），这种情况就需要使业务字段进行重复消费。 1.2.2 消费速度慢的处理方式1 提高消费并行度绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法： 同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。 提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax实现。 2 批量方式消费某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 consumer的 consumeMessageBatchMaxSize 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。 3 跳过非重要消息发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。例如，当某个队列的消息数堆积到100000条以上，则尝试丢弃部分或全部消息，这样就可以快速追上发送消息的速度。示例代码如下： 1234567891011121314public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; long offset = msgs.get(0).getQueueOffset(); String maxOffset = msgs.get(0).getProperty(Message.PROPERTY_MAX_OFFSET); long diff = Long.parseLong(maxOffset) - offset; if (diff &gt; 100000) &#123; // TODO 消息堆积情况的特殊处理 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; // TODO 正常消费过程 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;&#125; 4 优化每条消息消费过程举例如下，某条消息的消费过程如下： 根据消息从 DB 查询【数据 1】 根据消息从 DB 查询【数据 2】 复杂的业务计算 向 DB 插入【数据 3】 向 DB 插入【数据 4】 这条消息的消费过程中有4次与 DB的 交互，如果按照每次 5ms 计算，那么总共耗时 20ms，假设业务计算耗时 5ms，那么总过耗时 25ms，所以如果能把 4 次 DB 交互优化为 2 次，那么总耗时就可以优化到 15ms，即总体性能提高了 40%。所以应用如果对时延敏感的话，可以把DB部署在SSD硬盘，相比于SCSI磁盘，前者的RT会小很多。 1.2.3 消费打印日志如果消息量较少，建议在消费入口方法打印消息，消费耗时等，方便后续排查问题。 1234567public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; log.info(\"RECEIVE_MSG_BEGIN: \" + msgs.toString()); // TODO 正常消费过程 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; 如果能打印每条消息消费耗时，那么在排查消费慢等线上问题时，会更方便。 1.2.4 其他消费建议1 关于消费者和订阅第一件需要注意的事情是，不同的消费者组可以独立的消费一些 topic，并且每个消费者组都有自己的消费偏移量，请确保同一组内的每个消费者订阅信息保持一致。 2 关于有序消息消费者将锁定每个消息队列，以确保他们被逐个消费，虽然这将会导致性能下降，但是当你关心消息顺序的时候会很有用。我们不建议抛出异常，你可以返回 ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT 作为替代。 3 关于并发消费顾名思义，消费者将并发消费这些消息，建议你使用它来获得良好性能，我们不建议抛出异常，你可以返回 ConsumeConcurrentlyStatus.RECONSUME_LATER 作为替代。 4 关于消费状态Consume Status对于并发的消费监听器，你可以返回 RECONSUME_LATER 来通知消费者现在不能消费这条消息，并且希望可以稍后重新消费它。然后，你可以继续消费其他消息。对于有序的消息监听器，因为你关心它的顺序，所以不能跳过消息，但是你可以返回SUSPEND_CURRENT_QUEUE_A_MOMENT 告诉消费者等待片刻。 5 关于Blocking不建议阻塞监听器，因为它会阻塞线程池，并最终可能会终止消费进程 6 关于线程数设置消费者使用 ThreadPoolExecutor 在内部对消息进行消费，所以你可以通过设置 setConsumeThreadMin 或 setConsumeThreadMax 来改变它。 7 关于消费位点当建立一个新的消费者组时，需要决定是否需要消费已经存在于 Broker 中的历史消息CONSUME_FROM_LAST_OFFSET 将会忽略历史消息，并消费之后生成的任何消息。CONSUME_FROM_FIRST_OFFSET 将会消费每个存在于 Broker 中的信息。你也可以使用 CONSUME_FROM_TIMESTAMP 来消费在指定时间戳后产生的消息。 1.3 Broker1.3.1 Broker 角色 Broker 角色分为 ASYNC_MASTER（异步主机）、SYNC_MASTER（同步主机）以及SLAVE（从机）。如果对消息的可靠性要求比较严格，可以采用 SYNC_MASTER加SLAVE的部署方式。如果对消息可靠性要求不高，可以采用ASYNC_MASTER加SLAVE的部署方式。如果只是测试方便，则可以选择仅ASYNC_MASTER或仅SYNC_MASTER的部署方式。 1.3.2 FlushDiskType SYNC_FLUSH（同步刷新）相比于ASYNC_FLUSH（异步处理）会损失很多性能，但是也更可靠，所以需要根据实际的业务场景做好权衡。 1.3.3 Broker 配置 参数名 默认值 说明 listenPort 10911 接受客户端连接的监听端口 namesrvAddr null nameServer 地址 brokerIP1 网卡的 InetAddress 当前 broker 监听的 IP brokerIP2 跟 brokerIP1 一样 存在主从 broker 时，如果在 broker 主节点上配置了 brokerIP2 属性，broker 从节点会连接主节点配置的 brokerIP2 进行同步 brokerName null broker 的名称 brokerClusterName DefaultCluster 本 broker 所属的 Cluser 名称 brokerId 0 broker id, 0 表示 master, 其他的正整数表示 slave storePathCommitLog $HOME/store/commitlog/ 存储 commit log 的路径 storePathConsumerQueue $HOME/store/consumequeue/ 存储 consume queue 的路径 mapedFileSizeCommitLog 1024 1024 1024(1G) commit log 的映射文件大小 deleteWhen 04 在每天的什么时间删除已经超过文件保留时间的 commit log fileReserverdTime 72 以小时计算的文件保留时间 brokerRole ASYNC_MASTER SYNC_MASTER/ASYNC_MASTER/SLAVE flushDiskType ASYNC_FLUSH SYNC_FLUSH/ASYNC_FLUSH SYNC_FLUSH 模式下的 broker 保证在收到确认生产者之前将消息刷盘。ASYNC_FLUSH 模式下的 broker 则利用刷盘一组消息的模式，可以取得更好的性能。 1.4 NameServerRocketMQ 中，Name Servers 被设计用来做简单的路由管理。其职责包括： Brokers 定期向每个名称服务器注册路由数据。 名称服务器为客户端，包括生产者，消费者和命令行客户端提供最新的路由信息。​ 1.5 客户端配置 相对于RocketMQ的Broker集群，生产者和消费者都是客户端。本小节主要描述生产者和消费者公共的行为配置。 1.5.1 客户端寻址方式RocketMQ可以令客户端找到Name Server, 然后通过Name Server再找到Broker。如下所示有多种配置方式，优先级由高到低，高优先级会覆盖低优先级。 代码中指定Name Server地址，多个namesrv地址之间用分号分割 123producer.setNamesrvAddr(\"192.168.0.1:9876;192.168.0.2:9876\"); consumer.setNamesrvAddr(\"192.168.0.1:9876;192.168.0.2:9876\"); Java启动参数中指定Name Server地址 1-Drocketmq.namesrv.addr=192.168.0.1:9876;192.168.0.2:9876 环境变量指定Name Server地址 1export NAMESRV_ADDR=192.168.0.1:9876;192.168.0.2:9876 HTTP静态服务器寻址（默认） 客户端启动后，会定时访问一个静态HTTP服务器，地址如下：http://jmenv.tbsite.net:8080/rocketmq/nsaddr，这个URL的返回内容如下： 1192.168.0.1:9876;192.168.0.2:9876 客户端默认每隔2分钟访问一次这个HTTP服务器，并更新本地的Name Server地址。URL已经在代码中硬编码，可通过修改/etc/hosts文件来改变要访问的服务器，例如在/etc/hosts增加如下配置： 110.232.22.67 jmenv.taobao.net 推荐使用HTTP静态服务器寻址方式，好处是客户端部署简单，且Name Server集群可以热升级。 1.5.2 客户端配置DefaultMQProducer、TransactionMQProducer、DefaultMQPushConsumer、DefaultMQPullConsumer都继承于ClientConfig类，ClientConfig为客户端的公共配置类。客户端的配置都是get、set形式，每个参数都可以用spring来配置，也可以在代码中配置，例如namesrvAddr这个参数可以这样配置，producer.setNamesrvAddr(“192.168.0.1:9876”)，其他参数同理。 1 客户端的公共配置 参数名 默认值 说明 namesrvAddr Name Server地址列表，多个NameServer地址用分号隔开 clientIP 本机IP 客户端本机IP地址，某些机器会发生无法识别客户端IP地址情况，需要应用在代码中强制指定 instanceName DEFAULT 客户端实例名称，客户端创建的多个Producer、Consumer实际是共用一个内部实例（这个实例包含网络连接、线程资源等） clientCallbackExecutorThreads 4 通信层异步回调线程数 pollNameServerInteval 30000 轮询Name Server间隔时间，单位毫秒 heartbeatBrokerInterval 30000 向Broker发送心跳间隔时间，单位毫秒 persistConsumerOffsetInterval 5000 持久化Consumer消费进度间隔时间，单位毫秒 2 Producer配置 参数名 默认值 说明 producerGroup DEFAULT_PRODUCER Producer组名，多个Producer如果属于一个应用，发送同样的消息，则应该将它们归为同一组 createTopicKey TBW102 在发送消息时，自动创建服务器不存在的topic，需要指定Key，该Key可用于配置发送消息所在topic的默认路由。 defaultTopicQueueNums 4 在发送消息，自动创建服务器不存在的topic时，默认创建的队列数 sendMsgTimeout 10000 发送消息超时时间，单位毫秒 compressMsgBodyOverHowmuch 4096 消息Body超过多大开始压缩（Consumer收到消息会自动解压缩），单位字节 retryAnotherBrokerWhenNotStoreOK FALSE 如果发送消息返回sendResult，但是sendStatus!=SEND_OK，是否重试发送 retryTimesWhenSendFailed 2 如果消息发送失败，最大重试次数，该参数只对同步发送模式起作用 maxMessageSize 4MB 客户端限制的消息大小，超过报错，同时服务端也会限制，所以需要跟服务端配合使用。 transactionCheckListener 事务消息回查监听器，如果发送事务消息，必须设置 checkThreadPoolMinSize 1 Broker回查Producer事务状态时，线程池最小线程数 checkThreadPoolMaxSize 1 Broker回查Producer事务状态时，线程池最大线程数 checkRequestHoldMax 2000 Broker回查Producer事务状态时，Producer本地缓冲请求队列大小 RPCHook null 该参数是在Producer创建时传入的，包含消息发送前的预处理和消息响应后的处理两个接口，用户可以在第一个接口中做一些安全控制或者其他操作。 3 PushConsumer配置 参数名 默认值 说明 consumerGroup DEFAULT_CONSUMER Consumer组名，多个Consumer如果属于一个应用，订阅同样的消息，且消费逻辑一致，则应该将它们归为同一组 messageModel CLUSTERING 消费模型支持集群消费和广播消费两种 consumeFromWhere CONSUME_FROM_LAST_OFFSET Consumer启动后，默认从上次消费的位置开始消费，这包含两种情况：一种是上次消费的位置未过期，则消费从上次中止的位置进行；一种是上次消费位置已经过期，则从当前队列第一条消息开始消费 consumeTimestamp 半个小时前 只有当consumeFromWhere值为CONSUME_FROM_TIMESTAMP时才起作用。 allocateMessageQueueStrategy AllocateMessageQueueAveragely Rebalance算法实现策略 subscription 订阅关系 messageListener 消息监听器 offsetStore 消费进度存储 consumeThreadMin 10 消费线程池最小线程数 consumeThreadMax 20 消费线程池最大线程数 consumeConcurrentlyMaxSpan 2000 单队列并行消费允许的最大跨度 pullThresholdForQueue 1000 拉消息本地队列缓存消息最大数 pullInterval 0 拉消息间隔，由于是长轮询，所以为0，但是如果应用为了流控，也可以设置大于0的值，单位毫秒 consumeMessageBatchMaxSize 1 批量消费，一次消费多少条消息 pullBatchSize 32 批量拉消息，一次最多拉多少条 4 PullConsumer配置 参数名 默认值 说明 consumerGroup DEFAULT_CONSUMER Consumer组名，多个Consumer如果属于一个应用，订阅同样的消息，且消费逻辑一致，则应该将它们归为同一组 brokerSuspendMaxTimeMillis 20000 长轮询，Consumer拉消息请求在Broker挂起最长时间，单位毫秒 consumerTimeoutMillisWhenSuspend 30000 长轮询，Consumer拉消息请求在Broker挂起超过指定时间，客户端认为超时，单位毫秒 consumerPullTimeoutMillis 10000 非长轮询，拉消息超时时间，单位毫秒 messageModel BROADCASTING 消息支持两种模式：集群消费和广播消费 messageQueueListener 监听队列变化 offsetStore 消费进度存储 registerTopics 注册的topic集合 allocateMessageQueueStrategy AllocateMessageQueueAveragely Rebalance算法实现策略 5 Message数据结构 字段名 默认值 说明 Topic null 必填，消息所属topic的名称 Body null 必填，消息体 Tags null 选填，消息标签，方便服务器过滤使用。目前只支持每个消息设置一个tag Keys null 选填，代表这条消息的业务关键词，服务器会根据keys创建哈希索引，设置后，可以在Console系统根据Topic、Keys来查询消息，由于是哈希索引，请尽可能保证key唯一，例如订单号，商品Id等。 Flag 0 选填，完全由应用来设置，RocketMQ不做干预 DelayTimeLevel 0 选填，消息延时级别，0表示不延时，大于0会延时特定的时间才会被消费 WaitStoreMsgOK TRUE 选填，表示消息是否在服务器落盘后才返回应答。 1.6 系统配置本小节主要介绍系统（JVM/OS）相关的配置。 1.6.1 JVM选项 推荐使用最新发布的JDK 1.8版本。通过设置相同的Xms和Xmx值来防止JVM调整堆大小以获得更好的性能。简单的JVM配置如下所示：​​​-server -Xms8g -Xmx8g -Xmn4g​​​如果您不关心RocketMQ Broker的启动时间，还有一种更好的选择，就是通过“预触摸”Java堆以确保在JVM初始化期间每个页面都将被分配。那些不关心启动时间的人可以启用它：​ -XX:+AlwaysPreTouch禁用偏置锁定可能会减少JVM暂停，​ -XX:-UseBiasedLocking至于垃圾回收，建议使用带JDK 1.8的G1收集器。 123-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 这些GC选项看起来有点激进，但事实证明它在我们的生产环境中具有良好的性能。另外不要把-XX:MaxGCPauseMillis的值设置太小，否则JVM将使用一个小的年轻代来实现这个目标，这将导致非常频繁的minor GC，所以建议使用rolling GC日志文件： 123-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m 如果写入GC文件会增加代理的延迟，可以考虑将GC日志文件重定向到内存文件系统： 1-Xloggc:/dev/shm/mq_gc_%p.log123 1.6.2 Linux内核参数 os.sh脚本在bin文件夹中列出了许多内核参数，可以进行微小的更改然后用于生产用途。下面的参数需要注意，更多细节请参考/proc/sys/vm/*的文档 vm.extra_free_kbytes，告诉VM在后台回收（kswapd）启动的阈值与直接回收（通过分配进程）的阈值之间保留额外的可用内存。RocketMQ使用此参数来避免内存分配中的长延迟。（与具体内核版本相关） vm.min_free_kbytes，如果将其设置为低于1024KB，将会巧妙的将系统破坏，并且系统在高负载下容易出现死锁。 vm.max_map_count，限制一个进程可能具有的最大内存映射区域数。RocketMQ将使用mmap加载CommitLog和ConsumeQueue，因此建议将为此参数设置较大的值。（agressiveness –&gt; aggressiveness） vm.swappiness，定义内核交换内存页面的积极程度。较高的值会增加攻击性，较低的值会减少交换量。建议将值设置为10来避免交换延迟。 File descriptor limits，RocketMQ需要为文件（CommitLog和ConsumeQueue）和网络连接打开文件描述符。我们建议设置文件描述符的值为655350。 Disk schedulerRocketMQ建议使用I/O截止时间调度器，它试图为请求提供有保证的延迟。 )","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"在windows系统中安装Docker","slug":"05-docker-lession-index","date":"2019-10-01T02:20:27.000Z","updated":"2022-09-17T14:13:56.145Z","comments":false,"path":"docker/05-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/05-docker-lession-index/","excerpt":"","text":"开始安装Docker之前，先来了解一下 Docker for Windows 与 Docker Toolbox 的区别。 因为这两款软件是针对不同的系统环境分别使用的，选择一款适合自己系统环境的软件进行安装。 Docker for Windows 与 Docker Toolbox： Docker for Windows 一个集成的，易于部署的开发环境，用于在Windows PC上构建，调试和测试Docker应用程序。Docker for Windows是一款 本机Windows应用程序，与Hyper-V虚拟化，网络和文件系统深度集成，使其成为Windows中速度最快，最可靠的Docker环境。 Docker for Windows官方下载地址： https://store.docker.com/editions/community/docker-ce-desktop-windows 特别注意的是： Docker for Windows 只能运行于 Microsoft Windows 10 Professional或Enterprise 64位，但是它不支持Win7系统。如果你的系统是Win7，请使用 DockerToolbox。 Docker Toolbox Docker Toolbox提供了一种在Windows系统上使用Docker的方法。前提是你的机器必须具有运行Windows 7或更高版本的64位操作系统。 Docker Toolbox官方下载地址： https://docs.docker.com/toolbox/toolbox_install_windows/ 如果你的电脑是win10系统，则可以参考官方文档，进行安装 Docker for Windows 软件，官方文档地址： https://docs.docker.com/docker-for-windows/install/ 由于大多数人的系统为win7系统，我的电脑系统也是win7，因此，我就选择 Docker Toolbox 来安装Docker服务了。 安装 Docker Toolbox下载好 Docker Toolbox 软件之后，本地双击运行安装就行了。 安装完成后，你的电脑桌面上会出现以下几个应用图标： 上面三个图标软件的含义： Docker Quickstart Terminal：Docker的启动器终端，可以在这里进行Docker的一系列操作。 首次启动Docker Quickstart可能会遇到的问题【问题一】：安装好Docker Toolbox之后，当运行Docker Quickstart Terminal的时候，可能会出现如下图所示的问题： 首先需要明白bash.exe是什么？bash.exe是git软件的执行程序，因此，回想在安装Docker Toolbox时，会提示你安装一些软件，里面就有git选择。如下图（图片摘自网络）： 但是，有时候即使勾选了git选项，在启动Docker Quickstart Terminal的时候，还是提示找不到bash.exe文件，这时候怎么办呢？ 解决办法： 前提是你本地需要安装好git 或者找到bash.exe所在的目录。 右键桌面上的Docker Quickstart Terminal图标，选择属性，在弹出框中找到“快捷方式”选项卡，修改其中的“目标”一栏，最前面的内容修改为你本地电脑上bash.exe的位置即可。 效果如下图： 因为我本地电脑之前已经安装过了git，所以直接使用这个bash.exe的路径即可，安装路径截图如下： 【问题二】：双击运行Docker Quickstart Terminal应用的时候，不能正常启动。 错误信息如下图所示（图片摘自网络）： 造成以上的问题的原因，可能是有以下几种情况： 首先需要说明，在Docker Quickstart Terminal启动后会复制C:\\Users\\Administrator.docker\\machine\\cache下的镜像boot2docker.iso到C:\\Users\\Administrator.docker\\machine\\machines\\default下面。 【原因一】 检测到默认的boot2docker.iso镜像不是最新版本的，需要到https://github.com/boot2docker/boot2docker/releases下载最新的，并复制到C:\\Users\\Administrator\\.docker\\machine\\cache目录下。 【原因二】 如果本地目录C:\\Users\\Administrator.docker\\machine\\cache下面没有boot2docker.iso镜像文件的话，当自动去下载对应的boot2docker.iso镜像文件的时候，但是网络由于是国外的，依然会出现下载超时的情况，导致一直出现错误。 【原因三】 如果本地目录C:\\Users\\Administrator.docker\\machine\\cache下面没有boot2docker.iso镜像文件的话，加上国外网络不理想，那么，还有一种解决方式就是： 打开Docker Toolbox的安装目录，里面会有一个boot2docker.iso镜像文件，如下图所示（这是Docker Toolbox软件自带的镜像文件，肯定是兼容的）： 然后将boot2docker.iso文件复制到C:\\Users\\Administrator.docker\\machine\\cache目录下面，再重新启动Docker Quickstart Terminal应用即可。 如果依然出现上图所示的错误，请多次尝试启动Docker Quickstart Terminal，多次启动几次之后就会OK了。 如果Docker Toolbox软件安装目录下面没有boot2docker.iso镜像文件的话，你可以自行去下载： https://github.com/boot2docker/boot2docker/releases 首次运行Docker Quickstart Terminal的初始化过程 第一次运行Docker Quickstart Terminal的时候，软件会需要进行初始化操作，需要等待片刻。 大概的运行情况如下图所示（图片摘自网络）： 以上输出结果，说明Docker Quickstart Terminal已经可以正常启动运行了。 当下次运行该软件的时候，显示的信息如下图： 你可以在这里运行Docker命令，比如运行命令 docker images 查看安装的容器列表，效果如下图： 特别说明： 当你第一次运行Docker Quickstart Terminal的时候，且该软件初始化成功之后，你会发现界面上会输出一个IP地址信息，如下图（该图是我本地电脑上的，并非第一次运行的效果，不过每次启动都会显示IP信息的）： 这个IP地址的含义是什么呢？ 我忘记在哪里查到的资料了，简单来说就是，如果你电脑上安装的是Docker Toolbox用于操作Docker的话，那么当你启动容器之后（比如启动了一个Nginx镜像），要想能使用浏览器访问Nginx服务，则不能使用localhost或者127.0.0.1，必须使用192.168.99.100，也就是Docker Quickstart Terminal分配给你的IP地址。 新手的话，如果不仔细阅读这段话的意思的话，很容易使用localhost、127.0.0.1来访问你的容器服务，会出现访问超时的错误。就会误以为是Docker服务有问题，其实并非如此，建议新手一定要牢记上面的说明。 Oracle Virtual Box：Docker Toolbox使用Oracle Virtual Box而不是Hyper-V虚拟化产品。 Kitematic (Alpha)：Kitematic 是一个图形化界面的用于操作Docker的应用软件。我们可以简单快速地搭建我们的容器而不需要输入命令，可以在图形用户界面中通过简单的点击从而在容器上部署我们的应用。Kitematic 集成了 Docker Hub，允许我们搜索、拉取任何需要的镜像，并在上面部署应用。它同时也能很好地切换到命令行用户接口模式。 Kitematic官方地址：https://kitematic.com/ 软件首页如下图所示： 从上图软件界面可以知道，右侧就是列举了很多热门的开源镜像，方便进行操作使用。 而软件左侧，就是显示本地电脑上已经存在的容器，可以对容器进行停止和删除等操作。 软件还有很多功能，这里就不多做说明，自己网上查询资料学习吧。 使用终端软件连接Docker服务 我使用的是 MobaXterm 这个客户端软件，你也可以使用XShell等第三方软件。 MobaXterm下载地址（我已经上传到百度网盘里面了）： https://pan.baidu.com/s/1jKh9cr0 MobaXterm软件效果截图： 使用终端软件连接Docker服务 这里我就使用 MobaXterm 连接本地的Docker服务。 因为本地电脑是win7系统，Docker服务是运行在 boot2docker 所创建的虚拟机里的。 因此，默认的用户名是**docker** 密码是：**tcuser** 同时还需要注意一点，就是host，该填写什么IP呢？ 还记得上面讲过Docker Quickstart Terminal在初始化的时候，会默认分配一个IP地址，没错，就是填写这个IP地址。 具体的信息录入，我就不一一截图了，自己操作就行了，按照客户端提示填写即可。 最终成功连接Docker后的效果： 上图所示的输出信息，说明已经成功连接上Docker服务了。 这样的话，你既可以使用Docker Quickstart Terminal来操作Docker服务，也可以使用其他客户端连接Docker服务并进行一系列的操作。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ--样例","slug":"rocketmq_example","date":"2019-09-28T11:06:01.000Z","updated":"2022-06-14T02:49:31.937Z","comments":false,"path":"rocketmq/rocketmq_example/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq_example/","excerpt":"","text":"1. 样例 1.1 基本样例在基本样例中我们提供如下的功能场景： 使用RocketMQ发送三种类型的消息：同步消息、异步消息和单向消息。其中前两种消息是可靠的，因为会有发送是否成功的应答。 使用RocketMQ来消费接收到的消息。 1.1.1 加入依赖：12345678maven:&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.3.0&lt;/version&gt;&lt;/dependency&gt;gradlecompile &apos;org.apache.rocketmq:rocketmq-client:4.3.0&apos; 1.1.2 消息发送1、Producer端发送同步消息这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。 1234567891011121314151617181920212223public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 2、发送异步消息异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。 12345678910111213141516171819202122232425262728293031323334public class AsyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); // SendCallback接收异步返回结果的回调 producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); &#125; &#125;); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 3、单向发送消息这种方式主要用在不特别关心发送结果的场景，例如日志发送。 12345678910111213141516171819202122public class OnewayProducer &#123; public static void main(String[] args) throws Exception&#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送单向消息，没有任何返回结果 producer.sendOneway(msg); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 1.1.3 消费消息1234567891011121314151617181920212223242526public class Consumer &#123; public static void main(String[] args) throws InterruptedException, MQClientException &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 consumer.subscribe(\"TopicTest\", \"*\"); // 注册回调实现类来处理从broker拉取回来的消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); // 标记该消息已经被成功消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者实例 consumer.start(); System.out.printf(\"Consumer Started.%n\"); &#125;&#125; 1.2 顺序消息样例消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。 下面用订单进行分区有序的示例。一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。 1.2.1 顺序消息生产123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package org.apache.rocketmq.example.order2;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Date;import java.util.List;/*** Producer，发送顺序消息*/public class Producer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagC\", \"TagD\"&#125;; // 订单列表 List&lt;OrderStep&gt; orderList = new Producer().buildOrders(); Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateStr = sdf.format(date); for (int i = 0; i &lt; 10; i++) &#123; // 加个时间前缀 String body = dateStr + \" Hello RocketMQ \" + orderList.get(i); Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, body.getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); &#125; &#125;, orderList.get(i).getOrderId());//订单id System.out.println(String.format(\"SendResult status:%s, queueId:%d, body:%s\", sendResult.getSendStatus(), sendResult.getMessageQueue().getQueueId(), body)); &#125; producer.shutdown(); &#125; /** * 订单的步骤 */ private static class OrderStep &#123; private long orderId; private String desc; public long getOrderId() &#123; return orderId; &#125; public void setOrderId(long orderId) &#123; this.orderId = orderId; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return \"OrderStep&#123;\" + \"orderId=\" + orderId + \", desc='\" + desc + '\\'' + '&#125;'; &#125; &#125; /** * 生成模拟订单数据 */ private List&lt;OrderStep&gt; buildOrders() &#123; List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;(); OrderStep orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"推送\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); return orderList; &#125;&#125; 1.2.2 顺序消费消息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;package org.apache.rocketmq.example.order2;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeOrderlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeOrderlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerOrderly;import org.apache.rocketmq.common.consumer.ConsumeFromWhere;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;import java.util.Random;import java.util.concurrent.TimeUnit;/*** 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）*/public class ConsumerInOrder &#123; public static void main(String[] args) throws Exception &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\"); consumer.setNamesrvAddr(\"127.0.0.1:9876\"); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\"); consumer.registerMessageListener(new MessageListenerOrderly() &#123; Random random = new Random(); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序 System.out.println(\"consumeThread=\" + Thread.currentThread().getName() + \"queueId=\" + msg.getQueueId() + \", content:\" + new String(msg.getBody())); &#125; try &#123; //模拟业务逻辑处理中... TimeUnit.SECONDS.sleep(random.nextInt(10)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); consumer.start(); System.out.println(\"Consumer Started.\"); &#125;&#125; 1.3 延时消息样例1.3.1 启动消费者等待传入订阅消息12345678910111213141516171819202122232425262728import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;public class ScheduledMessageConsumer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\"); // 订阅Topics consumer.subscribe(\"TestTopic\", \"*\"); // 注册消息监听者 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123; for (MessageExt message : messages) &#123; // Print approximate delay time period System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \" + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\"); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者 consumer.start(); &#125;&#125; 1.3.2 发送延时消息123456789101112131415161718192021import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.common.message.Message;public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化一个生产者来产生延时消息 DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\"); // 启动生产者 producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125; // 关闭生产者 producer.shutdown(); &#125;&#125; 1.3.3 验证您将会看到消息的消费比存储时间晚10秒。 1.3.4 延时消息的使用场景比如电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。 1.3.5 延时消息的使用限制123// org/apache/rocketmq/store/config/MessageStoreConfig.javaprivate String messageDelayLevel = \"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\"; 现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18 消息消费失败会进入延时消息队列，消息发送时间与设置的延时等级和重试次数有关，详见代码SendMessageProcessor.java 1.4 批量消息样例批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。 1.4.1 发送批量消息如果您每次只发送不超过4MB的消息，则很容易使用批处理，样例如下： 1234567891011String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));try &#123; producer.send(messages);&#125; catch (Exception e) &#123; e.printStackTrace(); //处理error&#125; 1.4.2 消息列表分割复杂度只有当你发送大批量时才会增长，你可能不确定它是否超过了大小限制（4MB）。这时候你最好把你的消息列表分割一下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final int SIZE_LIMIT = 1024 * 1024 * 4; private final List&lt;Message&gt; messages; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; // 增加日志的开销20字节 if (tmpSize &gt; SIZE_LIMIT) &#123; //单个消息超过了最大的限制 //忽略,否则会阻塞分裂的进程 if (nextIndex - currIndex == 0) &#123; //假如下一个子列表没有元素,则添加这个子列表然后退出循环,否则只是退出循环 nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125;//把大的消息分裂成若干个小的消息ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; try &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem); &#125; catch (Exception e) &#123; e.printStackTrace(); //处理error &#125;&#125; 1.5 过滤消息样例在大多数情况下，TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如： 12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_EXAMPLE\");consumer.subscribe(\"TOPIC\", \"TAGA || TAGB || TAGC\"); 消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子： 1234567891011121314------------| message ||----------| a &gt; 5 AND b = &apos;abc&apos;| a = 10 | --------------------&gt; Gotten| b = &apos;abc&apos;|| c = true |------------------------| message ||----------| a &gt; 5 AND b = &apos;abc&apos;| a = 1 | --------------------&gt; Missed| b = &apos;abc&apos;|| c = true |------------ 1.5.1 基本语法RocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。 数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=； 字符比较，比如：=，&lt;&gt;，IN； IS NULL 或者 IS NOT NULL； 逻辑符号 AND，OR，NOT； 常量支持类型为： 数值，比如：123，3.1415； 字符，比如：‘abc’，必须用单引号包裹起来； NULL，特殊的常量 布尔值，TRUE 或 FALSE 只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下： 1public void subscribe(finalString topic, final MessageSelector messageSelector) 1.5.2 使用样例1、生产者样例发送消息时，你能通过putUserProperty来设置消息的属性 1234567891011DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.start();Message msg = new Message(\"TopicTest\", tag, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));// 设置一些属性msg.putUserProperty(\"a\", String.valueOf(i));SendResult sendResult = producer.send(msg);producer.shutdown(); 2、消费者样例用MessageSelector.bySql来使用sql筛选消息 12345678910DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3consumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\");consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 1.6 消息事务样例事务消息共有三种状态，提交状态、回滚状态、中间状态： TransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。 TransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。 TransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。 1.6.1 发送事务消息样例1、创建事务性生产者使用 TransactionMQProducer类创建生产者，并指定唯一的 ProducerGroup，就可以设置自定义线程池来处理这些检查请求。执行本地事务后、需要根据执行结果对消息队列进行回复。回传的事务状态在请参考前一节。 12345678910111213141516171819202122232425262728293031323334353637383940import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;public class TransactionProducer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; TransactionListener transactionListener = new TransactionListenerImpl(); TransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\"); ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName(\"client-transaction-msg-check-thread\"); return thread; &#125; &#125;); producer.setExecutorService(executorService); producer.setTransactionListener(transactionListener); producer.start(); String[] tags = new String[] &#123;\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"&#125;; for (int i = 0; i &lt; 10; i++) &#123; try &#123; Message msg = new Message(\"TopicTest1234\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(\"%s%n\", sendResult); Thread.sleep(10); &#125; catch (MQClientException | UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; for (int i = 0; i &lt; 100000; i++) &#123; Thread.sleep(1000); &#125; producer.shutdown(); &#125;&#125; 2、实现事务的监听接口当发送半消息成功时，我们使用 executeLocalTransaction 方法来执行本地事务。它返回前一节中提到的三个事务状态之一。checkLocalTranscation 方法用于检查本地事务状态，并回应消息队列的检查请求。它也是返回前一节中提到的三个事务状态之一。 1234567891011121314151617181920212223242526public class TransactionListenerImpl implements TransactionListener &#123; private AtomicInteger transactionIndex = new AtomicInteger(0); private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;(); @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; int value = transactionIndex.getAndIncrement(); int status = value % 3; localTrans.put(msg.getTransactionId(), status); return LocalTransactionState.UNKNOW; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; Integer status = localTrans.get(msg.getTransactionId()); if (null != status) &#123; switch (status) &#123; case 0: return LocalTransactionState.UNKNOW; case 1: return LocalTransactionState.COMMIT_MESSAGE; case 2: return LocalTransactionState.ROLLBACK_MESSAGE; &#125; &#125; return LocalTransactionState.COMMIT_MESSAGE; &#125;&#125; 1.6.2 事务消息使用上的限制 事务消息不支持延时消息和批量消息。 为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionCheckListener 类来修改这个行为。 事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionMsgTimeout 参数。 事务性消息可能不止一次被检查或消费。 提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。 事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。 1.7 Logappender样例RocketMQ日志提供log4j、log4j2和logback日志框架作为业务应用，下面是配置样例 1.7.1 log4j样例按下面样例使用log4j属性配置 1234567log4j.appender.mq=org.apache.rocketmq.logappender.log4j.RocketmqLog4jAppenderlog4j.appender.mq.Tag=yourTaglog4j.appender.mq.Topic=yourLogTopiclog4j.appender.mq.ProducerGroup=yourLogGrouplog4j.appender.mq.NameServerAddress=yourRocketmqNameserverAddresslog4j.appender.mq.layout=org.apache.log4j.PatternLayoutlog4j.appender.mq.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-4r [%t] (%F:%L) %-5p - %m%n 按下面样例使用log4j xml配置来使用异步添加日志 1234567891011121314&lt;appender name=&quot;mqAppender1&quot;class=&quot;org.apache.rocketmq.logappender.log4j.RocketmqLog4jAppender&quot;&gt; &lt;param name=&quot;Tag&quot; value=&quot;yourTag&quot; /&gt; &lt;param name=&quot;Topic&quot; value=&quot;yourLogTopic&quot; /&gt; &lt;param name=&quot;ProducerGroup&quot; value=&quot;yourLogGroup&quot; /&gt; &lt;param name=&quot;NameServerAddress&quot; value=&quot;yourRocketmqNameserverAddress&quot;/&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss&#125;-%p %t %c - %m%n&quot; /&gt; &lt;/layout&gt;&lt;/appender&gt;&lt;appender name=&quot;mqAsyncAppender1&quot;class=&quot;org.apache.log4j.AsyncAppender&quot;&gt; &lt;param name=&quot;BufferSize&quot; value=&quot;1024&quot; /&gt; &lt;param name=&quot;Blocking&quot; value=&quot;false&quot; /&gt; &lt;appender-ref ref=&quot;mqAppender1&quot;/&gt;&lt;/appender&gt; 1.7.2 log4j2样例用log4j2时，配置如下，如果想要非阻塞，只需要使用异步添加引用即可 1234&lt;RocketMQ name=&quot;rocketmqAppender&quot; producerGroup=&quot;yourLogGroup&quot; nameServerAddress=&quot;yourRocketmqNameserverAddress&quot; topic=&quot;yourLogTopic&quot; tag=&quot;yourTag&quot;&gt; &lt;PatternLayout pattern=&quot;%d [%p] hahahah %c %m%n&quot;/&gt;&lt;/RocketMQ&gt; 1.7.3 logback样例12345678910111213141516&lt;appender name=&quot;mqAppender1&quot;class=&quot;org.apache.rocketmq.logappender.logback.RocketmqLogbackAppender&quot;&gt; &lt;tag&gt;yourTag&lt;/tag&gt; &lt;topic&gt;yourLogTopic&lt;/topic&gt; &lt;producerGroup&gt;yourLogGroup&lt;/producerGroup&gt; &lt;nameServerAddress&gt;yourRocketmqNameserverAddress&lt;/nameServerAddress&gt; &lt;layout&gt; &lt;pattern&gt;%date %p %t - %m%n&lt;/pattern&gt; &lt;/layout&gt;&lt;/appender&gt;&lt;appender name=&quot;mqAsyncAppender1&quot;class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;queueSize&gt;1024&lt;/queueSize&gt; &lt;discardingThreshold&gt;80&lt;/discardingThreshold&gt; &lt;maxFlushTime&gt;2000&lt;/maxFlushTime&gt; &lt;neverBlock&gt;true&lt;/neverBlock&gt; &lt;appender-ref ref=&quot;mqAppender1&quot;/&gt;&lt;/appender&gt; 1.8 OpenMessaging样例OpenMessaging旨在建立消息和流处理规范，以为金融、电子商务、物联网和大数据领域提供通用框架及工业级指导方案。在分布式异构环境中，设计原则是面向云、简单、灵活和独立于语言。符合这些规范将帮助企业方便的开发跨平台和操作系统的异构消息传递应用程序。提供了openmessaging-api 0.3.0-alpha的部分实现，下面的示例演示如何基于OpenMessaging访问RocketMQ。 1.8.1 OMSProducer样例下面的示例演示如何在同步、异步或单向传输中向RocketMQ代理发送消息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import io.openmessaging.Future;import io.openmessaging.FutureListener;import io.openmessaging.Message;import io.openmessaging.MessagingAccessPoint;import io.openmessaging.OMS;import io.openmessaging.producer.Producer;import io.openmessaging.producer.SendResult;import java.nio.charset.Charset;import java.util.concurrent.CountDownLatch;public class SimpleProducer &#123; public static void main(String[] args) &#123; final MessagingAccessPoint messagingAccessPoint = OMS.getMessagingAccessPoint(\"oms:rocketmq://localhost:9876/default:default\"); final Producer producer = messagingAccessPoint.createProducer(); messagingAccessPoint.startup(); System.out.printf(\"MessagingAccessPoint startup OK%n\"); producer.startup(); System.out.printf(\"Producer startup OK%n\"); &#123; Message message = producer.createBytesMessage(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))); SendResult sendResult = producer.send(message); //final Void aVoid = result.get(3000L); System.out.printf(\"Send async message OK, msgId: %s%n\", sendResult.messageId()); &#125; final CountDownLatch countDownLatch = new CountDownLatch(1); &#123; final Future&lt;SendResult&gt; result = producer.sendAsync(producer.createBytesMessage(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\")))); result.addListener(new FutureListener&lt;SendResult&gt;() &#123; @Override public void operationComplete(Future&lt;SendResult&gt; future) &#123; if (future.getThrowable() != null) &#123; System.out.printf(\"Send async message Failed, error: %s%n\", future.getThrowable().getMessage()); &#125; else &#123; System.out.printf(\"Send async message OK, msgId: %s%n\", future.get().messageId()); &#125; countDownLatch.countDown(); &#125; &#125;); &#125; &#123; producer.sendOneway(producer.createBytesMessage(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\")))); System.out.printf(\"Send oneway message OK%n\"); &#125; try &#123; countDownLatch.await(); Thread.sleep(500); // 等一些时间来发送消息 &#125; catch (InterruptedException ignore) &#123; &#125; producer.shutdown(); &#125;&#125; 1.8.2 OMSPullConsumer用OMS PullConsumer 来从指定的队列中拉取消息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import io.openmessaging.Message;import io.openmessaging.MessagingAccessPoint;import io.openmessaging.OMS;import io.openmessaging.OMSBuiltinKeys;import io.openmessaging.consumer.PullConsumer;import io.openmessaging.producer.Producer;import io.openmessaging.producer.SendResult;public class SimplePullConsumer &#123; public static void main(String[] args) &#123; final MessagingAccessPoint messagingAccessPoint = OMS.getMessagingAccessPoint(\"oms:rocketmq://localhost:9876/default:default\"); messagingAccessPoint.startup(); final Producer producer = messagingAccessPoint.createProducer(); final PullConsumer consumer = messagingAccessPoint.createPullConsumer( OMS.newKeyValue().put(OMSBuiltinKeys.CONSUMER_ID, \"OMS_CONSUMER\")); messagingAccessPoint.startup(); System.out.printf(\"MessagingAccessPoint startup OK%n\"); final String queueName = \"TopicTest\"; producer.startup(); Message msg = producer.createBytesMessage(queueName, \"Hello Open Messaging\".getBytes()); SendResult sendResult = producer.send(msg); System.out.printf(\"Send Message OK. MsgId: %s%n\", sendResult.messageId()); producer.shutdown(); consumer.attachQueue(queueName); consumer.startup(); System.out.printf(\"Consumer startup OK%n\"); // 运行直到发现一个消息被发送了 boolean stop = false; while (!stop) &#123; Message message = consumer.receive(); if (message != null) &#123; String msgId = message.sysHeaders().getString(Message.BuiltinKeys.MESSAGE_ID); System.out.printf(\"Received one message: %s%n\", msgId); consumer.ack(msgId); if (!stop) &#123; stop = msgId.equalsIgnoreCase(sendResult.messageId()); &#125; &#125; else &#123; System.out.printf(\"Return without any message%n\"); &#125; &#125; consumer.shutdown(); messagingAccessPoint.shutdown(); &#125;&#125; 1.8.3 OMSPushConsumer以下示范如何将 OMS PushConsumer 添加到指定的队列，并通过 MessageListener 消费这些消息。 123456789101112131415161718192021222324252627282930313233import io.openmessaging.Message;import io.openmessaging.MessagingAccessPoint;import io.openmessaging.OMS;import io.openmessaging.OMSBuiltinKeys;import io.openmessaging.consumer.MessageListener;import io.openmessaging.consumer.PushConsumer;public class SimplePushConsumer &#123; public static void main(String[] args) &#123; final MessagingAccessPoint messagingAccessPoint = OMS .getMessagingAccessPoint(\"oms:rocketmq://localhost:9876/default:default\"); final PushConsumer consumer = messagingAccessPoint. createPushConsumer(OMS.newKeyValue().put(OMSBuiltinKeys.CONSUMER_ID, \"OMS_CONSUMER\")); messagingAccessPoint.startup(); System.out.printf(\"MessagingAccessPoint startup OK%n\"); Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123; @Override public void run() &#123; consumer.shutdown(); messagingAccessPoint.shutdown(); &#125; &#125;)); consumer.attachQueue(\"OMS_HELLO_TOPIC\", new MessageListener() &#123; @Override public void onReceived(Message message, Context context) &#123; System.out.printf(\"Received one message: %s%n\", message.sysHeaders().getString(Message.BuiltinKeys.MESSAGE_ID)); context.ack(); &#125; &#125;); consumer.startup(); System.out.printf(\"Consumer startup OK%n\"); &#125;&#125;","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"在Centos系统中安装Docker","slug":"04-docker-lession-index","date":"2019-09-28T10:48:08.000Z","updated":"2022-09-17T14:13:56.145Z","comments":false,"path":"docker/04-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/04-docker-lession-index/","excerpt":"","text":"前言： 网上很多关于docker在centos系统上的安装教程，但是又各有异同，比较混乱。所以，此文章接下来的对于docker的安装，将参照官方的文档进行安装。 官方文档地址：https://docs.docker.com/install/linux/docker-ce/centos/ Docker版本Docker如今划分成了2个版本： Docker CE（社区版） Docker EE（企业版） 具体详情以及区别，就不多做说明了。我们一般都会选择Docker CE（社区版），因为CE版本是开源免费的。对于大多数企业公司都比较节约成本。 因此，文章中所使用的Docker版本均为Docker CE版本。 安装Docker CE版本的先决条件 官方文档中有这样一段描述： 123&gt; OS requirements&gt; To install Docker CE, you need a maintained version of CentOS 7. Archived versions aren’t supported or tested.&gt; 翻译过来的中文意思就是： OS要求 要安装Docker CE，您需要维护的CentOS 7版本。不支持或测试归档版本。 官方推荐的系统是centos7以上，但其实centos6也是可以安装docker的，并没有强制必须是centos7。 但是我的文章是基于最新的centos7系统，所以对于低版本的centos系统如何安装docker，请自行网上查找资料或者实际操作。 卸载旧版本 老版本的Docker被称为docker或docker-engine。如果安装了它们，请卸载它们以及相关的依赖项。 在Linux命令行执行的命令如下： 12345678910yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 如下图所示，将上面的命令copy一下，并在Linux命令行下面直接回车运行： 如图中所示，最后出现 No Packages marked for removal 的提示信息，说明没有需要删除的资源包了，标明旧版本的docker资源包以及相关依赖包都已经删除掉了。 安装Docker CEDocker CE安装的不同方式 设置Docker的存储库并从中进行安装，以便安装和升级任务。这是推荐的方法。 有些用户下载RPM软件包并手动安装，并完全手动管理升级。这对于在无法访问互联网的系统上安装Docker等情况很有用。 在测试和开发环境中，一些用户选择使用自动便利脚本来安装Docker。 这里我们就选择第一种方式进行安装，这也是推荐的做法。 至于其他的安装方式，可自行网上学习，这里不做过多讲解。 使用存储库进行安装 首次在新主机上安装Docker CE之前，需要设置Docker存储库。之后，您可以从存储库安装和更新Docker。 设置存储库 安装所需的包。 yum-utils提供yum-config-manager实用程序，devicemapper存储驱动程序需要device-mapper-persistent-data和lvm2。 123yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 使用以下命令设置稳定的存储库。 即使您想从边缘或测试存储库安装构建，也总是需要稳定的存储库。 123yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo （可选）：启用边缘和测试存储库。 这些存储库包含在上面的docker.repo文件中，但默认情况下处于禁用状态。 您可以将它们与稳定的存储库一起启用。 12yum-config-manager --enable docker-ce-edgeyum-config-manager --enable docker-ce-test （可选）：与上一步相反的作用。通过使用–disable标志运行yum-config-manager命令，可以禁用边缘或测试存储库。 要重新启用它，请使用–enable标志。 以下命令禁用边缘存储库。 1yum-config-manager --disable docker-ce-edge 注意：从Docker 17.06开始，稳定版本也被推到边缘并测试版本库。 了解稳定和边缘构建 ：https://docs.docker.com/install/ 安装Docker CE 安装最新版本的Docker CE： 1yum install docker-ce 如果命令行下面出现如下图所示的确认信息，请输入“y”继续，主要是用于处理依赖包的事情： 上一步输入“y”之后，后面可能会遇到下图所示的确认提示信息，同样的输入“y”即可： 稍作等待，当命令行最终输出“Complete！”即表示安装完成： 启动Docker 1systemctl start docker 验证Docker是否安装成功 最简单的验证方式，就是使用 docker version 命令，类似于JDK的 java -version 一样的道理。 Docker安装成功的话，就可以直接在命令行运行Docker的命令的。 1docker version 如果出现如下图所示信息，说明Docker以及安装成功了！ 【可选】：当然，你也可以通过运行 hello-world 映像来检验Docker是否安装成功： 1docker run hello-world 上面的命令含义：下载官方提供的用于测试使用的hello-world镜像并将其运行到容器中，来检验Docker服务是否正常安装并运行。 执行上面的命令之后，Docker会自动下载hello-world镜像并自动运行到容器中，当命令行中出现“Hello from Docker!”的字样，说明已经成功运行了hello-world镜像，一切就OK了！ 这里就简单的作为Docker的入门操作，很简单的吧。让你有一个比较直观的感觉~ Docker默认挂载目录Docker CE安装成功之后，你可以发现 /var/lib 目录下有一个 docker 目录，你可以进入Docker目录查看Docker的一些结构，如下图所示： 其中有一个containers 目录，这个目录就是存放Docker容器的。上面我们有提及到 hello-world 镜像，如果你运行了 hello-world 镜像，那么这个镜像所生成的容器信息，就会存储在 containers 目录中。 具体 containers 目录中存放了什么内容，可自行网上查询资料学习。 配置Docker在系统启动时启动 未配置Docker在系统启动时启动，则系统重启之后，Docker服务是无法正常访问 这里是使用我的阿里云服务器作为测试，在阿里云的后台系统中手动重启了服务器，服务器启动完成并正常运行后，在我的本地电脑使用客户端软件连接Linux服务器的时候（可以使用XShell、或者其他终端软件），通过执行 docker version 命令查看Docker服务运行状况，如下图结果： 从图中可以看到，Docker Server 没有正常启动，原因很简单，就是没有设置Docker在服务器重启之后，没有自动启动导致。 如何解决？ 手动启动Docker服务： 1、通过在命令行中执行以下命令，即可实现Docker服务的启动： 12&gt; systemctl start docker&gt; 这时候重新在命令行中执行 docker version命令，效果如下： 出现Server相关的信息，标明Docker服务正常启动了，就可以对Docker进行一系列操作。 上面这种启动方式存在什么不足呢？ 当服务器重启的时候，Docker服务依然不能自动启动，还是需要手工去启动Docker服务。 那能不能做到系统重启之后，Docker服务自动启动，答案肯定是有的。 实现Docker服务随着系统重启后自动启动 大多数当前的Linux发行版（RHEL，CentOS，Fedora，Ubuntu 16.04和更高版本）使用systemd来管理在系统启动时启动哪些服务。 通过在命令行执行以下命令，用于设置Docker在系统重启时，自动启动Docker服务 12&gt; systemctl enable docker&gt; 执行该命令之后，会显示如下结果： 主要的意思就是 设置Docker服务会随着服务器重启，会自动启动Docker服务。 当然，执行该命令之后，对于当前的Docker服务状况是没有启动服务的，需要手动启动Docker服务；只有下次服务器重启，就无需手动启动Docker服务了。 官方文档介绍：https://docs.docker.com/install/linux/linux-postinstall/#configure-docker-to-start-on-boot 注意一点：由于Linux不同版本的系统的差异、或者低版本的系统，命令或许会出现差异。如有遇到这样的问题，请自行网上查找资料解决。 取消Docker服务随着系统重启后自动启动 如果你不想让Docker服务随着系统重启之后自动启动的话，你可以通过命令来取消这样的策略： 1systemctl disable docker 执行上面的命令，就可以了。 官方文档介绍：https://docs.docker.com/install/linux/linux-postinstall/#configure-docker-to-start-on-boot 卸载Docker CE 如果需要卸载机器上已经安装的Docker CE，可以通过简单命令实现。 卸载Docker包： 1yum remove docker-ce 上面的命令，不会自动删除主机上的图像，容器，卷或自定义配置文件。要想删除所有图像，容器和卷，执行以下命令： 1rm -rf /var/lib/docker 注意：必须手动删除任何已编辑的配置文件 shell一键安装12curl -fsSL get.docker.com -o get-docker.shsudo sh get-docker.sh 这样执行完了就完成安装了，简单便捷 然后启动docker 1sudo systemctl start docker 完美！鼓掌！！","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"},{"name":"Centos","slug":"Centos","permalink":"https://www.cicoding.cn/tags/Centos/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ插件部署console控制台","slug":"install-rocketmq-console","date":"2019-09-25T05:50:43.000Z","updated":"2022-09-17T14:13:56.150Z","comments":true,"path":"install/install-rocketmq-console/","link":"","permalink":"https://www.cicoding.cn/install/install-rocketmq-console/","excerpt":"","text":"RocketMQ插件部署 下载 地址：https://github.com/apache/rocketmq-externals 下载完成之后，进入‘rocketmq-externals\\rocketmq-console\\src\\main\\resources’文件夹，打开‘application.properties’进行配置 编译启动 ​ 进入‘\\rocketmq-externals\\rocketmq-console’文件夹，执行‘mvn clean package -Dmaven.test.skip=true’，编译生成。 ​ 编译成功之后，Cmd进入‘target’文件夹，执行‘java -jar rocketmq-console-ng-1.0.0.jar’，启动‘rocketmq-console-ng-1.0.0.jar’。 测试 浏览器中输入‘127.0.0.1：配置端口’，成功后即可查看。","categories":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}]},{"title":"windows下安装部署RocketMQ","slug":"install-windows-rocketmq","date":"2019-09-25T05:24:17.000Z","updated":"2022-09-17T14:13:56.150Z","comments":true,"path":"install/install-windows-rocketmq/","link":"","permalink":"https://www.cicoding.cn/install/install-windows-rocketmq/","excerpt":"","text":"一.预备环境 系统 1Windows 环境 1JDK1.8、Maven、Git 二. RocketMQ部署 下载 地址：http://rocketmq.apache.org/release_notes/release-notes-4.4.0/ 选择‘Binary’进行下载 解压已下载工程 三. 配置 系统环境变量配置 ​ 变量名：ROCKETMQ_HOME ​ 变量值：MQ解压路径\\MQ文件夹名 四. 启动 启动NAMESERVER ​ Cmd命令框执行进入至‘MQ文件夹\\bin’下，然后执行‘start mqnamesrv.cmd’，启动NAMESERVER。成功后会弹出提示框，此框勿关闭。 启动BROKER ​ Cmd命令框执行进入至‘MQ文件夹\\bin’下，然后执行‘start mqbroker.cmd -n 127.0.0.1:9876 autoCreateTopicEnable=true’，启动BROKER。成功后会弹出提示框，此框勿关闭。 假如弹出提示框提示‘错误: 找不到或无法加载主类 xxxxxx’。打开runbroker.cmd，然后将‘%CLASSPATH%’加上英文双引号。保存并重新执行start语句。 这样就可以启动成功了！","categories":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"安装教程","slug":"安装教程","permalink":"https://www.cicoding.cn/categories/安装教程/"}]},{"title":"SpringCloud微服务学习之旅","slug":"microservice","date":"2019-09-24T08:17:35.000Z","updated":"2022-09-19T12:33:11.828Z","comments":true,"path":"micro-service/microservice/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice/","excerpt":"","text":"微服务微服务简介 服务发现 - Eureka 微服务服务提供者在Eureka中注册 SpringCloud Ribbon SpringCloud Feign 熔断器-Ribbon使用Hystrix 熔断器-Feign使用Hystrix 熔断器-Hystrix Dashboard 熔断器 - Turbine SpringCloud组件之Zuul Spring Cloud Sleuth与Zipkin配合使用 Feign使用常见问题总结 SpringCloud如何使用Feign构造多参数的请求 SpringCloud Stream整合RocketMQ实现消息发送与接收 问题汇总SpringCloud—–Ribbon异常java.net.UnknownHostException Spring Boot Admin2.X监控的服务context-path问题 Feign调用全局异常处理解决","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"IntelliJ IDEA 快速高效 Plugins","slug":"IntelliJ-IDEA-Plugins","date":"2019-09-24T03:07:39.000Z","updated":"2022-09-19T12:33:11.829Z","comments":true,"path":"tools/IntelliJ-IDEA-Plugins/","link":"","permalink":"https://www.cicoding.cn/tools/IntelliJ-IDEA-Plugins/","excerpt":"","text":"GsonFormat插件作用：将JSON文本转换成Java类，并且支持Lombok 下载数：651K 插件主页：https://plugins.jetbrains.com/plugin/7654-gsonformat GitHub：https://github.com/zzz40500/GsonFormat 主要用于使用Gson库将JSONObject格式的String 解析成实体，该插件可以加快开发进度，使用非常方便，效率高。 插件地址：https://plugins.jetbrains.com/idea/plugin/7654-gsonformat 使用： 自定义个javaBean(无任何内容，就一个空的类) 复制你要解析的json 然后alt+insert弹出如下界面 或者使用快捷键 alt+s 粘贴到如下界面： 点击ok,自动生成对应javaBean的代码： Free Mybatis plugin插件作用：Mybatis代码提示、跳转 下载数：206.7K 插件主页：https://plugins.jetbrains.com/plugin/8321-free-mybatis-plugin GitHub：https://github.com/wuzhizhan/free-idea-mybatis 点击箭头 跳转到了mapper 再点击点头返回！ Maven Helper插件作用：分析Maven依赖，定位依赖冲突等 下载数：379K 插件主页：https://plugins.jetbrains.com/plugin/7179-maven-helper GitHub：https://github.com/krasa/MavenHelper位依赖冲突等 idea中运行 JRebel for IntelliJ 热部署插件 安装完成之后 第一个是JRebel for IntelliJ正常启动 第二个是JRebel for IntelliJ debug启动 CodeGlance类似SublimeText的Mini Map插件，看下图就知道什么用了： Lombok Plugin作用：简化模板代码，让代码更简洁 下载数：3824K 插件主页：https://plugins.jetbrains.com/plugin/6317-lombok-plugin GitHub：https://github.com/mplushnikov/lombok-intellij-plugin http://mp.weixin.qq.com/s?__biz=MzI1NDQ3MjQxNA==&amp;mid=2247484740&amp;idx=1&amp;sn=151715b1f67f0fc20df1df15c3008f26&amp;chksm=e9c5fcf5deb275e35494f4be71e5f71b742e5b321b2fc50a3bc7b7bfbfbd6dd6df4fd76a5185&amp;scene=21#wechat_redirect 从今天起让我们忘记Java中的get/set方法吧！ Alibaba Java Coding Guidelines作用：代码规约插件，让代码更加规范 下载数：535K 插件主页：https://plugins.jetbrains.com/plugin/10046-alibaba-java-coding-guidelines GitHub：https://github.com/alibaba/p3c 经过247天的持续研发，阿里巴巴于10月14日在杭州云栖大会上，正式发布众所期待的《阿里巴巴Java开发规约》扫描插件！该插件由阿里巴巴P3C项目组研发。P3C是世界知名的反潜机，专门对付水下潜水艇，寓意是扫描出所有潜在的代码隐患。 为了让开发者更加方便、快速将规范推动并实行起来，阿里巴巴基于手册内容，研发了一套自动化的IDE检测插件（IDEA、Eclipse）。该插件在扫描代码后，将不符合规约的代码按Blocker/Critical/Major三个等级显示在下方，甚至在IDEA上，我们还基于Inspection机制提供了实时检测功能，编写代码的同时也能快速发现问题所在。对于历史代码，部分规则实现了批量一键修复的功能，如此爽心悦目的功能是不是很值得拥有？提升代码质量，提高团队研发效能，插件将会一路同行。 Stack Overflow编码中几乎所有遇到的错误，都可以在Stack Overflow上找到，因此这个插件可称之为贴心助手，只不过默认使用Google搜索，大家注意。 Background Image Plus给你一个机会让你面向“对象”编程，设置你喜欢的图片，提升你编码逼格！ 安装后，在设置界面设置背景图片文件夹，里边放图片，并且可以设置定时更新： 设置完图片之后，重启一下IDEA,然后，你懂的！ Markdown supportIdea中优化Markdown Support显示效果 .ignoregit提交时过滤掉不需要提交的文件，很方便，有些本地文件是不需要提交到Git上的。 CamelCase将不是驼峰格式的名称，快速转成驼峰格式，安装好后，选中要修改的名称，按快捷键shift+alt+u。 codehelper.generator可以让你在创建一个对象并赋值的时候，快速的生成代码，不需要一个一个属性的向里面set,根据new关键字，自动生成掉用set方法的代码，还可以一键填入默认值。 GenAllSetter 特性 在Java方法中, 根据 new 关键词, 为Java Bean 生成所有Setter方法。 按GenAllSetter键两次, 会为Setter方法生成默认值。 可在Intellij Idea中为GenAllSetter设置快捷键。 如何使用: 将光标移动到 new 语句的下一行。 点击主菜单Tools-&gt; Codehelper-&gt; GenAllSetter, 或者按下GenAllSetter快捷键。 GenDaoCode 特性 根据Pojo 文件一键生成 Dao，Service，Xml，Sql文件。 Pojo文件更新后一键更新对应的Sql和mybatis xml文件。 提供insert，insertList，update，select，delete五种方法。 能够批量生成多个Pojo的对应的文件。 自动将pojo的注释添加到对应的Sql文件的注释中。 丰富的配置，如果没有配置文件，则会使用默认配置。 可以在Intellij Idea中快捷键配置中配置快捷键。 目前支持MySQL + Java，后续会支持更多的DB。 如果喜欢我们的插件，非常感谢您的分享。 GenDaoCode 使用方法主菜单Tools-&gt; Codehelper-&gt; GenDaoCode 按键便可生成代码。 方法一：点击GenDaoCode，然后根据提示框输入Pojo名字，多个Pojo以 | 分隔。Codehelper Generator会根据默认配置为您生成代码。 方法二：在工程目录下添加文件名为codehelper.properties的文件。点击GenDaoCode，Codehelper Generator会根据您的配置文件为您生成代码 GenerateAllSetter一键调用一个对象的所有set方法并且赋予默认值 在对象字段多的时候非常方便，在做项目时，每层都有各自的实体对象需要相互转换，但是考虑BeanUtil.copyProperties()等这些工具的弊端，有些地方就需要手动的赋值时，有这个插件就会很方便，创建完对象后在变量名上面按Alt+Enter就会出来 generate all setter选项。 Material Theme UI这是一款主题插件，可以让你的ide的图标变漂亮，配色搭配的很到位，还可以切换不同的颜色，甚至可以自定义颜色。默认的配色就很漂亮了，如果需要修改配色，可以在工具栏中Tools-&gt;Material Theme然后修改配色等。 active-power-mode这是一款让你在编码的时候，整个屏幕都为之颤抖的插件。 Nyan progress bar这是一个将你idea中的所有的进度条都变成萌新动画的小插件。 Translation作用：翻译 下载数：217K 插件主页：https://plugins.jetbrains.com/plugin/8579-translation GitHub：https://github.com/YiiGuxing/TranslationPlugin RestfulToolkit作用：自动识别Spring MVC的REST API，并可调试 下载数：33K 插件主页：https://plugins.jetbrains.com/plugin/10292-restfultoolkit GitHub：暂无 AceJump作用：在IDEA中高效跳转，丢弃鼠标 下载数：250K 插件主页：https://plugins.jetbrains.com/plugin/7086-acejump GitHub：https://github.com/johnlindquist/AceJump Statistic作用：代码统计 下载数：368K 插件主页：https://plugins.jetbrains.com/plugin/4509-statistic GitHub：暂无 截图： Kubernetes作用：官方出品，帮你快速编写Kubernetes编排文件，例如输入kdep迅速创建Deployment 下载数：118K 插件主页：https://plugins.jetbrains.com/plugin/10485-kubernetes GitHub：暂无 截图： Docker interation作用：官方出品，整合Docker 下载数：1807K 插件主页：https://plugins.jetbrains.com/plugin/7724-docker-integration GitHub：暂无 Rainbow Brackets作用：彩虹色括号，实现配对括号相同颜色，并且实现选中区域代码高亮的功能，让阅读代码更加轻松。 下载数：555K 插件主页：https://plugins.jetbrains.com/plugin/10080-rainbow-brackets GitHub：https://github.com/izhangzhihao/intellij-rainbow-brackets 截图： String Manipulation作用：各种命名方式交替变化，支持的格式有：camelCase, kebab-lowercase, KEBAB-UPPERCASE, snake_case, SCREAMING_SNAKE_CASE, dot.case, words lowercase, Words Capitalized, PascalCase） 下载数：594K 插件主页：https://plugins.jetbrains.com/plugin/2162-string-manipulation GitHub：https://github.com/krasa/StringManipulation Mybatis Log Plugin作用：打印出Mybatis执行的SQL，并且直接可执行，便于调试。 下载数：31K 插件主页：https://plugins.jetbrains.com/plugin/10065-mybatis-log-plugin GitHub：https://github.com/kookob/mybatis-log-plugin/ 截图： LiveEdit作用：前端修改无需刷新浏览器 下载数：3909K 插件主页：https://plugins.jetbrains.com/plugin/7007-liveedit GitHub：暂无 Material Theme UI作用：一款Theme UI的IDEA主题 下载数：3872K 插件主页：https://plugins.jetbrains.com/plugin/8006-material-theme-ui GitHub：https://github.com/ChrisRM/material-theme-jetbrains 截图： Vue.js作用：支持Vue.js的开发 下载数：845K 插件主页：https://plugins.jetbrains.com/plugin/9442-vue-js GitHub：暂无 BashSupport作用：支持编写Shell，高亮、代码提示、重构 下载数：9652K 插件主页：https://plugins.jetbrains.com/plugin/4230-bashsupport GitHub：https://github.com/BashSupport/BashSupport CodeGlance作用：代码缩略图 下载数：722K 插件主页：https://plugins.jetbrains.com/plugin/7275-codeglance GitHub：https://github.com/Vektah/CodeGlance 截图： Grep Console作用：控制台查询、搜索日志，并且可以配置高亮颜色。 下载数：662K 插件主页：https://plugins.jetbrains.com/plugin/7125-grep-console GitHub：https://github.com/krasa/GrepConsole Key Promoter X作用：一个学习IntelliJ IDEA快捷键的插件。 下载数：185K 插件主页：https://plugins.jetbrains.com/plugin/9792-key-promoter-x GitHub：https://github.com/halirutan/IntelliJ-Key-Promoter-X 截图： ignore作用：忽略不想提交的文件 下载数：8591K 插件主页：https://plugins.jetbrains.com/plugin/7495--ignore GitHub：https://github.com/hsz/idea-gitignore 截图： IDE Features Trainer作用：交互式学习IDEA的基本功能与快捷键 下载数：1019K 插件主页：https://plugins.jetbrains.com/plugin/8554-ide-features-trainer GitHub：https://github.com/JetBrains/ide-features-trainer 截图： Idea 类builder模式插件安装方法builder 模式的代码 手写的话不是不可能，字段多了 就恶心了，下面就会看到，长话短说，IEDA 安装 builder 插件 首先Idea 快捷键Ctrl +alt+s 打开preference 找Plugins 弹出来一个窗口 搜索InnerBuilder 点击右边的 install 就完了，等待下载完成，重启idea。进入我们写好的类，点击鼠标右键，选择Generate 下面有一个builder，选择想要的属性。体验优雅的代码 然后说一下Java中设计模式 ，提到设计模式，懂得人说：“代码变得更优雅，更好看”，不懂得人看了一脸懵逼，那就说一下builder模式吧，对于一些拥有特变多的类来说特别方便，为了使这个类，我们通常情况下会给这个类多个构造器以及一个默认的无参数构造器。 很多编译器有generate快捷键，可以快速生成一个含有该类属性的constructor， 但是当参数的个数比较多的时候，经常会传错。当然有人会说每个属性调用set方法不就完了么，那么你代码会变成一坨，不如点出来代码优雅，看下面的例子，build的优点儿就体现出来了。 资源&amp;网站 IDEA主题下载 IDEA主题下载 IntelliJ IDEA 注册码 教程 图文教程： CG国斌：史上最简单的 IntelliJ IDEA 教程 极客学院：IntelliJ IDEA 使用教程 GitHub：IntelliJ IDEA 简体中文专题教程 视频教程： 尚学堂：Intellij IDEA视频教程","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://www.cicoding.cn/tags/IDEA/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"Docker系列教程","slug":"00-docker-lession-index","date":"2019-09-24T02:22:55.000Z","updated":"2022-09-19T12:33:11.827Z","comments":true,"path":"docker/00-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/00-docker-lession-index/","excerpt":"","text":"Docker系列传统项目开发部署的流程是怎样的？ Docker是干什么用的？ Docker镜像、容器、仓库的介绍 在Centos系统中安装Docker 在windows系统中安装Docker 在Docker中安装JDK 在Docker中安装Tomcat 在Docker中安装Mysql 在Docker中安装Nginx 在Docker中安装Zookeeper以及集群环境搭建 在Docker中安装Redis以及主从环境搭建 Docker部署Spring Boot项目","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ--设计","slug":"rocketmq-design","date":"2019-09-16T11:36:00.000Z","updated":"2022-06-14T02:45:32.109Z","comments":false,"path":"rocketmq/rocketmq-design/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-design/","excerpt":"","text":"1. 设计(design) 1 消息存储 消息存储是RocketMQ中最为复杂和最为重要的一部分，本节将分别从RocketMQ的消息存储整体架构、PageCache与Mmap内存映射以及RocketMQ中两种不同的刷盘方式三方面来分别展开叙述。 1.1 消息存储整体架构消息存储架构图中主要有下面三个跟消息存储相关的文件构成。 (1) CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件； (2) ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M； (3) IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \\store\\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。 在上面的RocketMQ的消息存储整体架构图中可以看出，RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构，Producer发送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，如果一个消息拉取请求未拉取到消息，Broker允许等待30s的时间，只要这段时间内有新消息到达，将直接返回给消费端。这里，RocketMQ的具体做法是，使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据。 1.2 页缓存与内存映射页缓存（PageCache)是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。 在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。 另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中（这种Mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。 1.3 消息刷盘 (1) 同步刷盘：如上图所示，只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。 (2) 异步刷盘：能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。 2 通信机制RocketMQ消息队列集群主要包括NameServe、Broker(Master/Slave)、Producer、Consumer4个角色，基本通讯流程如下： (1) Broker启动后需要完成一次将自己注册至NameServer的操作；随后每隔30s时间定时向NameServer上报Topic路由信息。 (2) 消息生产者Producer作为客户端发送消息时候，需要根据消息的Topic从本地缓存的TopicPublishInfoTable获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取，同时Producer会默认每隔30s向NameServer拉取一次路由信息。 (3) 消息生产者Producer根据2）中获取的路由信息选择一个队列（MessageQueue）进行消息发送；Broker作为消息的接收者接收消息并落盘存储。 (4) 消息消费者Consumer根据2）中获取的路由信息，并再完成客户端的负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。 从上面1）~3）中可以看出在消息生产者, Broker和NameServer之间都会发生通信（这里只说了MQ的部分通信），因此如何设计一个良好的网络通信模块在MQ中至关重要，它将决定RocketMQ集群整体的消息传输能力与最终的性能。 rocketmq-remoting 模块是 RocketMQ消息队列中负责网络通信的模块，它几乎被其他所有需要网络通信的模块（诸如rocketmq-client、rocketmq-broker、rocketmq-namesrv）所依赖和引用。为了实现客户端与服务器之间高效的数据请求与接收，RocketMQ消息队列自定义了通信协议并在Netty的基础之上扩展了通信模块。 2.1 Remoting通信类结构 2.2 协议设计与编解码在Client和Server之间完成一次消息发送时，需要对发送的消息进行一个协议约定，因此就有必要自定义RocketMQ的消息协议。同时，为了高效地在网络中传输消息和对收到的消息读取，就需要对消息进行编解码。在RocketMQ中，RemotingCommand这个类在消息传输过程中对所有数据内容的封装，不但包含了所有的数据结构，还包含了编码解码操作。 Header字段 类型 Request说明 Response说明 code int 请求操作码，应答方根据不同的请求码进行不同的业务处理 应答响应码。0表示成功，非0则表示各种错误 language LanguageCode 请求方实现的语言 应答方实现的语言 version int 请求方程序的版本 应答方程序的版本 opaque int 相当于reqeustId，在同一个连接上的不同请求标识码，与响应消息中的相对应 应答不做修改直接返回 flag int 区分是普通RPC还是onewayRPC得标志 区分是普通RPC还是onewayRPC得标志 remark String 传输自定义文本信息 传输自定义文本信息 extFields HashMap 请求自定义扩展信息 响应自定义扩展信息 可见传输内容主要可以分为以下4部分： (1) 消息长度：总长度，四个字节存储，占用一个int类型； (2) 序列化类型&amp;消息头长度：同样占用一个int类型，第一个字节表示序列化类型，后面三个字节表示消息头长度； (3) 消息头数据：经过序列化后的消息头数据； (4) 消息主体数据：消息主体的二进制字节数据内容； 2.3 消息的通信方式和流程在RocketMQ消息队列中支持通信的方式主要有同步(sync)、异步(async)、单向(oneway) 三种。其中“单向”通信模式相对简单，一般用在发送心跳包场景下，无需关注其Response。这里，主要介绍RocketMQ的异步通信流程。 2.4 Reactor多线程设计RocketMQ的RPC通信采用Netty组件作为底层通信库，同样也遵循了Reactor多线程模型，同时又在这之上做了一些扩展和优化。 上面的框图中可以大致了解RocketMQ中NettyRemotingServer的Reactor 多线程模型。一个 Reactor 主线程（eventLoopGroupBoss，即为上面的1）负责监听 TCP网络连接请求，建立好连接，创建SocketChannel，并注册到selector上。RocketMQ的源码中会自动根据OS的类型选择NIO和Epoll，也可以通过参数配置）,然后监听真正的网络数据。拿到网络数据后，再丢给Worker线程池（eventLoopGroupSelector，即为上面的“N”，源码中默认设置为3），在真正执行业务逻辑之前需要进行SSL验证、编解码、空闲检查、网络连接管理，这些工作交给defaultEventExecutorGroup（即为上面的“M1”，源码中默认设置为8）去做。而处理业务操作放在业务线程池中执行，根据 RomotingCommand 的业务请求码code去processorTable这个本地缓存变量中找到对应的 processor，然后封装成task任务后，提交给对应的业务processor处理线程池来执行（sendMessageExecutor，以发送消息为例，即为上面的 “M2”）。从入口到业务逻辑的几个步骤中线程池一直再增加，这跟每一步逻辑复杂性相关，越复杂，需要的并发通道越宽。 线程数 线程名 线程具体说明 1 NettyBoss_%d Reactor 主线程 N NettyServerEPOLLSelector%d%d Reactor 线程池 M1 NettyServerCodecThread_%d Worker线程池 M2 RemotingExecutorThread_%d 业务processor处理线程池 3 消息过滤RocketMQ分布式消息队列的消息过滤方式有别于其它MQ中间件，是在Consumer端订阅消息时再做消息过滤的。RocketMQ这么做是还是在于其Producer端写入消息和Consomer端订阅消息采用分离存储的机制来实现的，Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引，然后再从CommitLog里面读取真正的消息实体内容，所以说到底也是还绕不开其存储结构。其ConsumeQueue的存储结构如下，可以看到其中有8个字节存储的Message Tag的哈希值，基于Tag的消息过滤正式基于这个字段值的。 主要支持如下2种的过滤方式 (1) Tag过滤方式：Consumer端在订阅消息时除了指定Topic还可以指定TAG，如果一个消息有多个TAG，可以用||分隔。其中，Consumer端会将这个订阅请求构建成一个 SubscriptionData，发送一个Pull消息的请求给Broker端。Broker端从RocketMQ的文件存储层—Store读取数据之前，会用这些数据先构建一个MessageFilter，然后传给Store。Store从 ConsumeQueue读取到一条记录后，会用它记录的消息tag hash值去做过滤，由于在服务端只是根据hashcode进行判断，无法精确对tag原始字符串进行过滤，故在消息消费端拉取到消息后，还需要对消息的原始tag字符串进行比对，如果不同，则丢弃该消息，不进行消息消费。 (2) SQL92的过滤方式：这种方式的大致做法和上面的Tag过滤方式一样，只是在Store层的具体过滤过程不太一样，真正的 SQL expression 的构建和执行由rocketmq-filter模块负责的。每次过滤都去执行SQL表达式会影响效率，所以RocketMQ使用了BloomFilter避免了每次都去执行。SQL92的表达式上下文为消息的属性。 4 负载均衡RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。 4.1 Producer的负载均衡Producer端在发送消息的时候，会先根据Topic找到指定的TopicPublishInfo，在获取了TopicPublishInfo路由信息后，RocketMQ的客户端在默认方式下selectOneMessageQueue()方法会从TopicPublishInfo中的messageQueueList中选择一个队列（MessageQueue）进行发送消息。具体的容错策略均在MQFaultStrategy这个类中定义。这里有一个sendLatencyFaultEnable开关变量，如果开启，在随机递增取模的基础上，再过滤掉not available的Broker代理。所谓的”latencyFaultTolerance”，是指对之前失败的，按一定的时间做退避。例如，如果上次请求的latency超过550Lms，就退避3000Lms；超过1000L，就退避60000L；如果关闭，采用随机递增取模的方式选择一个队列（MessageQueue）来发送消息，latencyFaultTolerance机制是实现消息发送高可用的核心关键所在。 4.2 Consumer的负载均衡在RocketMQ中，Consumer端的两种消费模式（Push/Pull）都是基于拉模式来获取消息的，而在Push模式只是对pull模式的一种封装，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到消息消费线程池后，又“马不停蹄”的继续向服务器再次尝试拉取消息。如果未拉取到消息，则延迟一下又继续拉取。在两种基于拉模式的消费方式（Push/Pull）中，均需要Consumer端在知道从Broker端的哪一个消息队列—队列中去获取消息。因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。 1、Consumer端的心跳包发送 在Consumer启动后，它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了，消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。Broker端在收到Consumer的心跳消息后，会将它维护在ConsumerManager的本地缓存变量—consumerTable，同时并将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中，为之后做Consumer端的负载均衡提供可以依据的元数据信息。 2、Consumer端实现负载均衡的核心类—RebalanceImpl 在Consumer实例的启动流程中的启动MQClientInstance实例部分，会完成负载均衡服务线程—RebalanceService的启动（每隔20s执行一次）。通过查看源码可以发现，RebalanceService线程的run()方法最终调用的是RebalanceImpl类的rebalanceByTopic()方法，该方法是实现Consumer端负载均衡的核心。这里，rebalanceByTopic()方法会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。这里主要来看下集群模式下的主要处理流程： (1) 从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中，获取该Topic主题下的消息消费队列集合（mqSet）； (2) 根据topic和consumerGroup为参数调用mQClientFactory.findConsumerIdList()方法向Broker端发送获取该消费组下消费者Id列表的RPC通信请求（Broker端基于前面Consumer端上报的心跳包数据而构建的consumerTable做出响应返回，业务请求码：GET_CONSUMER_LIST_BY_GROUP）； (3) 先对Topic下的消息消费队列、消费者Id排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列。这里的平均分配算法，类似于分页的算法，将所有MessageQueue排好序类似于记录，将所有消费端Consumer排好序类似页数，并求出每一页需要包含的平均size和每个页面记录的范围range，最后遍历整个range而计算出当前Consumer端应该分配到的记录（这里即为：MessageQueue）。 (4) 然后，调用updateProcessQueueTableInRebalance()方法，具体的做法是，先将分配到的消息队列集合（mqSet）与processQueueTable做一个过滤比对。 上图中processQueueTable标注的红色部分，表示与分配到的消息队列集合mqSet互不包含。将这些队列设置Dropped属性为true，然后查看这些队列是否可以移除出processQueueTable缓存变量，这里具体执行removeUnnecessaryMessageQueue()方法，即每隔1s 查看是否可以获取当前消费处理队列的锁，拿到的话返回true。如果等待1s后，仍然拿不到当前消费处理队列的锁则返回false。如果返回true，则从processQueueTable缓存变量中移除对应的Entry； 上图中processQueueTable的绿色部分，表示与分配到的消息队列集合mqSet的交集。判断该ProcessQueue是否已经过期了，在Pull模式的不用管，如果是Push模式的，设置Dropped属性为true，并且调用removeUnnecessaryMessageQueue()方法，像上面一样尝试移除Entry； 最后，为过滤后的消息队列集合（mqSet）中的每个MessageQueue创建一个ProcessQueue对象并存入RebalanceImpl的processQueueTable队列中（其中调用RebalanceImpl实例的computePullFromWhere(MessageQueue mq)方法获取该MessageQueue对象的下一个进度消费值offset，随后填充至接下来要创建的pullRequest对象属性中），并创建拉取请求对象—pullRequest添加到拉取列表—pullRequestList中，最后执行dispatchPullRequest()方法，将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中，待该服务线程取出后向Broker端发起Pull消息的请求。其中，可以重点对比下，RebalancePushImpl和RebalancePullImpl两个实现类的dispatchPullRequest()方法不同，RebalancePullImpl类里面的该方法为空，这样子也就回答了上一篇中最后的那道思考题了。 消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。 5 事务消息Apache RocketMQ在4.3.0版中已经支持分布式事务消息，这里RocketMQ采用了2PC的思想来实现了提交事务消息，同时增加一个补偿逻辑来处理二阶段超时或者失败的消息，如下图所示。 5.1 RocketMQ事务消息流程概要上图说明了事务消息的大致方案，其中分为两个流程：正常事务消息的发送及提交、事务消息的补偿流程。 1.事务消息发送及提交： (1) 发送消息（half消息）。 (2) 服务端响应消息写入结果。 (3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。 (4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见） 2.补偿流程： (1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” (2) Producer收到回查消息，检查回查消息对应的本地事务的状态 (3) 根据本地事务状态，重新Commit或者Rollback 其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。 5.2 RocketMQ事务消息设计1.事务消息在一阶段对用户不可见 ​ 在RocketMQ事务消息的主要流程中，一阶段的消息如何对用户不可见。其中，事务消息相对普通消息最大的特点就是一阶段发送的消息对用户是不可见的。那么，如何做到写入消息但是对用户不可见呢？RocketMQ事务消息的做法是：如果消息是half消息，将备份原消息的主题与消息消费队列，然后改变主题为RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费half类型的消息，然后RocketMQ会开启一个定时任务，从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。 在RocketMQ中，消息在服务端的存储结构如下，每条消息都会有对应的索引信息，Consumer通过ConsumeQueue这个二级索引来读取消息实体内容，其流程如下： ​ RocketMQ的具体实现策略是：写入的如果事务消息，对消息的Topic和Queue等属性进行替换，同时将原来的Topic和Queue信息存储到消息的属性中，正因为消息主题被替换，故消息并不会转发到该原主题的消息消费队列，消费者无法感知消息的存在，不会消费。其实改变消息主题是RocketMQ的常用“套路”，回想一下延时消息的实现机制。 2.Commit和Rollback操作以及Op消息的引入 ​ 在完成一阶段写入一条对用户不可见的消息后，二阶段如果是Commit操作，则需要让消息对用户可见；如果是Rollback则需要撤销一阶段的消息。先说Rollback的情况。对于Rollback，本身一阶段的消息对用户是不可见的，其实不需要真正撤销消息（实际上RocketMQ也无法去真正的删除一条消息，因为是顺序写文件的）。但是区别于这条消息没有确定状态（Pending状态，事务悬而未决），需要一个操作来标识这条消息的最终状态。RocketMQ事务消息方案中引入了Op消息的概念，用Op消息标识事务消息已经确定的状态（Commit或者Rollback）。如果一条事务消息没有对应的Op消息，说明这个事务的状态还无法确定（可能是二阶段失败了）。引入Op消息后，事务消息无论是Commit或者Rollback都会记录一个Op操作。Commit相对于Rollback只是在写入Op消息前创建Half消息的索引。 3.Op消息的存储和对应关系 ​ RocketMQ将Op消息写入到全局一个特定的Topic中通过源码中的方法—TransactionalMessageUtil.buildOpTopic()；这个Topic是一个内部的Topic（像Half消息的Topic一样），不会被用户消费。Op消息的内容为对应的Half消息的存储的Offset，这样通过Op消息能索引到Half消息进行后续的回查操作。 4.Half消息的索引构建 ​ 在执行二阶段Commit操作时，需要构建出Half消息的索引。一阶段的Half消息由于是写到一个特殊的Topic，所以二阶段构建索引时需要读取出Half消息，并将Topic和Queue替换成真正的目标的Topic和Queue，之后通过一次普通消息的写入操作来生成一条对用户可见的消息。所以RocketMQ事务消息二阶段其实是利用了一阶段存储的消息的内容，在二阶段时恢复出一条完整的普通消息，然后走一遍消息写入流程。 5.如何处理二阶段失败的消息？ ​ 如果在RocketMQ事务消息的二阶段过程中失败了，例如在做Commit操作时，出现网络问题导致Commit失败，那么需要通过一定的策略使这条消息最终被Commit。RocketMQ采用了一种补偿机制，称为“回查”。Broker端对未确定状态的消息发起回查，将消息发送到对应的Producer端（同一个Group的Producer），由Producer根据消息来检查本地事务的状态，进而执行Commit或者Rollback。Broker端通过对比Half消息和Op消息进行事务消息的回查并且推进CheckPoint（记录那些事务消息的状态是确定的）。 值得注意的是，rocketmq并不会无休止的的信息事务状态回查，默认回查15次，如果15次回查还是无法得知事务状态，rocketmq默认回滚该消息。 6 消息查询RocketMQ支持按照下面两种维度（“按照Message Id查询消息”、“按照Message Key查询消息”）进行消息查询。 6.1 按照MessageId查询消息​ RocketMQ中的MessageId的长度总共有16字节，其中包含了消息存储主机地址（IP地址和端口），消息Commit Log offset。“按照MessageId查询消息”在RocketMQ中具体做法是：Client端从MessageId中解析出Broker的地址（IP地址和端口）和Commit Log的偏移地址后封装成一个RPC请求后通过Remoting通信层发送（业务请求码：VIEW_MESSAGE_BY_ID）。Broker端走的是QueryMessageProcessor，读取消息的过程用其中的 commitLog offset 和 size 去 commitLog 中找到真正的记录并解析成一个完整的消息返回。 6.2 按照Message Key查询消息​ “按照Message Key查询消息”，主要是基于RocketMQ的IndexFile索引文件来实现的。RocketMQ的索引文件逻辑结构，类似JDK中HashMap的实现。索引文件的具体结构如下： ​ IndexFile索引文件为用户提供通过“按照Message Key查询消息”的消息索引查询服务，IndexFile文件的存储位置是：$HOME\\store\\index${fileName}，文件名fileName是以创建时的时间戳命名的，文件大小是固定的，等于40+500W4+2000W20= 420000040个字节大小。如果消息的properties中设置了UNIQ_KEY这个属性，就用 topic + “#” + UNIQ_KEY的value作为 key 来做写入操作。如果消息设置了KEYS属性（多个KEY以空格分隔），也会用 topic + “#” + KEY 来做索引。 ​ 其中的索引数据包含了Key Hash/CommitLog Offset/Timestamp/NextIndex offset 这四个字段，一共20 Byte。NextIndex offset 即前面读出来的 slotValue，如果有 hash冲突，就可以用这个字段将所有冲突的索引用链表的方式串起来了。Timestamp记录的是消息storeTimestamp之间的差，并不是一个绝对的时间。整个Index File的结构如图，40 Byte 的Header用于保存一些总的统计信息，4500W的 Slot Table并不保存真正的索引数据，而是保存每个槽位对应的单向链表的头。202000W 是真正的索引数据，即一个 Index File 可以保存 2000W个索引。 ​ “按照Message Key查询消息”的方式，RocketMQ的具体做法是，主要通过Broker端的QueryMessageProcessor业务处理器来查询，读取消息的过程就是用topic和key找到IndexFile索引文件中的一条记录，根据其中的commitLog offset从CommitLog文件中读取消息的实体内容。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"Docker镜像、容器、仓库的介绍","slug":"03-docker-lession-index","date":"2019-09-16T00:10:12.000Z","updated":"2022-09-17T14:13:56.144Z","comments":false,"path":"docker/03-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/03-docker-lession-index/","excerpt":"","text":"Docker镜像 因为Docker本身包含的知识点很多，网上太多的介绍文档了，这里我就简单概述一下。 通俗的理解镜像 Docker的镜像是一个只读的模板，一个独立的文件系统，包括运行容器所需的数据，可以用来创建新的容器。 Docker的镜像相当于ISO操作系统的安装包，ISO镜像的内容是固定的，不会发生改变，可以重复使用。 如果上面的形容还无法让你理解Docker镜像，那我再举一个例子： 从事Java开发的人都知道类和实例的关系。直观的感觉，类就像是一个模板，根据这个类模板，可以生成很多个具体的对象实例。 则，Docker镜像就相当于Java的类，而通过Docker镜像生成出来的东西，我们就叫他它“容器”。 通过上面的形容，应该可以感觉的到镜像和容器之间的关系了吧。 Docker容器 通俗的理解容器 在上一节已经介绍了镜像与容器的关系。 这里就直接copy文档中的一句话，来简单形容一下容器： Docker镜像就相当于Java的类，而通过Docker镜像生成出来的东西，我们就叫他它“容器”。 Docker仓库 通俗的理解Docker仓库 仓库支持的操作类似git，当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 pull 下来就可以了。 类似于，将某项目模块打成jar包，然后上传到私有或者公有的maven仓库，然后在其他的所有支持maven环境的机器上，都可以拉取这个jar进行使用。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ--架构","slug":"rocketmq-architecture","date":"2019-09-12T10:56:00.000Z","updated":"2022-06-13T14:13:33.444Z","comments":false,"path":"rocketmq/rocketmq-architecture/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-architecture/","excerpt":"","text":"1. 架构设计1.1 技术架构 RocketMQ架构上主要分为四部分，如上图所示: Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。 Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。 NameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。 BrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。 Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 1.2 部署架构 1.2.1 RocketMQ 网络部署特点 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息的读负载。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 结合部署架构图，描述集群工作流程： 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。 Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"Docker是干什么用的？","slug":"02-docker-lession-index","date":"2019-09-12T00:52:58.000Z","updated":"2022-09-17T14:13:56.144Z","comments":true,"path":"docker/02-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/02-docker-lession-index/","excerpt":"","text":"长话短说，这里我就不对docker进行系统的介绍说明了，网上很多介绍文章，我想新手的话可以先网上大概了解一下docker的基本概念。有一个模糊的、大概的感觉就行了。多看资料文档，有百利而无一害。 Docker不是虚拟机 很多人一开始学习Docker的时候，感觉Docker很像虚拟机，误以为Docker就是虚拟机。其实Docker不是虚拟机！这个千万不要搞错了！先记下这个硬性结果，后续真正搞环境搭建、项目部署的时候，就会明白了~不要着急，也不用担心^_^。 对Docker有一个感官的感受吧 比如公司买了一台新服务器，系统是centos，你要想把项目部署到服务器上，而且项目中使用到了mysql、redis、activemq、zookeeper等技术，要想项目能在服务器上正常运行，必须在新的服务器上搭建好mysql、redis、activemq、zookeeper服务环境。这样的话，在环境搭建和配置上就要花费太多的时间了（因为需要配置很多的配置文件、需要手动启动服务等）。 又或者每次重装一次系统或者换一个机器，你就要把环境重装一次，东西越多花费的时间越多、很麻烦、浪费时间和精力。 而使用Docker的话，你只需要一条命令，你就可以在你的centos系统上运行你需要的软件，比如mysql、tomcat、jdk、redis等。 光文字介绍，无法直观的感受到docker的强大之处，那就举两个例子看看吧~ 【示例1】：Docker上安装mysql 你需要MySQL服务，那么在docker中通过简单的命令就可以安装一个MySQL数据库服务： 1docker pull mysql 哇！mysql就这样安装好了？ my god！太简单快捷了吧！ 那如何启动mysql呢？命令如下： 1docker run -d -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 mysql 很简单吧，一个mysql服务就启动完成了，就可以正常使用了。可以通过mysql客户端（Navicat、DataGrip等）连接这个mysql数据库。 目前你可以不用去知道具体的命令以及参数的含义，感官上感觉一下docker的强大就行了。后面具体的环境部署搭建会详细说明。 【示例2】：Docker上安装jdk 你需要JDK环境，那么在Docker中通过简单的命令安装一个JDK的镜像， 然后通过一条命令启动这个容器就行了，容器会自动给你安装配置好JDK环境。 同样的，一条命令就可以完成： 1docker pull java 就这么简单的一条命令，JDK就安装好了。你可以在Docker容器的命令行中通过java -version来检测jdk是否安装成功。 镜像、容器： 对于新手而言，或许有点不明白镜像和容器分别是个什么东东，还是有点不明白。 你可以这样感官的理解： 镜像 —— 相当于ISO操作系统的安装包，ISO镜像的内容是固定的，不会发生改变，可以重复使用。 容器 —— 类似于使用 ISO镜像安装的新的操作系统，可以使用一个相同的ISO镜像，安装很多操作系统。 你也可以制作属于自己的镜像哦 你可以在某个Docker镜像的基础之上，对Docker容器进行修改。比如添加了一些你自己的软件或修改一些配置文件，然后执行commit命令，这样你就把这个容器制作成了一个新的镜像（也就是自定义镜像），以后你就可以用这个镜像创建出N个一模一样环境的容器。 比如你要学习搭载Redis集群，那么你可以下载一个Redis的镜像，然后启动容器，进入这个容器的文件系统里面，在这个容器里面把redis集群的配置都设置好后，然后通过commit命令提交这个容器生成新的镜像，以后就可以使用这个镜像运行出更多的redis集群环境的容器了，而且环境也都是一模一样的，就无需再去从头搭建redis集群环境了。 具体的环境搭建，这里不做过多的说明，后面会讲解。 Docker占用的资源很小。启动一个容器一般都是秒级的。 Docker的优缺点 这里不多做描述，随着学习后面的Docker容器启动、项目部署等教程，你自然就会感受到Docker的优势以及存在的不足。 当然，你也可以自行网上查询资料学习。 欢迎加我QQ交流学习！","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ--特性","slug":"rocketmq-features","date":"2019-09-10T11:55:43.000Z","updated":"2022-06-13T14:10:34.952Z","comments":false,"path":"rocketmq/rocketmq-features/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-features/","excerpt":"","text":"1. 特性(features)1.1 订阅与发布消息的发布是指某个生产者向某个topic发送消息；消息的订阅是指某个消费者关注了某个topic中带有某些tag的消息，进而从该topic消费数据。 1.2 消息顺序消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。RocketMQ可以严格的保证消息有序。 顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个Topic下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可。 全局顺序 对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景 分区顺序 对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。 同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。 Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。 适用场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。 1.3 消息过滤RocketMQ的消费者可以根据Tag进行消息过滤，也支持自定义属性过滤。消息过滤目前是在Broker端实现的，优点是减少了对于Consumer无用消息的网络传输，缺点是增加了Broker的负担、而且实现相对复杂。 1.4 消息可靠性RocketMQ支持消息的高可靠，影响消息可靠性的几种情况： 1) Broker正常关闭 2) Broker异常Crash 3) OS Crash 4) 机器掉电，但是能立即恢复供电情况 5) 机器无法开机（可能是cpu、主板、内存等关键设备损坏） 6) 磁盘设备损坏 1)、2)、3)、4) 四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。 5)、6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。注：RocketMQ从3.0版本开始支持同步双写。 1.5. 至少一次至少一次(At least Once)指每个消息必须投递一次。Consumer先Pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，所以RocketMQ可以很好的支持此特性。 1.6 回溯消费回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ支持按照时间回溯消费，时间维度精确到毫秒。 1.7 事务消息RocketMQ事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致。 1.8 定时消息定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。注意，messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级即可：msg.setDelayLevel(level)。level有以下三种情况： level == 0，消息为非延迟消息 1&lt;=level&lt;=maxLevel，消息延迟特定时间，例如level==1，延迟1s level &gt; maxLevel，则level== maxLevel，例如level==20，延迟2h 定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。 需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都会变高。 1.9 消息重试Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。Consumer消费消息失败通常可以认为有以下几种情况： 由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其它消息，而这条失败的消息即使立刻重试消费，99%也不成功，所以最好提供一种定时重试机制，即过10秒后再重试。 由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用sleep 30s，再消费下一条消息，这样可以减轻Broker重试消息的压力。 RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的），用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULE_TOPIC_XXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中。 1.10 消息重投生产者在发送消息时，同步消息失败会重投，异步消息有重试，oneway没有任何保证。消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是无法避免的问题。消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会是大概率事件。另外，生产者主动重发、consumer负载变化也会导致重复消息。如下方法可以设置消息重试策略： retryTimesWhenSendFailed:同步发送失败重投次数，默认为2，因此生产者会最多尝试发送retryTimesWhenSendFailed + 1次。不会选择上次失败的broker，尝试向其他broker发送，最大程度保证消息不丢。超过重投次数，抛出异常，由客户端保证消息不丢。当出现RemotingException、MQClientException和部分MQBrokerException时会重投。 retryTimesWhenSendAsyncFailed:异步发送失败重试次数，异步重试不会选择其他broker，仅在同一个broker上做重试，不保证消息不丢。 retryAnotherBrokerWhenNotStoreOK:消息刷盘（主或备）超时或slave不可用（返回状态非SEND_OK），是否尝试发送到其他broker，默认false。十分重要消息可以开启。 1.11 流量控制生产者流控，因为broker处理能力达到瓶颈；消费者流控，因为消费能力达到瓶颈。 生产者流控： commitLog文件被锁时间超过osPageCacheBusyTimeOutMills时，参数默认为1000ms，返回流控。 如果开启transientStorePoolEnable == true，且broker为异步刷盘的主机，且transientStorePool中资源不足，拒绝当前send请求，返回流控。 broker每隔10ms检查send请求队列头部请求的等待时间，如果超过waitTimeMillsInSendQueue，默认200ms，拒绝当前send请求，返回流控。 broker通过拒绝send 请求方式实现流量控制。 注意，生产者流控，不会尝试消息重投。 消费者流控： 消费者本地缓存消息数超过pullThresholdForQueue时，默认1000。 消费者本地缓存消息大小超过pullThresholdSizeForQueue时，默认100MB。 消费者本地缓存消息跨度超过consumeConcurrentlyMaxSpan时，默认2000。 消费者流控的结果是降低拉取频率。 1.12 死信队列死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。 RocketMQ将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。在RocketMQ中，可以通过使用console控制台对死信队列中的消息进行重发来使得消费者实例再次进行消费。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"传统项目开发部署的流程是怎样的？","slug":"01-docker-lession-index","date":"2019-09-07T12:29:40.000Z","updated":"2022-09-19T12:33:11.827Z","comments":true,"path":"docker/01-docker-lession-index/","link":"","permalink":"https://www.cicoding.cn/docker/01-docker-lession-index/","excerpt":"","text":"题外话 我个人的文档风格，不会一上来就讲什么专业名词、贴原理图、贴架构图、贴代码啥的。。。感觉这样会给人一种很大的入门门槛，会让很多人一开始就失去了学习的兴趣和信心（我不喜欢那样的“装逼”风格，虽然看似很牛B的样子，其实对于新手入门的朋友而言，是没有任何参考价值的）。 考虑到一些对于某一技术不太懂、或者刚刚接触的朋友，所以尽量会写的通俗易懂。 前言 学习docker技术之前呢，我们通过引入一个大家都经历过的开发场景，由此作为切入点，学习起来思路会很清晰明白。 传统项目开发部署的基本流程 这里只简单描述一下，项目发布的基本流程 本地开发+测试，没有问题的话，编译打包发布到测试环境 在测试环境中进行测试，测试完成后，发布到生产环境 在生产环境中进行最后的测试，如果没有问题，那么一切就OK了 存在什么问题？我想100%的人都亲身经历过这样的事情 —— 在自己本地测试都没有问题，发布到测试环境、生产环境后，就出现问题了！搞得自己非常苦恼！非常纠结！到底是哪里出了问题呢？明明代码什么的都一样啊~ 好吧，这里我就不仔细分析具体的原因是什么了，因为可能会有N种原因。 这里就列举一个比较常见的原因，就是： 本地开发环境与测试环境、生产环境上的软件环境配置，可能出现不一致的情况，导致有些时候相同的代码在不同的环境下运行会出现问题。 存在问题：不同机器上的软件环境不一致。（比较核心的问题） 再列举几个实际开发中遇到的情况： 公司在阿里云买了一台新服务器，要想能正常发布项目等，前提是需要在服务器上重新安装一些软件环境（比如jdk、tomcat等），在安装软件环境的过程中，很大几率会出现配置错误的情况；一些比较复杂的环境配置步骤会很多，很多人都记不清具体的步骤和命令，还得上网搜索…… 存在问题：软件环境的配置繁多、命令记不清楚。 像jdk、tomcat等基础的环境搭建，都已经很熟练了，每次有新机器的时候，都要重新搭建，这样就造成了重复性工作、效率低下、配置繁琐麻烦、易出错等情况。 存在问题：重复性搭建软件环境、效率低下。 当然也会有其他的问题，这里就不多做说明了。 比较好的做法是什么样的？ 举个例子： 比如你到了一家新公司工作，一般都会让你在电脑上安装开发环境（比如JDK等），这时候一个技术人员递给了你一个U盘，里面有很多安装文件以及资源，你直接插在自己电脑上，copy需要的软件安装就行了，无需重新下载软件。 上面的场景，比较好的一点是：不用在网上重新下载对应的软件，直接使用U盘里面已经有的软件进行安装就行了。而且，U盘中的软件可以进行版本更新以及提供给他人直接使用。多么方便。 所以，针对上面提到的开发过程中遇到的开发环境等问题，如果能做到只搭建一次环境，多次复用的话，就nice了！就不会出现环境不一致的问题，也不用重复搭建软件环境了。 有什么技术方案能解决这样的痛点吗？ 技术方案因此，Docker出现了！","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/tags/Docker/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"https://www.cicoding.cn/categories/Docker/"}]},{"title":"RocketMQ--组件","slug":"rocketmq-component","date":"2019-09-02T13:15:43.000Z","updated":"2022-06-13T14:15:35.203Z","comments":false,"path":"rocketmq/rocketmq-component/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-component/","excerpt":"","text":"RocketMQ服务端的组件有三个，NameServer，Broker，FilterServer（可选，部署于和Broker同一台机器） 下面分别介绍三个组件： Name ServerName Server是RocketMQ的寻址服务。用于把Broker的路由信息做聚合。用户端依靠Name Server决定去获取对应topic的路由信息，从而决定对哪些Broker做连接。 Name Server是一个几乎无状态的结点，Name Server之间采取share-nothing的设计，互不通信。 对于一个Name Server集群列表，客户端连接Name Server的时候，只会选择随机连接一个结点，以做到负载均衡。 Name Server所有状态都从Broker上报而来，本身不存储任何状态，所有数据均在内存。 如果中途所有Name Server全都挂了，影响到路由信息的更新，不会影响和Broker的通信。 BrokerBroker是处理消息存储，转发等处理的服务器。 Broker以group分开，每个group只允许一个master，若干个slave。 只有master才能进行写入操作，slave不允许。 slave从master中同步数据。同步策略取决于master的配置，可以采用同步双写，异步复制两种。 客户端消费可以从master和slave消费。在默认情况下，消费者都从master消费，在master挂后，客户端由于从Name Server中感知到Broker挂机，就会从slave消费。 Broker向所有的NameServer结点建立长连接，注册Topic信息。 Filter Server（可选）RocketMQ可以允许消费者上传一个Java类给Filter Server进行过滤。 Filter Server只能起在Broker所在的机器 可以有若干个Filter Server进程 拉取消息的时候，消息先经过Filter Server，Filter Server靠上传的Java类过滤消息后才推给Consumer消费。 客户端完全可以消费消息的时候做过滤，不需要Filter Server FilterServer存在的目的是用Broker的CPU资源换取网卡资源。因为Broker的瓶颈往往在网卡，而且CPU资源很闲。在客户端过滤会导致无需使用的消息在占用网卡资源。 使用 Java class上传作为过滤表达式是一个双刃剑——一方面方便了应用的过滤操作且节省网卡资源，另一方面也带来了服务器端的安全风险。这就需要应用来保证过滤代码安全——例如在过滤程序里尽可能不做申请大内存，创建线程等操作。避免 Broker 服务器资源泄漏。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"RocketMQ--概念","slug":"rocketmq-concept","date":"2019-08-31T12:15:43.000Z","updated":"2022-06-13T14:05:17.580Z","comments":false,"path":"rocketmq/rocketmq-concept/","link":"","permalink":"https://www.cicoding.cn/rocketmq/rocketmq-concept/","excerpt":"","text":"1. 基本概念1.1 消息模型（Message Model）RocketMQ主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。ConsumerGroup 由多个Consumer 实例构成。 1.2 消息生产者（Producer）负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要。 1.3 消息消费者（Consumer）负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费。 1.4 主题（Topic）表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。 1.5 代理服务器（Broker Server）消息中转角色，负责存储消息、转发消息。代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备。代理服务器也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等。 1.6 名字服务（Name Server）名称服务充当路由消息的提供者。生产者或消费者能够通过名字服务查找各主题相应的Broker IP列表。多个Namesrv实例组成集群，但相互独立，没有信息交换。 1.7 拉取式消费（Pull Consumer）Consumer消费的一种类型，应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程。 1.8 推动式消费（Push Consumer）Consumer消费的一种类型，该模式下Broker收到数据后会主动推送给消费端，该消费模式一般实时性较高。 1.9 生产者组（Producer Group）同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事物消息且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费。 1.10 消费者组（Consumer Group）同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例必须订阅完全相同的Topic。RocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broadcasting）。 1.11 集群消费（Clustering）集群消费模式下,相同Consumer Group的每个Consumer实例平均分摊消息。 1.12 广播消费（Broadcasting）广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息。 1.13 普通顺序消息（Normal Ordered Message）普通顺序消费模式下，消费者通过同一个消费队列收到的消息是有顺序的，不同消息队列收到的消息则可能是无顺序的。 1.14 严格顺序消息（Strictly Ordered Message）严格顺序消息模式下，消费者收到的所有消息均是有顺序的。 1.15 代理服务器（Broker Server）消息中转角色，负责存储消息、转发消息。代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备。代理服务器也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等。 1.16 消息（Message）消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。 1.17 标签（Tag）为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/tags/RocketMQ/"}],"keywords":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://www.cicoding.cn/categories/RocketMQ/"}]},{"title":"文件目录删除操作类","slug":"file-directory-delete-operation-class","date":"2019-05-27T08:19:22.000Z","updated":"2022-09-17T14:13:56.166Z","comments":true,"path":"other/file-directory-delete-operation-class/","link":"","permalink":"https://www.cicoding.cn/other/file-directory-delete-operation-class/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159package com.cicoding.demo.dir;import java.io.File;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date;/*** 文件目录删除操作类**/public class DeleteDirectory &#123; /** * 删除空目录 * * @param dir * 将要删除的目录路径 */ private static void doDeleteEmptyDir(String dir) &#123; boolean success = (new File(dir)).delete(); if (success) &#123; System.out.println(\"Successfully deleted empty directory: \" + dir); &#125; else &#123; System.out.println(\"Failed to delete empty directory: \" + dir); &#125; &#125; /** * 递归删除目录下的所有文件及子目录下所有文件 * * @param dir * 将要删除的文件目录 * @return boolean Returns \"true\" if all deletions were successful. If a * deletion fails, the method stops attempting to delete and returns * \"false\". */ private static boolean deleteDir(File dir) &#123; if (dir.isDirectory()) &#123; String[] children = dir.list(); // 递归删除目录中的子目录下 for (int i = 0; i &lt; children.length; i++) &#123; boolean success = deleteDir(new File(dir, children[i])); if (!success) &#123; return false; &#125; &#125; &#125; // 目录此时为空，可以删除 return dir.delete(); &#125; public static void traverseFolder2(String path) &#123; File file = new File(path); if (file.exists()) &#123; File[] files = file.listFiles(); if (files.length == 0) &#123; System.out.println(\"文件夹是空的!\"); return; &#125; else &#123; for (File file2 : files) &#123; if (file2.isDirectory()) &#123; System.out.println(\"文件夹:\" + file2.getAbsolutePath()); traverseFolder2(file2.getAbsolutePath()); &#125; else &#123; System.out.println(\"文件:\" + file2.getAbsolutePath()); &#125; &#125; &#125; &#125; else &#123; System.out.println(\"文件不存在!\"); &#125; &#125; public static void getDir(String strPath) &#123; File f = new File(strPath); if (f.isDirectory()) &#123; File[] fList = f.listFiles(); for (File f1 : fList) &#123; System.out.println(f1.getName()); &#125; &#125; &#125; //获取N天前的截止日期 public static Date getNextDay(Date date) &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(date); calendar.add(Calendar.DAY_OF_MONTH, -8); date = calendar.getTime(); return date; &#125; //删除 截止日期之前的文件夹 public static void getNextDay22(String strPath,Date date) &#123; Calendar ca = Calendar.getInstance();// Date curDate;// Date b;// 假设现在你已经实例化了a和b// curDate.after(b)返回一个boolean，如果curDate的时间在b之后（不包括等于）返回true// b.before(curDate)返回一个boolean，如果b的时间在curDate之前（不包括等于）返回true// curDate.equals(b)返回一个boolean,如果a的时间和b相等返回true //获取删除的截止日期 Date curDate = getNextDay(date); File f = new File(strPath); if (f.exists()) &#123; File[] files = f.listFiles(); if (files.length == 0) &#123; System.out.println(\"文件夹是空的!\"); return; &#125; else &#123; for (File file2 : files) &#123; if (file2.isDirectory()) &#123; SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMdd HH:mm:ss\"); try &#123; Date d = sdf.parse(file2.getName() + \" \" + \"00:00:00\"); if(d.before(curDate))&#123; System.out.println(strPath + \"/\" + file2.getName()); deleteDir(new File(strPath + \"/\" + file2.getName())); &#125; &#125; catch (ParseException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; else &#123; System.out.println(\"文件:\" + file2.getAbsolutePath()); &#125; &#125; &#125; &#125; else &#123; System.out.println(\"文件不存在!\"); &#125; &#125; /** * 测试 */ public static void main(String[] args) &#123; // doDeleteEmptyDir(\"new_dir1\");// String newDir2 = \"F:/data/20170525\";// boolean success = deleteDir(new File(newDir2));// if (success) &#123;// System.out.println(\"Successfully deleted populated directory: \" + newDir2);// &#125; else &#123;// System.out.println(\"Failed to delete populated directory: \" + newDir2);// &#125;// // traverseFolder2(\"F:/data\");// getDir(\"F:/data\"); Date d = new Date(); getNextDay22(\"F:/data\", d);// Date nextDay = getNextDay(d);// SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMdd\"); // String dateNowStr = sdf.format(nextDay); // System.out.println(\"格式化后的日期：\" + dateNowStr); &#125;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"File","slug":"File","permalink":"https://www.cicoding.cn/tags/File/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"时间工具类","slug":"time-tools","date":"2019-05-27T00:15:43.000Z","updated":"2022-09-17T14:13:56.169Z","comments":true,"path":"other/time-tools/","link":"","permalink":"https://www.cicoding.cn/other/time-tools/","excerpt":"","text":"工具类一： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313package cn.cicoding.time; import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date; /** * * 功能描述： * * @author Administrator * @Date Jul 19, 2019 * @Time 9:47:53 AM * @version 1.0 */public class DateUtil &#123; public static Date date = null; public static DateFormat dateFormat = null; public static Calendar calendar = null; /** * 功能描述：格式化日期 * * @param dateStr * String 字符型日期 * @param format * String 格式 * @return Date 日期 */ public static Date parseDate(String dateStr, String format) &#123; try &#123; dateFormat = new SimpleDateFormat(format); String dt = dateStr.replaceAll(\"-\", \"/\"); if ((!dt.equals(\"\")) &amp;&amp; (dt.length() &lt; format.length())) &#123; dt += format.substring(dt.length()).replaceAll(\"[YyMmDdHhSs]\", \"0\"); &#125; date = (Date) dateFormat.parse(dt); &#125; catch (Exception e) &#123;&#125; return date; &#125; /** * 功能描述：格式化日期 * * @param dateStr * String 字符型日期：YYYY-MM-DD 格式 * @return Date */ public static Date parseDate(String dateStr) &#123; return parseDate(dateStr, \"yyyy/MM/dd\"); &#125; /** * 功能描述：格式化输出日期 * * @param date * Date 日期 * @param format * String 格式 * @return 返回字符型日期 */ public static String format(Date date, String format) &#123; String result = \"\"; try &#123; if (date != null) &#123; dateFormat = new SimpleDateFormat(format); result = dateFormat.format(date); &#125; &#125; catch (Exception e) &#123;&#125; return result; &#125; /** * 功能描述： * * @param date * Date 日期 * @return */ public static String format(Date date) &#123; return format(date, \"yyyy/MM/dd\"); &#125; /** * 功能描述：返回年份 * * @param date * Date 日期 * @return 返回年份 */ public static int getYear(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.get(Calendar.YEAR); &#125; /** * 功能描述：返回月份 * * @param date * Date 日期 * @return 返回月份 */ public static int getMonth(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.get(Calendar.MONTH) + 1; &#125; /** * 功能描述：返回日份 * * @param date * Date 日期 * @return 返回日份 */ public static int getDay(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.get(Calendar.DAY_OF_MONTH); &#125; /** * 功能描述：返回小时 * * @param date * 日期 * @return 返回小时 */ public static int getHour(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.get(Calendar.HOUR_OF_DAY); &#125; /** * 功能描述：返回分钟 * * @param date * 日期 * @return 返回分钟 */ public static int getMinute(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.get(Calendar.MINUTE); &#125; /** * 返回秒钟 * * @param date * Date 日期 * @return 返回秒钟 */ public static int getSecond(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.get(Calendar.SECOND); &#125; /** * 功能描述：返回毫秒 * * @param date * 日期 * @return 返回毫秒 */ public static long getMillis(Date date) &#123; calendar = Calendar.getInstance(); calendar.setTime(date); return calendar.getTimeInMillis(); &#125; /** * 功能描述：返回字符型日期 * * @param date * 日期 * @return 返回字符型日期 yyyy/MM/dd 格式 */ public static String getDate(Date date) &#123; return format(date, \"yyyy/MM/dd\"); &#125; /** * 功能描述：返回字符型时间 * * @param date * Date 日期 * @return 返回字符型时间 HH:mm:ss 格式 */ public static String getTime(Date date) &#123; return format(date, \"HH:mm:ss\"); &#125; /** * 功能描述：返回字符型日期时间 * * @param date * Date 日期 * @return 返回字符型日期时间 yyyy/MM/dd HH:mm:ss 格式 */ public static String getDateTime(Date date) &#123; return format(date, \"yyyy/MM/dd HH:mm:ss\"); &#125; /** * 功能描述：日期相加 * * @param date * Date 日期 * @param day * int 天数 * @return 返回相加后的日期 */ public static Date addDate(Date date, int day) &#123; calendar = Calendar.getInstance(); long millis = getMillis(date) + ((long) day) * 24 * 3600 * 1000; calendar.setTimeInMillis(millis); return calendar.getTime(); &#125; /** * 功能描述：日期相减 * * @param date * Date 日期 * @param date1 * Date 日期 * @return 返回相减后的日期 */ public static int diffDate(Date date, Date date1) &#123; return (int)((getMillis(date) - getMillis(date1)) / (24 * 3600 * 1000)); &#125; /** * 功能描述：取得指定月份的第一天 * * @param strdate * String 字符型日期 * @return String yyyy-MM-dd 格式 */ public static String getMonthBegin(String strdate) &#123; date = parseDate(strdate); return format(date, \"yyyy-MM\") + \"-01\"; &#125; /** * 功能描述：取得指定月份的最后一天 * * @param strdate * String 字符型日期 * @return String 日期字符串 yyyy-MM-dd格式 */ public static String getMonthEnd(String strdate) &#123; date = parseDate(getMonthBegin(strdate)); calendar = Calendar.getInstance(); calendar.setTime(date); calendar.add(Calendar.MONTH, 1); calendar.add(Calendar.DAY_OF_YEAR, -1); return formatDate(calendar.getTime()); &#125; /** * 功能描述：常用的格式化日期 * * @param date * Date 日期 * @return String 日期字符串 yyyy-MM-dd格式 */ public static String formatDate(Date date) &#123; return formatDateByFormat(date, \"yyyy-MM-dd\"); &#125; /** * 功能描述：以指定的格式来格式化日期 * * @param date * Date 日期 * @param format * String 格式 * @return String 日期字符串 */ public static String formatDateByFormat(Date date, String format) &#123; String result = \"\"; if (date != null) &#123; try &#123; SimpleDateFormat sdf = new SimpleDateFormat(format); result = sdf.format(date); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; return result; &#125; public static void main(String[] args) &#123; Date d = new Date(); // System.out.println(d.toString()); // System.out.println(formatDate(d).toString()); // System.out.println(getMonthBegin(formatDate(d).toString())); // System.out.println(getMonthBegin(\"2008/07/19\")); // System.out.println(getMonthEnd(\"2008/07/19\")); System.out.println(addDate(d, 15).toString()); &#125; &#125; 工具类二： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281package www.cicoding.cn; import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Calendar;import java.util.Date;import java.util.List;import java.util.Locale;import java.util.TimeZone; public class DateUtils &#123; //http响应头Expire属性时间格式 public static final String HTTP_RESPONSE_DATE_HEADER = \"EEE, dd MMM yyyy HH:mm:ss zzz\"; //http响应头Expire属性时间格式工具 public static final SimpleDateFormat responseHeaderFormat = new SimpleDateFormat(HTTP_RESPONSE_DATE_HEADER, Locale.US); static &#123; responseHeaderFormat.setTimeZone(TimeZone.getTimeZone(\"GMT\")); &#125; /** * 某个时间点的下个月的第一天 * @param day * @return */ public static Date firstDayInNextMonth(Date day) &#123; Calendar c = Calendar.getInstance(); c.setTime(day); c.set(Calendar.MONTH, c.get(Calendar.MONTH) + 1); c.set(Calendar.DAY_OF_MONTH, 1); c.set(Calendar.HOUR_OF_DAY, 0); c.set(Calendar.MINUTE, 0); c.set(Calendar.SECOND, 0); return c.getTime(); &#125; /** * 获取某天在星期中的排序值： * 星期日 -&gt; 星期六 对应为：1 -&gt; 7 * @param date * @return */ public static int getDateInWeek(Date date) &#123; Calendar c = Calendar.getInstance(); c.setTime(date); return c.get(Calendar.DAY_OF_WEEK); &#125; /** * 获取指定日期后n天的凌晨 * @param date * @param n * @return */ public static Date getDateNextDay(Date date, int n) &#123; Calendar c = Calendar.getInstance(); c.setTime(date); c.add(Calendar.DATE, n); return c.getTime(); &#125; /** * 获取下n个月后的日期 * @param n 月份偏移量 * @return */ public static Date getDateNextMonth(int n) &#123; Calendar now = Calendar.getInstance(); now.set(Calendar.MONTH, now.get(Calendar.MONTH) + n); // 设置时间向前进n个月 now.set(Calendar.HOUR_OF_DAY, 0); now.set(Calendar.MINUTE, 0); now.set(Calendar.SECOND, 0); return now.getTime(); &#125; /** * 获取今天在本月中的号码 * @return */ public static int getDateOfMoth() &#123; return Calendar.getInstance().get(Calendar.DAY_OF_MONTH); &#125; /** * 本月的所有日期集合 * @return */ public static List &lt; Date &gt; getDatesInMonth() &#123; List &lt; Date &gt; dates = new ArrayList &lt; Date &gt; (); Calendar c = Calendar.getInstance(); // 设置代表的日期为1号 c.set(Calendar.DATE, 1); // 获得当前月的最大日期数 int maxDay = c.getActualMaximum(Calendar.DATE); for (int i = 1; i &lt;= maxDay; i++) &#123; c.set(Calendar.DATE, i); dates.add(c.getTime()); &#125; return dates; &#125; /** * 获取某个时间所在的月份 * @param date * @return */ public static int getMonth(Date date) &#123; Calendar c = Calendar.getInstance(); c.setTime(date); return c.get(Calendar.MONTH) + 1; &#125; /** * 获取本月最后一天 * @return */ public static Date getMonthEnd() &#123; int length = getDateOfMoth(); Calendar c = Calendar.getInstance(); c.set(Calendar.DATE, length); c.set(Calendar.HOUR, 24); c.set(Calendar.MINUTE, 0); c.set(Calendar.SECOND, 0); return c.getTime(); &#125; /** * 获取某个时间所在月份的最后一秒 * @param date * @return */ public static Date getMonthEnd(Date date) &#123; if (date == null) &#123; return null; &#125; Calendar start = Calendar.getInstance(); start.setTime(date); start.set(Calendar.MONTH, start.get(Calendar.MONTH) + 1); start.set(Calendar.DAY_OF_MONTH, 1); start.set(Calendar.HOUR, 0); start.set(Calendar.MINUTE, 0); start.set(Calendar.SECOND, 0); return start.getTime(); &#125; /** * 获取某个时间所在月份的第一天凌晨 * @param date * @return */ public static Date getMonthStart(Date date) &#123; if (date == null) &#123; return null; &#125; Calendar start = Calendar.getInstance(); start.setTime(date); start.set(Calendar.DAY_OF_MONTH, 1); start.set(Calendar.HOUR, 0); start.set(Calendar.MINUTE, 0); start.set(Calendar.SECOND, 0); return start.getTime(); &#125; /** * 获取今天凌晨 * @return */ public static Date getMorning() &#123; return getMorning(new Date()); &#125; /** * 获取指定时间当天的凌晨 * @param date 给定时间当天的凌晨 * @return */ public static Date getMorning(Date date) &#123; Calendar c = Calendar.getInstance(); c.setTime(date); c.set(Calendar.HOUR_OF_DAY, 0); c.set(Calendar.MINUTE, 0); c.set(Calendar.SECOND, 0); return c.getTime(); &#125; /** * 获取当前时间N天后的凌晨 */ public static Date getMorningNextDate(int n) &#123; Calendar now = Calendar.getInstance(); now.set(Calendar.DATE, now.get(Calendar.DATE) + n); //设置时间向前进n天 now.set(Calendar.HOUR_OF_DAY, 0); now.set(Calendar.MINUTE, 0); now.set(Calendar.SECOND, 0); return now.getTime(); &#125; /** * 系统当前时间过N个月后的时间 * @param nextStep 月份偏移量 * @return */ public static Date getNextMonth(int nextStep) &#123; Calendar c = Calendar.getInstance(); int m = c.get(Calendar.MONTH); c.set(Calendar.MONTH, m + nextStep); return c.getTime(); &#125; /** * 计算给定时间推进一个月对应的时间 * @param date 给定时间 * @return 某时间过一个月后所在的时间 */ public static Date getNextMonthToday(Date date) &#123; Calendar c = Calendar.getInstance(); c.setTime(date); c.set(Calendar.MONTH, c.get(Calendar.MONTH) + 1); return c.getTime(); &#125; /** * 获取系统当前时间所在的年份 * @return */ public static int getYear() &#123; return Calendar.getInstance().get(Calendar.YEAR); &#125; /** * 获取给定时间所在的年份 * @param date 时间 * @return 时间所在的年份 */ public static int getYear(Date date) &#123; Calendar c = Calendar.getInstance(); c.setTime(date); return c.get(Calendar.YEAR); &#125; /** * 获取某年分的最后一天结束的时间 * @param year 年份 * @return 指定年份的最后一天结束 */ public static Date getYearEnd(int year) &#123; Calendar c = Calendar.getInstance(); c.set(Calendar.YEAR, year); c.set(Calendar.MONTH, Calendar.DECEMBER); c.set(Calendar.DAY_OF_MONTH, 31); c.set(Calendar.HOUR_OF_DAY, 23); c.set(Calendar.MINUTE, 59); c.set(Calendar.SECOND, 59); return c.getTime(); &#125; /** * 获取某年份的第一天凌晨 * @param year 年份 * @return 指定年份的第一天凌晨 */ public static Date getYearStart(int year) &#123; Calendar c = Calendar.getInstance(); c.set(Calendar.YEAR, year); c.set(Calendar.MONTH, Calendar.JANUARY); c.set(Calendar.DAY_OF_MONTH, 1); c.set(Calendar.HOUR_OF_DAY, 0); c.set(Calendar.MINUTE, 0); c.set(Calendar.SECOND, 0); return c.getTime(); &#125;&#125; 工具类三： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283import static java.util.Calendar.HOUR_OF_DAY;import static java.util.Calendar.MILLISECOND;import static java.util.Calendar.MINUTE;import static java.util.Calendar.SECOND;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Arrays;import java.util.Calendar;import java.util.Date;import java.util.List;public class DateUtil extends org.apache.commons.lang.time.DateUtils &#123; /** * 默认的日期格式化样式 */ public static final String DAY_PATTERN = “yyyy - MM - dd”; /** * 默认的时间格式化样式 */ public static final String TIME_PATTERN = “HH: mm: ss”; /** * 将Date格式化成符合默认格式的字符串 * * @param date * @return 返回样例:2012-03-29 14:32:23 */ public static String format(Date date) &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(DAY_PATTERN + ”” +TIME_PATTERN); return formatTool.format(date); &#125; /** * 将Date格式化成符合默认日期格式的字符串 * * @param date * @return 返回样例:2012-03-29 */ public static String formatDate(Date date) &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(DAY_PATTERN); return formatTool.format(date); &#125; /** * 将Date格式化成符合默认时间格式的字符串 * * @param date * @return 返回样例:14:32:23 */ public static String formatTime(Date date) &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(TIME_PATTERN); return formatTool.format(date); &#125; /** * 按照pattern格式格式化Date * * @param date * @param pattern * 样例: yyyy/MM/dd * @return 返回样例:2012/03/29 */ public static String format(Date date, String pattern) &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(pattern); return formatTool.format(date); &#125; /** * 将符合默认格式的字符串转换成Date * * @param dateValue * 样例:2012-03-29 14:32:23 * @return * @throws ParseException */ public static Date parse(String dateValue) throws ParseException &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(DAY_PATTERN + ”” +TIME_PATTERN); return formatTool.parse(dateValue); &#125; /** * 将符合默认格式的日期字符串转换成Date * * @param dateValue * 样例:2012-03-29 * @return * @throws ParseException */ public static Date parseDate(String dateValue) throws ParseException &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(DAY_PATTERN); return formatTool.parse(dateValue); &#125; /** * 将符合pattern格式的dateValue转换成Date * * @param dateValue * 样例:2012/03/29 * @param pattern * 样例:yyyy/MM/dd * @return * @throws ParseException */ public static Date parse(String dateValue, String pattern) throws ParseException &#123; SimpleDateFormat formatTool = new SimpleDateFormat(); formatTool.applyPattern(pattern); return formatTool.parse(dateValue); &#125; /** * 返回这一天的最早的时候 * * @param date * @return */ public static Date getEarliest(Date date) &#123; return parseTime(date, 0, 0, 0, 0); &#125; /** * 返回这一天的最晚时候 * * @param date * @return */ public static Date getLastest(Date date) &#123; return parseTime(date, 23, 59, 59, 999); &#125; /** * 得到指定月的天数 * * @param year * @param month * @return */ public static int getMonthLastDay(int year, int month) &#123; Calendar a = Calendar.getInstance(); a.set(Calendar.YEAR, year); a.set(Calendar.MONTH, month– 1); a.set(Calendar.DATE, 1); // 把日期设置为当月第一天 a.roll(Calendar.DATE, -1);// 日期回滚一天，也就是最后一天 int maxDate = a.get(Calendar.DATE); return maxDate; &#125; /** * 返回指定时间加上num天后的时间 * * @param date * @param num * @return */ public static Date add(Date date, int num) &#123; Calendar a = Calendar.getInstance(); a.setTime(date); a.add(Calendar.DAY_OF_MONTH, num); return a.getTime(); &#125; /** * 返回false：date=null，date是1970年；其它都返回true * * @param date * @return */ public static boolean isNotEmpty(Date date) &#123; if (date != null) &#123; Calendar a = Calendar.getInstance(); a.setTime(date); return a.get(Calendar.YEAR) != 1970; &#125; return Boolean.FALSE; &#125; /** * 获得date的小时数0-23 * * @param date * @return */ public static int getHours(Date date) &#123; Calendar a = Calendar.getInstance(); a.setTime(date); return a.get(Calendar.HOUR_OF_DAY); &#125; /** * 获得date是一周的第几天，注意：周日 返回 1，周六 返回 7 * * @param date * @return */ public static int getDay(Date date) &#123; Calendar a = Calendar.getInstance(); a.setTime(date); return a.get(Calendar.DAY_OF_WEEK); &#125; /** * 设定date的时间细节 * * @param date * 要设定时间细节的date * @param hourOfDay * 0-23 * @param minute * 0-59 * @param second * 0-59 * @param milliSecond * 0-999 * @return */ public static Date parseTime(Date date, int hourOfDay, int minute, int second, int milliSecond) &#123; Calendar cal = Calendar.getInstance(); cal.setTime(date); setCalendarTime(cal, hourOfDay, minute, second, milliSecond); return cal.getTime(); &#125; /** * 设定date的时间细节 * * @param date * 要设定时间细节的date * @param timeDetail * 以:号分隔的24小时制的时间，例:16:23:42:267 或 16(等同于16:00:00:000) * @return */ public static Date parseTime(Date date, String timeDetail) &#123; List &lt; String &gt; strList = new ArrayList &lt; String &gt; (); strList.addAll(Arrays.asList(timeDetail.split(“: ”))); while (strList.size() &lt; 4) &#123; strList.add(“0″); &#125; return parseTime(date, Integer.parseInt(strList.get(0)), Integer.parseInt(strList.get(1)), Integer.parseInt(strList.get(2)), Integer.parseInt(strList.get(3))); &#125; /** * 指定时间 是否在 当前时间 之后，注：和日期无关 * * @param time * 指定的时间， 传入样例:16:23:42:267 或 16(等同于16:00:00:000) * @return */ public static boolean isAfterTime(String time) &#123; Date date = parseTime(new Date(), time); return date.after(new Date()); &#125; /** * 指定时间 是否在 当前时间 之前，注：和日期无关 * * @param time * 指定的时间， 传入样例:16:23:42:267 或 16(等同于16:00:00:000) * @return */ public static boolean isBeforeTime(String time) &#123; Date date = parseTime(new Date(), time); return date.before(new Date()); &#125; private static void setCalendarTime(Calendar cal, int hourOfDay, int minute, int second, int milliSecond) &#123; cal.set(HOUR_OF_DAY, hourOfDay); cal.set(MINUTE, minute); cal.set(SECOND, second); cal.set(MILLISECOND, milliSecond); &#125;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/tags/工具/"},{"name":"时间工具类","slug":"时间工具类","permalink":"https://www.cicoding.cn/tags/时间工具类/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"Feign设置assessToken","slug":"feign-set-assesstoken","date":"2019-05-26T12:18:50.000Z","updated":"2022-09-17T14:13:56.154Z","comments":true,"path":"micro-service/feign-set-assesstoken/","link":"","permalink":"https://www.cicoding.cn/micro-service/feign-set-assesstoken/","excerpt":"","text":"首先继承接口RequestInterceptor实现apply方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.oauth2.client.OAuth2RestTemplate; import feign.RequestInterceptor;import feign.RequestTemplate; /** * *用于解决fegin无法传递授权信息 * @author cicoding * @date 2018年5月26日 * @Copyright * * &lt;pre&gt; * =================Modify Record================= * Modifier date Content * cicoding 2019年5月26日 新增 * * &lt;/pre&gt; */@Configurationpublic class FeignRequestInterceptor implements RequestInterceptor &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); private static final String AUTHORIZATION_HEADER = \"Authorization\"; private static final String BEARER_TOKEN_TYPE = \"Bearer\"; @Autowired private OAuth2RestTemplate oAuth2RestTemplate; @Override public void apply(RequestTemplate requestTemplate) &#123; String accessToken = WebContextUtil.getAccessToken(); if(accessToken == null)&#123; accessToken =oAuth2RestTemplate.getAccessToken().getValue(); &#125; logger.debug(\"RequestInterceptorConfig accessToken :\" +accessToken); requestTemplate.header(AUTHORIZATION_HEADER, String.format(\"%s %s\", BEARER_TOKEN_TYPE, accessToken)); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.oauth2.client.DefaultOAuth2RequestAuthenticator;import org.springframework.security.oauth2.client.OAuth2RestTemplate;import org.springframework.security.oauth2.client.token.grant.client.ClientCredentialsResourceDetails; /** * *用于解决fegin无法传递授权信息 * @author cicoding * @date 2018年5月26日 * @Copyright * * &lt;pre&gt; * =================Modify Record================= * Modifier date Content * cicoding 2019年5月26日 新增 * * &lt;/pre&gt; */@Configurationpublic class OAuth2RestTemplateConfiguration &#123; @Bean public OAuth2RestTemplate oauth2RestTemplate() &#123; ClientCredentialsResourceDetails resourceDetails = new ClientCredentialsResourceDetails(); resourceDetails.setClientId(\"webapp\"); resourceDetails.setClientSecret(\"webapp\"); resourceDetails.setId(\"service-user\"); resourceDetails.setAccessTokenUri(\"http://127.0.0.1:9060/oauth/token\"); OAuth2RestTemplate oAuth2RestTemplate = new OAuth2RestTemplate(resourceDetails); oAuth2RestTemplate.setAuthenticator(new DefaultOAuth2RequestAuthenticator()); return oAuth2RestTemplate; &#125;&#125; FeignRequestInterceptor 和OAuth2RestTemplateConfiguration 类！","categories":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/categories/Feign/"}],"tags":[{"name":"assessToken","slug":"assessToken","permalink":"https://www.cicoding.cn/tags/assessToken/"},{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/tags/Feign/"}],"keywords":[{"name":"Feign","slug":"Feign","permalink":"https://www.cicoding.cn/categories/Feign/"}]},{"title":"升级MySQL8问题总结","slug":"mysql-8-problems","date":"2019-05-06T09:11:14.000Z","updated":"2022-09-17T14:13:56.143Z","comments":true,"path":"database/mysql-8-problems/","link":"","permalink":"https://www.cicoding.cn/database/mysql-8-problems/","excerpt":"","text":"mysql 8驱动变更Loading class com.mysql.jdbc.Driver&#39;. This is deprecated. The new driver class iscom.mysql.cj.jdbc.Driver’. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 解决办法： com.mysql.jdbc.Driver 修改为 com.mysql.cj.jdbc.Driver MySQL 8.0 Public Key Retrieval is not allowed 错误的解决方法在使用 MySQL 8.0 时重启应用后提示 com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Public Key Retrieval is not allowed 最简单的解决方法是在连接后面添加 allowPublicKeyRetrieval=true 文档中(https://mysql-net.github.io/MySqlConnector/connection-options/)给出的解释是： 如果用户使用了 sha256_password 认证，密码在传输过程中必须使用 TLS 协议保护，但是如果 RSA 公钥不可用，可以使用服务器提供的公钥；可以在连接中通过 ServerRSAPublicKeyFile 指定服务器的 RSA 公钥，或者AllowPublicKeyRetrieval=True参数以允许客户端从服务器获取公钥；但是需要注意的是 AllowPublicKeyRetrieval=True可能会导致恶意的代理通过中间人攻击(MITM)获取到明文密码，所以默认是关闭的，必须显式开启","categories":[{"name":"数据库","slug":"数据库","permalink":"https://www.cicoding.cn/categories/数据库/"}],"tags":[{"name":"MySQL8","slug":"MySQL8","permalink":"https://www.cicoding.cn/tags/MySQL8/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://www.cicoding.cn/categories/数据库/"}]},{"title":"SpringCloud-----Ribbon异常java.net.UnknownHostException","slug":"SpringCloud01","date":"2019-04-28T02:23:35.000Z","updated":"2022-09-17T14:13:56.153Z","comments":false,"path":"micro-service/SpringCloud01/","link":"","permalink":"https://www.cicoding.cn/micro-service/SpringCloud01/","excerpt":"","text":"如何解决Feign/Ribbon第一次请求失败的问题？** Spring Cloud中，Feign和Ribbon在整合了Hystrix后，可能会出现首次调用失败的问题，要如何解决该问题呢？ 造成该问题的原因 Hystrix默认的超时时间是1秒，如果超过这个时间尚未响应，将会进入fallback代码。而首次请求往往会比较慢（由于Ribbon是懒加载的，在首次请求时，才会开始初始化相关类），这个响应时间可能就大于1秒了。知道原因后，我们来总结一下解决方案。以feign为例，解决方案有如下四种。 方法一、将Hystrix超时设长 1hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 5000 该配置是让Hystrix的超时时间改为5秒，这是最容易想到的办法，不过有点治标不治本。 方法二、禁用Hystrix超时 1hystrix.command.default.execution.timeout.enabled: false 该配置，用于禁用Hystrix的超时时间，一般不建议使用。 方法三、为Feign禁用Hystrix 全局禁用 1feign.hystrix.enabled: false 索性禁用feign的hystrix，该做法比较极端，除非一些特殊场景，不推荐使用。 局部禁用 为名为microservice-provider-user 的Feign Client禁用Hystrix 123456789101112@FeignClient(name = &quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @GetMapping(&quot;/users/&#123;id&#125;&quot;) User findById(@PathVariable(&quot;id&quot;) Long id);&#125;class FooConfiguration &#123; @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder()&#123; return Feign.builder(); &#125;&#125; 方法四、Ribbon配置饥饿加载（最佳） 从Dalston开始，Ribbon支持配置eager load实现在启动时就初始化Ribbon相关类。 1234ribbon: eager-load: enabled: true clients: client1, client2, client3 Dalson之前版本可以通过一些Hack的机制实现eager load，不过成本略高，不建议","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"微服务简介","slug":"microservice01","date":"2019-04-26T13:23:35.000Z","updated":"2022-09-17T14:13:56.156Z","comments":true,"path":"micro-service/microservice01/","link":"","permalink":"https://www.cicoding.cn/micro-service/microservice01/","excerpt":"","text":"什么是微服务架构近年来，在软件开发领域关于微服务的讨论呈现出火爆的局面，有人倾向于在系统设计与开发中采用微服务方式实现软件系统的松耦合、跨部门开发，被认为是IT软件架构的未来方向，Martin Fowler也给微服务架构极高的评价；同时，反对之声也很强烈，持反对观点的人表示微服务增加了系统维护、部署的难度，导致一些功能模块或代码无法复用，同时微服务允许使用不同的语言和框架来开发各个系统模块，这又会增加系统集成与测试的难度，而且随着系统规模的日渐增长，微服务在一定程度上也会导致系统变得越来越复杂。尽管一些公司已经在生产系统中采用了微服务架构，并且取得了良好的效果；但更多公司还是处在观望的态度。 什么是微服务架构呢？简单说就是将一个完整的应用（单体应用）按照一定的拆分规则（后文讲述）拆分成多个不同的服务，每个服务都能独立地进行开发、部署、扩展。服务于服务之间通过注入RESTful api或其他方式调用。大家可以搜索到很多相关介绍和文章。本文暂不细表。在此推荐两个比较好的博客： http://microservices.io/ http://martinfowler.com/articles/microservices.html Spring Cloud是一个综合项目，它包含很多的子项目。由于子项目也维护着自己的版本号，Spring Cloud采用了这种版本命名方式，从而避免与子项目的版本混淆。其中，英文单词叫做“release train”，Angel、Brixton、Camden等都是伦敦地铁站的名称，它们按照字母顺序发行，我们可将其理解为主版本的演进。SR表示“Service Release”，一般表示Bug修复；在SR版本发布之前，会先发布一个Release版本，例如Camden RELEASE。 经过以上讲解，相信大家就能很好地理解Spring Cloud的版本了。例如，Camden SR3表示Camden版本的第3次Bug修复版本。 PS: Spring Cloud版本发布记录可详见：https://github.com/spring-cloud/spring-cloud-release/releases ，从中我们可清晰看到Spring Cloud版本发布的时间及先后顺序。 Spring Cloud版本演进计划：https://github.com/spring-cloud/spring-cloud-release/milestones，从中我们可了解Spring Cloud的版本演进计划，例如计划什么时间点发布什么版本等。 事实上，Spring有不少项目使用类似的命名方式。例如Spring Data、Spring Cloud Stream等。 子项目一览理解Spring Cloud的版本后，我们来看一下各版本Spring Cloud包含的子项目及版本。不同的Spring Cloud版本有不同的子项目： Component Edgware.SR5 Finchley.SR2 Finchley.BUILD-SNAPSHOT spring-cloud-aws 1.2.3.RELEASE 2.0.1.RELEASE 2.0.1.BUILD-SNAPSHOT spring-cloud-bus 1.3.3.RELEASE 2.0.0.RELEASE 2.0.1.BUILD-SNAPSHOT spring-cloud-cli 1.4.1.RELEASE 2.0.0.RELEASE 2.0.1.BUILD-SNAPSHOT spring-cloud-commons 1.3.5.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-contract 1.2.6.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-config 1.4.5.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-netflix 1.4.6.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-security 1.2.3.RELEASE 2.0.1.RELEASE 2.0.1.BUILD-SNAPSHOT spring-cloud-cloudfoundry 1.1.2.RELEASE 2.0.1.RELEASE 2.0.1.BUILD-SNAPSHOT spring-cloud-consul 1.3.5.RELEASE 2.0.1.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-sleuth 1.3.5.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-stream Ditmars.SR4 Elmhurst.SR1 Elmhurst.BUILD-SNAPSHOT spring-cloud-zookeeper 1.2.2.RELEASE 2.0.0.RELEASE 2.0.1.BUILD-SNAPSHOT spring-boot 1.5.16.RELEASE 2.0.6.RELEASE 2.0.7.BUILD-SNAPSHOT spring-cloud-task 1.2.3.RELEASE 2.0.0.RELEASE 2.0.1.BUILD-SNAPSHOT spring-cloud-vault 1.1.2.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-gateway 1.0.2.RELEASE 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-openfeign 2.0.2.RELEASE 2.0.2.BUILD-SNAPSHOT spring-cloud-function 1.0.1.RELEASE 1.0.0.RELEASE 1.0.1.BUILD-SNAPSHOT spring cloud子项目包括： Spring Cloud Config：配置管理开发工具包，可以让你把配置放到远程服务器，目前支持本地存储、Git以及Subversion。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring Cloud Netflix：针对多种Netflix组件提供的开发工具包，其中包括Eureka、Hystrix、Zuul、Archaius等。 Netflix Eureka：云端负载均衡，一个基于 REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移。 Netflix Hystrix：容错管理工具，旨在通过控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。 Netflix Zuul：边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务。 Netflix Archaius：配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。 Spring Cloud for Cloud Foundry：通过Oauth2协议绑定服务到CloudFoundry，CloudFoundry是VMware推出的开源PaaS云平台。 Spring Cloud Sleuth：日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 Spring Cloud Data Flow：大数据操作工具，通过命令行方式操作数据流。 Spring Cloud Security：安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 Spring Cloud Consul：封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Zookeeper：操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 Spring Cloud Stream：数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud CLI：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件 Spring-Cloud-task: 任务处理框架 更多：https://spring.io/projects/spring-cloud Spring Cloud/Spring Boot兼容性【重要】 Spring Cloud版本 Spring Boot版本 Spring Cloud Alibaba Greenwich 2.1.x 0.9.x Finchley 2.0.x 0.2.x Edgware 1.5.x 0.1.x Dalston 1.5.x 0.1.x 可前往https://spring.io/projects/spring-cloud#overview查看版本兼容性。 https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E SpringCloud入门概述 Spring的三大模块：SpringBoot（构建），Spring Cloud（协调），Spring Cloud Data Flow（连接） SpringCloud是什么 分布式系统的简化版（官方介绍） SpringCloud基于SpringBoot提供了一整套微服务的解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于Netflix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件 SpringCloud利用SpringBoot的开发便利性巧妙地简化了分布式系统的基础设施开发，SpringCloud为开发人员提供了快速构建分布式系统的一些工具，包括配置管理、服务发现、断路器、路由、微代理、事件总线，全局所、决策精选、分布式会话等等，他们都可以用SpringBoot的开发风格做到一键启动和部署。 一句话概括：SpringCloud是分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的几何体，俗称微服务全家桶 SpringCloud和SpringBoot的关系SpringBoot：专注于快速方便的开发单个个体微服务（关注微观） SpringCloud：关注全局的微服务协调治理框架，将SpringBoot开发的一个个单体微服务组合并管理起来（关注宏观） SpringBoot可以离开SpringCloud独立使用，但是SpringCloud不可以离开SpringBoot，属于依赖关系 SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。 解决的问题域不一样：Dubbo的定位是一款RPC框架，Spring Cloud的目标是微服务架构下的一站式解决方案 微服务的优缺点优点 每个服务足够内聚，足够小，比较容易聚焦一个指定的业务需求或者业务功能 开发简单且效率高，一个服务只做一件事情 开发团队小，一般2-5人足以（当然按实际为准） 微服务是松耦合的，无论开发还是部署都可以独立完成 微服务能用不同的语言开发 易于和第三方集成，微服务允许容易且灵活的自动集成部署（持续集成工具有Jenkins,Hudson,bamboo等） 微服务易于被开发人员理解，修改和维护，这样可以使小团队更加关注自己的工作成果，而无需一定要通过合作才能体现价值 微服务允许你融合最新的技术 微服务只是业务逻辑的代码，不会和HTML,CSS或其他界面组件融合。 每个微服务都可以有自己的存储能力，数据库可自有也可以统一，十分灵活。 缺点 开发人员要处理分布式系统的复杂性 多服务运维难度，随着服务的增加，运维的压力也会增大 依赖系统部署 服务间通讯的成本 数据的一致性 系统集成测试 性能监控的难度","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://www.cicoding.cn/tags/Spring-Cloud/"}],"keywords":[{"name":"微服务","slug":"微服务","permalink":"https://www.cicoding.cn/categories/微服务/"}]},{"title":"执行ajax成功后进行页面的刷新","slug":"ajax-f5","date":"2019-04-20T14:25:27.000Z","updated":"2022-09-17T14:13:56.188Z","comments":false,"path":"web/ajax-f5/","link":"","permalink":"https://www.cicoding.cn/web/ajax-f5/","excerpt":"","text":"location.reload(true); window.location.reload(); &lt;script src=&quot;/include/static/js/jquery.min.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; $(&quot;#train&quot;).on(&quot;click&quot;,function(){ var id = $(&quot;#id_res&quot;).val(); var is_ok = $(&quot;#is_ok&quot;).val(); var type = &apos;caiji_train&apos;; //异步获取信息 var url = &apos;__URL__/caiji_train&apos;; var data = {type:type,is_ok:is_ok,id:id}; $.ajax({ url:url, data:data, dataType:&apos;json&apos;, type:&quot;POST&quot;, success:function(data){ if(data.code==1){ alert(data.msg); $(&apos;#train&apos;).text(&apos;已审核&apos;); location.reload(true); } if(data.code==0){ alert(data.msg); $(&apos;#train&apos;).text(&apos;未审核&apos;); } } }) }) &lt;/script&gt;","categories":[{"name":"Ajax","slug":"Ajax","permalink":"https://www.cicoding.cn/categories/Ajax/"}],"tags":[{"name":"Ajax","slug":"Ajax","permalink":"https://www.cicoding.cn/tags/Ajax/"}],"keywords":[{"name":"Ajax","slug":"Ajax","permalink":"https://www.cicoding.cn/categories/Ajax/"}]},{"title":"阿里面试题：为什么Map桶中个数超过8才转为红黑树","slug":"ali-interview-questions001","date":"2019-03-31T12:47:50.000Z","updated":"2022-09-19T10:20:45.721Z","comments":true,"path":"other/ali-interview-questions001/","link":"","permalink":"https://www.cicoding.cn/other/ali-interview-questions001/","excerpt":"","text":"这是笔者一个好友面试阿里时，被问及的一个问题，应该不少人看到这个问题都会一面懵逼。因为，大部分的文章都是分析链表是怎么转换成红黑树的，但是并没有说明为什么当链表长度为8的时候才做转换动作。笔者第一反应也是一样，只能初略的猜测是因为时间和空间的权衡。要弄明白这个问题，我们首先要明白为什么要转换，这个问题比较简单，因为Map中桶的元素初始化是链表保存的，其查找性能是O(n)，而树结构能将查找性能提升到O(log(n))。当链表长度很小的时候，即使遍历，速度也非常快，但是当链表长度不断变长，肯定会对查询性能有一定的影响，所以才需要转成树。至于为什么阈值是8，我想，去源码中找寻答案应该是最可靠的途径。 8这个阈值定义在HashMap中，如下所示，这段注释只说明了8是bin（bin就是bucket，即HashMap中hashCode值一样的元素保存的地方）从链表转成树的阈值，但是并没有说明为什么是8： 12345678/** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon shrinkage. */static final int TREEIFY_THRESHOLD = 8; 我们继续往下看，在HashMap中有一段Implementation notes，笔者摘录了几段重要的描述，第一段如下所示，大概含义是当bin变得很大的时候，就会被转换成TreeNodes中的bin，其结构和TreeMap相似，也就是红黑树： 123This map usually acts as a binned (bucketed) hash table, butwhen bins get too large, they are transformed into bins of TreeNodes,each structured similarly to those in java.util.TreeMap 继续往下看，TreeNodes占用空间是普通Nodes的两倍，所以只有当bin包含足够多的节点时才会转成TreeNodes，而是否足够多就是由TREEIFY_THRESHOLD的值决定的。当bin中节点数变少时，又会转成普通的bin。并且我们查看源码的时候发现，链表长度达到8就转成红黑树，当长度降到6就转成普通bin。 这样就解析了为什么不是一开始就将其转换为TreeNodes，而是需要一定节点数才转为TreeNodes，说白了就是trade-off，空间和时间的权衡： 1234567891011121314151617181920212223Because TreeNodes are about twice the size of regular nodes, weuse them only when bins contain enough nodes to warrant use(see TREEIFY_THRESHOLD). And when they become too small (due toremoval or resizing) they are converted back to plain bins. Inusages with well-distributed user hashCodes, tree bins arerarely used. Ideally, under random hashCodes, the frequency ofnodes in bins follows a Poisson distribution(http://en.wikipedia.org/wiki/Poisson_distribution) with aparameter of about 0.5 on average for the default resizingthreshold of 0.75, although with a large variance because ofresizing granularity. Ignoring variance, the expectedoccurrences of list size k are (exp(-0.5)*pow(0.5, k)/factorial(k)). The first values are:0: 0.606530661: 0.303265332: 0.075816333: 0.012636064: 0.001579525: 0.000157956: 0.000013167: 0.000000948: 0.00000006more: less than 1 in ten million 这段内容还说到：当hashCode离散性很好的时候，树型bin用到的概率非常小，因为数据均匀分布在每个bin中，几乎不会有bin中链表长度会达到阈值。但是在随机hashCode下，离散性可能会变差，然而JDK又不能阻止用户实现这种不好的hash算法，因此就可能导致不均匀的数据分布。不过理想情况下随机hashCode算法下所有bin中节点的分布频率会遵循泊松分布，我们可以看到，一个bin中链表长度达到8个元素的概率为0.00000006，几乎是不可能事件。所以，之所以选择8，不是拍拍屁股决定的，而是根据概率统计决定的。由此可见，发展30年的Java每一项改动和优化都是非常严谨和科学的。 画外音 笔者通过搜索引擎搜索这个问题，发现很多下面这个答案（猜测也是相互转发）： 红黑树的平均查找长度是log(n)，如果长度为8，平均查找长度为log(8)=3，链表的平均查找长度为n/2，当长度为8时，平均查找长度为8/2=4，这才有转换成树的必要；链表长度如果是小于等于6，6/2=3，而log(6)=2.6，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。 笔者认为这个答案不够严谨：3相比4有转换的必要，而2.6相比3就没有转换的必要？起码我不敢苟同这个观点。","categories":[{"name":"面试","slug":"面试","permalink":"https://www.cicoding.cn/categories/面试/"}],"tags":[{"name":"Map","slug":"Map","permalink":"https://www.cicoding.cn/tags/Map/"},{"name":"红黑树","slug":"红黑树","permalink":"https://www.cicoding.cn/tags/红黑树/"}],"keywords":[{"name":"面试","slug":"面试","permalink":"https://www.cicoding.cn/categories/面试/"}]},{"title":"Druid连接池加密","slug":"druid-connection-pool-encryption","date":"2019-02-10T13:23:31.000Z","updated":"2022-09-17T14:13:56.143Z","comments":true,"path":"database/druid-connection-pool-encryption/","link":"","permalink":"https://www.cicoding.cn/database/druid-connection-pool-encryption/","excerpt":"","text":"一、什么是druidDruid是阿里的一个开源项目，首先是一个数据库连接池，类似于c3p0，但它不仅仅是一个数据库连接池，它还包含一个ProxyDriver，一系列内置的JDBC组件库，一个SQL Parser。 二、密码加密首先看druid的数据库连接池配置： 1234567891011121314151617181920212223&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;!-- 基本属性driverClassName、 url、user、password --&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;!-- 通常来说，只需要修改initialSize、minIdle、maxActive --&gt; &lt;property name=\"initialSize\" value=\"2\" /&gt; &lt;property name=\"minIdle\" value=\"2\" /&gt; &lt;property name=\"maxActive\" value=\"30\" /&gt; &lt;property name=\"testWhileIdle\" value=\"false\" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=\"maxWait\" value=\"5000\" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=\"minEvictableIdleTimeMillis\" value=\"30000\" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=\"timeBetweenEvictionRunsMillis\" value=\"60000\" /&gt; &lt;!-- 解密密码必须要配置的项 --&gt; &lt;property name=\"filters\" value=\"config\" /&gt; &lt;property name=\"connectionProperties\" value=\"config.decrypt=true\" /&gt;&lt;/bean&gt; 如果jdbc.properties中的密码要想加密则最后两个property是解密密码必须要配置的项，例如jdbc.password属性为123456。加密后则是： 1Biyu5YzU+6sxDRbmWEa3B2uUcImzDo0BuXjTlL505+/pTb+/0Oqd3ou1R6J8+9Fy3CYrM18nBDqf6wAaPgUGOg== 这样一串数字是无法破解的，是安全的。那么如何得到可供druid解析的加密密码呢。 首先要找到druid.jar所在位置：D:\\Java\\m2\\repository\\com\\alibaba\\druid\\0.2.23 shift右键进入命令窗口： 输入： 1java -cp druid-0.2.23.jar com.alibaba.druid.filter.config.ConfigTools 123456 （最后是要加密的密码） 得到： 那么在jdbc.properties中的jdbc.password可以写上面得到的值。","categories":[{"name":"Druid","slug":"Druid","permalink":"https://www.cicoding.cn/categories/Druid/"}],"tags":[{"name":"Druid","slug":"Druid","permalink":"https://www.cicoding.cn/tags/Druid/"},{"name":"加密","slug":"加密","permalink":"https://www.cicoding.cn/tags/加密/"}],"keywords":[{"name":"Druid","slug":"Druid","permalink":"https://www.cicoding.cn/categories/Druid/"}]},{"title":"为什么我们做分布式使用 Redis ?","slug":"Why-do-we-do-distributed-use-Redis","date":"2019-01-20T12:41:13.000Z","updated":"2022-09-17T14:13:56.166Z","comments":true,"path":"other/Why-do-we-do-distributed-use-Redis/","link":"","permalink":"https://www.cicoding.cn/other/Why-do-we-do-distributed-use-Redis/","excerpt":"","text":"摘要: 原创出处 https://my.oschina.net/u/3971241/blog/2221560 「Ala6」欢迎转载，保留摘要，谢谢！ 绝大部分写业务的程序员，在实际开发中使用 Redis 的时候，只会 Set Value 和 Get Value 两个操作，对 Redis 整体缺乏一个认知。这里对 Redis 常见问题做一个总结，解决大家的知识盲点。 1、为什么使用 Redis在项目中使用 Redis，主要考虑两个角度：性能和并发。如果只是为了分布式锁这些其他功能，还有其他中间件 Zookpeer 等代替，并非一定要使用 Redis。 性能：如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 特别是在秒杀系统，在同一时间，几乎所有人都在点，都在下单。。。执行的是同一操作———向数据库查数据。 根据交互效果的不同，响应时间没有固定标准。在理想状态下，我们的页面跳转需要在瞬间解决，对于页内操作则需要在刹那间解决。 并发：如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用 Redis 做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。 2、使用 Redis 的常见问题缓存和数据库双写一致性问题缓存雪崩问题缓存击穿问题缓存的并发竞争问题 3、单线程的 Redis 为什么这么快这个问题是对 Redis 内部机制的一个考察。很多人都不知道 Redis 是单线程工作模型。 原因主要是以下三点： 纯内存操作单线程操作，避免了频繁的上下文切换采用了非阻塞 I/O 多路复用机制仔细说一说 I/O 多路复用机制，打一个比方：小名在 A 城开了一家快餐店店，负责同城快餐服务。小明因为资金限制，雇佣了一批配送员，然后小曲发现资金不够了，只够买一辆车送快递。 经营方式一客户每下一份订单，小明就让一个配送员盯着，然后让人开车去送。慢慢的小曲就发现了这种经营方式存在下述问题： 时间都花在了抢车上了，大部分配送员都处在闲置状态，抢到车才能去送。随着下单的增多，配送员也越来越多，小明发现快递店里越来越挤，没办法雇佣新的配送员了。配送员之间的协调很花时间。综合上述缺点，小明痛定思痛，提出了经营方式二。 经营方式二小明只雇佣一个配送员。当客户下单，小明按送达地点标注好，依次放在一个地方。最后，让配送员依次开着车去送，送好了就回来拿下一个。上述两种经营方式对比，很明显第二种效率更高。 在上述比喻中： 每个配送员→每个线程每个订单→每个 Socket(I/O 流)订单的送达地点→Socket 的不同状态客户送餐请求→来自客户端的请求明曲的经营方式→服务端运行的代码一辆车→CPU 的核数于是有了如下结论： 经营方式一就是传统的并发模型，每个 I/O 流(订单)都有一个新的线程(配送员)管理。经营方式二就是 I/O 多路复用。只有单个线程(一个配送员)，通过跟踪每个 I/O 流的状态(每个配送员的送达地点)，来管理多个 I/O 流。下面类比到真实的 Redis 线程模型，如图所示： Redis-client 在操作的时候，会产生具有不同事件类型的 Socket。在服务端，有一段 I/O 多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 4、Redis 的数据类型及使用场景一个合格的程序员，这五种类型都会用到。 String最常规的 set/get 操作，Value 可以是 String 也可以是数字。一般做一些复杂的计数功能的缓存。 Hash这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 Session 的效果。 List使用 List 的数据结构，可以做简单的消息队列的功能。另外，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。 Set因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能。我们的系统一般都是集群部署，使用 JVM 自带的 Set 比较麻烦。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。 Sorted SetSorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。Sorted Set 可以用来做延时任务。 5、Redis 的过期策略和内存淘汰机制Redis 是否用到家，从这就能看出来。比如你 Redis 只能存 5G 数据，可是你写了 10G，那会删 5G 的数据。怎么删的，这个问题思考过么？ 正解：Redis 采用的是定期删除+惰性删除策略。 为什么不用定时删除策略 定时删除，用一个定时器来负责监视 Key，过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。 定期删除+惰性删除如何工作 定期删除，Redis 默认每个 100ms 检查，有过期 Key 则删除。需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查。如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。 采用定期删除+惰性删除就没其他问题了么 不是的，如果定期删除没删除掉 Key。并且你也没及时去请求 Key，也就是说惰性删除也没生效。这样，Redis 的内存会越来越高。那么就应该采用内存淘汰机制。 在 redis.conf 中有一行配置： maxmemory-policy volatile-lru 该配置就是配内存淘汰策略的： noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（推荐使用，目前项目在用这种）(最近最久使用算法)allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。（应该也没人用吧，你不删最少使用 Key，去随机删）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。（不推荐）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。（依然不推荐）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。（不推荐） 6、Redis 和数据库双写一致性问题一致性问题还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。前提是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。 另外，我们所做的方案从根本上来说，只能降低不一致发生的概率。因此，有强一致性要求的数据，不能放缓存。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 7、如何应对缓存穿透和缓存雪崩问题这两个问题，一般中小型传统软件企业很难碰到。如果有大并发的项目，流量有几百万左右，这两个问题一定要深刻考虑。缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。 缓存穿透解决方案： 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。采用异步更新策略，无论 Key 是否取到值，都直接返回。Value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的 Key。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。 缓存雪崩解决方案： 给缓存的失效时间，加上一个随机值，避免集体失效。使用互斥锁，但是该方案吞吐量明显下降了。双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。然后细分以下几个小点：从缓存 A 读数据库，有则直接返回；A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程，更新线程同时更新缓存 A 和缓存 B。 8、如何解决 Redis 的并发竞争 Key 问题这个问题大致就是，同时有多个子系统去 Set 一个 Key。这个时候要注意什么呢？大家基本都是推荐用 Redis 事务机制。 但是我并不推荐使用 Redis 的事务机制。因为我们的生产环境，基本都是 Redis 集群环境，做了数据分片操作。你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。 如果对这个 Key 操作，不要求顺序这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。 如果对这个 Key 操作，要求顺序假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。 期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。 假设时间戳如下：系统 A key 1 {valueA 3:00} 系统 B key 1 {valueB 3:05} 系统 C key 1 {valueC 3:10} 那么，假设系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。其他方法，比如利用队列，将 set 方法变成串行访问也可以。 9、总结Redis 在国内各大公司都能看到其身影，比如我们熟悉的新浪，阿里，腾讯，百度，美团，小米等。学习 Redis，这几方面尤其重要：Redis 客户端、Redis 高级功能、Redis 持久化和开发运维常用问题探讨、Redis 复制的原理和优化策略、Redis 分布式解决方案等。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/categories/Redis/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://www.cicoding.cn/tags/分布式/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/tags/Redis/"}],"keywords":[{"name":"Redis","slug":"Redis","permalink":"https://www.cicoding.cn/categories/Redis/"}]},{"title":"手把手使用SonarQube分析、改善项目代码质量","slug":"SonarQube","date":"2019-01-18T09:43:44.000Z","updated":"2022-09-19T12:33:11.828Z","comments":true,"path":"other/SonarQube/","link":"","permalink":"https://www.cicoding.cn/other/SonarQube/","excerpt":"","text":"TIPS 本文基于SonarQube 7.9.1，理论支持6.0及更高版本。 SonarQube是一个开源的代码质量管理系统，可用来快速定位代码中的Bug、漏洞以及不优雅的代码。它支持几乎所有的常见编程语言，例如Java、JavaScript、TypeScript、Kotlin、Ruby、Go, Scala等。并且还有插件机制，利用插件，可以让SonarQube更加强大，例如可以整合Findbugs、PMD、Checkstyle等。可以说，SonarQube是一款提升项目代码质量必备的根据。 本文手把手搭建、使用SonarQube。 下载前往 https://www.sonarqube.org/downloads/ ，按照如图说明下载即可。建议下载 LTS 版本，以便获得长期的维护与支持。 系统需求 X64的操作系统 JDK（对于7.9.x，那么需要JDK 11或更高版；对于6.x - 7.8.x，需要JDK 8或更高版本） 2G内存 其他需求详见：https://docs.sonarqube.org/7.9/requirements/requirements/ TIPS 《其他需求》建议大家参照一下，里面探讨如何修改Linux文件描述符限制等说明； 上面贴的是是7.9版的链接，如果你使用的是其他版本，只需将版本名称改掉即可，例如改为7.8即可查看7.8.x的需求。 安装与启动 解压压缩包 将目录切换到SonarQube的 /bin 目录，可看到类似如下的目录结构： 1├── bin│ ├── jsw-license│ ├── linux-x86-64│ ├── macosx-universal-64│ └── windows-x86-64 根据你的操作系统，切换到响应目录。例如，您的机器是macOS ，则可切换到 macosx-universal-64 目录。 执行如下命令即可启动SonarQube。 1./sonar.sh start 当然，该shell还有其他命令，可输入 ./sonar.sh --help 或者 ./sonar.sh 查阅。 稍等片刻，访问 http://localhost:9000/ 即可看到类似如下的界面，说明安装成功。 停止SonarQube，只需执行 ./sonar.sh stop 即可。 如需重启，只需执行 ./sonar.sh restart 即可。 管理员登录访问：http://localhost:9000 账号：admin 密码：admin 生产环境可用默认情况下，SonarQube使用的是H2数据库，这是一款非常流行的嵌入式数据库。但生产环境中，SonarQube并不建议使用H2。SonarQube支持多种数据库，例如Qracle、PostgreSQL、SQL Server等。下面，我们以PostgreSQL为例，让SonarQube使用PostgreSQL存储数据。 TIPS 支持的数据库及数据库版本请前往这篇文档查看，避免SonarQube不支持你的数据库版本以及注意点。 https://docs.sonarqube.org/7.9/requirements/requirements/ 举个例子：SonarQube 7.9要求使用PostgreSQL 9.3-9.6或者PostgreSQL 10，并且必须配置使用UTF-8 搭建PostgreSQL简单起见，我用Docker搭建PostgreSQL。 1version: &apos;3.1&apos;services: postgres: image: postgres:10 restart: always environment: - POSTGRES_USER=itmuch - POSTGRES_PASSWORD=itmuch - POSTGRES_DB=sonar ports: - &quot;5432:5432&quot; 修改SonarQube配置 修改配置文件：$SONARQUBE_HOME/conf/sonar.properties 。 找到类似如下的内容： 1#----- PostgreSQL 9.3 or greater# By default the schema named &quot;public&quot; is used. It can be overridden with the parameter &quot;currentSchema&quot;.#sonar.jdbc.url=jdbc:postgresql://localhost/sonarqube?currentSchema=my_schema 在这行下面，添加如下内容： 1sonar.jdbc.url=jdbc:postgresql://localhost/sonar?currentSchema=publicsonar.jdbc.username=itmuchsonar.jdbc.password=itmuch 这里，数据库地址、账号、密码根据你的需求修改。 执行 ./sonar.sh restart ，重启SonarQube。观察PostgreSQL，可以发现，此时SonarQube会自动在PostgreSQL数据库中建表并插入初始化数据。 类似的方式，你也可以为你的SonarQube配置其他数据库。 整合Maven方法一：全局配置 在Maven的全局配置文件： $MAVEN_PATH/conf/settings.xml （也可能是.m2/settings.xml 看你是怎么配置Maven的）中添加如下内容： 1&lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.jdbc.url&gt;jdbc:postgresql://localhost/sonar?currentSchema=public&lt;/sonar.jdbc.url&gt; &lt;sonar.jdbc.driver&gt;org.postgresql.Driver&lt;/sonar.jdbc.driver&gt; &lt;sonar.jdbc.username&gt;itmuch&lt;/sonar.jdbc.username&gt; &lt;sonar.jdbc.password&gt;itmuch&lt;/sonar.jdbc.password&gt; &lt;sonar.host.url&gt;http://127.0.0.1:9000&lt;/sonar.host.url&gt; &lt;/properties&gt;&lt;/profile&gt; 到Maven项目的根目录执行如下命令，即可使用SonarQube分析项目： 1mvn sonar:sonar -Dsonar.java.binaries=target/sonar 等待片刻后，项目构建成功： 1[INFO] Spring Cloud YES ................................... SUCCESS [ 12.431 s][INFO] turbine-stream-server .............................. SKIPPED[INFO] zuul-server ........................................ SKIPPED[INFO] hystrix-dashboard .................................. SKIPPED[INFO] commons ............................................ SKIPPED[INFO] ms-content-sample-mybatis .......................... SKIPPED[INFO] ms-consumer-sample ................................. SKIPPED 此时，再次访问 http://localhost:9000 ，即可看到类似如下的界面： 如右上角所示，此时可以看到SonarQube已经为我们分析了一个项目，该项目有1个Bug、2个脆弱点、31个代码味道问题。点击项目名称（图中的 Spring Cloud YES）即可看到详情，可以根据SonarQube给我们的提示进行修正、重构。 方法二：直接命令行控制 右上角头像 - My Account - Security页中，在 Generate New Token 中填入你的Token名称，并点击Generate 按钮。 点击按钮后，将会看到生成的Token，例如 62b615f477557f98bc60b396c2b4ca2793afbdea 使用如下命令，即可使用Sonar分析项目。 1mvn sonar:sonar \\ -Dsonar.host.url=http://localhost:9000 \\ -Dsonar.login=62b615f477557f98bc60b396c2b4ca2793afbdea \\ -Dsonar.java.binaries=target/sonar 插件安装SonarQube有一个强大的插件机制。以安装汉化插件为例—— 按照图示进行操作： 点击 Install 按钮后，将会弹出重启SonarQube的提示，点击即可重启。重启后，可看到类似如下的界面 类似的方式，也可为SonarQube安装其他插件。 相关文章 我的技术干货小程序正式上线啦！ 技术讨论 一点作为原创作者的心声…… 福利","categories":[{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/categories/其他/"}],"tags":[{"name":"SonarQube","slug":"SonarQube","permalink":"https://www.cicoding.cn/tags/SonarQube/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/categories/其他/"}]},{"title":"聊聊Spring家族中的那几百个注解","slug":"spring-annotation-hundred","date":"2019-01-07T13:50:43.000Z","updated":"2022-09-17T14:13:56.175Z","comments":true,"path":"spring/spring-annotation-hundred/","link":"","permalink":"https://www.cicoding.cn/spring/spring-annotation-hundred/","excerpt":"","text":"查找所有注解 首先，我们来创建一个项目，使用SPRING INITIALIZR生成一个引入Spring各种组件的项目模板，然后引入如下工具包： 12345&lt;dependency&gt; &lt;groupId&gt;org.reflections&lt;/groupId&gt; &lt;artifactId&gt;reflections&lt;/artifactId&gt; &lt;version&gt;0.9.11&lt;/version&gt;&lt;/dependency&gt; 通过这个反射工具包，我们可以创建一个Spring Boot应用程序，以一行代码打印出所有Spring框架的注解： 1234567891011121314151617import org.reflections.Reflections;import org.springframework.boot.CommandLineRunner;import org.springframework.stereotype.Component;import java.lang.annotation.Annotation;@Componentpublic class ScanAnnotationRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; new Reflections(\"org.springframework\") .getSubTypesOf(Annotation.class) .stream() .map(clazz-&gt;clazz.getName()) .sorted() .forEach(System.out::println); &#125;&#125; 输出结果，下面我们逐一进行梳理其中的一些重要注解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105org.springframework.beans.factory.annotation.Autowiredorg.springframework.beans.factory.annotation.Configurableorg.springframework.beans.factory.annotation.Lookuporg.springframework.beans.factory.annotation.Qualifierorg.springframework.beans.factory.annotation.Requiredorg.springframework.beans.factory.annotation.Valueorg.springframework.boot.SpringBootConfigurationorg.springframework.boot.autoconfigure.AutoConfigurationPackageorg.springframework.boot.autoconfigure.AutoConfigureAfterorg.springframework.boot.autoconfigure.AutoConfigureBeforeorg.springframework.boot.autoconfigure.AutoConfigureOrderorg.springframework.boot.autoconfigure.EnableAutoConfigurationorg.springframework.boot.autoconfigure.ImportAutoConfigurationorg.springframework.boot.autoconfigure.SpringBootApplicationorg.springframework.boot.autoconfigure.condition.ConditionalOnBeanorg.springframework.boot.autoconfigure.condition.ConditionalOnClassorg.springframework.boot.autoconfigure.condition.ConditionalOnCloudPlatformorg.springframework.boot.autoconfigure.condition.ConditionalOnExpressionorg.springframework.boot.autoconfigure.condition.ConditionalOnJavaorg.springframework.boot.autoconfigure.condition.ConditionalOnJndiorg.springframework.boot.autoconfigure.condition.ConditionalOnMissingBeanorg.springframework.boot.autoconfigure.condition.ConditionalOnMissingClassorg.springframework.boot.autoconfigure.condition.ConditionalOnNotWebApplicationorg.springframework.boot.autoconfigure.condition.ConditionalOnPropertyorg.springframework.boot.autoconfigure.condition.ConditionalOnResourceorg.springframework.boot.autoconfigure.condition.ConditionalOnSingleCandidateorg.springframework.boot.autoconfigure.condition.ConditionalOnWebApplicationorg.springframework.boot.autoconfigure.data.ConditionalOnRepositoryTypeorg.springframework.boot.autoconfigure.domain.EntityScanorg.springframework.boot.autoconfigure.flyway.FlywayDataSourceorg.springframework.boot.autoconfigure.liquibase.LiquibaseDataSourceorg.springframework.boot.autoconfigure.quartz.QuartzDataSourceorg.springframework.boot.autoconfigure.web.ConditionalOnEnabledResourceChainorg.springframework.boot.autoconfigure.web.servlet.ConditionalOnMissingFilterBeanorg.springframework.boot.context.properties.ConfigurationPropertiesorg.springframework.boot.context.properties.ConfigurationPropertiesBindingorg.springframework.boot.context.properties.DeprecatedConfigurationPropertyorg.springframework.boot.context.properties.EnableConfigurationPropertiesorg.springframework.boot.context.properties.NestedConfigurationPropertyorg.springframework.boot.convert.DataSizeUnitorg.springframework.boot.convert.Delimiterorg.springframework.boot.convert.DurationFormatorg.springframework.boot.convert.DurationUnitorg.springframework.boot.jackson.JsonComponentorg.springframework.boot.web.server.LocalServerPortorg.springframework.boot.web.servlet.ServletComponentScanorg.springframework.cache.annotation.CacheConfigorg.springframework.cache.annotation.CacheEvictorg.springframework.cache.annotation.CachePutorg.springframework.cache.annotation.Cacheableorg.springframework.cache.annotation.Cachingorg.springframework.cache.annotation.EnableCachingorg.springframework.context.annotation.Beanorg.springframework.context.annotation.ComponentScanorg.springframework.context.annotation.ComponentScan$Filterorg.springframework.context.annotation.ComponentScansorg.springframework.context.annotation.Conditionalorg.springframework.context.annotation.Configurationorg.springframework.context.annotation.DependsOnorg.springframework.context.annotation.Descriptionorg.springframework.context.annotation.EnableAspectJAutoProxyorg.springframework.context.annotation.EnableLoadTimeWeavingorg.springframework.context.annotation.EnableMBeanExportorg.springframework.context.annotation.Importorg.springframework.context.annotation.ImportResourceorg.springframework.context.annotation.Lazyorg.springframework.context.annotation.Primaryorg.springframework.context.annotation.Profileorg.springframework.context.annotation.PropertySourceorg.springframework.context.annotation.PropertySourcesorg.springframework.context.annotation.Roleorg.springframework.context.annotation.Scopeorg.springframework.context.event.EventListenerorg.springframework.core.annotation.AliasFororg.springframework.core.annotation.Orderorg.springframework.format.annotation.DateTimeFormatorg.springframework.format.annotation.NumberFormatorg.springframework.jmx.export.annotation.ManagedAttributeorg.springframework.jmx.export.annotation.ManagedMetricorg.springframework.jmx.export.annotation.ManagedNotificationorg.springframework.jmx.export.annotation.ManagedNotificationsorg.springframework.jmx.export.annotation.ManagedOperationorg.springframework.jmx.export.annotation.ManagedOperationParameterorg.springframework.jmx.export.annotation.ManagedOperationParametersorg.springframework.jmx.export.annotation.ManagedResourceorg.springframework.lang.NonNullorg.springframework.lang.NonNullApiorg.springframework.lang.NonNullFieldsorg.springframework.lang.Nullableorg.springframework.lang.UsesJava7org.springframework.lang.UsesJava8org.springframework.lang.UsesSunHttpServerorg.springframework.lang.UsesSunMiscorg.springframework.objenesis.instantiator.annotations.Instantiatororg.springframework.scheduling.annotation.Asyncorg.springframework.scheduling.annotation.EnableAsyncorg.springframework.scheduling.annotation.EnableSchedulingorg.springframework.scheduling.annotation.Scheduledorg.springframework.scheduling.annotation.Schedulesorg.springframework.stereotype.Componentorg.springframework.stereotype.Controllerorg.springframework.stereotype.Indexedorg.springframework.stereotype.Repositoryorg.springframework.stereotype.Serviceorg.springframework.validation.annotation.Validated 有关注解 Java的Annotation注解（类似于C#的Attribute特性），说白了就是给代码打上标签的能力。我们可以配置这个标签的保留阶段，仅源代码，源代码+字节码，源代码+字节码+运行时。通过引入注解，我们可以简单快速赋予代码生命力，大大提高代码可读性和扩展性。注解本身不具有任何能力，只是一个标签，但是我们可以定义各种标签然后实现各种标签处理器来对类、方法、属性甚至参数等进行功能扩展、功能开启、属性定义、行为定义、规则定义、关联处理、元数据定义等等。在实现各种框架的时候，我们经常会自定义标签方便框架使用者仅仅通过在合适的地方引入合适的注解来启用（或自定义）框架的一些能力并应用到我们的程序中。 不仅仅是框架的作者会大量使用注解，在之前的系列文章中我们也多次自定义注解，我们有通过定义@Metrics注解配合Spring AOP来为程序启动打点、日志、异常等功能，我们有通过定义@Sign注解配合Spring MVC的ResponseBodyAdvice进行数据签名功能，我们还经常会定义各种自定义注解配合Spring MVC的HandlerMethodArgumentResolver进行权限的校验等等功能。采用这种模式，我们的核心业务逻辑可以保持清晰干净，通过注解配合AOP赋予代码额外的能力。 你可能会说，注解还是有侵入性，我们需要耦合框架定义的那些注解，这个问题其实是无解的，100%无侵入性也代表了可读性的降低，代码的功能和能力应当聚合在一起，这也就是为什么Spring现在也不建议采用XML来做配置。Java核心类库并没有什么注解，好在Spring已经有了大量注解，而Spring也变为了Java开发的标准，所以其实我们很多时候如果希望自己的框架（RPC啥的）完全没有侵入性的话可以借用Spring的那些注解@Autowired、@Controller、@Service等注解，配合各种包的规范其实我们可以对目标元素的功能识别个八九不离十，完全有可能实现0侵入的功能增强。 有关如何实现自定义注解不赘述，这里我们简单回顾一下几个元注解（注解的注解）： A. @Documented：将会在被此注解注解的元素的javadoc文档中列出注解，一般都打上这个注解没坏处 B. @Target：注解能被应用的目标元素，比如类、方法、属性、参数等等，需要仔细思考 C. @Retention：仅在源码保留，还是保留到编译后的字节码，还是到运行时也去加载，超过90%的应用会在运行时去解析注解进行额外的处理，所以大部分情况我们都会设置配置为RetentionPolicy.RUNTIME D. @Inherited：如果子类没有定义注解的话，能自动从父类获取定义了继承属性的注解，比如Spring的@Service是没有继承特性的，但是@Transactional是有继承特性的，在OO继承体系中使用Spring注解的时候请特别注意这点，理所当然认为注解是能被子类继承的话可能会引起不必要的Bug，需要仔细斟酌是否开启继承 E. @Repeatable：Java 8 引入的特性，通过关联注解容器定义可重复注解，小小语法糖提高了代码可读性，对于元素有多个重复注解其实是很常见的事情，比如某方法可以是A角色可以访问也可以是B角色可以访问，某方法需要定时任务执行，要在A条件执行也需要在B条件执行 F. @Native：是否在.h头文件中生成被标记的字段，除非原生程序需要和Java程序交互，否则很少会用到这个元注解现在我们来从几个方面逐一温习一下Spring的那些常用的值得关注的注解。 Spring核心注解 A. 首先来看一下各种stereotype：按分类定义了由Spring管理的各种组件，@Controller定义表现层组件，@Service定义业务逻辑层组件，@Repository定义数据访问层资源库组件，@Component定义其它组件（比如访问外部服务的组件），之前也说过了随着这些注解功能无区别，但是对组件进行合适的分类意义重大，不仅仅增加可读性而且方便我们通过AOP对不同类型的组件进行更多自动增强 B.再来看看IOC相关的一些注解：@Autowired自动装配不用多说了；@Required用于在setter方法标记属性值需要由Spring进行装配，对于目前版本的Spring这个注解已经废弃，现在Spring更推荐使用构造方法注入；@Qualifier用于通过给Bean定义修饰语来注入相应的Bean，和@Autowired一起使用相当于@Resource的效果，当然还有一种常见用法是嵌入其它注解用于对Bean进行区分，然后配合@Autowired一起使用，参见后面提到的Spring Cloud的@LoadBalanced注解；@Value用于注入属性配置或SpEL表达式（前者是我们常见用法，后者可以从其它对象获取值，功能更强大一点）；@Lookup可以实现方法注入，如果我们的类是单例的，但是又希望Spring注入的依赖的对象是Prototype生命周期（每次new一个出来）的，这个时候可以通过此注解进行方法注入 C. 然后来看一下有关事务的几个注解：@EnableTransactionManagement用于开启事务管理，使用Spring Boot如果引入Spring Data的话不需要手动开启（不过建议大家在使用事务的时候还是通过日志来验证事务管理是否生效）；@Transactional大家都知道用于开启事务以及设置传播性、隔离性、回滚条件等；@TransactionalEventListener用于配置事务的回调方法，可以在事务提交前、提交后、完成后以及回滚后几个阶段接受回调事件。 D. @Order注解可以设置Spring管理对象的加载顺序，在之前介绍AOP的文章中我们看到有的时候我们必须通过设置合理的@Order来合理安排切面的切入顺序避免一些问题，还有在一些业务场景中，我们往往会去定义一组类似于Filter的@Component，然后会从容器获得一组Bean，这个时候业务组件的运行顺序往往会比较重要，也可以通过这个方式进行排序 E. @AliasFor注解可以设置一组注解属性相互作为别名，对于有歧义的时候会使代码更清晰，此外还有一个用途是创建复合注解，Spring MVC的@GetMapping注解就是基于@RequestMapping这个注解创建的复合注解，我们可以很方便得通过这种方式来实现注解的继承 Spring上下文注解 A. 首先来看一下配置相关的一些注解：@Configuration用于标注配置类，启用Java配置方式的Bean配置；@Bean用于配置一个Bean；@ComponentScan（@ComponentScans用于配置一组@ComponentScan，Java 8可以直接使用重复注解特性配置多个@ComponentScan）用于扫描包方式配置Bean；@PropertySource以及 @PropertySources用于导入配置文件；@Conditional用于设置关联的条件类，在合适的时候启用Bean的配置（Spring Boot自动配置根基）；@Import用于导入其它配置类； @ImportResource用于导入非Java配置方式的XML配置；@Profile用于指定在合适的Profile下启用配置；@Lazy用于告知容器延迟到使用的时候实例化Bean（默认情况下容器启动的时候实例化Bean来检查所有的问题）；@Description用于给Bean设置描述；@Scope用于设置Bean的生命周期；@Primary用于在定义了多个Bean的时候指定首选的Bean B. 其它一些注解包括：@EventListener用于设置回调方法监听Spring制定的以及自定义的各种事件；@EnableAspectJAutoProxy用于开启支持AspectJ的 @Aspect切面配置支持，使用Spring Boot引入了AOP启动器的话不需要显式开启 Spring Web注解 Spring MVC的各种注解对应了Spring MVC各方面的功能，下面我们来了解一下： A. 首先是三个定义了Bean特殊生命周期的复合注解：@RequestScope、@SessionScope和 @ApplicationScope。在Web应用中，我们可能需要Bean跟随请求、会话和应用程序的声明周期来进行创建，这个时候可以直接使用这三个快捷的复合注解 B. 接下去可以看到各种 @XXXMapping的注解，分别用于配置HandlerMethod匹配到不同的Http Method，当然不使用这些快捷的注解也是可以的，直接使用@RequestMapping然后手动设置method C. @ResponseStatus可以用到方法上也可以用到异常上，前者会直接使请求得到指定的响应代码或原因（可以配合@ExceptionHandler使用），后者可以实现遇到指定异常的时候给出指定的响应代码或原因，@ResponseBody我们实现Restful接口的时候（@RestController）最常用了，把返回内容（序列化后）输出到请求体 D. Spring MVC给了我们各种注解方便我们从HTTP请求各种地方获取参数，@RequestBody从请求体（处理复杂数据，比如JSON），@RequestHeader从请求头，@CookieValue从cookie中，@SessionAttribute从会话中，@RequestAttribute从请求的Attribute中（比如过滤器和拦截器手动设置的一些临时数据），@RequestParam从请求参数（处理简单数据，键值对），@PathVariable从路径片段，@MatrixAttribute矩阵变量允许我们采用特殊的规则在URL路径后加参数（分号区分不同参数，逗号为参数增加多个值） E. @ControllerAdvice是一个重要注解，允许我们在集中的地方配置控制器（有@RequestMapping的方法）相关的增强（@RestControllerAdvice也是差不多的，只是相当于为@ExceptionHandler加上了@ResponseBody）。那么可以应用哪些增强呢？首先是可以用 @ExceptionHandler进行统一的全局异常处理；第二是 @InitBinder用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求参数到Model中；第三是 @ModelAttribute让全局的@RequestMapping都能获得在此处设置的键值对。当然，这里说的@InitBinder和@ExceptionHandler也可以不定义在@ControllerAdvice内部（作为全局开启），定义在Controller内部应用到某个Controller也是可以的 F. 其它还有一些注解比如：@CrossOrigin可以用到Controller或Method上（需要配合@RequestMapping）设置细粒度的跨域行为在之前的文章中我们也提到，对于Spring MVC，定义自己的注解应用到参数、方法、控制器上，配合HandlerMethodArgumentResolver、XXAdvise、以及Interceptor实现具体的功能来使用太太常见了，几乎所有的非业务横切关注点，我们都不应该在方法实现中重复任何一行代码。 Spring Boot注解 A. 来看一下上下文相关的注解：@ConfigurationProperties很常用（配合 @EnableConfigurationProperties注解来设置需要启用的配置类），用来自定义配置类和配置文件进行关联；@DeprecatedConfigurationProperty用于标记废弃的配置以及设置替代配置和告知废弃原因；@ConfigurationPropertiesBinding用于指定自定义的转换器用于配置解析的时的类型转换； @NestedConfigurationProperty用于关联外部的类型作为嵌套配置类 B. 再看看自动配置相关的注解，自动配置是Spring Boot最重要的特性，在之前的系列文章中我有提到一个观点，IOC是好事情，但是把组件内部的一些默认配置以及组件和组件的组装交给外部用户来配置其实是不合理的，组件应当可以自动进行自我配置实现开箱急用，只有需要自定义组件的时候才要求外部来进行个性化配置：@EnableAutoConfiguration注解可以启用自动配置，Spring Boot应用程序一般我们会直接使用复合注解@SpringBootApplication；@AutoConfigureOrder（值越小优先级越高）、@AutoConfigureAfter、@AutoConfigureBefore用于设置自动配置类加载顺序，以及精确控制加载依赖关系，有的时候我们的自动配置需要相互依赖或者会相互干扰，需要手动调节 C. 最后来看一下十几种配置条件，用好这些注解是实现完善的自动配置的关键：@ConditionalOnBean用于仅当容器中已经包含指定的Bean类型或名称时才匹配条件；@ConditionalOnClass仅当classpath上存在指定类时条件匹配；@ConditionalOnCloudPlatform仅当指定的云平台处于活动状态时条件匹配；@ConditionalOnExpression依赖于SpEL表达式的值的条件元素的配置注解；@ConditionalOnJava基于应用运行的JVM版本的条件匹配；@ConditionalOnJndi基于JNDI可用和可以查找指定位置的条件匹配；@ConditionalOnMissingBean仅当容器中不包含指定的Bean类型或名称时条件匹配；@ConditionalOnMissingClass仅当classpath上不存在指定类时条件匹配；@ConditionalOnNotWebApplication 仅当不是WebApplicationContext（非Web项目）时条件匹配，对应 @ConditionalOnWebApplication；@ConditionalOnProperty是检查指定的属性是否具有指定的值；@ConditionalOnResource表示仅当 classpath 上存在指定资源时条件匹配；@ConditionalOnSingleCandidate仅当容器中包含指定的Bean类并且可以判断只有单个候选者时条件匹配。其实所有这些实现原理都是扩展SpringBootCondition抽象类（实现之前提到的Condition接口），我们完全可以实现自己的条件注解（配合 @Conditional注解关联到自己实现的SpringBootCondition） Spring Cloud注解 在介绍本系列文章的第一篇中我们就提到了，Spring Cloud整齐划一通过各种EnableXXX注解开启某个功能，这里就不对这些注解进行说明了，使用Spring Boot组件的功能非常简单，基本就是引POM+EnableXXX+设置配置文件三部曲。 A. 首先是 Netflix包下的一些注解，各种EnableXXX就不说了，参考前一篇文章，之前没介绍过 @RibbonClient，这个注解用来为负载均衡客户端做一些自定义的配置，可以进一步配置或自定义从哪里获取服务端列表、负载均衡策略、Ping也就是服务鉴活策略等等 B. client包下的 @SpringCloudApplication之前文章中我们也没有使用到，这是一个复合注解就是 @SpringBootApplication+ @EnableDiscoveryClient+ @EnableCircuitBreaker，Spring Cloud那堆东西很多，还是自己亲手定义一个一个功能的注解来的踏实； @LoadBalanced注解用于和RestTemplate配合使用构成一个负载均衡的Http客户端，实现原理上其实这个注解是一个@Qualifier注解，Spring会为所有@LoadBalanced的RestTemplate加入一个LoadBalancerInterceptor（实现ClientHttpRequestInterceptor）实现负载均衡 C. sleuth包下面的注解和链路跟踪相关，比较常用的是通过 @SpanName手动设置span的名称，其它注解对于业务开发并不常用 总结 元注解，也就是注解的注解 Spring容器相关的一些注解，包括@Qualifier、@AliasFor、@Order等看似不重要但其实很重要的注解 Spring Java配置相关的一些注解，包括条件注解 Spring Boot自动配置相关的一些注解 很多注解可以同时应用到类型、方法、参数上，有的时候应用到不同的地方作用会略微不一样，这个需要重点关注 我们知道注解其实只是一个标识，注解如何起作用背后的实现原理还是比较多样的，你可以进一步结合本文介绍的Spring的各种注解探寻一下背后实现的原理。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"},{"name":"注解","slug":"注解","permalink":"https://www.cicoding.cn/tags/注解/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"分库分表之后，id 主键如何处理？","slug":"Sub-library-table","date":"2018-12-26T06:48:17.000Z","updated":"2022-09-19T12:33:11.826Z","comments":true,"path":"database/Sub-library-table/","link":"","permalink":"https://www.cicoding.cn/database/Sub-library-table/","excerpt":"","text":"面试题分库分表之后，id 主键如何处理？ 面试官心理分析其实这是分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个全局唯一的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。 面试题剖析数据库自增 id这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。 这个方案的好处就是方便简单，谁都会用；缺点就是单库生成自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是无论如何都是基于单个数据库。 适合的场景：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你并发不高，但是数据量太大导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。 uuid好处就是本地生成，不要基于数据库来了；不好之处就是，uuid 太长了，作为主键性能太差了，不适合用于主键。 适合的场景：如果你是要随机生成个什么文件名了，编号之类的，你可以用uuid，但是作为主键是不能用uuid的。 1UUID.randomUUID().toString().replace(“-”, “”) -&gt; sfsdf23423rr234sfdaf 获取系统当前时间这个就是获取当前时间即可，但是问题是，并发很高的时候，比如一秒并发几千，会有重复的情况，这个是肯定不合适的。基本就不用考虑了。 适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。 snowflake 算法snowflake 算法是 twitter 开源的分布式 id 生成算法，就是把一个 64 位的 long 型的 id，1 个bit是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 2^41 - 1，也就是可以标识 2^41 - 1 个毫秒值，换算成年就是表示69年的时间。 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 2^5个机房（32个机房），每个机房里可以代表 2^5 个机器（32台机器）。 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 2^12 - 1 = 4096，也就是说可以用这个 12 bit 代表的数字来区分同一个毫秒内的 4096 个不同的 id。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101110 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000public class IdWorker &#123; private long workerId; private long datacenterId; private long sequence; public IdWorker(long workerId, long datacenterId, long sequence) &#123; // sanity check for workerId // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0 if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException( String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException( String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId)); &#125; System.out.printf( \"worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d\", timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId); this.workerId = workerId; this.datacenterId = datacenterId; this.sequence = sequence; &#125; private long twepoch = 1288834974657L; private long workerIdBits = 5L; private long datacenterIdBits = 5L; // 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内 private long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); // 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内 private long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); private long lastTimestamp = -1L; public long getWorkerId() &#123; return workerId; &#125; public long getDatacenterId() &#123; return datacenterId; &#125; public long getTimestamp() &#123; return System.currentTimeMillis(); &#125; public synchronized long nextId() &#123; // 这儿就是获取当前时间戳，单位是毫秒 long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; System.err.printf(\"clock is moving backwards. Rejecting requests until %d.\", lastTimestamp); throw new RuntimeException(String.format( \"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); &#125; if (lastTimestamp == timestamp) &#123; // 这个意思是说一个毫秒内最多只能有4096个数字 // 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围 sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0; &#125; // 这儿记录一下最近一次生成id的时间戳，单位是毫秒 lastTimestamp = timestamp; // 这儿就是将时间戳左移，放到 41 bit那儿； // 将机房 id左移放到 5 bit那儿； // 将机器id左移放到5 bit那儿；将序号放最后12 bit； // 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型 return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; private long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; private long timeGen() &#123; return System.currentTimeMillis(); &#125; // ---------------测试--------------- public static void main(String[] args) &#123; IdWorker worker = new IdWorker(1, 1, 1); for (int i = 0; i &lt; 30; i++) &#123; System.out.println(worker.nextId()); &#125; &#125;&#125; 怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个机房 id（但是最大只能是32以内），5 bit 是你传递进来的机器 id（但是最大只能是32以内），剩下的那个 12 bit序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。 所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。 利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了5 bit + 5 bit，你换成别的有业务含义的东西也可以的。 这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。","categories":[{"name":"主键","slug":"主键","permalink":"https://www.cicoding.cn/categories/主键/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://www.cicoding.cn/tags/分布式/"}],"keywords":[{"name":"主键","slug":"主键","permalink":"https://www.cicoding.cn/categories/主键/"}]},{"title":"theme使用","slug":"theme-Use","date":"2018-10-18T09:43:44.000Z","updated":"2022-09-19T12:33:11.829Z","comments":true,"path":"other/theme-Use/","link":"","permalink":"https://www.cicoding.cn/other/theme-Use/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859D:\\hexo&gt;hexo new page categoriesINFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\categories\\index.mdD:\\hexo&gt;hexo new page &quot;tags&quot;INFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\tags\\index.mdD:\\hexo&gt;hexo new page &quot;about&quot;INFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\about\\index.mdD:\\hexo&gt;hexo new page &quot;books/rocketmq/&quot;INFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\books-rocketmq\\index.mdD:\\hexo&gt;hexo new page &quot;books rocketmq&quot;INFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\books-rocketmq\\index.mdD:\\hexo&gt;hexo new page books/&quot;rocketmq&quot;INFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\books-rocketmq\\index.mdD:\\hexo&gt;hexo new page &quot;rocketmq&quot;INFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\books\\rocketmq\\index.mdD:\\hexo&gt;hexo new &quot;00-docker-lession-index&quot; --lang dockerINFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\_posts\\00-docker-lession-index.mdD:\\hexo&gt;hexo new &quot;00-docker-lession-index&quot; --lang dockerINFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\_posts\\00-docker-lession-index.mdD:\\hexo&gt;hexo new &quot;00-docker-lession-index&quot; --lang dockerINFO =========================================INFO Welcome to use Snippet theme for hexoINFO =========================================INFO Created: D:\\hexo\\source\\_posts\\docker\\00-docker-lession-index.md","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.cicoding.cn/tags/Hexo/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"spring注解大全解析","slug":"spring-annotation","date":"2018-09-30T12:28:40.000Z","updated":"2022-09-17T14:13:56.175Z","comments":true,"path":"spring/spring-annotation/","link":"","permalink":"https://www.cicoding.cn/spring/spring-annotation/","excerpt":"","text":"@Service用于标注业务层组件 @Controller用于标注控制层组件（如struts中的action） @Repository用于标注数据访问组件，即DAO组件 @Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 @Autowired后不需要getter()和setter()方法，Spring也会自动注入。 在接口前面标上@Autowired注释使得接口可以被容器注入，如： 123@Autowired @Qualifier(\"chinese\") private Man man; 当接口存在两个实现类的时候必须使用@Qualifier指定注入哪个实现类，否则可以省略，只写@Autowired。使用@Autowired时你的OrganDaoIbatis 必须以@Service或@Component注解才行。 之前用户使用的是3个注解注解他们的main类。分别是@Configuration,@EnableAutoConfiguration,@ComponentScan。由于这些注解一般都是一起使用，spring boot提供了一个统一的注解@SpringBootApplication。@SpringBootApplication = (默认属性)@Configuration + @EnableAutoConfiguration + @ComponentScan1、@Configuration提到@Configuration就要提到他的搭档@Bean。使用这两个注解就可以创建一个简单的spring配置类，可以用来替代相应的xml配置文件。派生到我的代码片 123456&lt;beans&gt; &lt;bean id = \"car\" class=\"com.test.Car\"&gt; &lt;property name=\"wheel\" ref = \"wheel\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id = \"wheel\" class=\"com.test.Wheel\"&gt;&lt;/bean&gt; &lt;/beans&gt; 相当于：派生到我的代码片 12345678910111213@Configuration public class Conf &#123; @Bean public Car car() &#123; Car car = new Car(); car.setWheel(wheel()); return car; &#125; @Bean public Wheel wheel() &#123; return new Wheel(); &#125; &#125; 1、@Configuration注解类标识这个类可以使用Spring IoC容器作为bean定义的来源。@Bean注解告诉Spring，一个带有@Bean的注解方法将返回一个对象，该对象应该被注册为在Spring应用程序上下文中的bean。 2、@EnableAutoConfiguration能够自动配置spring的上下文，试图猜测和配置你想要的bean类，通常会自动根据你的类路径和你的bean定义自动配置。 3、@ComponentScan会自动扫描指定包下的全部标有@Component的类，并注册成bean，当然包括@Component下的子注解@Service,@Repository,@Controller。 4、@ResponseBody用该注解修饰的函数，会将结果直接填充到HTTP的响应体中，一般用于构建RESTful的api； 5、@Controller用于定义控制器类，在spring 项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层）。 6、@RestController@ResponseBody和@Controller的合集 7、@RequestMapping提供路由信息，负责URL到Controller中的具体函数的映射。 8、@EnableAutoConfigurationSpring Boot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。例如，如果你的classpath下存在HSQLDB，并且你没有手动配置任何数据库连接beans，那么我们将自动配置一个内存型（in-memory）数据库”。你可以将@EnableAutoConfiguration或者@SpringBootApplication注解添加到一个@Configuration类上来选择自动配置。如果发现应用了你不想要的特定自动配置类，你可以使用@EnableAutoConfiguration注解的排除属性来禁用它们。 9、@ComponentScan表示将该类自动发现（扫描）并注册为Bean，可以自动收集所有的Spring组件，包括@Configuration类。我们经常使用@ComponentScan注解搜索beans，并结合@Autowired注解导入。 10、@Configuration相当于传统的xml配置文件，如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。 11、@SpringBootApplication相当于@EnableAutoConfiguration、@ComponentScan和@Configuration的合集。 12、@Import用来导入其他配置类。 13、@ImportResource用来加载xml配置文件。 14、@Autowired自动导入依赖的bean 15、@Service一般用于修饰service层的组件 16、@Repository使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项 17、@MapperScan使用mybatis注解需要的配置。如下面的代码所示，使用@MapperScan来扫描注册mybatis数据库接口类，其中basePackages属性表明接口类所在的包，sqlSessionTemplateRef表明接口类使用的SqlSessionTemplate。如果项目需要配置两个数据库，@MapperScan也需要分别配置。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/tags/Spring/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://www.cicoding.cn/categories/Spring/"}]},{"title":"史上最全的maven pom.xml文件教程详解","slug":"maven-pom","date":"2018-09-27T09:10:22.000Z","updated":"2023-06-20T06:38:19.047Z","comments":true,"path":"maven/maven-pom/","link":"","permalink":"https://www.cicoding.cn/maven/maven-pom/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd \"&gt; &lt;!-- 父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。 --&gt; &lt;parent&gt; &lt;!-- 被继承的父项目的构件标识符 --&gt; &lt;artifactId /&gt; &lt;!-- 被继承的父项目的全球唯一标识符 --&gt; &lt;groupId /&gt; &lt;!-- 被继承的父项目的版本 --&gt; &lt;version /&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;!-- 声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --&gt; &lt;modelVersion&gt; 4.0.0 &lt;/modelVersion&gt; &lt;!-- 项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --&gt; &lt;groupId&gt; asia.banseon &lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源码，二进制发布和WARs等。 --&gt; &lt;artifactId&gt; banseon-maven2 &lt;/artifactId&gt; &lt;!-- 项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --&gt; &lt;packaging&gt; jar &lt;/packaging&gt; &lt;!-- 项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --&gt; &lt;version&gt; 1.0-SNAPSHOT &lt;/version&gt; &lt;!-- 项目的名称, Maven产生的文档用 --&gt; &lt;name&gt; banseon-maven &lt;/name&gt; &lt;!-- 项目主页的URL, Maven产生的文档用 --&gt; &lt;url&gt; http://www.baidu.com/banseon &lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --&gt; &lt;description&gt; A maven project to study maven. &lt;/description&gt; &lt;!-- 描述了这个项目构建环境中的前提条件。 --&gt; &lt;prerequisites&gt; &lt;!-- 构建该项目或使用该插件所需要的Maven的最低版本 --&gt; &lt;maven /&gt; &lt;/prerequisites&gt; &lt;!-- 项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --&gt; &lt;issueManagement&gt; &lt;!-- 问题管理系统（例如jira）的名字， --&gt; &lt;system&gt; jira &lt;/system&gt; &lt;!-- 该项目使用的问题管理系统的URL --&gt; &lt;url&gt; http://jira.baidu.com/banseon &lt;/url&gt; &lt;/issueManagement&gt; &lt;!-- 项目持续集成信息 --&gt; &lt;ciManagement&gt; &lt;!-- 持续集成系统的名字，例如continuum --&gt; &lt;system /&gt; &lt;!-- 该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --&gt; &lt;url /&gt; &lt;!-- 构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --&gt; &lt;notifiers&gt; &lt;!-- 配置一种方式，当构建中断时，以该方式通知用户/开发者 --&gt; &lt;notifier&gt; &lt;!-- 传送通知的途径 --&gt; &lt;type /&gt; &lt;!-- 发生错误时是否通知 --&gt; &lt;sendOnError /&gt; &lt;!-- 构建失败时是否通知 --&gt; &lt;sendOnFailure /&gt; &lt;!-- 构建成功时是否通知 --&gt; &lt;sendOnSuccess /&gt; &lt;!-- 发生警告时是否通知 --&gt; &lt;sendOnWarning /&gt; &lt;!-- 不赞成使用。通知发送到哪里 --&gt; &lt;address /&gt; &lt;!-- 扩展配置项 --&gt; &lt;configuration /&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!-- 项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --&gt; &lt;inceptionYear /&gt; &lt;!-- 项目相关邮件列表信息 --&gt; &lt;mailingLists&gt; &lt;!-- 该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --&gt; &lt;mailingList&gt; &lt;!-- 邮件的名称 --&gt; &lt;name&gt; Demo &lt;/name&gt; &lt;!-- 发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;post&gt; banseon@126.com &lt;/post&gt; &lt;!-- 订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;subscribe&gt; banseon@126.com &lt;/subscribe&gt; &lt;!-- 取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;unsubscribe&gt; banseon@126.com &lt;/unsubscribe&gt; &lt;!-- 你可以浏览邮件信息的URL --&gt; &lt;archive&gt; http:/hi.baidu.com/banseon/demo/dev/ &lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!-- 项目开发者列表 --&gt; &lt;developers&gt; &lt;!-- 某个项目开发者的信息 --&gt; &lt;developer&gt; &lt;!-- SCM里项目开发者的唯一标识符 --&gt; &lt;id&gt; HELLO WORLD &lt;/id&gt; &lt;!-- 项目开发者的全名 --&gt; &lt;name&gt; banseon &lt;/name&gt; &lt;!-- 项目开发者的email --&gt; &lt;email&gt; banseon@126.com &lt;/email&gt; &lt;!-- 项目开发者的主页的URL --&gt; &lt;url /&gt; &lt;!-- 项目开发者在项目中扮演的角色，角色元素描述了各种角色 --&gt; &lt;roles&gt; &lt;role&gt; Project Manager &lt;/role&gt; &lt;role&gt; Architect &lt;/role&gt; &lt;/roles&gt; &lt;!-- 项目开发者所属组织 --&gt; &lt;organization&gt; demo &lt;/organization&gt; &lt;!-- 项目开发者所属组织的URL --&gt; &lt;organizationUrl&gt; http://hi.baidu.com/banseon &lt;/organizationUrl&gt; &lt;!-- 项目开发者属性，如即时消息如何处理等 --&gt; &lt;properties&gt; &lt;dept&gt; No &lt;/dept&gt; &lt;/properties&gt; &lt;!-- 项目开发者所在时区， -11到12范围内的整数。 --&gt; &lt;timezone&gt; -5 &lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!-- 项目的其他贡献者列表 --&gt; &lt;contributors&gt; &lt;!-- 项目的其他贡献者。参见developers/developer元素 --&gt; &lt;contributor&gt; &lt;name /&gt;&lt;email /&gt;&lt;url /&gt;&lt;organization /&gt;&lt;organizationUrl /&gt;&lt;roles /&gt;&lt;timezone /&gt;&lt;properties /&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!-- 该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --&gt; &lt;licenses&gt; &lt;!-- 描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --&gt; &lt;license&gt; &lt;!-- license用于法律上的名称 --&gt; &lt;name&gt; Apache 2 &lt;/name&gt; &lt;!-- 官方的license正文页面的URL --&gt; &lt;url&gt; http://www.baidu.com/banseon/LICENSE-2.0.txt &lt;/url&gt; &lt;!-- 项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --&gt; &lt;distribution&gt; repo &lt;/distribution&gt; &lt;!-- 关于license的补充信息 --&gt; &lt;comments&gt; A business-friendly OSS license &lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!-- SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --&gt; &lt;scm&gt; &lt;!-- SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!-- 给开发者使用的，类似connection元素。即该连接不仅仅只读 --&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!-- 当前代码的标签，在开发阶段默认为HEAD --&gt; &lt;tag /&gt; &lt;!-- 指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --&gt; &lt;url&gt; http://svn.baidu.com/banseon &lt;/url&gt; &lt;/scm&gt; &lt;!-- 描述项目所属组织的各种属性。Maven产生的文档用 --&gt; &lt;organization&gt; &lt;!-- 组织的全名 --&gt; &lt;name&gt; demo &lt;/name&gt; &lt;!-- 组织主页的URL --&gt; &lt;url&gt; http://www.baidu.com/banseon &lt;/url&gt; &lt;/organization&gt; &lt;!-- 构建项目需要的信息 --&gt; &lt;build&gt; &lt;!-- 该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;sourceDirectory /&gt; &lt;!-- 该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --&gt; &lt;scriptSourceDirectory /&gt; &lt;!-- 该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;testSourceDirectory /&gt; &lt;!-- 被编译过的应用程序class文件存放的目录。 --&gt; &lt;outputDirectory /&gt; &lt;!-- 被编译过的测试class文件存放的目录。 --&gt; &lt;testOutputDirectory /&gt; &lt;!-- 使用来自该项目的一系列构建扩展 --&gt; &lt;extensions&gt; &lt;!-- 描述使用到的构建扩展。 --&gt; &lt;extension&gt; &lt;!-- 构建扩展的groupId --&gt; &lt;groupId /&gt; &lt;!-- 构建扩展的artifactId --&gt; &lt;artifactId /&gt; &lt;!-- 构建扩展的版本 --&gt; &lt;version /&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!-- 当项目没有规定目标（Maven2 叫做阶段）时的默认值 --&gt; &lt;defaultGoal /&gt; &lt;!-- 这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --&gt; &lt;resources&gt; &lt;!-- 这个元素描述了项目相关或测试相关的所有资源路径 --&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven/messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --&gt; &lt;targetPath /&gt; &lt;!-- 是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --&gt; &lt;filtering /&gt; &lt;!-- 描述存放资源的目录，该路径相对POM路径 --&gt; &lt;directory /&gt; &lt;!-- 包含的模式列表，例如**/*.xml. --&gt; &lt;includes /&gt; &lt;!-- 排除的模式列表，例如**/*.xml --&gt; &lt;excludes /&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- 这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --&gt; &lt;testResources&gt; &lt;!-- 这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --&gt; &lt;testResource&gt; &lt;targetPath /&gt;&lt;filtering /&gt;&lt;directory /&gt;&lt;includes /&gt;&lt;excludes /&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!-- 构建产生的所有文件存放的目录 --&gt; &lt;directory /&gt; &lt;!-- 产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。 --&gt; &lt;finalName /&gt; &lt;!-- 当filtering开关打开时，使用到的过滤器属性文件列表 --&gt; &lt;filters /&gt; &lt;!-- 子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --&gt; &lt;pluginManagement&gt; &lt;!-- 使用的插件列表 。 --&gt; &lt;plugins&gt; &lt;!-- plugin元素包含描述插件所需要的信息。 --&gt; &lt;plugin&gt; &lt;!-- 插件在仓库里的group ID --&gt; &lt;groupId /&gt; &lt;!-- 插件在仓库里的artifact ID --&gt; &lt;artifactId /&gt; &lt;!-- 被使用的插件的版本（或版本范围） --&gt; &lt;version /&gt; &lt;!-- 是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --&gt; &lt;extensions /&gt; &lt;!-- 在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --&gt; &lt;executions&gt; &lt;!-- execution元素包含了插件执行需要的信息 --&gt; &lt;execution&gt; &lt;!-- 执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --&gt; &lt;id /&gt; &lt;!-- 绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --&gt; &lt;phase /&gt; &lt;!-- 配置的执行目标 --&gt; &lt;goals /&gt; &lt;!-- 配置是否被传播到子POM --&gt; &lt;inherited /&gt; &lt;!-- 作为DOM对象的配置 --&gt; &lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!-- 项目引入插件所需要的额外依赖 --&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 任何配置是否被传播到子项目 --&gt; &lt;inherited /&gt; &lt;!-- 作为DOM对象的配置 --&gt; &lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 使用的插件列表 --&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId /&gt;&lt;artifactId /&gt;&lt;version /&gt;&lt;extensions /&gt; &lt;executions&gt; &lt;execution&gt; &lt;id /&gt;&lt;phase /&gt;&lt;goals /&gt;&lt;inherited /&gt;&lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals /&gt;&lt;inherited /&gt;&lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 在列的项目构建profile，如果被激活，会修改构建处理 --&gt; &lt;profiles&gt; &lt;!-- 根据环境参数或命令行参数激活某个构建处理 --&gt; &lt;profile&gt; &lt;!-- 构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --&gt; &lt;id /&gt; &lt;!-- 自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --&gt; &lt;activation&gt; &lt;!-- profile默认是否激活的标志 --&gt; &lt;activeByDefault /&gt; &lt;!-- 当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt; &lt;jdk /&gt; &lt;!-- 当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt; &lt;os&gt; &lt;!-- 激活profile的操作系统的名字 --&gt; &lt;name&gt; Windows XP &lt;/name&gt; &lt;!-- 激活profile的操作系统所属家族(如 'windows') --&gt; &lt;family&gt; Windows &lt;/family&gt; &lt;!-- 激活profile的操作系统体系结构 --&gt; &lt;arch&gt; x86 &lt;/arch&gt; &lt;!-- 激活profile的操作系统版本 --&gt; &lt;version&gt; 5.1.2600 &lt;/version&gt; &lt;/os&gt; &lt;!-- 如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt; &lt;property&gt; &lt;!-- 激活profile的属性的名称 --&gt; &lt;name&gt; mavenVersion &lt;/name&gt; &lt;!-- 激活profile的属性的值 --&gt; &lt;value&gt; 2.0.3 &lt;/value&gt; &lt;/property&gt; &lt;!-- 提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt; &lt;file&gt; &lt;!-- 如果指定的文件存在，则激活profile。 --&gt; &lt;exists&gt; /usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ &lt;/exists&gt; &lt;!-- 如果指定的文件不存在，则激活profile。 --&gt; &lt;missing&gt; /usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ &lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!-- 构建项目所需要的信息。参见build元素 --&gt; &lt;build&gt; &lt;defaultGoal /&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath /&gt;&lt;filtering /&gt;&lt;directory /&gt;&lt;includes /&gt;&lt;excludes /&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath /&gt;&lt;filtering /&gt;&lt;directory /&gt;&lt;includes /&gt;&lt;excludes /&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory /&gt;&lt;finalName /&gt;&lt;filters /&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId /&gt;&lt;artifactId /&gt;&lt;version /&gt;&lt;extensions /&gt; &lt;executions&gt; &lt;execution&gt; &lt;id /&gt;&lt;phase /&gt;&lt;goals /&gt;&lt;inherited /&gt;&lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals /&gt;&lt;inherited /&gt;&lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId /&gt;&lt;artifactId /&gt;&lt;version /&gt;&lt;extensions /&gt; &lt;executions&gt; &lt;execution&gt; &lt;id /&gt;&lt;phase /&gt;&lt;goals /&gt;&lt;inherited /&gt;&lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals /&gt;&lt;inherited /&gt;&lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules /&gt; &lt;!-- 发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!-- 参见repositories/repository元素 --&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled /&gt;&lt;updatePolicy /&gt;&lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled /&gt;&lt;updatePolicy /&gt;&lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;id /&gt;&lt;name /&gt;&lt;url /&gt;&lt;layout /&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled /&gt;&lt;updatePolicy /&gt;&lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled /&gt;&lt;updatePolicy /&gt;&lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;id /&gt;&lt;name /&gt;&lt;url /&gt;&lt;layout /&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports /&gt; &lt;!-- 该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --&gt; &lt;reporting&gt; &lt;/reporting&gt; &lt;!-- 参见dependencyManagement元素 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 参见distributionManagement元素 --&gt; &lt;distributionManagement&gt; &lt;/distributionManagement&gt; &lt;!-- 参见properties元素 --&gt; &lt;properties /&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules /&gt; &lt;!-- 发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!-- 包含需要连接到远程仓库的信息 --&gt; &lt;repository&gt; &lt;!-- 如何处理远程仓库里发布版本的下载 --&gt; &lt;releases&gt; &lt;!-- true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled /&gt; &lt;!-- 该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt; &lt;updatePolicy /&gt; &lt;!-- 当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --&gt; &lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled /&gt;&lt;updatePolicy /&gt;&lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;!-- 远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --&gt; &lt;id&gt; banseon-repository-proxy &lt;/id&gt; &lt;!-- 远程仓库名称 --&gt; &lt;name&gt; banseon-repository-proxy &lt;/name&gt; &lt;!-- 远程仓库URL，按protocol://hostname/path形式 --&gt; &lt;url&gt; http://192.168.1.169:9999/repository/ &lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt; &lt;layout&gt; default &lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 依赖的group ID --&gt; &lt;groupId&gt; org.apache.maven &lt;/groupId&gt; &lt;!-- 依赖的artifact ID --&gt; &lt;artifactId&gt; maven-artifact &lt;/artifactId&gt; &lt;!-- 依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --&gt; &lt;version&gt; 3.8.1 &lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应，尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在plugin里定义新的类型。所以前面的类型的例子不完整。 --&gt; &lt;type&gt; jar &lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!-- 依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --&gt; &lt;scope&gt; test &lt;/scope&gt; &lt;!-- 仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。 --&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!-- 当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt; spring-core &lt;/artifactId&gt; &lt;groupId&gt; org.springframework &lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!-- 可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --&gt; &lt;optional&gt; true &lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!-- 该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --&gt; &lt;reporting&gt; &lt;!-- true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。 --&gt; &lt;excludeDefaults /&gt; &lt;!-- 所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。 --&gt; &lt;outputDirectory /&gt; &lt;!-- 使用的报表插件和他们的配置。 --&gt; &lt;plugins&gt; &lt;!-- plugin元素包含描述报表插件需要的信息 --&gt; &lt;plugin&gt; &lt;!-- 报表插件在仓库里的group ID --&gt; &lt;groupId /&gt; &lt;!-- 报表插件在仓库里的artifact ID --&gt; &lt;artifactId /&gt; &lt;!-- 被使用的报表插件的版本（或版本范围） --&gt; &lt;version /&gt; &lt;!-- 任何配置是否被传播到子项目 --&gt; &lt;inherited /&gt; &lt;!-- 报表插件的配置 --&gt; &lt;configuration /&gt; &lt;!-- 一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --&gt; &lt;reportSets&gt; &lt;!-- 表示报表的一个集合，以及产生该集合的配置 --&gt; &lt;reportSet&gt; &lt;!-- 报表集合的唯一标识符，POM继承时用到 --&gt; &lt;id /&gt; &lt;!-- 产生报表集合时，被使用的报表的配置 --&gt; &lt;configuration /&gt; &lt;!-- 配置是否被继承到子POMs --&gt; &lt;inherited /&gt; &lt;!-- 这个集合里使用到哪些报表 --&gt; &lt;reports /&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID匹配到这里的依赖，并使用这里的依赖信息。 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --&gt; &lt;distributionManagement&gt; &lt;!-- 部署项目产生的构件到远程仓库需要的信息 --&gt; &lt;repository&gt; &lt;!-- 是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --&gt; &lt;uniqueVersion /&gt; &lt;id&gt; banseon-maven2 &lt;/id&gt; &lt;name&gt; banseon maven2 &lt;/name&gt; &lt;url&gt; file://$&#123;basedir&#125;/target/deploy &lt;/url&gt; &lt;layout /&gt; &lt;/repository&gt; &lt;!-- 构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion /&gt; &lt;id&gt; banseon-maven2 &lt;/id&gt; &lt;name&gt; Banseon-maven2 Snapshot Repository &lt;/name&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/usr/local/maven-snapshot &lt;/url&gt; &lt;layout /&gt; &lt;/snapshotRepository&gt; &lt;!-- 部署项目的网站需要的信息 --&gt; &lt;site&gt; &lt;!-- 部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --&gt; &lt;id&gt; banseon-site &lt;/id&gt; &lt;!-- 部署位置的名称 --&gt; &lt;name&gt; business api website &lt;/name&gt; &lt;!-- 部署位置的URL，按protocol://hostname/path形式 --&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!-- 项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --&gt; &lt;downloadUrl /&gt; &lt;!-- 如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --&gt; &lt;relocation&gt; &lt;!-- 构件新的group ID --&gt; &lt;groupId /&gt; &lt;!-- 构件新的artifact ID --&gt; &lt;artifactId /&gt; &lt;!-- 构件新的版本号 --&gt; &lt;version /&gt; &lt;!-- 显示给用户的，关于移动的额外信息，例如原因。 --&gt; &lt;message /&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部署），verified（被核实时正确的和最终的）。 --&gt; &lt;status /&gt; &lt;/distributionManagement&gt; &lt;!-- 以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。 --&gt; &lt;properties /&gt; &lt;/project&gt;","categories":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/tags/Maven/"}],"keywords":[{"name":"Maven","slug":"Maven","permalink":"https://www.cicoding.cn/categories/Maven/"}]},{"title":"Java添加水印（图片水印，文字水印）","slug":"java-images-watermark","date":"2018-08-18T11:55:45.000Z","updated":"2022-09-17T14:13:56.167Z","comments":true,"path":"other/java-images-watermark/","link":"","permalink":"https://www.cicoding.cn/other/java-images-watermark/","excerpt":"","text":"因为项目中考虑到添加图片版权的保护，特意看了下水印的处理…以下有两种方式: 第一种是添加文字水印： import java.awt.*; import java.awt.image.*; import java.io.*; import javax.swing.*; import com.sun.image.codec.jpeg.*; public class WaterSet { /** * 给图片添加水印 * * @param filePath * 需要添加水印的图片的路径 * @param markContent * 水印的文字 * @param markContentColor * 水印文字的颜色 * @param qualNum * 图片质量 * @return */ public boolean createMark(String filePath, String markContent, Color markContentColor, float qualNum) { ImageIcon imgIcon = new ImageIcon(filePath); Image theImg = imgIcon.getImage(); int width = theImg.getWidth(null); int height = theImg.getHeight(null); BufferedImage bimage = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); Graphics2D g = bimage.createGraphics(); g.setColor(markContentColor); g.setBackground(Color.white); g.drawImage(theImg, 0, 0, null); g.drawString(markContent, width / 5, height / 5); // 添加水印的文字和设置水印文字出现的内容 g.dispose(); try { FileOutputStream out = new FileOutputStream(filePath); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); JPEGEncodeParam param = encoder.getDefaultJPEGEncodeParam(bimage); param.setQuality(qualNum, true); encoder.encode(bimage, param); out.close(); } catch (Exception e) { return false; } return true; } }第二种是添加图片水印和文字水印两种方法，水印图片可以是GIF,PNG透明的文件，我一般采用的是PNG的，因为它的质量和GIF相比要高一些： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116import java.awt.Color;import java.awt.Font;import java.awt.Graphics;import java.awt.Image;import java.awt.image.BufferedImage;import java.io.File;import java.io.FileOutputStream;import javax.imageio.ImageIO;import com.sun.image.codec.jpeg.JPEGCodec;import com.sun.image.codec.jpeg.JPEGImageEncoder;public final class ImageUtils &#123; public ImageUtils() &#123; &#125; /* * public final static String getPressImgPath() &#123; return ApplicationContext * .getRealPath(\"/template/data/util/shuiyin.gif\"); &#125; */ /** * 把图片印刷到图片上 * * @param pressImg -- * 水印文件 * @param targetImg -- * 目标文件 * @param x * --x坐标 * @param y * --y坐标 */ public final static void pressImage(String pressImg, String targetImg, int x, int y) &#123; try &#123; //目标文件 File _file = new File(targetImg); Image src = ImageIO.read(_file); int wideth = src.getWidth(null); int height = src.getHeight(null); BufferedImage image = new BufferedImage(wideth, height, BufferedImage.TYPE_INT_RGB); Graphics g = image.createGraphics(); g.drawImage(src, 0, 0, wideth, height, null); //水印文件 File _filebiao = new File(pressImg); Image src_biao = ImageIO.read(_filebiao); int wideth_biao = src_biao.getWidth(null); int height_biao = src_biao.getHeight(null); g.drawImage(src_biao, (wideth - wideth_biao) / 2, (height - height_biao) / 2, wideth_biao, height_biao, null); //水印文件结束 g.dispose(); FileOutputStream out = new FileOutputStream(targetImg); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(image); out.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 打印文字水印图片 * * @param pressText * --文字 * @param targetImg -- * 目标图片 * @param fontName -- * 字体名 * @param fontStyle -- * 字体样式 * @param color -- * 字体颜色 * @param fontSize -- * 字体大小 * @param x -- * 偏移量 * @param y */ public static void pressText(String pressText, String targetImg, String fontName, int fontStyle, int color, int fontSize, int x, int y) &#123; try &#123; File _file = new File(targetImg); Image src = ImageIO.read(_file); int wideth = src.getWidth(null); int height = src.getHeight(null); BufferedImage image = new BufferedImage(wideth, height, BufferedImage.TYPE_INT_RGB); Graphics g = image.createGraphics(); g.drawImage(src, 0, 0, wideth, height, null); // String s=\"www.qhd.com.cn\"; g.setColor(Color.RED); g.setFont(new Font(fontName, fontStyle, fontSize)); g.drawString(pressText, wideth - fontSize - x, height - fontSize / 2 - y); g.dispose(); FileOutputStream out = new FileOutputStream(targetImg); JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder(out); encoder.encode(image); out.close(); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125; public static void main(String[] args) &#123; pressImage(\"F:/logo.png\", \"F:/123.jpg\", 0, 0); &#125;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}],"tags":[{"name":"图片水印","slug":"图片水印","permalink":"https://www.cicoding.cn/tags/图片水印/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"https://www.cicoding.cn/categories/工具/"}]},{"title":"简约至上","slug":"simplicity-is-paramount","date":"2018-06-20T12:41:13.000Z","updated":"2022-09-17T14:13:56.168Z","comments":false,"path":"other/simplicity-is-paramount/","link":"","permalink":"https://www.cicoding.cn/other/simplicity-is-paramount/","excerpt":"","text":"主要适合Web应用、互联网产品、移动应用产品经理及交互式设计人员阅读，也许远远不止适合这些同学 简单 简单的产品能在专业领域内聚焦非核心玩家的核心功能，产出惊人的效果 转移复杂的简单不是简单。复杂自己，简单别人@Google 简单的目的是提高用户体验。设计产品应该从用户而非产品本身角度来考虑 简单并不需要极简主义，并不意味着最少化。简单并不意味着欠缺和低劣，也不意味着不注重装饰或完全赤裸裸。而是说装饰应该紧密贴近设计本身，任何无关的要素都应该予以剔除 貌似简单不是真的简单。证明简洁的东西能在哪些方面带来好处，这样才能说服别人接受简洁。对简洁的事项进行排序，更优方式是对排序进行分组，高 ROI 的马上做，中 ROI 的暂缓缓，低 ROI 的先抛弃 明确认识 如何建立判定简单的标准： 方法一：建立一个需要遵循的简单规则列表，当犹豫的时候，和规则列表进行比对（反向） 方法二：理解用户的体验和使用场景，尽量考虑到所有细节（正向） 了解用户使用产品的环境，特别是要知道他们在使用你的软件的时候经常会发生什么事情，发掘可能忽略的需求 不同的环境，玩家可能受到完全不一样的干扰 主流用户想要什么？ 感兴趣的是立即把工作做完 vs 喜欢设定自己的偏好 认为容易操作是最有价值的事 vs 在乎操作是否精准 得到靠谱的结果 vs 得到完美的结果 害怕弄坏什么 vs 刨根问到底 适合即可 vs 精确匹配 想要事例和故事 vs 想要原理 感情需求：找到用户感情上不愿意处理但又无法避免的需求，这些会成为用户的精神负担，从而放弃使用软件 简单就是感觉在掌控一切，设计不能和这种感觉抵触，而是要放大这种感觉。要让用户感觉到自己在掌控技术，掌控生活。对主流用户来说，掌控的含义就是掌控结果 如何正确地选择做“什么”？有了用户需求后，从用户的角度，用户的语言来描述这个需求，不要遗漏每个细节 当需要描述需求或者把问题转化成一种认知时，特别是在想要说服别人时，故事是一种很好的形式。故事可以让读者更容易明白什么重要和为什么重要 讲故事的方法。不要长篇大论。好故事应该简明、具体、可信，并且拥有相关细节 要满足简单的体验需要功能要满足极端的条件，诸如任何人都要能用，相应速度瞬间完成等。设定不可能达成的目标可以让事情保持在正确的放向上运行。妥协的目标必让产品变得越来越糟糕 尝试用简洁、清晰、完整的语言向事先不给任何提示的人描述想法 要有优秀的洞察力去观察什么因素对客户的行为影响最大 设计者可能希望马上开始设计，但要克制自己，太早设计意味着会遗漏重要的见解。任何项目的前三个方案大约都是对真正重要问题的描述，这段时间非常让人头疼，复杂性与日俱增，脑子也没有什么想法，但坚持不懈寻找问题的关键和深层次原因，是最后能拿出一个优雅和堪称完美有效方案的关键 与别人分享你的知识，即使你不在场也能保证做出正确的决定。跟参与项目的每一个人复述你的故事，不停的讲，直到自己都厌恶为止 简约四策略 以简化遥控器为例： 删除：去掉不必要的功能，直到不能再减为止 组织：按照有意义的标准将按钮划分成组 隐藏：把不重要的按钮安排在活动舱盖下，分散用户注意力 转移：只在遥控器上保留最基本的功能，将其他控制转移到屏幕的菜单里，从而将复杂性从遥控器转移到了电视 删除 Standish Group 2002的报告：64% 的软件功能“从未使用或极少使用” 要通过删除来简化设计，请准备好一张白纸，问自己：“最重要的问题是什么？”然后，逐渐添加最重要的功能和内容—— MVP（Minimum Viable Product） 简化设计最明显的方式是删除不必要的功能 增加价值始于改进核心体验。按照优先级对功能排序时，要时刻记住用户认为哪些关系到他们日常使用体验的功能最有价值 以“去掉他们是一种浪费”作为理由而抓住残缺的功能不放，可能会妨碍你成功 不要猜测用户可能会或者可能不会怎么样 如果一个改动让流程变得更复杂就应该退一步去寻找更好的解决方案 用户在意的是你的功能是否能解决他们的问题 确定删除和保留功能时候的原则： 对用户想要达到的目的排序 优先满足最高优先级用户的需求，然后再考虑其他用户 确定用户使用产品过程中的感染源并排序并找到解决方案 要能明白满足主流用户和专家级用户的方案之间的差别 提供有限选择，用户反而会更喜欢 想要设计简单的用户体验，就该牢记删除那些干扰因素，让用户注意力保持集中——如文章中的超链接(-_-) 默认值是节省用户时间和精力的有效方式，也是清除设计蓝图中“减速带”的首选方式 主流用户希望“够好就行了，快点”，专家用户则希望“尽可能地完美，等多长时间都愿意”。如果你想要设计受主流用户喜爱的简单体验，就应该放弃因为最求完美而牺牲速度和简单的方案。 简化体验的一个重要思路是看用户会犯什么错误，这些发生错误的地方既有可能是一个简化点— 减少视觉混乱 1）使用空白和轻微的背景色来划分页面，不是用线条 2）尽量少使用强调 3）不使用黑粗线 4）控制信息层次 5）减少元素大小和形状变化 删除不必要的说明文字——标题下边的“单击这里”超链接可以直接做在标题上 “删除”的核心策略是干掉哪些焚烧用户注意力的因素，聚焦于项目。聚焦于给用户提供价值的功能、聚焦于达成用户目标，删除干扰用户的、增加用户负担的“减速带”、聚焦于可以利用的资源为用户创造价值 不可避免的法律文书不能够去掉 组织 不是任何时候都需要分块，如果按照索引顺序检索则没必要分块，如字母表。 简单的组织模式具有清晰的界限，即是非分明。这样用户才能明确知道到哪里去找自己想要的东西 按资源格式分类，看起来简单但不讨好 在没有提供有效导航的情况下，用户会使用搜索。在需要从大量类似项中挑选一个已知项（比如 iTunes 找歌），用户也会倾向使用搜索。 利用不可见的网格来对其节目元素是一种吸引用户注意力的有效方式。用户虽然看不见网格，但视觉上的想象会告诉他们“接着看这里”。网格越简单，效果越明显 网格布局会让人感觉局促和受压制，可以通过设计不对称的布局来解决。如包含奇数列或者让少量元素跨在两列和三列上。 如果一个元素的重要性为 1/2，那就把它的大小做成 1/4 感知分层技术：人们在无意的状态下，只会感知到自己关心的东西，而忽略其他东西。 在确保人们会花很长时间学习，而且他们会重复使用你的设计时，色标系统非常合适 隐藏 隐藏部分功能是一种低成本的方案，但不要尝试先隐藏再删除，欲删从速 不常用但不能少的功能很适合隐藏 自动定制不会让界面变得简单 1）很难保证默认菜单的准确性 2）用户需要把每个功能看两遍才能确定 3）用户不知道去哪里找自己想要的命令，因为位置会变 “核心功能加扩展功能”的渐进展示模式不仅能够简化设计，更是一种强大的交互手段 阶段展示，比如向导，在符合用户心理预期的情况下，阶段展示的效果最好。 把标签放在那里比把标签做多大更重要，必须要标签放在用户关注点之内 保证用户在前进的过程中能够遇到提示，但不要挡住他们的去路 隐藏策略需要做到： 1）隐藏一次性设计和选项 2）隐藏精确控制选项，但专家用户能够让用户这些选项保持可见 3）不要强迫或寄希望与主流用户使用自定义功能，但专家用户可以有 4）巧妙因此，首先要彻底影藏，其次是适时出现 转移 人和电脑分别擅长不同的东西，电脑擅长计算，人喜欢控制结果。可以把一些规则很复杂的工作（如制定目标和组织游记）留给用户，人处理有些信息更方便 让某个功能具有多功能也是一种简化方式——汽车后挡风玻璃的加热丝也是收音机天线 简单界面的最高境界是专家和主流用户都觉得他非常好用 输入结构化数据（填表）非常让人讨厌，解决办法是让用户按照自己想要的格式输入，结构化的过程由计算机完成 转移之后，需要在用户面前建立设备和应用间能正常工作的信任，唯一方式是让用户参与测试原型和实物模型 小结 简化就像打地鼠，一个地方下去了，另一个地方又冒出来了 简单的秘诀就是把复杂性转移到正确的地方 简单不能忽视细节，只说坐1号线，但是没说方向，一样导致困惑 简单的体验应该为用户留出足够的空间，让他们能够想象到当前正在做的事情同样也是自己生活的一部分","categories":[{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/categories/其他/"}],"tags":[{"name":"Web应用","slug":"Web应用","permalink":"https://www.cicoding.cn/tags/Web应用/"},{"name":"互联网产品","slug":"互联网产品","permalink":"https://www.cicoding.cn/tags/互联网产品/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/categories/其他/"}]},{"title":"主题配置","slug":"theme-config","date":"2018-06-19T09:43:44.000Z","updated":"2022-09-19T12:33:11.829Z","comments":true,"path":"other/theme-config/","link":"","permalink":"https://www.cicoding.cn/other/theme-config/","excerpt":"","text":"主题配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217## menu -- 导航菜单显示&#123;[@page:名字,@url:地址,@icon:图标]&#125;menu: - page: home url: / icon: fa-home## favicon -- 网站图标位置&#123;@favicon&#125;favicon: /favicon.ico## rss --rss文件位置&#123;@rss&#125;rss: /atom.xml# 各个小工具的设置## widgets -- 6个左边小工具&#123;@widgets:[notification,category,archive,tagcloud,friends]&#125;widgets: - search - notification - social - category - archive - tagcloud - friends# 各个小工具的设置## 搜索jsonContent: searchLocal: true // 是否启用本地搜索 searchGoogle: true //是否启用谷歌搜索 posts: title: true text: true content: true categories: false tags: false## notification config --网站公告设置,支持 html 和 纯文本notification: |- &lt;p&gt;主题已经上线！欢迎下载或更新~ &lt;br/&gt; 主题下载：&lt;a href=&quot;https://github.com/shenliyang/hexo-theme-snippet&quot; title=&quot;fork me&quot; target=&quot;_blank&quot;&gt;Snippet主题&lt;/a&gt; &lt;br/&gt; &lt;hr/&gt;接受贡献，包括不限于提交问题与需求，修复代码。欢迎Pull Request&lt;br/&gt;支持主题：&lt;a href=&quot;https://github.com/shenliyang/hexo-theme-snippet/stargazers&quot;&gt;Star一下&lt;/a&gt;&lt;/p&gt;## 社交设置&#123;@name:社交工具名字，@icon:社交工具图标，@href:设置工具链接&#125; [参考图标](http://fontawesome.io/icons/)social: - name: Github icon: git href: //github.com/shenliyang## 文章分类设置&#123;@cate_config:&#123;@show_count:是否显示数字，@show_current: 是否高亮当前category&#125;&#125;cate_config: show_count: true show_current: true## 文章归档设置&#123;@arch_config:/*参数参考：https://hexo.io/zh-cn/docs/helpers.html#list-archives*/&#125;## 推荐组合方式：[&#123;type: &apos;monthly&apos;,format: &apos;YYYY年MM月&apos;&#125;,&#123;type: &apos;yearly&apos;,format: &apos;YYYY年&apos;&#125;]arch_config: type: &apos;monthly&apos; format: &apos;YYYY年MM月&apos; show_count: true order: -1## 标签云设置&#123;/*参数参考：http://www.goat1000.com/tagcanvas-options.php */&#125;tagcloud: tag3d: false // 是否启用3D标签云 textColour: &apos;#444&apos; // 字体颜色 outlineMethod: &apos;block&apos; // 选中模式(outline|classic|block|colour|size|none) outlineColour: &apos;#FFDAB9&apos; // 选中模式的颜色 interval: 30 // 动画帧之间的时间间隔，值越大，转动幅度越大 freezeActive: true // 选中的标签是否继续滚动 frontSelect: true // 不选标签云后部的标签 reverse: true // 是否反向触发 wheelZoom: false // 是否启用鼠标滚轮## 友链设置&#123;@链接名称：链接地址&#123;@links:[,,,]&#125;&#125;links: - Hexo官网: https://hexo.io/zh-cn/# 主题自定义个性化配置## 网站宣传语&#123;@branding：网站宣传语(不设置显示本地图片)&#125;branding: 从未如此简单有趣## 设置banner背景图片&#123;@img:自定义图片地址(支持绝对和相对路径),主题默认&#123;&quot;静态背景&quot;:&quot;banner.jpg&quot;&#125;,&#123;&quot;动态背景&quot;:&quot;banner2.jpg&quot;&#125;,&#123;&quot;动态星空背景&quot;:&quot;banner3.jpg&quot;&#125;&#125;## 例如：http://snippet.shenliyang.com/img/banner|2|3.jpg, 或者 &apos;./img/banner-img.jpg&apos;(相对本地资源地址)banner: img: http://snippet.shenliyang.com/img/banner.jpg## 设置carousel&#123;@img:图片地址,@url:点击跳转链接(默认值:&quot;javascript:&quot;)&#125;carousel: img: &apos;img/head-img.jpg&apos; url: &apos;javascript:&apos;## 首页列表底部面板&#123;@homePanel: 是否开启&#125;homePanel: true## 首页文章列表缩略图### 加载规则: 自定义文章缩略图(在Front-matter中添加的&apos;img&apos;字段) &gt; 文章内的图片 &gt; defaultImgs(随机获取) &gt; 无图模式列表## 自定义随机图片defaultImgs: - http://www.example.jpg //远程图片链接示例 - /img/default-1.jpg //本地图片链接示例### 文章摘要&#123;@摘要显示优先级：自定义摘要 &gt; 自动截取摘要 &#125;### 自定义摘要范围&#123;@&lt;!--more--&gt;:截取more之前的内容为摘要&#125;### 自动截取摘要&#123;@excerptLength:自动截取文章前多少个字为摘要，不配置默认：120字&#125;excerptLength: 120## 是否开启文章目录toc: true## 代码高亮配置&#123;@highlightTheme: 主题名称,(配置暂时不可用，后续开发中…)&#125;highlightTheme: default //TODO## 文章过期提醒功能 &#123;@warning:&#123;days:临界天数(默认300天,设置0关闭功能),text:提醒文字/*%d为过期总天数占位符*/&#125;&#125;warning: days: 300 text: &apos;本文于%d天之前发表，文中内容可能已经过时。&apos;## 文章内声明&#123;@declaration: &#123;enable:是否开启,title:声明标题,tip:提示内容&#125;&#125;declaration: enable: true title: &apos;转载声明&apos; tip: |- 商业转载请联系作者获得授权,非商业转载请注明出处 © &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;Snippet&lt;/a&gt;## 文章打赏&#123;@reward: &#123;alipay:支付宝打赏,wepay:微信打赏,tip:打赏提示语; 链接都为空,关闭打赏功能&#125;&#125;reward: alipay: &apos;&apos; wepay: &apos;../img/reward-wepay.jpg&apos; tip: 赞赏是不耍流氓的鼓励## 主题评论### gitmentgitment: enable: false owner: repo: client_id: client_secret: labels: perPage: maxCommentHeight:### 来必力(默认选项)livere: enable: true livere_uid:### 友言评论(服务不稳定，经常无法加载)uyan: enable: false uyan_id:### Disqus评论(需要翻墙，或者搭建代理)disqus: enable: false shortname: snippet count: false### 畅言评论(需要ICP备案)changyan: enable: false appid: conf:### Valine评论 参考网站: [valine评论](https://valine.js.org/)valine: enable: true appId: appKey: placeholder: 说点什么吧 notify: false // 邮件通知 verify: false // 验证码 avatar: mm // avatar头像 meta: nick,mail // 输入框内容，可选值nick,mail,link pageSize: 10## 网站访客统计 [不蒜子统计](http://busuanzi.ibruce.info/)visit_counter: site: true // 总访问量和访问人数统计 page: true // 文章阅读量统计## 网站访问统计### 网盟CNZZ统计 参考网站: [网盟CNZZ](http://www.umeng.com/)cnzz_anaylytics:### 百度统计 参考网站: [百度统计](https://tongji.baidu.com/)baidu_anaylytics:### 谷歌统计 参考网站：[谷歌统计](https://www.google-analytics.com/)google_anaylytics:### 腾讯分析 参考网站：[腾讯分析](http://ta.qq.com/)tencent_analytics:### 百度站点认证baidu-site-verification:### 百度自动推送(@baidu_push: 是否启用百度自动推送) 参考网站: [百度站长资源](https://ziyuan.baidu.com/college/courseinfo?id=267&amp;page=2#h2_article_title18)baidu_push:## ICON配置 (不配则启用本地Font Icon)fontAwesome: //cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css## 网站主题配置since: 2017 //建站时间robot: &apos;all&apos; //控制搜索引擎的抓取和索引编制行为，默认为allversion: 1.2.1 //当前主题版本号 1234567891011//编译生成静态页面hexo g //generetor的缩写//启动本地服务hexo s //server的缩写//开始部署hexo d //清除缓存文件 hexo clean 更多参考：https://hexo.io/zh-cn/docs/commands.html","categories":[{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/categories/其他/"}],"tags":[{"name":"theme","slug":"theme","permalink":"https://www.cicoding.cn/tags/theme/"},{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/tags/其他/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://www.cicoding.cn/categories/其他/"}]}]}